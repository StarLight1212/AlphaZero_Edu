2025-04-15 21:30:46,497 [INFO] 设置多进程启动方法为: spawn
2025-04-15 21:30:46,554 [INFO] CUDA可用，使用GPU
2025-04-15 21:30:46,554 [INFO] 配置参数:
2025-04-15 21:30:46,554 [INFO] 训练参数:
2025-04-15 21:30:46,554 [INFO]   训练轮数: 15
2025-04-15 21:30:46,554 [INFO]   批量大小: 4096
2025-04-15 21:30:46,554 [INFO]   迭代次数: 200
2025-04-15 21:30:46,555 [INFO]   每次迭代的自我对弈次数: 100
2025-04-15 21:30:46,555 [INFO]   训练样本队列最大长度: 200000
2025-04-15 21:30:46,555 [INFO]   保留的历史迭代数: 20
2025-04-15 21:30:46,555 [INFO]   新模型胜率阈值: 0.55
2025-04-15 21:30:46,555 [INFO]   竞技场比赛次数: 40
2025-04-15 21:30:46,555 [INFO]   温度阈值: 5
2025-04-15 21:30:46,555 [INFO] 神经网络参数:
2025-04-15 21:30:46,555 [INFO]   通道数: 512
2025-04-15 21:30:46,555 [INFO]   Dropout率: 0.3
2025-04-15 21:30:46,555 [INFO]   学习率范围: 5e-05 - 0.01
2025-04-15 21:30:46,555 [INFO]   梯度裁剪: 1.0
2025-04-15 21:30:46,555 [INFO]   优化器: adam
2025-04-15 21:30:46,555 [INFO] MCTS参数:
2025-04-15 21:30:46,555 [INFO]   模拟次数: 800
2025-04-15 21:30:46,555 [INFO]   PUCT常数: 4.0
2025-04-15 21:30:46,555 [INFO]   Dirichlet噪声参数: 0.3
2025-04-15 21:30:46,555 [INFO]   Dirichlet噪声权重: 0.25
2025-04-15 21:30:46,555 [INFO] 游戏参数:
2025-04-15 21:30:46,555 [INFO]   棋盘大小: 15
2025-04-15 21:30:46,555 [INFO]   获胜所需的连续棋子数: 5
2025-04-15 21:30:46,555 [INFO] 系统参数:
2025-04-15 21:30:46,555 [INFO]   使用CUDA: True
2025-04-15 21:30:46,555 [INFO]   检查点目录: ./models
2025-04-15 21:30:46,555 [INFO]   数据目录: ./data
2025-04-15 21:30:46,555 [INFO]   加载模型: False
2025-04-15 21:30:46,556 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-15 21:30:46,556 [INFO]   工作线程数: 4
2025-04-15 21:30:46,556 [INFO]   使用Weights & Biases: False
2025-04-15 21:30:46,556 [INFO] GUI参数:
2025-04-15 21:30:46,556 [INFO]   窗口宽度: 800
2025-04-15 21:30:46,556 [INFO]   窗口高度: 850
2025-04-15 21:30:46,556 [INFO]   格子大小: 40
2025-04-15 21:30:46,556 [INFO]   边距: 40
2025-04-15 21:30:46,556 [INFO]   底部边距: 80
2025-04-15 21:30:46,556 [INFO]   帧率: 30
2025-04-15 21:30:46,760 [INFO] Using device: cuda
2025-04-15 21:30:48,166 [INFO] Using device: cuda
2025-04-15 21:30:48,188 [INFO] 设置并行进程数为: 8
2025-04-15 21:30:48,188 [INFO] 开始训练
2025-04-15 21:30:48,188 [INFO] 开始迭代 1/200
2025-04-15 21:30:48,188 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-16 01:39:19,201 [INFO] 保存训练样本
2025-04-16 01:39:20,425 [INFO] 使用 35328 个样本训练神经网络
2025-04-16 01:39:20,425 [INFO] Training with 35328 examples
2025-04-16 01:39:27,173 [INFO] Epoch 1/15 - Policy Loss: 5.4383, Value Loss: 1.0190, Total Loss: 6.4573, LR: 0.001211
2025-04-16 01:39:33,373 [INFO] Epoch 2/15 - Policy Loss: 5.4209, Value Loss: 1.0415, Total Loss: 6.4624, LR: 0.002538
2025-04-16 01:39:39,628 [INFO] Epoch 3/15 - Policy Loss: 5.4147, Value Loss: 1.0175, Total Loss: 6.4323, LR: 0.003864
2025-04-16 01:39:45,947 [INFO] Epoch 4/15 - Policy Loss: 5.4075, Value Loss: 0.9523, Total Loss: 6.3599, LR: 0.005191
2025-04-16 01:39:52,237 [INFO] Epoch 5/15 - Policy Loss: 5.3999, Value Loss: 0.8814, Total Loss: 6.2813, LR: 0.006517
2025-04-16 01:39:58,551 [INFO] Epoch 6/15 - Policy Loss: 5.3921, Value Loss: 0.8172, Total Loss: 6.2093, LR: 0.007844
2025-04-16 01:40:04,793 [INFO] Epoch 7/15 - Policy Loss: 5.3886, Value Loss: 0.7510, Total Loss: 6.1396, LR: 0.009171
2025-04-16 01:40:11,058 [INFO] Epoch 8/15 - Policy Loss: 5.3859, Value Loss: 0.6912, Total Loss: 6.0771, LR: 0.009503
2025-04-16 01:40:17,360 [INFO] Epoch 9/15 - Policy Loss: 5.3805, Value Loss: 0.6324, Total Loss: 6.0129, LR: 0.008176
2025-04-16 01:40:23,648 [INFO] Epoch 10/15 - Policy Loss: 5.3749, Value Loss: 0.5789, Total Loss: 5.9538, LR: 0.006849
2025-04-16 01:40:29,890 [INFO] Epoch 11/15 - Policy Loss: 5.3687, Value Loss: 0.5331, Total Loss: 5.9018, LR: 0.005522
2025-04-16 01:40:36,169 [INFO] Epoch 12/15 - Policy Loss: 5.3629, Value Loss: 0.4937, Total Loss: 5.8566, LR: 0.004196
2025-04-16 01:40:42,430 [INFO] Epoch 13/15 - Policy Loss: 5.3577, Value Loss: 0.4599, Total Loss: 5.8176, LR: 0.002869
2025-04-16 01:40:48,733 [INFO] Epoch 14/15 - Policy Loss: 5.3525, Value Loss: 0.4308, Total Loss: 5.7834, LR: 0.001543
2025-04-16 01:40:55,027 [INFO] Epoch 15/15 - Policy Loss: 5.3478, Value Loss: 0.4053, Total Loss: 5.7531, LR: 0.000216
2025-04-16 01:40:55,035 [INFO] 训练完成，总损失: 5.7531
2025-04-16 01:40:55,035 [INFO] 与最佳模型对比
2025-04-16 01:40:55,035 [INFO] 使用 8 个进程进行并行竞技场评估
2025-04-16 01:45:35,514 [INFO] 评估结果 - 最佳模型胜: 40, 新模型胜: 0, 平局: 0
2025-04-16 01:45:35,515 [INFO] 新模型的胜率: 0.0000
2025-04-16 01:45:35,515 [INFO] 新模型没有显著改进，保持最佳模型不变
2025-04-16 01:45:35,519 [INFO] 开始迭代 2/200
2025-04-16 01:45:35,519 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-16 05:53:57,111 [INFO] 保存训练样本
2025-04-16 05:53:59,583 [INFO] 使用 71136 个样本训练神经网络
2025-04-16 05:53:59,583 [INFO] Training with 71136 examples
2025-04-16 05:54:12,811 [INFO] Epoch 1/15 - Policy Loss: 6.7272, Value Loss: 1.9716, Total Loss: 8.6988, LR: 0.009295
2025-04-16 05:54:25,699 [INFO] Epoch 2/15 - Policy Loss: 6.0705, Value Loss: 1.9899, Total Loss: 8.0604, LR: 0.007963
2025-04-16 05:54:38,586 [INFO] Epoch 3/15 - Policy Loss: 5.8509, Value Loss: 2.0062, Total Loss: 7.8571, LR: 0.006631
2025-04-16 05:54:51,488 [INFO] Epoch 4/15 - Policy Loss: 5.7411, Value Loss: 2.0095, Total Loss: 7.7506, LR: 0.005299
2025-04-16 05:55:04,388 [INFO] Epoch 5/15 - Policy Loss: 5.6752, Value Loss: 2.0118, Total Loss: 7.6869, LR: 0.003967
2025-04-16 05:55:17,265 [INFO] Epoch 6/15 - Policy Loss: 5.6312, Value Loss: 2.0141, Total Loss: 7.6454, LR: 0.002635
2025-04-16 05:55:30,164 [INFO] Epoch 7/15 - Policy Loss: 5.5998, Value Loss: 2.0127, Total Loss: 7.6126, LR: 0.001304
2025-04-16 05:55:43,287 [INFO] Epoch 8/15 - Policy Loss: 5.5763, Value Loss: 2.0135, Total Loss: 7.5898, LR: 0.000050
2025-04-16 05:55:56,069 [INFO] Epoch 9/15 - Policy Loss: 5.5580, Value Loss: 2.0153, Total Loss: 7.5733, LR: 0.000050
2025-04-16 05:56:08,807 [INFO] Epoch 10/15 - Policy Loss: 5.5434, Value Loss: 2.0158, Total Loss: 7.5591, LR: 0.000050
2025-04-16 05:56:21,487 [INFO] Epoch 11/15 - Policy Loss: 5.5314, Value Loss: 2.0168, Total Loss: 7.5482, LR: 0.000050
2025-04-16 05:56:34,215 [INFO] Epoch 12/15 - Policy Loss: 5.5214, Value Loss: 2.0167, Total Loss: 7.5381, LR: 0.000050
2025-04-16 05:56:47,013 [INFO] Epoch 13/15 - Policy Loss: 5.5129, Value Loss: 2.0172, Total Loss: 7.5302, LR: 0.000050
2025-04-16 05:57:00,069 [INFO] Epoch 14/15 - Policy Loss: 5.5057, Value Loss: 2.0181, Total Loss: 7.5238, LR: 0.000050
2025-04-16 05:57:12,870 [INFO] Epoch 15/15 - Policy Loss: 5.4994, Value Loss: 2.0176, Total Loss: 7.5170, LR: 0.000050
2025-04-16 05:57:12,882 [INFO] 训练完成，总损失: 7.5170
2025-04-16 05:57:12,882 [INFO] 与最佳模型对比
2025-04-16 05:57:12,882 [INFO] 使用 8 个进程进行并行竞技场评估
2025-04-16 06:01:50,227 [INFO] 评估结果 - 最佳模型胜: 40, 新模型胜: 0, 平局: 0
2025-04-16 06:01:50,229 [INFO] 新模型的胜率: 0.0000
2025-04-16 06:01:50,229 [INFO] 新模型没有显著改进，保持最佳模型不变
2025-04-16 06:01:50,232 [INFO] 开始迭代 3/200
2025-04-16 06:01:50,232 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-16 10:08:18,890 [INFO] 保存训练样本
2025-04-16 10:08:22,977 [INFO] 使用 106840 个样本训练神经网络
2025-04-16 10:08:22,977 [INFO] Training with 106840 examples
2025-04-16 10:08:43,549 [INFO] Epoch 1/15 - Policy Loss: 5.4260, Value Loss: 1.0626, Total Loss: 6.4886, LR: 0.000050
2025-04-16 10:09:04,054 [INFO] Epoch 2/15 - Policy Loss: 5.4047, Value Loss: 1.0310, Total Loss: 6.4357, LR: 0.000050
2025-04-16 10:09:24,556 [INFO] Epoch 3/15 - Policy Loss: 5.3957, Value Loss: 1.0200, Total Loss: 6.4157, LR: 0.000050
2025-04-16 10:09:45,080 [INFO] Epoch 4/15 - Policy Loss: 5.3903, Value Loss: 1.0141, Total Loss: 6.4045, LR: 0.000050
2025-04-16 10:10:05,526 [INFO] Epoch 5/15 - Policy Loss: 5.3865, Value Loss: 1.0103, Total Loss: 6.3968, LR: 0.000050
2025-04-16 10:10:25,815 [INFO] Epoch 6/15 - Policy Loss: 5.3834, Value Loss: 1.0072, Total Loss: 6.3906, LR: 0.000050
2025-04-16 10:10:46,513 [INFO] Epoch 7/15 - Policy Loss: 5.3807, Value Loss: 1.0035, Total Loss: 6.3842, LR: 0.000050
2025-04-16 10:11:06,918 [INFO] Epoch 8/15 - Policy Loss: 5.3781, Value Loss: 0.9976, Total Loss: 6.3756, LR: 0.000050
2025-04-16 10:11:27,234 [INFO] Epoch 9/15 - Policy Loss: 5.3754, Value Loss: 0.9887, Total Loss: 6.3641, LR: 0.000050
2025-04-16 10:11:47,581 [INFO] Epoch 10/15 - Policy Loss: 5.3728, Value Loss: 0.9769, Total Loss: 6.3497, LR: 0.000050
2025-04-16 10:12:08,109 [INFO] Epoch 11/15 - Policy Loss: 5.3702, Value Loss: 0.9628, Total Loss: 6.3330, LR: 0.000050
2025-04-16 10:12:28,521 [INFO] Epoch 12/15 - Policy Loss: 5.3676, Value Loss: 0.9466, Total Loss: 6.3142, LR: 0.000050
2025-04-16 10:12:48,970 [INFO] Epoch 13/15 - Policy Loss: 5.3651, Value Loss: 0.9294, Total Loss: 6.2945, LR: 0.000050
2025-04-16 10:13:09,415 [INFO] Epoch 14/15 - Policy Loss: 5.3627, Value Loss: 0.9108, Total Loss: 6.2735, LR: 0.000050
2025-04-16 10:13:30,096 [INFO] Epoch 15/15 - Policy Loss: 5.3604, Value Loss: 0.8909, Total Loss: 6.2513, LR: 0.000050
2025-04-16 10:13:30,115 [INFO] 训练完成，总损失: 6.2513
2025-04-16 10:13:30,115 [INFO] 与最佳模型对比
2025-04-16 10:13:30,115 [INFO] 使用 8 个进程进行并行竞技场评估
2025-04-16 10:18:12,758 [INFO] 评估结果 - 最佳模型胜: 40, 新模型胜: 0, 平局: 0
2025-04-16 10:18:12,759 [INFO] 新模型的胜率: 0.0000
2025-04-16 10:18:12,759 [INFO] 新模型没有显著改进，保持最佳模型不变
2025-04-16 10:18:12,763 [INFO] 开始迭代 4/200
2025-04-16 10:18:12,763 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-16 14:30:29,817 [INFO] 保存训练样本
2025-04-16 14:30:34,992 [INFO] 使用 142624 个样本训练神经网络
2025-04-16 14:30:34,993 [INFO] Training with 142624 examples
2025-04-16 14:31:01,703 [INFO] Epoch 1/15 - Policy Loss: 5.4088, Value Loss: 0.9264, Total Loss: 6.3352, LR: 0.000050
2025-04-16 14:31:28,610 [INFO] Epoch 2/15 - Policy Loss: 5.3975, Value Loss: 0.8258, Total Loss: 6.2233, LR: 0.000050
2025-04-16 14:31:55,759 [INFO] Epoch 3/15 - Policy Loss: 5.3921, Value Loss: 0.7327, Total Loss: 6.1249, LR: 0.000050
2025-04-16 14:32:22,586 [INFO] Epoch 4/15 - Policy Loss: 5.3889, Value Loss: 0.6512, Total Loss: 6.0401, LR: 0.000050
2025-04-16 14:32:49,409 [INFO] Epoch 5/15 - Policy Loss: 5.3864, Value Loss: 0.5826, Total Loss: 5.9690, LR: 0.000050
2025-04-16 14:33:16,205 [INFO] Epoch 6/15 - Policy Loss: 5.3841, Value Loss: 0.5254, Total Loss: 5.9095, LR: 0.000050
2025-04-16 14:33:42,930 [INFO] Epoch 7/15 - Policy Loss: 5.3819, Value Loss: 0.4781, Total Loss: 5.8600, LR: 0.000050
2025-04-16 14:34:09,612 [INFO] Epoch 8/15 - Policy Loss: 5.3797, Value Loss: 0.4390, Total Loss: 5.8188, LR: 0.000050
2025-04-16 14:34:36,325 [INFO] Epoch 9/15 - Policy Loss: 5.3775, Value Loss: 0.4067, Total Loss: 5.7842, LR: 0.000050
2025-04-16 14:35:03,153 [INFO] Epoch 10/15 - Policy Loss: 5.3752, Value Loss: 0.3794, Total Loss: 5.7546, LR: 0.000050
2025-04-16 14:35:29,893 [INFO] Epoch 11/15 - Policy Loss: 5.3729, Value Loss: 0.3560, Total Loss: 5.7289, LR: 0.000050
2025-04-16 14:35:56,623 [INFO] Epoch 12/15 - Policy Loss: 5.3703, Value Loss: 0.3360, Total Loss: 5.7063, LR: 0.000050
2025-04-16 14:36:23,475 [INFO] Epoch 13/15 - Policy Loss: 5.3675, Value Loss: 0.3184, Total Loss: 5.6860, LR: 0.000050
2025-04-16 14:36:50,248 [INFO] Epoch 14/15 - Policy Loss: 5.3647, Value Loss: 0.3031, Total Loss: 5.6678, LR: 0.000050
2025-04-16 14:37:16,944 [INFO] Epoch 15/15 - Policy Loss: 5.3618, Value Loss: 0.2895, Total Loss: 5.6513, LR: 0.000050
2025-04-16 14:37:16,969 [INFO] 训练完成，总损失: 5.6513
2025-04-16 14:37:16,969 [INFO] 与最佳模型对比
2025-04-16 14:37:16,969 [INFO] 使用 8 个进程进行并行竞技场评估
2025-04-16 14:41:55,200 [INFO] 评估结果 - 最佳模型胜: 40, 新模型胜: 0, 平局: 0
2025-04-16 14:41:55,201 [INFO] 新模型的胜率: 0.0000
2025-04-16 14:41:55,201 [INFO] 新模型没有显著改进，保持最佳模型不变
2025-04-16 14:41:55,204 [INFO] 开始迭代 5/200
2025-04-16 14:41:55,204 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-16 18:46:51,291 [INFO] 保存训练样本
2025-04-16 18:46:57,903 [INFO] 使用 177904 个样本训练神经网络
2025-04-16 18:46:57,904 [INFO] Training with 177904 examples
2025-04-16 18:47:32,573 [INFO] Epoch 1/15 - Policy Loss: 5.4102, Value Loss: 0.9376, Total Loss: 6.3477, LR: 0.000050
2025-04-16 18:48:07,566 [INFO] Epoch 2/15 - Policy Loss: 5.3990, Value Loss: 0.8584, Total Loss: 6.2574, LR: 0.000050
2025-04-16 18:48:42,611 [INFO] Epoch 3/15 - Policy Loss: 5.3941, Value Loss: 0.7872, Total Loss: 6.1812, LR: 0.000050
2025-04-16 18:49:17,410 [INFO] Epoch 4/15 - Policy Loss: 5.3911, Value Loss: 0.7204, Total Loss: 6.1115, LR: 0.000050
2025-04-16 18:49:52,268 [INFO] Epoch 5/15 - Policy Loss: 5.3889, Value Loss: 0.6594, Total Loss: 6.0483, LR: 0.000050
2025-04-16 18:50:27,236 [INFO] Epoch 6/15 - Policy Loss: 5.3872, Value Loss: 0.6072, Total Loss: 5.9944, LR: 0.000050
2025-04-16 18:51:01,778 [INFO] Epoch 7/15 - Policy Loss: 5.3857, Value Loss: 0.5623, Total Loss: 5.9480, LR: 0.000050
2025-04-16 18:51:36,429 [INFO] Epoch 8/15 - Policy Loss: 5.3843, Value Loss: 0.5229, Total Loss: 5.9072, LR: 0.000050
2025-04-16 18:52:11,272 [INFO] Epoch 9/15 - Policy Loss: 5.3829, Value Loss: 0.4888, Total Loss: 5.8717, LR: 0.000050
2025-04-16 18:52:45,845 [INFO] Epoch 10/15 - Policy Loss: 5.3814, Value Loss: 0.4590, Total Loss: 5.8404, LR: 0.000050
2025-04-16 18:53:20,504 [INFO] Epoch 11/15 - Policy Loss: 5.3799, Value Loss: 0.4327, Total Loss: 5.8126, LR: 0.000050
2025-04-16 18:53:55,231 [INFO] Epoch 12/15 - Policy Loss: 5.3782, Value Loss: 0.4096, Total Loss: 5.7879, LR: 0.000050
2025-04-16 18:54:30,049 [INFO] Epoch 13/15 - Policy Loss: 5.3765, Value Loss: 0.3891, Total Loss: 5.7656, LR: 0.000050
2025-04-16 18:55:04,671 [INFO] Epoch 14/15 - Policy Loss: 5.3746, Value Loss: 0.3709, Total Loss: 5.7455, LR: 0.000050
2025-04-16 18:55:39,473 [INFO] Epoch 15/15 - Policy Loss: 5.3725, Value Loss: 0.3544, Total Loss: 5.7270, LR: 0.000050
2025-04-16 18:55:39,504 [INFO] 训练完成，总损失: 5.7270
2025-04-16 18:55:39,504 [INFO] 与最佳模型对比
2025-04-16 18:55:39,504 [INFO] 使用 8 个进程进行并行竞技场评估
2025-04-16 19:00:34,965 [INFO] 评估结果 - 最佳模型胜: 40, 新模型胜: 0, 平局: 0
2025-04-16 19:00:34,966 [INFO] 新模型的胜率: 0.0000
2025-04-16 19:00:34,967 [INFO] 新模型没有显著改进，保持最佳模型不变
2025-04-16 19:00:34,970 [INFO] 开始迭代 6/200
2025-04-16 19:00:34,970 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-16 23:13:33,860 [INFO] 保存训练样本
2025-04-16 23:13:40,430 [INFO] 截断训练样本，保持长度为 200000
2025-04-16 23:13:41,300 [INFO] 使用 200000 个样本训练神经网络
2025-04-16 23:13:41,300 [INFO] Training with 200000 examples
2025-04-16 23:14:19,337 [INFO] Epoch 1/15 - Policy Loss: 5.4090, Value Loss: 0.9511, Total Loss: 6.3601, LR: 0.000050
2025-04-16 23:14:57,417 [INFO] Epoch 2/15 - Policy Loss: 5.3977, Value Loss: 0.8895, Total Loss: 6.2872, LR: 0.000050
2025-04-16 23:15:35,291 [INFO] Epoch 3/15 - Policy Loss: 5.3926, Value Loss: 0.8305, Total Loss: 6.2231, LR: 0.000050
2025-04-16 23:16:13,362 [INFO] Epoch 4/15 - Policy Loss: 5.3895, Value Loss: 0.7742, Total Loss: 6.1637, LR: 0.000050
2025-04-16 23:16:51,957 [INFO] Epoch 5/15 - Policy Loss: 5.3874, Value Loss: 0.7216, Total Loss: 6.1090, LR: 0.000050
2025-04-16 23:17:30,277 [INFO] Epoch 6/15 - Policy Loss: 5.3856, Value Loss: 0.6736, Total Loss: 6.0593, LR: 0.000050
2025-04-16 23:18:08,217 [INFO] Epoch 7/15 - Policy Loss: 5.3842, Value Loss: 0.6300, Total Loss: 6.0141, LR: 0.000050
2025-04-16 23:18:46,038 [INFO] Epoch 8/15 - Policy Loss: 5.3828, Value Loss: 0.5908, Total Loss: 5.9736, LR: 0.000050
2025-04-16 23:19:24,259 [INFO] Epoch 9/15 - Policy Loss: 5.3814, Value Loss: 0.5553, Total Loss: 5.9366, LR: 0.000050
2025-04-16 23:20:01,837 [INFO] Epoch 10/15 - Policy Loss: 5.3799, Value Loss: 0.5234, Total Loss: 5.9033, LR: 0.000050
2025-04-16 23:20:39,592 [INFO] Epoch 11/15 - Policy Loss: 5.3785, Value Loss: 0.4952, Total Loss: 5.8737, LR: 0.000050
2025-04-16 23:21:17,599 [INFO] Epoch 12/15 - Policy Loss: 5.3768, Value Loss: 0.4699, Total Loss: 5.8466, LR: 0.000050
2025-04-16 23:21:55,644 [INFO] Epoch 13/15 - Policy Loss: 5.3750, Value Loss: 0.4474, Total Loss: 5.8223, LR: 0.000050
2025-04-16 23:22:33,575 [INFO] Epoch 14/15 - Policy Loss: 5.3730, Value Loss: 0.4271, Total Loss: 5.8001, LR: 0.000050
2025-04-16 23:23:11,891 [INFO] Epoch 15/15 - Policy Loss: 5.3708, Value Loss: 0.4087, Total Loss: 5.7795, LR: 0.000050
2025-04-16 23:23:11,931 [INFO] 训练完成，总损失: 5.7795
2025-04-16 23:23:11,931 [INFO] 与最佳模型对比
2025-04-16 23:23:11,931 [INFO] 使用 8 个进程进行并行竞技场评估
2025-04-16 23:27:55,026 [INFO] 评估结果 - 最佳模型胜: 40, 新模型胜: 0, 平局: 0
2025-04-16 23:27:55,027 [INFO] 新模型的胜率: 0.0000
2025-04-16 23:27:55,027 [INFO] 新模型没有显著改进，保持最佳模型不变
2025-04-16 23:27:55,030 [INFO] 开始迭代 7/200
2025-04-16 23:27:55,031 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-17 03:26:44,716 [INFO] 保存训练样本
2025-04-17 03:26:53,106 [INFO] 截断训练样本，保持长度为 200000
2025-04-17 03:26:53,301 [INFO] 使用 200000 个样本训练神经网络
2025-04-17 03:26:53,301 [INFO] Training with 200000 examples
2025-04-17 03:27:31,823 [INFO] Epoch 1/15 - Policy Loss: 5.4079, Value Loss: 0.9606, Total Loss: 6.3684, LR: 0.000050
2025-04-17 03:28:09,765 [INFO] Epoch 2/15 - Policy Loss: 5.3969, Value Loss: 0.9057, Total Loss: 6.3026, LR: 0.000050
2025-04-17 03:28:47,524 [INFO] Epoch 3/15 - Policy Loss: 5.3920, Value Loss: 0.8576, Total Loss: 6.2497, LR: 0.000050
2025-04-17 03:29:25,377 [INFO] Epoch 4/15 - Policy Loss: 5.3890, Value Loss: 0.8083, Total Loss: 6.1973, LR: 0.000050
2025-04-17 03:30:03,172 [INFO] Epoch 5/15 - Policy Loss: 5.3868, Value Loss: 0.7600, Total Loss: 6.1468, LR: 0.000050
2025-04-17 03:30:41,135 [INFO] Epoch 6/15 - Policy Loss: 5.3850, Value Loss: 0.7145, Total Loss: 6.0995, LR: 0.000050
2025-04-17 03:31:18,950 [INFO] Epoch 7/15 - Policy Loss: 5.3835, Value Loss: 0.6726, Total Loss: 6.0561, LR: 0.000050
2025-04-17 03:31:56,652 [INFO] Epoch 8/15 - Policy Loss: 5.3821, Value Loss: 0.6343, Total Loss: 6.0164, LR: 0.000050
2025-04-17 03:32:34,091 [INFO] Epoch 9/15 - Policy Loss: 5.3807, Value Loss: 0.5992, Total Loss: 5.9799, LR: 0.000050
2025-04-17 03:33:11,722 [INFO] Epoch 10/15 - Policy Loss: 5.3793, Value Loss: 0.5672, Total Loss: 5.9465, LR: 0.000050
2025-04-17 03:33:49,289 [INFO] Epoch 11/15 - Policy Loss: 5.3778, Value Loss: 0.5383, Total Loss: 5.9161, LR: 0.000050
2025-04-17 03:34:27,180 [INFO] Epoch 12/15 - Policy Loss: 5.3763, Value Loss: 0.5123, Total Loss: 5.8885, LR: 0.000050
2025-04-17 03:35:04,708 [INFO] Epoch 13/15 - Policy Loss: 5.3746, Value Loss: 0.4887, Total Loss: 5.8633, LR: 0.000050
2025-04-17 03:35:42,096 [INFO] Epoch 14/15 - Policy Loss: 5.3728, Value Loss: 0.4670, Total Loss: 5.8398, LR: 0.000050
2025-04-17 03:36:19,671 [INFO] Epoch 15/15 - Policy Loss: 5.3708, Value Loss: 0.4476, Total Loss: 5.8184, LR: 0.000050
2025-04-17 03:36:19,732 [INFO] 训练完成，总损失: 5.8184
2025-04-17 03:36:19,732 [INFO] 与最佳模型对比
2025-04-17 03:36:19,732 [INFO] 使用 8 个进程进行并行竞技场评估
2025-04-17 03:41:07,774 [INFO] 评估结果 - 最佳模型胜: 40, 新模型胜: 0, 平局: 0
2025-04-17 03:41:07,775 [INFO] 新模型的胜率: 0.0000
2025-04-17 03:41:07,775 [INFO] 新模型没有显著改进，保持最佳模型不变
2025-04-17 03:41:07,778 [INFO] 开始迭代 8/200
2025-04-17 03:41:07,778 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-17 07:43:15,069 [INFO] 保存训练样本
2025-04-17 07:43:23,342 [INFO] 截断训练样本，保持长度为 200000
2025-04-17 07:43:24,045 [INFO] 使用 200000 个样本训练神经网络
2025-04-17 07:43:24,046 [INFO] Training with 200000 examples
2025-04-17 07:44:01,496 [INFO] Epoch 1/15 - Policy Loss: 5.4075, Value Loss: 0.9614, Total Loss: 6.3689, LR: 0.000050
2025-04-17 07:44:39,596 [INFO] Epoch 2/15 - Policy Loss: 5.3958, Value Loss: 0.9086, Total Loss: 6.3044, LR: 0.000050
2025-04-17 07:45:17,011 [INFO] Epoch 3/15 - Policy Loss: 5.3907, Value Loss: 0.8651, Total Loss: 6.2558, LR: 0.000050
2025-04-17 07:45:54,149 [INFO] Epoch 4/15 - Policy Loss: 5.3878, Value Loss: 0.8258, Total Loss: 6.2136, LR: 0.000050
2025-04-17 07:46:31,493 [INFO] Epoch 5/15 - Policy Loss: 5.3856, Value Loss: 0.7845, Total Loss: 6.1701, LR: 0.000050
2025-04-17 07:47:08,867 [INFO] Epoch 6/15 - Policy Loss: 5.3839, Value Loss: 0.7434, Total Loss: 6.1273, LR: 0.000050
2025-04-17 07:47:46,518 [INFO] Epoch 7/15 - Policy Loss: 5.3824, Value Loss: 0.7044, Total Loss: 6.0868, LR: 0.000050
2025-04-17 07:48:23,903 [INFO] Epoch 8/15 - Policy Loss: 5.3810, Value Loss: 0.6687, Total Loss: 6.0497, LR: 0.000050
2025-04-17 07:49:01,381 [INFO] Epoch 9/15 - Policy Loss: 5.3798, Value Loss: 0.6360, Total Loss: 6.0158, LR: 0.000050
2025-04-17 07:49:39,175 [INFO] Epoch 10/15 - Policy Loss: 5.3785, Value Loss: 0.6057, Total Loss: 5.9842, LR: 0.000050
2025-04-17 07:50:16,588 [INFO] Epoch 11/15 - Policy Loss: 5.3772, Value Loss: 0.5779, Total Loss: 5.9551, LR: 0.000050
2025-04-17 07:50:54,086 [INFO] Epoch 12/15 - Policy Loss: 5.3758, Value Loss: 0.5521, Total Loss: 5.9278, LR: 0.000050
2025-04-17 07:51:31,756 [INFO] Epoch 13/15 - Policy Loss: 5.3743, Value Loss: 0.5284, Total Loss: 5.9027, LR: 0.000050
2025-04-17 07:52:09,146 [INFO] Epoch 14/15 - Policy Loss: 5.3727, Value Loss: 0.5067, Total Loss: 5.8794, LR: 0.000050
2025-04-17 07:52:46,628 [INFO] Epoch 15/15 - Policy Loss: 5.3709, Value Loss: 0.4867, Total Loss: 5.8577, LR: 0.000050
2025-04-17 07:52:46,662 [INFO] 训练完成，总损失: 5.8577
2025-04-17 07:52:46,662 [INFO] 与最佳模型对比
2025-04-17 07:52:46,663 [INFO] 使用 8 个进程进行并行竞技场评估
2025-04-17 07:57:20,424 [INFO] 评估结果 - 最佳模型胜: 40, 新模型胜: 0, 平局: 0
2025-04-17 07:57:20,425 [INFO] 新模型的胜率: 0.0000
2025-04-17 07:57:20,425 [INFO] 新模型没有显著改进，保持最佳模型不变
2025-04-17 07:57:20,429 [INFO] 开始迭代 9/200
2025-04-17 07:57:20,429 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-17 11:56:00,399 [INFO] 保存训练样本
2025-04-17 11:56:10,736 [INFO] 截断训练样本，保持长度为 200000
2025-04-17 11:56:10,925 [INFO] 使用 200000 个样本训练神经网络
2025-04-17 11:56:10,925 [INFO] Training with 200000 examples
2025-04-17 11:56:50,148 [INFO] Epoch 1/15 - Policy Loss: 5.4068, Value Loss: 0.9665, Total Loss: 6.3733, LR: 0.000050
2025-04-17 11:57:28,104 [INFO] Epoch 2/15 - Policy Loss: 5.3956, Value Loss: 0.9226, Total Loss: 6.3182, LR: 0.000050
2025-04-17 11:58:06,264 [INFO] Epoch 3/15 - Policy Loss: 5.3906, Value Loss: 0.8813, Total Loss: 6.2719, LR: 0.000050
2025-04-17 11:58:44,568 [INFO] Epoch 4/15 - Policy Loss: 5.3876, Value Loss: 0.8392, Total Loss: 6.2268, LR: 0.000050
2025-04-17 11:59:22,503 [INFO] Epoch 5/15 - Policy Loss: 5.3853, Value Loss: 0.7990, Total Loss: 6.1843, LR: 0.000050
2025-04-17 12:00:00,686 [INFO] Epoch 6/15 - Policy Loss: 5.3835, Value Loss: 0.7598, Total Loss: 6.1433, LR: 0.000050
2025-04-17 12:00:39,619 [INFO] Epoch 7/15 - Policy Loss: 5.3820, Value Loss: 0.7237, Total Loss: 6.1057, LR: 0.000050
2025-04-17 12:01:17,816 [INFO] Epoch 8/15 - Policy Loss: 5.3805, Value Loss: 0.6898, Total Loss: 6.0703, LR: 0.000050
2025-04-17 12:01:55,858 [INFO] Epoch 9/15 - Policy Loss: 5.3791, Value Loss: 0.6582, Total Loss: 6.0374, LR: 0.000050
2025-04-17 12:02:33,866 [INFO] Epoch 10/15 - Policy Loss: 5.3778, Value Loss: 0.6289, Total Loss: 6.0067, LR: 0.000050
2025-04-17 12:03:11,898 [INFO] Epoch 11/15 - Policy Loss: 5.3762, Value Loss: 0.6019, Total Loss: 5.9781, LR: 0.000050
2025-04-17 12:03:49,946 [INFO] Epoch 12/15 - Policy Loss: 5.3745, Value Loss: 0.5771, Total Loss: 5.9516, LR: 0.000050
2025-04-17 12:04:28,022 [INFO] Epoch 13/15 - Policy Loss: 5.3726, Value Loss: 0.5538, Total Loss: 5.9263, LR: 0.000050
2025-04-17 12:05:06,158 [INFO] Epoch 14/15 - Policy Loss: 5.3704, Value Loss: 0.5320, Total Loss: 5.9024, LR: 0.000050
2025-04-17 12:05:44,096 [INFO] Epoch 15/15 - Policy Loss: 5.3680, Value Loss: 0.5122, Total Loss: 5.8802, LR: 0.000050
2025-04-17 12:05:44,135 [INFO] 训练完成，总损失: 5.8802
2025-04-17 12:05:44,135 [INFO] 与最佳模型对比
2025-04-17 12:05:44,135 [INFO] 使用 8 个进程进行并行竞技场评估
2025-04-17 12:11:12,031 [INFO] 评估结果 - 最佳模型胜: 40, 新模型胜: 0, 平局: 0
2025-04-17 12:11:12,032 [INFO] 新模型的胜率: 0.0000
2025-04-17 12:11:12,032 [INFO] 新模型没有显著改进，保持最佳模型不变
2025-04-17 12:11:12,038 [INFO] 开始迭代 10/200
2025-04-17 12:11:12,038 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-17 16:24:09,301 [INFO] 保存训练样本
2025-04-17 16:24:20,109 [INFO] 截断训练样本，保持长度为 200000
2025-04-17 16:24:20,296 [INFO] 使用 200000 个样本训练神经网络
2025-04-17 16:24:20,296 [INFO] Training with 200000 examples
2025-04-17 16:24:58,126 [INFO] Epoch 1/15 - Policy Loss: 5.4064, Value Loss: 0.9755, Total Loss: 6.3820, LR: 0.000050
2025-04-17 16:25:35,307 [INFO] Epoch 2/15 - Policy Loss: 5.3951, Value Loss: 0.9324, Total Loss: 6.3275, LR: 0.000050
2025-04-17 16:26:12,202 [INFO] Epoch 3/15 - Policy Loss: 5.3899, Value Loss: 0.8931, Total Loss: 6.2829, LR: 0.000050
2025-04-17 16:26:49,080 [INFO] Epoch 4/15 - Policy Loss: 5.3867, Value Loss: 0.8544, Total Loss: 6.2411, LR: 0.000050
2025-04-17 16:27:26,394 [INFO] Epoch 5/15 - Policy Loss: 5.3844, Value Loss: 0.8171, Total Loss: 6.2015, LR: 0.000050
2025-04-17 16:28:03,269 [INFO] Epoch 6/15 - Policy Loss: 5.3826, Value Loss: 0.7818, Total Loss: 6.1645, LR: 0.000050
2025-04-17 16:28:40,119 [INFO] Epoch 7/15 - Policy Loss: 5.3812, Value Loss: 0.7486, Total Loss: 6.1298, LR: 0.000050
2025-04-17 16:29:16,940 [INFO] Epoch 8/15 - Policy Loss: 5.3798, Value Loss: 0.7172, Total Loss: 6.0970, LR: 0.000050
2025-04-17 16:29:53,860 [INFO] Epoch 9/15 - Policy Loss: 5.3785, Value Loss: 0.6875, Total Loss: 6.0660, LR: 0.000050
2025-04-17 16:30:30,734 [INFO] Epoch 10/15 - Policy Loss: 5.3772, Value Loss: 0.6595, Total Loss: 6.0368, LR: 0.000050
2025-04-17 16:31:07,659 [INFO] Epoch 11/15 - Policy Loss: 5.3759, Value Loss: 0.6334, Total Loss: 6.0093, LR: 0.000050
2025-04-17 16:31:44,959 [INFO] Epoch 12/15 - Policy Loss: 5.3744, Value Loss: 0.6087, Total Loss: 5.9832, LR: 0.000050
2025-04-17 16:32:21,721 [INFO] Epoch 13/15 - Policy Loss: 5.3729, Value Loss: 0.5858, Total Loss: 5.9588, LR: 0.000050
2025-04-17 16:32:58,646 [INFO] Epoch 14/15 - Policy Loss: 5.3713, Value Loss: 0.5644, Total Loss: 5.9357, LR: 0.000050
2025-04-17 16:33:35,790 [INFO] Epoch 15/15 - Policy Loss: 5.3695, Value Loss: 0.5443, Total Loss: 5.9138, LR: 0.000050
2025-04-17 16:33:35,825 [INFO] 训练完成，总损失: 5.9138
2025-04-17 16:33:35,825 [INFO] 与最佳模型对比
2025-04-17 16:33:35,825 [INFO] 使用 8 个进程进行并行竞技场评估
2025-04-17 16:38:16,392 [INFO] 评估结果 - 最佳模型胜: 40, 新模型胜: 0, 平局: 0
2025-04-17 16:38:16,393 [INFO] 新模型的胜率: 0.0000
2025-04-17 16:38:16,393 [INFO] 新模型没有显著改进，保持最佳模型不变
2025-04-17 16:38:16,396 [INFO] 开始迭代 11/200
2025-04-17 16:38:16,397 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-17 20:22:00,838 [INFO] 设置多进程启动方法为: spawn
2025-04-17 20:22:01,037 [INFO] CUDA可用，使用GPU
2025-04-17 20:22:01,037 [INFO] 配置参数:
2025-04-17 20:22:01,037 [INFO] 训练参数:
2025-04-17 20:22:01,037 [INFO]   训练轮数: 15
2025-04-17 20:22:01,037 [INFO]   批量大小: 4096
2025-04-17 20:22:01,037 [INFO]   迭代次数: 200
2025-04-17 20:22:01,037 [INFO]   每次迭代的自我对弈次数: 80
2025-04-17 20:22:01,037 [INFO]   训练样本队列最大长度: 200000
2025-04-17 20:22:01,037 [INFO]   保留的历史迭代数: 20
2025-04-17 20:22:01,037 [INFO]   新模型胜率阈值: 0.55
2025-04-17 20:22:01,037 [INFO]   竞技场比赛次数: 40
2025-04-17 20:22:01,037 [INFO]   温度阈值: 5
2025-04-17 20:22:01,037 [INFO] 神经网络参数:
2025-04-17 20:22:01,037 [INFO]   通道数: 512
2025-04-17 20:22:01,037 [INFO]   Dropout率: 0.3
2025-04-17 20:22:01,037 [INFO]   初始学习率: 0.2
2025-04-17 20:22:01,037 [INFO]   学习率降低阈值: [0.25, 0.5, 0.75]
2025-04-17 20:22:01,038 [INFO]   学习率降低值: [0.01, 0.005, 0.0005]
2025-04-17 20:22:01,038 [INFO]   最小学习率: 0.0001
2025-04-17 20:22:01,038 [INFO]   梯度裁剪: 1.0
2025-04-17 20:22:01,038 [INFO]   优化器: adam
2025-04-17 20:22:01,038 [INFO] MCTS参数:
2025-04-17 20:22:01,038 [INFO]   模拟次数: 600
2025-04-17 20:22:01,038 [INFO]   PUCT常数: 4.0
2025-04-17 20:22:01,038 [INFO]   Dirichlet噪声参数: 0.3
2025-04-17 20:22:01,038 [INFO]   Dirichlet噪声权重: 0.25
2025-04-17 20:22:01,038 [INFO] 游戏参数:
2025-04-17 20:22:01,038 [INFO]   棋盘大小: 15
2025-04-17 20:22:01,038 [INFO]   获胜所需的连续棋子数: 5
2025-04-17 20:22:01,038 [INFO] 系统参数:
2025-04-17 20:22:01,038 [INFO]   使用CUDA: True
2025-04-17 20:22:01,038 [INFO]   检查点目录: ./models
2025-04-17 20:22:01,038 [INFO]   数据目录: ./data
2025-04-17 20:22:01,038 [INFO]   加载模型: False
2025-04-17 20:22:01,038 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-17 20:22:01,038 [INFO]   工作线程数: 4
2025-04-17 20:22:01,038 [INFO]   使用Weights & Biases: False
2025-04-17 20:22:01,038 [INFO] GUI参数:
2025-04-17 20:22:01,038 [INFO]   窗口宽度: 800
2025-04-17 20:22:01,038 [INFO]   窗口高度: 850
2025-04-17 20:22:01,038 [INFO]   格子大小: 40
2025-04-17 20:22:01,038 [INFO]   边距: 40
2025-04-17 20:22:01,038 [INFO]   底部边距: 80
2025-04-17 20:22:01,038 [INFO]   帧率: 30
2025-04-17 20:22:01,243 [INFO] Using device: cuda
2025-04-17 20:22:02,425 [INFO] 设置并行进程数为: 8
2025-04-17 20:22:02,425 [INFO] 开始训练
2025-04-17 20:22:02,425 [INFO] 加载之前的训练样本
2025-04-17 20:22:05,750 [INFO] 加载了 10 组训练样本
2025-04-17 20:22:05,750 [INFO] 开始迭代 1/200
2025-04-17 20:22:05,750 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-17 23:02:08,713 [INFO] 保存训练样本
2025-04-17 23:02:19,597 [INFO] 截断训练样本，保持长度为 200000
2025-04-17 23:02:20,742 [INFO] 使用 200000 个样本训练神经网络
2025-04-17 23:02:20,742 [INFO] Training with 200000 examples
2025-04-17 23:02:58,896 [INFO] Epoch 1/15 - Policy Loss: 5.8493, Value Loss: 1.9535, Total Loss: 7.8028, LR: 0.200000
2025-04-17 23:03:36,497 [INFO] Epoch 2/15 - Policy Loss: 5.6309, Value Loss: 1.9627, Total Loss: 7.5936, LR: 0.200000
2025-04-17 23:04:13,700 [INFO] Epoch 3/15 - Policy Loss: 5.5581, Value Loss: 1.9671, Total Loss: 7.5251, LR: 0.200000
2025-04-17 23:04:50,330 [INFO] Epoch 4/15 - Policy Loss: 5.5216, Value Loss: 1.9694, Total Loss: 7.4910, LR: 0.010000
2025-04-17 23:05:27,034 [INFO] Epoch 5/15 - Policy Loss: 5.4996, Value Loss: 1.9730, Total Loss: 7.4727, LR: 0.010000
2025-04-17 23:06:03,703 [INFO] Epoch 6/15 - Policy Loss: 5.4850, Value Loss: 1.9744, Total Loss: 7.4594, LR: 0.010000
2025-04-17 23:06:40,295 [INFO] Epoch 7/15 - Policy Loss: 5.4745, Value Loss: 1.9752, Total Loss: 7.4497, LR: 0.010000
2025-04-17 23:07:17,391 [INFO] Epoch 8/15 - Policy Loss: 5.4666, Value Loss: 1.9751, Total Loss: 7.4418, LR: 0.005000
2025-04-17 23:07:54,976 [INFO] Epoch 9/15 - Policy Loss: 5.4605, Value Loss: 1.9752, Total Loss: 7.4357, LR: 0.005000
2025-04-17 23:08:32,983 [INFO] Epoch 10/15 - Policy Loss: 5.4556, Value Loss: 1.9757, Total Loss: 7.4313, LR: 0.005000
2025-04-17 23:09:10,312 [INFO] Epoch 11/15 - Policy Loss: 5.4516, Value Loss: 1.9758, Total Loss: 7.4274, LR: 0.005000
2025-04-17 23:09:47,532 [INFO] Epoch 12/15 - Policy Loss: 5.4483, Value Loss: 1.9760, Total Loss: 7.4242, LR: 0.000500
2025-04-17 23:10:25,763 [INFO] Epoch 13/15 - Policy Loss: 5.4455, Value Loss: 1.9756, Total Loss: 7.4211, LR: 0.000500
2025-04-17 23:11:03,310 [INFO] Epoch 14/15 - Policy Loss: 5.4430, Value Loss: 1.9760, Total Loss: 7.4191, LR: 0.000500
2025-04-17 23:11:40,893 [INFO] Epoch 15/15 - Policy Loss: 5.4409, Value Loss: 1.9761, Total Loss: 7.4171, LR: 0.000500
2025-04-17 23:11:40,924 [INFO] 训练完成，总损失: 7.4171
2025-04-17 23:11:40,924 [INFO] 保存迭代 1 的模型
2025-04-17 23:11:41,570 [INFO] Model saved to ./models/best.pt
2025-04-17 23:11:42,205 [INFO] Model saved to ./models/iteration_1.pt
2025-04-17 23:11:42,205 [INFO] 所有训练迭代完成
2025-04-17 23:11:42,205 [INFO] 开始迭代 2/200
2025-04-17 23:11:42,205 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-17 23:14:51,178 [INFO] 设置多进程启动方法为: spawn
2025-04-17 23:14:51,403 [INFO] CUDA可用，使用GPU
2025-04-17 23:14:51,403 [INFO] 配置参数:
2025-04-17 23:14:51,403 [INFO] 训练参数:
2025-04-17 23:14:51,403 [INFO]   训练轮数: 15
2025-04-17 23:14:51,403 [INFO]   批量大小: 4096
2025-04-17 23:14:51,403 [INFO]   迭代次数: 200
2025-04-17 23:14:51,403 [INFO]   每次迭代的自我对弈次数: 80
2025-04-17 23:14:51,403 [INFO]   训练样本队列最大长度: 200000
2025-04-17 23:14:51,403 [INFO]   保留的历史迭代数: 20
2025-04-17 23:14:51,404 [INFO]   新模型胜率阈值: 0.55
2025-04-17 23:14:51,404 [INFO]   竞技场比赛次数: 40
2025-04-17 23:14:51,404 [INFO]   温度阈值: 5
2025-04-17 23:14:51,404 [INFO] 神经网络参数:
2025-04-17 23:14:51,404 [INFO]   通道数: 512
2025-04-17 23:14:51,404 [INFO]   Dropout率: 0.3
2025-04-17 23:14:51,404 [INFO]   学习率范围: 0.0002 - 0.005
2025-04-17 23:14:51,404 [INFO]   梯度裁剪: 1.0
2025-04-17 23:14:51,404 [INFO]   优化器: adam
2025-04-17 23:14:51,404 [INFO] MCTS参数:
2025-04-17 23:14:51,404 [INFO]   模拟次数: 800
2025-04-17 23:14:51,404 [INFO]   PUCT常数: 4.0
2025-04-17 23:14:51,404 [INFO]   Dirichlet噪声参数: 0.3
2025-04-17 23:14:51,404 [INFO]   Dirichlet噪声权重: 0.25
2025-04-17 23:14:51,404 [INFO] 游戏参数:
2025-04-17 23:14:51,404 [INFO]   棋盘大小: 15
2025-04-17 23:14:51,404 [INFO]   获胜所需的连续棋子数: 5
2025-04-17 23:14:51,404 [INFO] 系统参数:
2025-04-17 23:14:51,404 [INFO]   使用CUDA: True
2025-04-17 23:14:51,404 [INFO]   检查点目录: ./models
2025-04-17 23:14:51,404 [INFO]   数据目录: ./data
2025-04-17 23:14:51,404 [INFO]   加载模型: False
2025-04-17 23:14:51,405 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-17 23:14:51,405 [INFO]   工作线程数: 4
2025-04-17 23:14:51,405 [INFO]   使用Weights & Biases: False
2025-04-17 23:14:51,405 [INFO] GUI参数:
2025-04-17 23:14:51,405 [INFO]   窗口宽度: 800
2025-04-17 23:14:51,405 [INFO]   窗口高度: 850
2025-04-17 23:14:51,405 [INFO]   格子大小: 40
2025-04-17 23:14:51,405 [INFO]   边距: 40
2025-04-17 23:14:51,405 [INFO]   底部边距: 80
2025-04-17 23:14:51,405 [INFO]   帧率: 30
2025-04-17 23:14:51,634 [INFO] Using device: cuda
2025-04-17 23:14:52,868 [INFO] 设置循环学习率: 最小值=0.0002, 最大值=0.005
2025-04-17 23:14:52,868 [INFO] 设置并行进程数为: 8
2025-04-17 23:14:52,868 [INFO] 开始训练
2025-04-17 23:14:52,868 [INFO] 加载之前的训练样本
2025-04-17 23:14:57,237 [INFO] 加载了 11 组训练样本
2025-04-17 23:14:57,237 [INFO] 开始迭代 1/200
2025-04-17 23:14:57,237 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-18 12:40:21,522 [INFO] 保存训练样本
2025-04-18 12:40:31,985 [INFO] 截断训练样本，保持长度为 200000
2025-04-18 12:40:32,101 [INFO] 使用 200000 个样本训练神经网络
2025-04-18 12:40:32,101 [INFO] Training with 200000 examples
2025-04-18 12:40:32,101 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-18 12:40:32,845 [INFO] 循环学习率周期大小: 144 步
2025-04-18 12:41:11,596 [INFO] Epoch 1/15 - Policy Loss: 5.3919, Value Loss: 1.0072, Total Loss: 6.3991, LR: 0.001767
2025-04-18 12:41:50,037 [INFO] Epoch 2/15 - Policy Loss: 5.3672, Value Loss: 0.9732, Total Loss: 6.3404, LR: 0.003367
2025-04-18 12:42:28,636 [INFO] Epoch 3/15 - Policy Loss: 5.3430, Value Loss: 0.9388, Total Loss: 6.2819, LR: 0.004967
2025-04-18 12:43:07,303 [INFO] Epoch 4/15 - Policy Loss: 5.3221, Value Loss: 0.8921, Total Loss: 6.2142, LR: 0.003433
2025-04-18 12:43:46,371 [INFO] Epoch 5/15 - Policy Loss: 5.3045, Value Loss: 0.8276, Total Loss: 6.1320, LR: 0.001833
2025-04-18 12:44:25,435 [INFO] Epoch 6/15 - Policy Loss: 5.2900, Value Loss: 0.7585, Total Loss: 6.0485, LR: 0.000233
2025-04-18 12:45:04,589 [INFO] Epoch 7/15 - Policy Loss: 5.2792, Value Loss: 0.6988, Total Loss: 5.9780, LR: 0.001767
2025-04-18 12:45:43,176 [INFO] Epoch 8/15 - Policy Loss: 5.2717, Value Loss: 0.6548, Total Loss: 5.9265, LR: 0.003367
2025-04-18 12:46:21,686 [INFO] Epoch 9/15 - Policy Loss: 5.2675, Value Loss: 0.6205, Total Loss: 5.8880, LR: 0.004967
2025-04-18 12:47:00,434 [INFO] Epoch 10/15 - Policy Loss: 5.2632, Value Loss: 0.5854, Total Loss: 5.8486, LR: 0.003433
2025-04-18 12:47:39,846 [INFO] Epoch 11/15 - Policy Loss: 5.2581, Value Loss: 0.5494, Total Loss: 5.8076, LR: 0.001833
2025-04-18 12:48:18,450 [INFO] Epoch 12/15 - Policy Loss: 5.2532, Value Loss: 0.5152, Total Loss: 5.7684, LR: 0.000233
2025-04-18 12:48:57,310 [INFO] Epoch 13/15 - Policy Loss: 5.2489, Value Loss: 0.4847, Total Loss: 5.7336, LR: 0.001767
2025-04-18 12:49:36,309 [INFO] Epoch 14/15 - Policy Loss: 5.2454, Value Loss: 0.4586, Total Loss: 5.7040, LR: 0.003367
2025-04-18 12:50:15,347 [INFO] Epoch 15/15 - Policy Loss: 5.2428, Value Loss: 0.4382, Total Loss: 5.6810, LR: 0.004967
2025-04-18 12:50:15,408 [INFO] 训练完成，总损失: 5.6810
2025-04-18 12:50:15,408 [INFO] 保存迭代 1 的模型
2025-04-18 12:50:16,302 [INFO] Model saved to ./models/best.pt
2025-04-18 12:50:17,142 [INFO] Model saved to ./models/iteration_1.pt
2025-04-18 12:50:17,143 [INFO] 所有训练迭代完成
2025-04-18 12:50:17,143 [INFO] 开始迭代 2/200
2025-04-18 12:50:17,143 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-18 22:33:29,731 [INFO] 保存训练样本
2025-04-18 22:33:44,677 [INFO] 截断训练样本，保持长度为 200000
2025-04-18 22:33:44,886 [INFO] 使用 200000 个样本训练神经网络
2025-04-18 22:33:44,886 [INFO] Training with 200000 examples
2025-04-18 22:33:44,886 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-18 22:33:44,974 [INFO] 循环学习率周期大小: 144 步
2025-04-18 22:34:23,924 [INFO] Epoch 1/15 - Policy Loss: 5.2054, Value Loss: 0.2556, Total Loss: 5.4611, LR: 0.001767
2025-04-18 22:35:02,961 [INFO] Epoch 2/15 - Policy Loss: 5.1966, Value Loss: 0.2232, Total Loss: 5.4197, LR: 0.003367
2025-04-18 22:35:41,894 [INFO] Epoch 3/15 - Policy Loss: 5.1916, Value Loss: 0.2101, Total Loss: 5.4017, LR: 0.004967
2025-04-18 22:36:20,434 [INFO] Epoch 4/15 - Policy Loss: 5.1844, Value Loss: 0.2026, Total Loss: 5.3870, LR: 0.003433
2025-04-18 22:36:59,631 [INFO] Epoch 5/15 - Policy Loss: 5.1755, Value Loss: 0.1884, Total Loss: 5.3640, LR: 0.001833
2025-04-18 22:37:37,953 [INFO] Epoch 6/15 - Policy Loss: 5.1666, Value Loss: 0.1733, Total Loss: 5.3400, LR: 0.000233
2025-04-18 22:38:16,415 [INFO] Epoch 7/15 - Policy Loss: 5.1591, Value Loss: 0.1611, Total Loss: 5.3202, LR: 0.001767
2025-04-18 22:38:54,916 [INFO] Epoch 8/15 - Policy Loss: 5.1535, Value Loss: 0.1516, Total Loss: 5.3051, LR: 0.003367
2025-04-18 22:39:33,338 [INFO] Epoch 9/15 - Policy Loss: 5.1496, Value Loss: 0.1459, Total Loss: 5.2956, LR: 0.004967
2025-04-18 22:40:11,639 [INFO] Epoch 10/15 - Policy Loss: 5.1461, Value Loss: 0.1426, Total Loss: 5.2887, LR: 0.003433
2025-04-18 22:40:49,996 [INFO] Epoch 11/15 - Policy Loss: 5.1417, Value Loss: 0.1380, Total Loss: 5.2797, LR: 0.001833
2025-04-18 22:41:28,920 [INFO] Epoch 12/15 - Policy Loss: 5.1366, Value Loss: 0.1326, Total Loss: 5.2692, LR: 0.000233
2025-04-18 22:42:07,972 [INFO] Epoch 13/15 - Policy Loss: 5.1322, Value Loss: 0.1273, Total Loss: 5.2595, LR: 0.001767
2025-04-18 22:42:47,053 [INFO] Epoch 14/15 - Policy Loss: 5.1280, Value Loss: 0.1228, Total Loss: 5.2509, LR: 0.003367
2025-04-18 22:43:26,260 [INFO] Epoch 15/15 - Policy Loss: 5.1252, Value Loss: 0.1196, Total Loss: 5.2448, LR: 0.004967
2025-04-18 22:43:26,318 [INFO] 训练完成，总损失: 5.2448
2025-04-18 22:43:26,319 [INFO] 保存迭代 2 的模型
2025-04-18 22:43:27,207 [INFO] Model saved to ./models/best.pt
2025-04-18 22:43:27,897 [INFO] Model saved to ./models/iteration_2.pt
2025-04-18 22:43:27,897 [INFO] 所有训练迭代完成
2025-04-18 22:43:27,897 [INFO] 开始迭代 3/200
2025-04-18 22:43:27,897 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-19 08:30:30,042 [INFO] 保存训练样本
2025-04-19 08:30:43,222 [INFO] 截断训练样本，保持长度为 200000
2025-04-19 08:30:43,358 [INFO] 使用 200000 个样本训练神经网络
2025-04-19 08:30:43,358 [INFO] Training with 200000 examples
2025-04-19 08:30:43,358 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-19 08:30:44,166 [INFO] 循环学习率周期大小: 144 步
2025-04-19 08:31:22,292 [INFO] Epoch 1/15 - Policy Loss: 5.1466, Value Loss: 0.2045, Total Loss: 5.3511, LR: 0.001767
2025-04-19 08:32:00,385 [INFO] Epoch 2/15 - Policy Loss: 5.1228, Value Loss: 0.1790, Total Loss: 5.3018, LR: 0.003367
2025-04-19 08:32:38,314 [INFO] Epoch 3/15 - Policy Loss: 5.1063, Value Loss: 0.1678, Total Loss: 5.2741, LR: 0.004967
2025-04-19 08:33:15,973 [INFO] Epoch 4/15 - Policy Loss: 5.0916, Value Loss: 0.1607, Total Loss: 5.2523, LR: 0.003433
2025-04-19 08:33:54,029 [INFO] Epoch 5/15 - Policy Loss: 5.0777, Value Loss: 0.1495, Total Loss: 5.2273, LR: 0.001833
2025-04-19 08:34:32,152 [INFO] Epoch 6/15 - Policy Loss: 5.0636, Value Loss: 0.1387, Total Loss: 5.2023, LR: 0.000233
2025-04-19 08:35:10,063 [INFO] Epoch 7/15 - Policy Loss: 5.0519, Value Loss: 0.1296, Total Loss: 5.1815, LR: 0.001767
2025-04-19 08:35:48,609 [INFO] Epoch 8/15 - Policy Loss: 5.0423, Value Loss: 0.1224, Total Loss: 5.1648, LR: 0.003367
2025-04-19 08:36:27,106 [INFO] Epoch 9/15 - Policy Loss: 5.0350, Value Loss: 0.1172, Total Loss: 5.1522, LR: 0.004967
2025-04-19 08:37:05,727 [INFO] Epoch 10/15 - Policy Loss: 5.0311, Value Loss: 0.1145, Total Loss: 5.1455, LR: 0.003433
2025-04-19 08:37:44,096 [INFO] Epoch 11/15 - Policy Loss: 5.0258, Value Loss: 0.1114, Total Loss: 5.1371, LR: 0.001833
2025-04-19 08:38:22,416 [INFO] Epoch 12/15 - Policy Loss: 5.0195, Value Loss: 0.1077, Total Loss: 5.1272, LR: 0.000233
2025-04-19 08:39:00,951 [INFO] Epoch 13/15 - Policy Loss: 5.0133, Value Loss: 0.1041, Total Loss: 5.1174, LR: 0.001767
2025-04-19 08:39:39,270 [INFO] Epoch 14/15 - Policy Loss: 5.0080, Value Loss: 0.1009, Total Loss: 5.1089, LR: 0.003367
2025-04-19 08:40:17,662 [INFO] Epoch 15/15 - Policy Loss: 5.0034, Value Loss: 0.0985, Total Loss: 5.1019, LR: 0.004967
2025-04-19 08:40:17,714 [INFO] 训练完成，总损失: 5.1019
2025-04-19 08:40:17,715 [INFO] 保存迭代 3 的模型
2025-04-19 08:40:18,516 [INFO] Model saved to ./models/best.pt
2025-04-19 08:40:19,162 [INFO] Model saved to ./models/iteration_3.pt
2025-04-19 08:40:19,162 [INFO] 所有训练迭代完成
2025-04-19 08:40:19,162 [INFO] 开始迭代 4/200
2025-04-19 08:40:19,162 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-19 17:09:40,063 [INFO] 保存训练样本
2025-04-19 17:09:52,717 [INFO] 截断训练样本，保持长度为 200000
2025-04-19 17:09:52,853 [INFO] 使用 200000 个样本训练神经网络
2025-04-19 17:09:52,854 [INFO] Training with 200000 examples
2025-04-19 17:09:52,854 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-19 17:09:52,913 [INFO] 循环学习率周期大小: 144 步
2025-04-19 17:10:31,319 [INFO] Epoch 1/15 - Policy Loss: 5.0608, Value Loss: 0.1647, Total Loss: 5.2255, LR: 0.001767
2025-04-19 17:11:09,355 [INFO] Epoch 2/15 - Policy Loss: 5.0316, Value Loss: 0.1466, Total Loss: 5.1782, LR: 0.003367
2025-04-19 17:11:47,170 [INFO] Epoch 3/15 - Policy Loss: 5.0113, Value Loss: 0.1384, Total Loss: 5.1496, LR: 0.004967
2025-04-19 17:12:24,683 [INFO] Epoch 4/15 - Policy Loss: 4.9916, Value Loss: 0.1349, Total Loss: 5.1266, LR: 0.003433
2025-04-19 17:13:02,045 [INFO] Epoch 5/15 - Policy Loss: 4.9730, Value Loss: 0.1276, Total Loss: 5.1006, LR: 0.001833
2025-04-19 17:13:39,440 [INFO] Epoch 6/15 - Policy Loss: 4.9573, Value Loss: 0.1196, Total Loss: 5.0770, LR: 0.000233
2025-04-19 17:14:17,140 [INFO] Epoch 7/15 - Policy Loss: 4.9443, Value Loss: 0.1130, Total Loss: 5.0573, LR: 0.001767
2025-04-19 17:14:55,831 [INFO] Epoch 8/15 - Policy Loss: 4.9332, Value Loss: 0.1077, Total Loss: 5.0410, LR: 0.003367
2025-04-19 17:15:33,678 [INFO] Epoch 9/15 - Policy Loss: 4.9242, Value Loss: 0.1039, Total Loss: 5.0281, LR: 0.004967
2025-04-19 17:16:12,270 [INFO] Epoch 10/15 - Policy Loss: 4.9175, Value Loss: 0.1019, Total Loss: 5.0195, LR: 0.003433
2025-04-19 17:16:51,061 [INFO] Epoch 11/15 - Policy Loss: 4.9112, Value Loss: 0.1000, Total Loss: 5.0113, LR: 0.001833
2025-04-19 17:17:29,169 [INFO] Epoch 12/15 - Policy Loss: 4.9045, Value Loss: 0.0974, Total Loss: 5.0019, LR: 0.000233
2025-04-19 17:18:07,024 [INFO] Epoch 13/15 - Policy Loss: 4.8981, Value Loss: 0.0948, Total Loss: 4.9928, LR: 0.001767
2025-04-19 17:18:45,640 [INFO] Epoch 14/15 - Policy Loss: 4.8920, Value Loss: 0.0924, Total Loss: 4.9844, LR: 0.003367
2025-04-19 17:19:24,369 [INFO] Epoch 15/15 - Policy Loss: 4.8882, Value Loss: 0.0905, Total Loss: 4.9787, LR: 0.004967
2025-04-19 17:19:24,422 [INFO] 训练完成，总损失: 4.9787
2025-04-19 17:19:24,422 [INFO] 保存迭代 4 的模型
2025-04-19 17:19:25,244 [INFO] Model saved to ./models/best.pt
2025-04-19 17:19:25,842 [INFO] Model saved to ./models/iteration_4.pt
2025-04-19 17:19:25,842 [INFO] 所有训练迭代完成
2025-04-19 17:19:25,842 [INFO] 开始迭代 5/200
2025-04-19 17:19:25,842 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-20 00:32:30,152 [INFO] 保存训练样本
2025-04-20 00:32:44,171 [INFO] 截断训练样本，保持长度为 200000
2025-04-20 00:32:44,381 [INFO] 使用 200000 个样本训练神经网络
2025-04-20 00:32:44,382 [INFO] Training with 200000 examples
2025-04-20 00:32:44,382 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-20 00:32:45,893 [INFO] 循环学习率周期大小: 144 步
2025-04-20 00:33:24,714 [INFO] Epoch 1/15 - Policy Loss: 4.9813, Value Loss: 0.1561, Total Loss: 5.1374, LR: 0.001767
2025-04-20 00:34:03,461 [INFO] Epoch 2/15 - Policy Loss: 4.9503, Value Loss: 0.1410, Total Loss: 5.0912, LR: 0.003367
2025-04-20 00:34:42,240 [INFO] Epoch 3/15 - Policy Loss: 4.9235, Value Loss: 0.1332, Total Loss: 5.0567, LR: 0.004967
2025-04-20 00:35:20,823 [INFO] Epoch 4/15 - Policy Loss: 4.9021, Value Loss: 0.1285, Total Loss: 5.0305, LR: 0.003433
2025-04-20 00:35:59,455 [INFO] Epoch 5/15 - Policy Loss: 4.8817, Value Loss: 0.1224, Total Loss: 5.0041, LR: 0.001833
2025-04-20 00:36:37,848 [INFO] Epoch 6/15 - Policy Loss: 4.8637, Value Loss: 0.1156, Total Loss: 4.9792, LR: 0.000233
2025-04-20 00:37:16,116 [INFO] Epoch 7/15 - Policy Loss: 4.8487, Value Loss: 0.1098, Total Loss: 4.9585, LR: 0.001767
2025-04-20 00:37:54,312 [INFO] Epoch 8/15 - Policy Loss: 4.8368, Value Loss: 0.1051, Total Loss: 4.9419, LR: 0.003367
2025-04-20 00:38:32,482 [INFO] Epoch 9/15 - Policy Loss: 4.8276, Value Loss: 0.1018, Total Loss: 4.9294, LR: 0.004967
2025-04-20 00:39:10,576 [INFO] Epoch 10/15 - Policy Loss: 4.8201, Value Loss: 0.1000, Total Loss: 4.9201, LR: 0.003433
2025-04-20 00:39:48,786 [INFO] Epoch 11/15 - Policy Loss: 4.8129, Value Loss: 0.0979, Total Loss: 4.9108, LR: 0.001833
2025-04-20 00:40:27,055 [INFO] Epoch 12/15 - Policy Loss: 4.8051, Value Loss: 0.0955, Total Loss: 4.9007, LR: 0.000233
2025-04-20 00:41:05,315 [INFO] Epoch 13/15 - Policy Loss: 4.7982, Value Loss: 0.0933, Total Loss: 4.8915, LR: 0.001767
2025-04-20 00:41:43,599 [INFO] Epoch 14/15 - Policy Loss: 4.7926, Value Loss: 0.0913, Total Loss: 4.8839, LR: 0.003367
2025-04-20 00:42:22,321 [INFO] Epoch 15/15 - Policy Loss: 4.7876, Value Loss: 0.0897, Total Loss: 4.8773, LR: 0.004967
2025-04-20 00:42:22,382 [INFO] 训练完成，总损失: 4.8773
2025-04-20 00:42:22,383 [INFO] 保存迭代 5 的模型
2025-04-20 00:42:23,110 [INFO] Model saved to ./models/best.pt
2025-04-20 00:42:23,565 [INFO] Model saved to ./models/iteration_5.pt
2025-04-20 00:42:23,565 [INFO] 所有训练迭代完成
2025-04-20 00:42:23,565 [INFO] 开始迭代 6/200
2025-04-20 00:42:23,566 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-20 08:10:56,968 [INFO] 保存训练样本
2025-04-20 08:11:09,851 [INFO] 截断训练样本，保持长度为 200000
2025-04-20 08:11:10,783 [INFO] 使用 200000 个样本训练神经网络
2025-04-20 08:11:10,783 [INFO] Training with 200000 examples
2025-04-20 08:11:10,784 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-20 08:11:10,844 [INFO] 循环学习率周期大小: 144 步
2025-04-20 08:11:48,120 [INFO] Epoch 1/15 - Policy Loss: 4.9189, Value Loss: 0.1570, Total Loss: 5.0760, LR: 0.001767
2025-04-20 08:12:25,639 [INFO] Epoch 2/15 - Policy Loss: 4.8841, Value Loss: 0.1410, Total Loss: 5.0251, LR: 0.003367
2025-04-20 08:13:03,068 [INFO] Epoch 3/15 - Policy Loss: 4.8564, Value Loss: 0.1334, Total Loss: 4.9898, LR: 0.004967
2025-04-20 08:13:40,595 [INFO] Epoch 4/15 - Policy Loss: 4.8336, Value Loss: 0.1291, Total Loss: 4.9627, LR: 0.003433
2025-04-20 08:14:18,245 [INFO] Epoch 5/15 - Policy Loss: 4.8118, Value Loss: 0.1229, Total Loss: 4.9347, LR: 0.001833
2025-04-20 08:14:55,893 [INFO] Epoch 6/15 - Policy Loss: 4.7922, Value Loss: 0.1164, Total Loss: 4.9086, LR: 0.000233
2025-04-20 08:15:33,568 [INFO] Epoch 7/15 - Policy Loss: 4.7770, Value Loss: 0.1110, Total Loss: 4.8880, LR: 0.001767
2025-04-20 08:16:11,356 [INFO] Epoch 8/15 - Policy Loss: 4.7645, Value Loss: 0.1065, Total Loss: 4.8710, LR: 0.003367
2025-04-20 08:16:49,227 [INFO] Epoch 9/15 - Policy Loss: 4.7548, Value Loss: 0.1031, Total Loss: 4.8578, LR: 0.004967
2025-04-20 08:17:27,092 [INFO] Epoch 10/15 - Policy Loss: 4.7472, Value Loss: 0.1009, Total Loss: 4.8481, LR: 0.003433
2025-04-20 08:18:04,975 [INFO] Epoch 11/15 - Policy Loss: 4.7392, Value Loss: 0.0985, Total Loss: 4.8377, LR: 0.001833
2025-04-20 08:18:43,033 [INFO] Epoch 12/15 - Policy Loss: 4.7310, Value Loss: 0.0962, Total Loss: 4.8272, LR: 0.000233
2025-04-20 08:19:20,957 [INFO] Epoch 13/15 - Policy Loss: 4.7233, Value Loss: 0.0939, Total Loss: 4.8172, LR: 0.001767
2025-04-20 08:19:59,082 [INFO] Epoch 14/15 - Policy Loss: 4.7165, Value Loss: 0.0920, Total Loss: 4.8085, LR: 0.003367
2025-04-20 08:20:37,187 [INFO] Epoch 15/15 - Policy Loss: 4.7109, Value Loss: 0.0904, Total Loss: 4.8013, LR: 0.004967
2025-04-20 08:20:37,246 [INFO] 训练完成，总损失: 4.8013
2025-04-20 08:20:37,246 [INFO] 保存迭代 6 的模型
2025-04-20 08:20:37,920 [INFO] Model saved to ./models/best.pt
2025-04-20 08:20:38,303 [INFO] Model saved to ./models/iteration_6.pt
2025-04-20 08:20:38,303 [INFO] 所有训练迭代完成
2025-04-20 08:20:38,303 [INFO] 开始迭代 7/200
2025-04-20 08:20:38,304 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-20 15:12:14,337 [INFO] 保存训练样本
2025-04-20 15:12:27,549 [INFO] 截断训练样本，保持长度为 200000
2025-04-20 15:12:27,689 [INFO] 使用 200000 个样本训练神经网络
2025-04-20 15:12:27,689 [INFO] Training with 200000 examples
2025-04-20 15:12:27,689 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-20 15:12:27,749 [INFO] 循环学习率周期大小: 144 步
2025-04-20 15:13:05,196 [INFO] Epoch 1/15 - Policy Loss: 4.8586, Value Loss: 0.1497, Total Loss: 5.0083, LR: 0.001767
2025-04-20 15:13:42,704 [INFO] Epoch 2/15 - Policy Loss: 4.8198, Value Loss: 0.1368, Total Loss: 4.9566, LR: 0.003367
2025-04-20 15:14:20,332 [INFO] Epoch 3/15 - Policy Loss: 4.7894, Value Loss: 0.1309, Total Loss: 4.9203, LR: 0.004967
2025-04-20 15:14:58,024 [INFO] Epoch 4/15 - Policy Loss: 4.7667, Value Loss: 0.1299, Total Loss: 4.8966, LR: 0.003433
2025-04-20 15:15:35,805 [INFO] Epoch 5/15 - Policy Loss: 4.7422, Value Loss: 0.1244, Total Loss: 4.8666, LR: 0.001833
2025-04-20 15:16:14,421 [INFO] Epoch 6/15 - Policy Loss: 4.7213, Value Loss: 0.1180, Total Loss: 4.8393, LR: 0.000233
2025-04-20 15:16:52,129 [INFO] Epoch 7/15 - Policy Loss: 4.7048, Value Loss: 0.1126, Total Loss: 4.8174, LR: 0.001767
2025-04-20 15:17:29,904 [INFO] Epoch 8/15 - Policy Loss: 4.6911, Value Loss: 0.1080, Total Loss: 4.7991, LR: 0.003367
2025-04-20 15:18:07,719 [INFO] Epoch 9/15 - Policy Loss: 4.6808, Value Loss: 0.1046, Total Loss: 4.7854, LR: 0.004967
2025-04-20 15:18:45,488 [INFO] Epoch 10/15 - Policy Loss: 4.6727, Value Loss: 0.1025, Total Loss: 4.7752, LR: 0.003433
2025-04-20 15:19:23,188 [INFO] Epoch 11/15 - Policy Loss: 4.6641, Value Loss: 0.1003, Total Loss: 4.7643, LR: 0.001833
2025-04-20 15:20:00,849 [INFO] Epoch 12/15 - Policy Loss: 4.6551, Value Loss: 0.0979, Total Loss: 4.7529, LR: 0.000233
2025-04-20 15:20:38,484 [INFO] Epoch 13/15 - Policy Loss: 4.6473, Value Loss: 0.0956, Total Loss: 4.7430, LR: 0.001767
2025-04-20 15:21:16,240 [INFO] Epoch 14/15 - Policy Loss: 4.6403, Value Loss: 0.0937, Total Loss: 4.7340, LR: 0.003367
2025-04-20 15:21:53,920 [INFO] Epoch 15/15 - Policy Loss: 4.6344, Value Loss: 0.0920, Total Loss: 4.7264, LR: 0.004967
2025-04-20 15:21:53,965 [INFO] 训练完成，总损失: 4.7264
2025-04-20 15:21:53,966 [INFO] 保存迭代 7 的模型
2025-04-20 15:21:54,736 [INFO] Model saved to ./models/best.pt
2025-04-20 15:21:55,198 [INFO] Model saved to ./models/iteration_7.pt
2025-04-20 15:21:55,199 [INFO] 所有训练迭代完成
2025-04-20 15:21:55,199 [INFO] 开始迭代 8/200
2025-04-20 15:21:55,199 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-20 21:34:23,431 [INFO] 保存训练样本
2025-04-20 21:34:49,405 [INFO] 截断训练样本，保持长度为 200000
2025-04-20 21:34:49,661 [INFO] 使用 200000 个样本训练神经网络
2025-04-20 21:34:49,661 [INFO] Training with 200000 examples
2025-04-20 21:34:49,661 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-20 21:34:53,012 [INFO] 循环学习率周期大小: 144 步
2025-04-20 21:35:33,723 [INFO] Epoch 1/15 - Policy Loss: 4.7993, Value Loss: 0.1482, Total Loss: 4.9474, LR: 0.001767
2025-04-20 21:36:15,978 [INFO] Epoch 2/15 - Policy Loss: 4.7568, Value Loss: 0.1342, Total Loss: 4.8910, LR: 0.003367
2025-04-20 21:36:57,035 [INFO] Epoch 3/15 - Policy Loss: 4.7242, Value Loss: 0.1270, Total Loss: 4.8511, LR: 0.004967
2025-04-20 21:37:38,568 [INFO] Epoch 4/15 - Policy Loss: 4.6986, Value Loss: 0.1233, Total Loss: 4.8219, LR: 0.003433
2025-04-20 21:38:19,465 [INFO] Epoch 5/15 - Policy Loss: 4.6736, Value Loss: 0.1179, Total Loss: 4.7915, LR: 0.001833
2025-04-20 21:39:00,934 [INFO] Epoch 6/15 - Policy Loss: 4.6522, Value Loss: 0.1123, Total Loss: 4.7645, LR: 0.000233
2025-04-20 21:39:42,834 [INFO] Epoch 7/15 - Policy Loss: 4.6340, Value Loss: 0.1075, Total Loss: 4.7415, LR: 0.001767
2025-04-20 21:40:25,163 [INFO] Epoch 8/15 - Policy Loss: 4.6199, Value Loss: 0.1037, Total Loss: 4.7235, LR: 0.003367
2025-04-20 21:41:06,076 [INFO] Epoch 9/15 - Policy Loss: 4.6080, Value Loss: 0.1009, Total Loss: 4.7090, LR: 0.004967
2025-04-20 21:41:47,284 [INFO] Epoch 10/15 - Policy Loss: 4.5997, Value Loss: 0.0994, Total Loss: 4.6992, LR: 0.003433
2025-04-20 21:42:29,297 [INFO] Epoch 11/15 - Policy Loss: 4.5901, Value Loss: 0.0975, Total Loss: 4.6876, LR: 0.001833
2025-04-20 21:43:11,537 [INFO] Epoch 12/15 - Policy Loss: 4.5815, Value Loss: 0.0953, Total Loss: 4.6769, LR: 0.000233
2025-04-20 21:43:53,220 [INFO] Epoch 13/15 - Policy Loss: 4.5731, Value Loss: 0.0934, Total Loss: 4.6665, LR: 0.001767
2025-04-20 21:44:34,360 [INFO] Epoch 14/15 - Policy Loss: 4.5660, Value Loss: 0.0916, Total Loss: 4.6576, LR: 0.003367
2025-04-20 21:45:15,894 [INFO] Epoch 15/15 - Policy Loss: 4.5600, Value Loss: 0.0901, Total Loss: 4.6501, LR: 0.004967
2025-04-20 21:45:16,030 [INFO] 训练完成，总损失: 4.6501
2025-04-20 21:45:16,030 [INFO] 保存迭代 8 的模型
2025-04-20 21:45:17,463 [INFO] Model saved to ./models/best.pt
2025-04-20 21:45:18,242 [INFO] Model saved to ./models/iteration_8.pt
2025-04-20 21:45:18,242 [INFO] 所有训练迭代完成
2025-04-20 21:45:18,242 [INFO] 开始迭代 9/200
2025-04-20 21:45:18,242 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-21 04:31:51,362 [INFO] 保存训练样本
2025-04-21 04:32:20,014 [INFO] 截断训练样本，保持长度为 200000
2025-04-21 04:32:21,830 [INFO] 使用 200000 个样本训练神经网络
2025-04-21 04:32:21,832 [INFO] Training with 200000 examples
2025-04-21 04:32:21,833 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-21 04:32:21,982 [INFO] 循环学习率周期大小: 144 步
2025-04-21 04:33:03,711 [INFO] Epoch 1/15 - Policy Loss: 4.7464, Value Loss: 0.1553, Total Loss: 4.9018, LR: 0.001767
2025-04-21 04:33:44,310 [INFO] Epoch 2/15 - Policy Loss: 4.7025, Value Loss: 0.1399, Total Loss: 4.8424, LR: 0.003367
2025-04-21 04:34:26,716 [INFO] Epoch 3/15 - Policy Loss: 4.6672, Value Loss: 0.1325, Total Loss: 4.7997, LR: 0.004967
2025-04-21 04:35:07,669 [INFO] Epoch 4/15 - Policy Loss: 4.6395, Value Loss: 0.1278, Total Loss: 4.7672, LR: 0.003433
2025-04-21 04:35:48,197 [INFO] Epoch 5/15 - Policy Loss: 4.6135, Value Loss: 0.1224, Total Loss: 4.7359, LR: 0.001833
2025-04-21 04:36:30,558 [INFO] Epoch 6/15 - Policy Loss: 4.5906, Value Loss: 0.1167, Total Loss: 4.7073, LR: 0.000233
2025-04-21 04:37:12,428 [INFO] Epoch 7/15 - Policy Loss: 4.5732, Value Loss: 0.1117, Total Loss: 4.6849, LR: 0.001767
2025-04-21 04:37:55,173 [INFO] Epoch 8/15 - Policy Loss: 4.5586, Value Loss: 0.1076, Total Loss: 4.6662, LR: 0.003367
2025-04-21 04:38:38,328 [INFO] Epoch 9/15 - Policy Loss: 4.5478, Value Loss: 0.1044, Total Loss: 4.6523, LR: 0.004967
2025-04-21 04:39:20,476 [INFO] Epoch 10/15 - Policy Loss: 4.5381, Value Loss: 0.1019, Total Loss: 4.6400, LR: 0.003433
2025-04-21 04:40:03,343 [INFO] Epoch 11/15 - Policy Loss: 4.5282, Value Loss: 0.0998, Total Loss: 4.6280, LR: 0.001833
2025-04-21 04:40:45,348 [INFO] Epoch 12/15 - Policy Loss: 4.5187, Value Loss: 0.0977, Total Loss: 4.6163, LR: 0.000233
2025-04-21 04:41:27,779 [INFO] Epoch 13/15 - Policy Loss: 4.5098, Value Loss: 0.0957, Total Loss: 4.6055, LR: 0.001767
2025-04-21 04:42:09,885 [INFO] Epoch 14/15 - Policy Loss: 4.5014, Value Loss: 0.0940, Total Loss: 4.5954, LR: 0.003367
2025-04-21 04:42:50,695 [INFO] Epoch 15/15 - Policy Loss: 4.4949, Value Loss: 0.0926, Total Loss: 4.5875, LR: 0.004967
2025-04-21 04:42:50,739 [INFO] 训练完成，总损失: 4.5875
2025-04-21 04:42:50,739 [INFO] 保存迭代 9 的模型
2025-04-21 04:42:51,673 [INFO] Model saved to ./models/best.pt
2025-04-21 04:42:52,408 [INFO] Model saved to ./models/iteration_9.pt
2025-04-21 04:42:52,409 [INFO] 所有训练迭代完成
2025-04-21 04:42:52,409 [INFO] 开始迭代 10/200
2025-04-21 04:42:52,409 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-21 12:31:06,868 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-21 12:31:06,921 [INFO] 保存训练样本
2025-04-21 12:31:38,598 [INFO] 截断训练样本，保持长度为 200000
2025-04-21 12:31:38,839 [INFO] 使用 200000 个样本训练神经网络
2025-04-21 12:31:38,839 [INFO] Training with 200000 examples
2025-04-21 12:31:38,840 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-21 12:31:38,979 [INFO] 循环学习率周期大小: 144 步
2025-04-21 12:32:22,933 [INFO] Epoch 1/15 - Policy Loss: 4.6584, Value Loss: 0.1626, Total Loss: 4.8211, LR: 0.001767
2025-04-21 12:33:06,945 [INFO] Epoch 2/15 - Policy Loss: 4.6134, Value Loss: 0.1496, Total Loss: 4.7631, LR: 0.003367
2025-04-21 12:33:51,351 [INFO] Epoch 3/15 - Policy Loss: 4.5766, Value Loss: 0.1404, Total Loss: 4.7170, LR: 0.004967
2025-04-21 12:34:35,723 [INFO] Epoch 4/15 - Policy Loss: 4.5465, Value Loss: 0.1353, Total Loss: 4.6818, LR: 0.003433
2025-04-21 12:35:18,838 [INFO] Epoch 5/15 - Policy Loss: 4.5167, Value Loss: 0.1292, Total Loss: 4.6458, LR: 0.001833
2025-04-21 12:36:04,918 [INFO] Epoch 6/15 - Policy Loss: 4.4917, Value Loss: 0.1228, Total Loss: 4.6145, LR: 0.000233
2025-04-21 12:36:49,404 [INFO] Epoch 7/15 - Policy Loss: 4.4714, Value Loss: 0.1177, Total Loss: 4.5891, LR: 0.001767
2025-04-21 12:37:33,573 [INFO] Epoch 8/15 - Policy Loss: 4.4543, Value Loss: 0.1137, Total Loss: 4.5680, LR: 0.003367
2025-04-21 12:38:17,482 [INFO] Epoch 9/15 - Policy Loss: 4.4403, Value Loss: 0.1102, Total Loss: 4.5505, LR: 0.004967
2025-04-21 12:39:01,933 [INFO] Epoch 10/15 - Policy Loss: 4.4296, Value Loss: 0.1079, Total Loss: 4.5375, LR: 0.003433
2025-04-21 12:39:47,440 [INFO] Epoch 11/15 - Policy Loss: 4.4192, Value Loss: 0.1055, Total Loss: 4.5247, LR: 0.001833
2025-04-21 12:40:30,060 [INFO] Epoch 12/15 - Policy Loss: 4.4084, Value Loss: 0.1031, Total Loss: 4.5115, LR: 0.000233
2025-04-21 12:41:14,910 [INFO] Epoch 13/15 - Policy Loss: 4.3985, Value Loss: 0.1010, Total Loss: 4.4994, LR: 0.001767
2025-04-21 12:42:03,086 [INFO] Epoch 14/15 - Policy Loss: 4.3888, Value Loss: 0.0992, Total Loss: 4.4880, LR: 0.003367
2025-04-21 12:42:49,919 [INFO] Epoch 15/15 - Policy Loss: 4.3815, Value Loss: 0.0977, Total Loss: 4.4793, LR: 0.004967
2025-04-21 12:42:49,955 [INFO] 训练完成，总损失: 4.4793
2025-04-21 12:42:49,955 [INFO] 保存迭代 10 的模型
2025-04-21 12:42:51,460 [INFO] Model saved to ./models/best.pt
2025-04-21 12:42:52,187 [INFO] Model saved to ./models/iteration_10.pt
2025-04-21 12:42:52,187 [INFO] 所有训练迭代完成
2025-04-21 12:42:52,187 [INFO] 开始迭代 11/200
2025-04-21 12:42:52,187 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-21 18:50:14,659 [INFO] 设置多进程启动方法为: spawn
2025-04-21 18:50:14,709 [INFO] CUDA可用，使用GPU
2025-04-21 18:50:14,709 [INFO] 配置参数:
2025-04-21 18:50:14,709 [INFO] 训练参数:
2025-04-21 18:50:14,709 [INFO]   训练轮数: 25
2025-04-21 18:50:14,709 [INFO]   批量大小: 4096
2025-04-21 18:50:14,709 [INFO]   迭代次数: 300
2025-04-21 18:50:14,709 [INFO]   每次迭代的自我对弈次数: 100
2025-04-21 18:50:14,709 [INFO]   训练样本队列最大长度: 200000
2025-04-21 18:50:14,709 [INFO]   保留的历史迭代数: 20
2025-04-21 18:50:14,709 [INFO]   新模型胜率阈值: 0.55
2025-04-21 18:50:14,709 [INFO]   竞技场比赛次数: 40
2025-04-21 18:50:14,709 [INFO]   温度阈值: 5
2025-04-21 18:50:14,710 [INFO] 神经网络参数:
2025-04-21 18:50:14,710 [INFO]   通道数: 256
2025-04-21 18:50:14,710 [INFO]   Dropout率: 0.3
2025-04-21 18:50:14,710 [INFO]   学习率范围: 0.0001 - 0.005
2025-04-21 18:50:14,710 [INFO]   梯度裁剪: 1.0
2025-04-21 18:50:14,710 [INFO]   优化器: adam
2025-04-21 18:50:14,710 [INFO] MCTS参数:
2025-04-21 18:50:14,710 [INFO]   模拟次数: 800
2025-04-21 18:50:14,710 [INFO]   PUCT常数: 4.0
2025-04-21 18:50:14,710 [INFO]   Dirichlet噪声参数: 0.3
2025-04-21 18:50:14,710 [INFO]   Dirichlet噪声权重: 0.25
2025-04-21 18:50:14,710 [INFO] 游戏参数:
2025-04-21 18:50:14,710 [INFO]   棋盘大小: 15
2025-04-21 18:50:14,710 [INFO]   获胜所需的连续棋子数: 5
2025-04-21 18:50:14,710 [INFO] 系统参数:
2025-04-21 18:50:14,710 [INFO]   使用CUDA: True
2025-04-21 18:50:14,710 [INFO]   检查点目录: ./models
2025-04-21 18:50:14,710 [INFO]   数据目录: ./data
2025-04-21 18:50:14,710 [INFO]   加载模型: False
2025-04-21 18:50:14,710 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-21 18:50:14,710 [INFO]   工作线程数: 4
2025-04-21 18:50:14,710 [INFO]   使用Weights & Biases: False
2025-04-21 18:50:14,710 [INFO] GUI参数:
2025-04-21 18:50:14,710 [INFO]   窗口宽度: 800
2025-04-21 18:50:14,710 [INFO]   窗口高度: 850
2025-04-21 18:50:14,710 [INFO]   格子大小: 40
2025-04-21 18:50:14,710 [INFO]   边距: 40
2025-04-21 18:50:14,710 [INFO]   底部边距: 80
2025-04-21 18:50:14,710 [INFO]   帧率: 30
2025-04-21 18:50:14,883 [INFO] Using device: cuda
2025-04-21 18:50:16,074 [INFO] 设置循环学习率: 最小值=0.0001, 最大值=0.005
2025-04-21 18:50:16,075 [INFO] 设置并行进程数为: 8
2025-04-21 18:50:16,075 [INFO] 开始训练
2025-04-21 18:50:16,075 [INFO] 开始迭代 1/300
2025-04-21 18:50:16,075 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-21 19:56:09,018 [INFO] 设置多进程启动方法为: spawn
2025-04-21 19:56:09,074 [INFO] CUDA可用，使用GPU
2025-04-21 19:56:09,074 [INFO] 配置参数:
2025-04-21 19:56:09,074 [INFO] 训练参数:
2025-04-21 19:56:09,074 [INFO]   训练轮数: 25
2025-04-21 19:56:09,074 [INFO]   批量大小: 4096
2025-04-21 19:56:09,074 [INFO]   迭代次数: 300
2025-04-21 19:56:09,074 [INFO]   每次迭代的自我对弈次数: 100
2025-04-21 19:56:09,074 [INFO]   训练样本队列最大长度: 200000
2025-04-21 19:56:09,074 [INFO]   保留的历史迭代数: 20
2025-04-21 19:56:09,074 [INFO]   新模型胜率阈值: 0.55
2025-04-21 19:56:09,074 [INFO]   竞技场比赛次数: 40
2025-04-21 19:56:09,074 [INFO]   温度阈值: 5
2025-04-21 19:56:09,074 [INFO] 神经网络参数:
2025-04-21 19:56:09,074 [INFO]   通道数: 256
2025-04-21 19:56:09,074 [INFO]   Dropout率: 0.3
2025-04-21 19:56:09,074 [INFO]   学习率范围: 0.0001 - 0.005
2025-04-21 19:56:09,074 [INFO]   梯度裁剪: 1.0
2025-04-21 19:56:09,074 [INFO]   优化器: adam
2025-04-21 19:56:09,074 [INFO] MCTS参数:
2025-04-21 19:56:09,074 [INFO]   模拟次数: 800
2025-04-21 19:56:09,075 [INFO]   PUCT常数: 4.0
2025-04-21 19:56:09,075 [INFO]   Dirichlet噪声参数: 0.3
2025-04-21 19:56:09,075 [INFO]   Dirichlet噪声权重: 0.25
2025-04-21 19:56:09,075 [INFO] 游戏参数:
2025-04-21 19:56:09,075 [INFO]   棋盘大小: 15
2025-04-21 19:56:09,075 [INFO]   获胜所需的连续棋子数: 5
2025-04-21 19:56:09,075 [INFO] 系统参数:
2025-04-21 19:56:09,075 [INFO]   使用CUDA: True
2025-04-21 19:56:09,075 [INFO]   检查点目录: ./models
2025-04-21 19:56:09,075 [INFO]   数据目录: ./data
2025-04-21 19:56:09,075 [INFO]   加载模型: False
2025-04-21 19:56:09,075 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-21 19:56:09,075 [INFO]   工作线程数: 4
2025-04-21 19:56:09,075 [INFO]   使用Weights & Biases: False
2025-04-21 19:56:09,075 [INFO] GUI参数:
2025-04-21 19:56:09,075 [INFO]   窗口宽度: 800
2025-04-21 19:56:09,075 [INFO]   窗口高度: 850
2025-04-21 19:56:09,075 [INFO]   格子大小: 40
2025-04-21 19:56:09,075 [INFO]   边距: 40
2025-04-21 19:56:09,075 [INFO]   底部边距: 80
2025-04-21 19:56:09,075 [INFO]   帧率: 30
2025-04-21 19:56:09,236 [INFO] Using device: cuda
2025-04-21 19:56:10,350 [INFO] 设置循环学习率: 最小值=0.0001, 最大值=0.005
2025-04-21 19:56:10,350 [INFO] 设置并行进程数为: 8
2025-04-21 19:56:10,350 [INFO] 开始训练
2025-04-21 19:56:10,350 [INFO] 开始迭代 1/300
2025-04-21 19:56:10,350 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-21 20:42:21,704 [INFO] 设置多进程启动方法为: spawn
2025-04-21 20:42:21,905 [INFO] CUDA可用，使用GPU
2025-04-21 20:42:21,905 [INFO] 配置参数:
2025-04-21 20:42:21,906 [INFO] 训练参数:
2025-04-21 20:42:21,906 [INFO]   训练轮数: 25
2025-04-21 20:42:21,906 [INFO]   批量大小: 4096
2025-04-21 20:42:21,906 [INFO]   迭代次数: 300
2025-04-21 20:42:21,906 [INFO]   每次迭代的自我对弈次数: 100
2025-04-21 20:42:21,906 [INFO]   训练样本队列最大长度: 200000
2025-04-21 20:42:21,906 [INFO]   保留的历史迭代数: 20
2025-04-21 20:42:21,906 [INFO]   新模型胜率阈值: 0.55
2025-04-21 20:42:21,906 [INFO]   竞技场比赛次数: 40
2025-04-21 20:42:21,906 [INFO]   温度阈值: 5
2025-04-21 20:42:21,906 [INFO] 神经网络参数:
2025-04-21 20:42:21,906 [INFO]   通道数: 256
2025-04-21 20:42:21,906 [INFO]   Dropout率: 0.3
2025-04-21 20:42:21,906 [INFO]   学习率范围: 0.0001 - 0.005
2025-04-21 20:42:21,906 [INFO]   梯度裁剪: 1.0
2025-04-21 20:42:21,906 [INFO]   优化器: adam
2025-04-21 20:42:21,906 [INFO] MCTS参数:
2025-04-21 20:42:21,906 [INFO]   模拟次数: 800
2025-04-21 20:42:21,906 [INFO]   PUCT常数: 4.0
2025-04-21 20:42:21,906 [INFO]   Dirichlet噪声参数: 0.3
2025-04-21 20:42:21,906 [INFO]   Dirichlet噪声权重: 0.25
2025-04-21 20:42:21,906 [INFO] 游戏参数:
2025-04-21 20:42:21,906 [INFO]   棋盘大小: 15
2025-04-21 20:42:21,906 [INFO]   获胜所需的连续棋子数: 5
2025-04-21 20:42:21,906 [INFO] 系统参数:
2025-04-21 20:42:21,906 [INFO]   使用CUDA: True
2025-04-21 20:42:21,906 [INFO]   检查点目录: ./models
2025-04-21 20:42:21,906 [INFO]   数据目录: ./data
2025-04-21 20:42:21,906 [INFO]   加载模型: False
2025-04-21 20:42:21,906 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-21 20:42:21,906 [INFO]   工作线程数: 4
2025-04-21 20:42:21,906 [INFO]   使用Weights & Biases: False
2025-04-21 20:42:21,906 [INFO] GUI参数:
2025-04-21 20:42:21,906 [INFO]   窗口宽度: 800
2025-04-21 20:42:21,906 [INFO]   窗口高度: 850
2025-04-21 20:42:21,907 [INFO]   格子大小: 40
2025-04-21 20:42:21,907 [INFO]   边距: 40
2025-04-21 20:42:21,907 [INFO]   底部边距: 80
2025-04-21 20:42:21,907 [INFO]   帧率: 30
2025-04-21 20:42:22,070 [INFO] Using device: cuda
2025-04-21 20:42:23,145 [INFO] 设置循环学习率: 最小值=0.0001, 最大值=0.005
2025-04-21 20:42:23,145 [INFO] 设置并行进程数为: 8
2025-04-21 20:42:23,145 [INFO] 开始训练
2025-04-21 20:42:23,145 [INFO] 开始迭代 1/300
2025-04-21 20:42:23,145 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-21 20:52:54,107 [INFO] 设置多进程启动方法为: spawn
2025-04-21 20:52:54,474 [INFO] CUDA可用，使用GPU
2025-04-21 20:52:54,474 [INFO] 配置参数:
2025-04-21 20:52:54,474 [INFO] 训练参数:
2025-04-21 20:52:54,474 [INFO]   训练轮数: 25
2025-04-21 20:52:54,474 [INFO]   批量大小: 4096
2025-04-21 20:52:54,474 [INFO]   迭代次数: 300
2025-04-21 20:52:54,474 [INFO]   每次迭代的自我对弈次数: 100
2025-04-21 20:52:54,474 [INFO]   训练样本队列最大长度: 200000
2025-04-21 20:52:54,474 [INFO]   保留的历史迭代数: 20
2025-04-21 20:52:54,474 [INFO]   新模型胜率阈值: 0.55
2025-04-21 20:52:54,474 [INFO]   竞技场比赛次数: 40
2025-04-21 20:52:54,474 [INFO]   温度阈值: 5
2025-04-21 20:52:54,474 [INFO] 神经网络参数:
2025-04-21 20:52:54,474 [INFO]   通道数: 256
2025-04-21 20:52:54,474 [INFO]   Dropout率: 0.3
2025-04-21 20:52:54,474 [INFO]   学习率范围: 0.0001 - 0.005
2025-04-21 20:52:54,474 [INFO]   梯度裁剪: 1.0
2025-04-21 20:52:54,474 [INFO]   优化器: adam
2025-04-21 20:52:54,475 [INFO] MCTS参数:
2025-04-21 20:52:54,475 [INFO]   模拟次数: 800
2025-04-21 20:52:54,475 [INFO]   PUCT常数: 4.0
2025-04-21 20:52:54,475 [INFO]   Dirichlet噪声参数: 0.3
2025-04-21 20:52:54,475 [INFO]   Dirichlet噪声权重: 0.25
2025-04-21 20:52:54,475 [INFO] 游戏参数:
2025-04-21 20:52:54,475 [INFO]   棋盘大小: 15
2025-04-21 20:52:54,475 [INFO]   获胜所需的连续棋子数: 5
2025-04-21 20:52:54,475 [INFO] 系统参数:
2025-04-21 20:52:54,475 [INFO]   使用CUDA: True
2025-04-21 20:52:54,475 [INFO]   检查点目录: ./models
2025-04-21 20:52:54,475 [INFO]   数据目录: ./data
2025-04-21 20:52:54,475 [INFO]   加载模型: False
2025-04-21 20:52:54,475 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-21 20:52:54,475 [INFO]   工作线程数: 4
2025-04-21 20:52:54,475 [INFO]   使用Weights & Biases: False
2025-04-21 20:52:54,475 [INFO] GUI参数:
2025-04-21 20:52:54,475 [INFO]   窗口宽度: 800
2025-04-21 20:52:54,475 [INFO]   窗口高度: 850
2025-04-21 20:52:54,475 [INFO]   格子大小: 40
2025-04-21 20:52:54,475 [INFO]   边距: 40
2025-04-21 20:52:54,475 [INFO]   底部边距: 80
2025-04-21 20:52:54,475 [INFO]   帧率: 30
2025-04-21 20:52:54,639 [INFO] Using device: cuda
2025-04-21 20:52:55,745 [INFO] 设置循环学习率: 最小值=0.0001, 最大值=0.005
2025-04-21 20:52:55,745 [INFO] 设置并行进程数为: 8
2025-04-21 20:52:55,745 [INFO] 开始训练
2025-04-21 20:52:55,746 [INFO] 开始迭代 1/300
2025-04-21 20:52:55,746 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-21 22:19:43,648 [INFO] 保存训练样本
2025-04-21 22:19:44,522 [INFO] 使用 36976 个样本训练神经网络
2025-04-21 22:19:44,522 [INFO] Training with 36976 examples
2025-04-21 22:19:44,522 [INFO] 总训练步数: 225, 每轮次批次数: 9
2025-04-21 22:19:44,530 [INFO] 循环学习率周期大小: 45 步
2025-04-21 22:19:52,080 [INFO] Epoch 1/25 - Policy Loss: 5.4260, Value Loss: 1.0453, Total Loss: 6.4713, LR: 0.000971
2025-04-21 22:19:59,176 [INFO] Epoch 2/25 - Policy Loss: 5.4087, Value Loss: 0.9925, Total Loss: 6.4012, LR: 0.001951
2025-04-21 22:20:06,273 [INFO] Epoch 3/25 - Policy Loss: 5.3995, Value Loss: 0.9289, Total Loss: 6.3284, LR: 0.002931
2025-04-21 22:20:13,374 [INFO] Epoch 4/25 - Policy Loss: 5.3932, Value Loss: 0.8755, Total Loss: 6.2687, LR: 0.003911
2025-04-21 22:20:20,593 [INFO] Epoch 5/25 - Policy Loss: 5.3876, Value Loss: 0.8269, Total Loss: 6.2145, LR: 0.004891
2025-04-21 22:20:27,694 [INFO] Epoch 6/25 - Policy Loss: 5.3807, Value Loss: 0.7679, Total Loss: 6.1486, LR: 0.004129
2025-04-21 22:20:34,780 [INFO] Epoch 7/25 - Policy Loss: 5.3724, Value Loss: 0.6972, Total Loss: 6.0696, LR: 0.003149
2025-04-21 22:20:41,867 [INFO] Epoch 8/25 - Policy Loss: 5.3649, Value Loss: 0.6296, Total Loss: 5.9945, LR: 0.002169
2025-04-21 22:20:48,957 [INFO] Epoch 9/25 - Policy Loss: 5.3571, Value Loss: 0.5716, Total Loss: 5.9287, LR: 0.001189
2025-04-21 22:20:56,081 [INFO] Epoch 10/25 - Policy Loss: 5.3493, Value Loss: 0.5230, Total Loss: 5.8723, LR: 0.000209
2025-04-21 22:21:03,249 [INFO] Epoch 11/25 - Policy Loss: 5.3423, Value Loss: 0.4828, Total Loss: 5.8251, LR: 0.000971
2025-04-21 22:21:10,380 [INFO] Epoch 12/25 - Policy Loss: 5.3362, Value Loss: 0.4484, Total Loss: 5.7846, LR: 0.001951
2025-04-21 22:21:17,501 [INFO] Epoch 13/25 - Policy Loss: 5.3301, Value Loss: 0.4190, Total Loss: 5.7491, LR: 0.002931
2025-04-21 22:21:24,635 [INFO] Epoch 14/25 - Policy Loss: 5.3249, Value Loss: 0.3933, Total Loss: 5.7182, LR: 0.003911
2025-04-21 22:21:31,755 [INFO] Epoch 15/25 - Policy Loss: 5.3203, Value Loss: 0.3712, Total Loss: 5.6915, LR: 0.004891
2025-04-21 22:21:38,874 [INFO] Epoch 16/25 - Policy Loss: 5.3195, Value Loss: 0.3587, Total Loss: 5.6782, LR: 0.004129
2025-04-21 22:21:46,002 [INFO] Epoch 17/25 - Policy Loss: 5.3175, Value Loss: 0.3430, Total Loss: 5.6605, LR: 0.003149
2025-04-21 22:21:53,120 [INFO] Epoch 18/25 - Policy Loss: 5.3144, Value Loss: 0.3273, Total Loss: 5.6417, LR: 0.002169
2025-04-21 22:22:00,249 [INFO] Epoch 19/25 - Policy Loss: 5.3108, Value Loss: 0.3126, Total Loss: 5.6234, LR: 0.001189
2025-04-21 22:22:07,360 [INFO] Epoch 20/25 - Policy Loss: 5.3074, Value Loss: 0.2996, Total Loss: 5.6069, LR: 0.000209
2025-04-21 22:22:14,480 [INFO] Epoch 21/25 - Policy Loss: 5.3039, Value Loss: 0.2875, Total Loss: 5.5914, LR: 0.000971
2025-04-21 22:22:21,595 [INFO] Epoch 22/25 - Policy Loss: 5.3007, Value Loss: 0.2764, Total Loss: 5.5772, LR: 0.001951
2025-04-21 22:22:28,707 [INFO] Epoch 23/25 - Policy Loss: 5.2976, Value Loss: 0.2663, Total Loss: 5.5639, LR: 0.002931
2025-04-21 22:22:35,814 [INFO] Epoch 24/25 - Policy Loss: 5.2947, Value Loss: 0.2569, Total Loss: 5.5516, LR: 0.003911
2025-04-21 22:22:42,937 [INFO] Epoch 25/25 - Policy Loss: 5.2917, Value Loss: 0.2484, Total Loss: 5.5401, LR: 0.004891
2025-04-21 22:22:42,943 [INFO] 训练完成，总损失: 5.5401
2025-04-21 22:22:42,943 [INFO] 保存迭代 1 的模型
2025-04-21 22:22:43,226 [INFO] Model saved to ./models/best.pt
2025-04-21 22:22:43,494 [INFO] Model saved to ./models/iteration_1.pt
2025-04-21 22:22:43,494 [INFO] 所有训练迭代完成
2025-04-21 22:22:43,494 [INFO] 开始迭代 2/300
2025-04-21 22:22:43,494 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-21 22:59:28,806 [INFO] 设置多进程启动方法为: spawn
2025-04-21 22:59:29,031 [INFO] CUDA可用，使用GPU
2025-04-21 22:59:29,031 [INFO] 配置参数:
2025-04-21 22:59:29,031 [INFO] 训练参数:
2025-04-21 22:59:29,031 [INFO]   训练轮数: 25
2025-04-21 22:59:29,031 [INFO]   批量大小: 2048
2025-04-21 22:59:29,031 [INFO]   迭代次数: 300
2025-04-21 22:59:29,031 [INFO]   每次迭代的自我对弈次数: 100
2025-04-21 22:59:29,031 [INFO]   训练样本队列最大长度: 200000
2025-04-21 22:59:29,031 [INFO]   保留的历史迭代数: 20
2025-04-21 22:59:29,031 [INFO]   新模型胜率阈值: 0.55
2025-04-21 22:59:29,031 [INFO]   竞技场比赛次数: 40
2025-04-21 22:59:29,031 [INFO]   温度阈值: 5
2025-04-21 22:59:29,031 [INFO] 神经网络参数:
2025-04-21 22:59:29,031 [INFO]   通道数: 256
2025-04-21 22:59:29,031 [INFO]   Dropout率: 0.3
2025-04-21 22:59:29,031 [INFO]   学习率范围: 0.0001 - 0.005
2025-04-21 22:59:29,032 [INFO]   梯度裁剪: 1.0
2025-04-21 22:59:29,032 [INFO]   优化器: adam
2025-04-21 22:59:29,032 [INFO] MCTS参数:
2025-04-21 22:59:29,032 [INFO]   模拟次数: 800
2025-04-21 22:59:29,032 [INFO]   PUCT常数: 4.0
2025-04-21 22:59:29,032 [INFO]   Dirichlet噪声参数: 0.3
2025-04-21 22:59:29,032 [INFO]   Dirichlet噪声权重: 0.25
2025-04-21 22:59:29,032 [INFO] 游戏参数:
2025-04-21 22:59:29,032 [INFO]   棋盘大小: 15
2025-04-21 22:59:29,032 [INFO]   获胜所需的连续棋子数: 5
2025-04-21 22:59:29,032 [INFO] 系统参数:
2025-04-21 22:59:29,032 [INFO]   使用CUDA: True
2025-04-21 22:59:29,032 [INFO]   检查点目录: ./models
2025-04-21 22:59:29,032 [INFO]   数据目录: ./data
2025-04-21 22:59:29,032 [INFO]   加载模型: False
2025-04-21 22:59:29,032 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-21 22:59:29,032 [INFO]   工作线程数: 4
2025-04-21 22:59:29,032 [INFO]   使用Weights & Biases: False
2025-04-21 22:59:29,032 [INFO] GUI参数:
2025-04-21 22:59:29,032 [INFO]   窗口宽度: 800
2025-04-21 22:59:29,032 [INFO]   窗口高度: 850
2025-04-21 22:59:29,032 [INFO]   格子大小: 40
2025-04-21 22:59:29,032 [INFO]   边距: 40
2025-04-21 22:59:29,032 [INFO]   底部边距: 80
2025-04-21 22:59:29,032 [INFO]   帧率: 30
2025-04-21 22:59:29,196 [INFO] Using device: cuda
2025-04-21 22:59:30,309 [INFO] 设置循环学习率: 最小值=0.0001, 最大值=0.005
2025-04-21 22:59:30,309 [INFO] 设置并行进程数为: 8
2025-04-21 22:59:30,310 [INFO] 开始训练
2025-04-21 22:59:30,310 [INFO] 加载之前的训练样本
2025-04-21 22:59:30,663 [INFO] 加载了 1 组训练样本
2025-04-21 22:59:30,663 [INFO] 开始迭代 1/300
2025-04-21 22:59:30,663 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 00:30:49,240 [INFO] 保存训练样本
2025-04-22 00:30:51,284 [INFO] 使用 75264 个样本训练神经网络
2025-04-22 00:30:51,284 [INFO] Training with 75264 examples
2025-04-22 00:30:51,284 [INFO] 总训练步数: 900, 每轮次批次数: 36
2025-04-22 00:30:51,440 [INFO] 循环学习率周期大小: 180 步
2025-04-22 00:31:05,833 [INFO] Epoch 1/25 - Policy Loss: 5.4089, Value Loss: 0.9564, Total Loss: 6.3653, LR: 0.001053
2025-04-22 00:31:19,766 [INFO] Epoch 2/25 - Policy Loss: 5.3942, Value Loss: 0.8557, Total Loss: 6.2500, LR: 0.002033
2025-04-22 00:31:33,710 [INFO] Epoch 3/25 - Policy Loss: 5.3792, Value Loss: 0.6908, Total Loss: 6.0700, LR: 0.003013
2025-04-22 00:31:47,654 [INFO] Epoch 4/25 - Policy Loss: 5.3629, Value Loss: 0.5548, Total Loss: 5.9177, LR: 0.003993
2025-04-22 00:32:01,584 [INFO] Epoch 5/25 - Policy Loss: 5.3478, Value Loss: 0.4649, Total Loss: 5.8127, LR: 0.004973
2025-04-22 00:32:15,517 [INFO] Epoch 6/25 - Policy Loss: 5.3348, Value Loss: 0.4013, Total Loss: 5.7360, LR: 0.004047
2025-04-22 00:32:29,450 [INFO] Epoch 7/25 - Policy Loss: 5.3228, Value Loss: 0.3563, Total Loss: 5.6792, LR: 0.003067
2025-04-22 00:32:43,388 [INFO] Epoch 8/25 - Policy Loss: 5.3111, Value Loss: 0.3193, Total Loss: 5.6305, LR: 0.002087
2025-04-22 00:32:57,340 [INFO] Epoch 9/25 - Policy Loss: 5.3004, Value Loss: 0.2897, Total Loss: 5.5900, LR: 0.001107
2025-04-22 00:33:11,295 [INFO] Epoch 10/25 - Policy Loss: 5.2915, Value Loss: 0.2653, Total Loss: 5.5568, LR: 0.000127
2025-04-22 00:33:25,247 [INFO] Epoch 11/25 - Policy Loss: 5.2834, Value Loss: 0.2454, Total Loss: 5.5288, LR: 0.001053
2025-04-22 00:33:39,177 [INFO] Epoch 12/25 - Policy Loss: 5.2768, Value Loss: 0.2290, Total Loss: 5.5058, LR: 0.002033
2025-04-22 00:33:53,108 [INFO] Epoch 13/25 - Policy Loss: 5.2719, Value Loss: 0.2152, Total Loss: 5.4871, LR: 0.003013
2025-04-22 00:34:07,038 [INFO] Epoch 14/25 - Policy Loss: 5.2675, Value Loss: 0.2035, Total Loss: 5.4709, LR: 0.003993
2025-04-22 00:34:20,967 [INFO] Epoch 15/25 - Policy Loss: 5.2644, Value Loss: 0.1934, Total Loss: 5.4578, LR: 0.004973
2025-04-22 00:34:34,892 [INFO] Epoch 16/25 - Policy Loss: 5.2616, Value Loss: 0.1855, Total Loss: 5.4471, LR: 0.004047
2025-04-22 00:34:48,832 [INFO] Epoch 17/25 - Policy Loss: 5.2584, Value Loss: 0.1780, Total Loss: 5.4364, LR: 0.003067
2025-04-22 00:35:02,758 [INFO] Epoch 18/25 - Policy Loss: 5.2551, Value Loss: 0.1711, Total Loss: 5.4261, LR: 0.002087
2025-04-22 00:35:16,697 [INFO] Epoch 19/25 - Policy Loss: 5.2518, Value Loss: 0.1646, Total Loss: 5.4164, LR: 0.001107
2025-04-22 00:35:30,620 [INFO] Epoch 20/25 - Policy Loss: 5.2487, Value Loss: 0.1586, Total Loss: 5.4073, LR: 0.000127
2025-04-22 00:35:44,560 [INFO] Epoch 21/25 - Policy Loss: 5.2459, Value Loss: 0.1531, Total Loss: 5.3989, LR: 0.001053
2025-04-22 00:35:58,654 [INFO] Epoch 22/25 - Policy Loss: 5.2430, Value Loss: 0.1480, Total Loss: 5.3910, LR: 0.002033
2025-04-22 00:36:12,693 [INFO] Epoch 23/25 - Policy Loss: 5.2409, Value Loss: 0.1435, Total Loss: 5.3844, LR: 0.003013
2025-04-22 00:36:26,873 [INFO] Epoch 24/25 - Policy Loss: 5.2386, Value Loss: 0.1393, Total Loss: 5.3779, LR: 0.003993
2025-04-22 00:36:41,046 [INFO] Epoch 25/25 - Policy Loss: 5.2366, Value Loss: 0.1355, Total Loss: 5.3721, LR: 0.004973
2025-04-22 00:36:41,058 [INFO] 训练完成，总损失: 5.3721
2025-04-22 00:36:41,058 [INFO] 保存迭代 1 的模型
2025-04-22 00:36:41,428 [INFO] Model saved to ./models/best.pt
2025-04-22 00:36:41,795 [INFO] Model saved to ./models/iteration_1.pt
2025-04-22 00:36:41,795 [INFO] 所有训练迭代完成
2025-04-22 00:36:41,795 [INFO] 开始迭代 2/300
2025-04-22 00:36:41,795 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 01:11:12,258 [INFO] 设置多进程启动方法为: spawn
2025-04-22 01:11:12,469 [INFO] CUDA可用，使用GPU
2025-04-22 01:11:12,469 [INFO] 配置参数:
2025-04-22 01:11:12,469 [INFO] 训练参数:
2025-04-22 01:11:12,469 [INFO]   训练轮数: 25
2025-04-22 01:11:12,469 [INFO]   批量大小: 2048
2025-04-22 01:11:12,469 [INFO]   迭代次数: 300
2025-04-22 01:11:12,469 [INFO]   每次迭代的自我对弈次数: 100
2025-04-22 01:11:12,469 [INFO]   训练样本队列最大长度: 200000
2025-04-22 01:11:12,469 [INFO]   保留的历史迭代数: 20
2025-04-22 01:11:12,469 [INFO]   新模型胜率阈值: 0.55
2025-04-22 01:11:12,469 [INFO]   竞技场比赛次数: 40
2025-04-22 01:11:12,469 [INFO]   温度阈值: 5
2025-04-22 01:11:12,469 [INFO] 神经网络参数:
2025-04-22 01:11:12,469 [INFO]   通道数: 256
2025-04-22 01:11:12,469 [INFO]   Dropout率: 0.3
2025-04-22 01:11:12,469 [INFO]   学习率范围: 0.0001 - 0.005
2025-04-22 01:11:12,469 [INFO]   梯度裁剪: 1.0
2025-04-22 01:11:12,469 [INFO]   优化器: adam
2025-04-22 01:11:12,469 [INFO] MCTS参数:
2025-04-22 01:11:12,469 [INFO]   模拟次数: 800
2025-04-22 01:11:12,469 [INFO]   PUCT常数: 4.0
2025-04-22 01:11:12,469 [INFO]   Dirichlet噪声参数: 0.3
2025-04-22 01:11:12,469 [INFO]   Dirichlet噪声权重: 0.25
2025-04-22 01:11:12,469 [INFO] 游戏参数:
2025-04-22 01:11:12,469 [INFO]   棋盘大小: 15
2025-04-22 01:11:12,469 [INFO]   获胜所需的连续棋子数: 5
2025-04-22 01:11:12,469 [INFO] 系统参数:
2025-04-22 01:11:12,469 [INFO]   使用CUDA: True
2025-04-22 01:11:12,469 [INFO]   检查点目录: ./models
2025-04-22 01:11:12,469 [INFO]   数据目录: ./data
2025-04-22 01:11:12,470 [INFO]   加载模型: False
2025-04-22 01:11:12,470 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-22 01:11:12,470 [INFO]   工作线程数: 4
2025-04-22 01:11:12,470 [INFO]   使用Weights & Biases: False
2025-04-22 01:11:12,470 [INFO] GUI参数:
2025-04-22 01:11:12,470 [INFO]   窗口宽度: 800
2025-04-22 01:11:12,470 [INFO]   窗口高度: 850
2025-04-22 01:11:12,470 [INFO]   格子大小: 40
2025-04-22 01:11:12,470 [INFO]   边距: 40
2025-04-22 01:11:12,470 [INFO]   底部边距: 80
2025-04-22 01:11:12,470 [INFO]   帧率: 30
2025-04-22 01:11:12,633 [INFO] Using device: cuda
2025-04-22 01:11:13,749 [INFO] 设置循环学习率: 最小值=0.0001, 最大值=0.005
2025-04-22 01:11:13,749 [INFO] 设置并行进程数为: 8
2025-04-22 01:11:13,749 [INFO] 开始训练
2025-04-22 01:11:13,749 [INFO] 加载之前的训练样本
2025-04-22 01:11:14,465 [INFO] 加载了 2 组训练样本
2025-04-22 01:11:14,465 [INFO] 开始迭代 1/300
2025-04-22 01:11:14,465 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 02:50:20,224 [INFO] 保存训练样本
2025-04-22 02:50:23,822 [INFO] 使用 116912 个样本训练神经网络
2025-04-22 02:50:23,822 [INFO] Training with 116912 examples
2025-04-22 02:50:23,823 [INFO] 总训练步数: 1425, 每轮次批次数: 57
2025-04-22 02:50:24,154 [INFO] 循环学习率周期大小: 285 步
2025-04-22 02:50:47,101 [INFO] Epoch 1/25 - Policy Loss: 5.4126, Value Loss: 0.9768, Total Loss: 6.3894, LR: 0.001063
2025-04-22 02:51:09,509 [INFO] Epoch 2/25 - Policy Loss: 5.3890, Value Loss: 0.8533, Total Loss: 6.2423, LR: 0.002043
2025-04-22 02:51:31,928 [INFO] Epoch 3/25 - Policy Loss: 5.3671, Value Loss: 0.6908, Total Loss: 6.0579, LR: 0.003023
2025-04-22 02:51:54,322 [INFO] Epoch 4/25 - Policy Loss: 5.3489, Value Loss: 0.5547, Total Loss: 5.9036, LR: 0.004003
2025-04-22 02:52:16,718 [INFO] Epoch 5/25 - Policy Loss: 5.3357, Value Loss: 0.4688, Total Loss: 5.8046, LR: 0.004983
2025-04-22 02:52:39,039 [INFO] Epoch 6/25 - Policy Loss: 5.3229, Value Loss: 0.4070, Total Loss: 5.7299, LR: 0.004037
2025-04-22 02:53:01,399 [INFO] Epoch 7/25 - Policy Loss: 5.3113, Value Loss: 0.3599, Total Loss: 5.6712, LR: 0.003057
2025-04-22 02:53:23,814 [INFO] Epoch 8/25 - Policy Loss: 5.3005, Value Loss: 0.3224, Total Loss: 5.6229, LR: 0.002077
2025-04-22 02:53:46,227 [INFO] Epoch 9/25 - Policy Loss: 5.2906, Value Loss: 0.2923, Total Loss: 5.5829, LR: 0.001097
2025-04-22 02:54:08,641 [INFO] Epoch 10/25 - Policy Loss: 5.2815, Value Loss: 0.2677, Total Loss: 5.5492, LR: 0.000117
2025-04-22 02:54:30,794 [INFO] Epoch 11/25 - Policy Loss: 5.2741, Value Loss: 0.2474, Total Loss: 5.5214, LR: 0.001063
2025-04-22 02:54:52,856 [INFO] Epoch 12/25 - Policy Loss: 5.2676, Value Loss: 0.2305, Total Loss: 5.4981, LR: 0.002043
2025-04-22 02:55:15,133 [INFO] Epoch 13/25 - Policy Loss: 5.2628, Value Loss: 0.2170, Total Loss: 5.4798, LR: 0.003023
2025-04-22 02:55:37,190 [INFO] Epoch 14/25 - Policy Loss: 5.2590, Value Loss: 0.2057, Total Loss: 5.4647, LR: 0.004003
2025-04-22 02:55:59,236 [INFO] Epoch 15/25 - Policy Loss: 5.2556, Value Loss: 0.1960, Total Loss: 5.4516, LR: 0.004983
2025-04-22 02:56:21,283 [INFO] Epoch 16/25 - Policy Loss: 5.2534, Value Loss: 0.1877, Total Loss: 5.4411, LR: 0.004037
2025-04-22 02:56:43,318 [INFO] Epoch 17/25 - Policy Loss: 5.2503, Value Loss: 0.1799, Total Loss: 5.4303, LR: 0.003057
2025-04-22 02:57:05,759 [INFO] Epoch 18/25 - Policy Loss: 5.2471, Value Loss: 0.1725, Total Loss: 5.4196, LR: 0.002077
2025-04-22 02:57:28,272 [INFO] Epoch 19/25 - Policy Loss: 5.2437, Value Loss: 0.1657, Total Loss: 5.4093, LR: 0.001097
2025-04-22 02:57:50,752 [INFO] Epoch 20/25 - Policy Loss: 5.2407, Value Loss: 0.1594, Total Loss: 5.4001, LR: 0.000117
2025-04-22 02:58:13,315 [INFO] Epoch 21/25 - Policy Loss: 5.2379, Value Loss: 0.1537, Total Loss: 5.3916, LR: 0.001063
2025-04-22 02:58:35,891 [INFO] Epoch 22/25 - Policy Loss: 5.2354, Value Loss: 0.1487, Total Loss: 5.3841, LR: 0.002043
2025-04-22 02:58:58,453 [INFO] Epoch 23/25 - Policy Loss: 5.2330, Value Loss: 0.1440, Total Loss: 5.3770, LR: 0.003023
2025-04-22 02:59:20,810 [INFO] Epoch 24/25 - Policy Loss: 5.2310, Value Loss: 0.1398, Total Loss: 5.3708, LR: 0.004003
2025-04-22 02:59:42,889 [INFO] Epoch 25/25 - Policy Loss: 5.2293, Value Loss: 0.1362, Total Loss: 5.3655, LR: 0.004983
2025-04-22 02:59:42,903 [INFO] 训练完成，总损失: 5.3655
2025-04-22 02:59:42,903 [INFO] 保存迭代 1 的模型
2025-04-22 02:59:43,264 [INFO] Model saved to ./models/best.pt
2025-04-22 02:59:43,603 [INFO] Model saved to ./models/iteration_1.pt
2025-04-22 02:59:43,603 [INFO] 所有训练迭代完成
2025-04-22 02:59:43,603 [INFO] 开始迭代 2/300
2025-04-22 02:59:43,604 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 04:39:01,731 [INFO] 保存训练样本
2025-04-22 04:39:06,402 [INFO] 使用 163616 个样本训练神经网络
2025-04-22 04:39:06,403 [INFO] Training with 163616 examples
2025-04-22 04:39:06,404 [INFO] 总训练步数: 1975, 每轮次批次数: 79
2025-04-22 04:39:06,783 [INFO] 循环学习率周期大小: 395 步
2025-04-22 04:39:37,074 [INFO] Epoch 1/25 - Policy Loss: 5.0200, Value Loss: 0.2993, Total Loss: 5.3193, LR: 0.001068
2025-04-22 04:40:07,375 [INFO] Epoch 2/25 - Policy Loss: 4.9325, Value Loss: 0.1935, Total Loss: 5.1260, LR: 0.002048
2025-04-22 04:40:37,699 [INFO] Epoch 3/25 - Policy Loss: 4.8705, Value Loss: 0.1509, Total Loss: 5.0215, LR: 0.003028
2025-04-22 04:41:07,992 [INFO] Epoch 4/25 - Policy Loss: 4.8180, Value Loss: 0.1295, Total Loss: 4.9475, LR: 0.004008
2025-04-22 04:41:38,260 [INFO] Epoch 5/25 - Policy Loss: 4.7662, Value Loss: 0.1179, Total Loss: 4.8841, LR: 0.004988
2025-04-22 04:42:08,517 [INFO] Epoch 6/25 - Policy Loss: 4.7181, Value Loss: 0.1101, Total Loss: 4.8282, LR: 0.004032
2025-04-22 04:42:38,801 [INFO] Epoch 7/25 - Policy Loss: 4.6658, Value Loss: 0.1025, Total Loss: 4.7683, LR: 0.003052
2025-04-22 04:43:09,074 [INFO] Epoch 8/25 - Policy Loss: 4.6149, Value Loss: 0.0959, Total Loss: 4.7108, LR: 0.002072
2025-04-22 04:43:39,365 [INFO] Epoch 9/25 - Policy Loss: 4.5672, Value Loss: 0.0903, Total Loss: 4.6576, LR: 0.001092
2025-04-22 04:44:09,646 [INFO] Epoch 10/25 - Policy Loss: 4.5249, Value Loss: 0.0856, Total Loss: 4.6105, LR: 0.000112
2025-04-22 04:44:39,929 [INFO] Epoch 11/25 - Policy Loss: 4.4881, Value Loss: 0.0818, Total Loss: 4.5698, LR: 0.001068
2025-04-22 04:45:10,215 [INFO] Epoch 12/25 - Policy Loss: 4.4572, Value Loss: 0.0785, Total Loss: 4.5358, LR: 0.002048
2025-04-22 04:45:40,510 [INFO] Epoch 13/25 - Policy Loss: 4.4316, Value Loss: 0.0759, Total Loss: 4.5075, LR: 0.003028
2025-04-22 04:46:10,793 [INFO] Epoch 14/25 - Policy Loss: 4.4121, Value Loss: 0.0736, Total Loss: 4.4857, LR: 0.004008
2025-04-22 04:46:41,070 [INFO] Epoch 15/25 - Policy Loss: 4.3971, Value Loss: 0.0721, Total Loss: 4.4692, LR: 0.004988
2025-04-22 04:47:11,358 [INFO] Epoch 16/25 - Policy Loss: 4.3840, Value Loss: 0.0712, Total Loss: 4.4552, LR: 0.004032
2025-04-22 04:47:41,637 [INFO] Epoch 17/25 - Policy Loss: 4.3687, Value Loss: 0.0701, Total Loss: 4.4388, LR: 0.003052
2025-04-22 04:48:12,248 [INFO] Epoch 18/25 - Policy Loss: 4.3522, Value Loss: 0.0688, Total Loss: 4.4210, LR: 0.002072
2025-04-22 04:48:42,533 [INFO] Epoch 19/25 - Policy Loss: 4.3353, Value Loss: 0.0674, Total Loss: 4.4027, LR: 0.001092
2025-04-22 04:49:12,869 [INFO] Epoch 20/25 - Policy Loss: 4.3188, Value Loss: 0.0662, Total Loss: 4.3850, LR: 0.000112
2025-04-22 04:49:43,136 [INFO] Epoch 21/25 - Policy Loss: 4.3039, Value Loss: 0.0651, Total Loss: 4.3690, LR: 0.001068
2025-04-22 04:50:13,385 [INFO] Epoch 22/25 - Policy Loss: 4.2902, Value Loss: 0.0640, Total Loss: 4.3542, LR: 0.002048
2025-04-22 04:50:43,657 [INFO] Epoch 23/25 - Policy Loss: 4.2778, Value Loss: 0.0631, Total Loss: 4.3409, LR: 0.003028
2025-04-22 04:51:13,955 [INFO] Epoch 24/25 - Policy Loss: 4.2678, Value Loss: 0.0622, Total Loss: 4.3300, LR: 0.004008
2025-04-22 04:51:44,217 [INFO] Epoch 25/25 - Policy Loss: 4.2599, Value Loss: 0.0615, Total Loss: 4.3214, LR: 0.004988
2025-04-22 04:51:44,235 [INFO] 训练完成，总损失: 4.3214
2025-04-22 04:51:44,236 [INFO] 保存迭代 2 的模型
2025-04-22 04:51:44,575 [INFO] Model saved to ./models/best.pt
2025-04-22 04:51:44,823 [INFO] Model saved to ./models/iteration_2.pt
2025-04-22 04:51:44,824 [INFO] 所有训练迭代完成
2025-04-22 04:51:44,824 [INFO] 开始迭代 3/300
2025-04-22 04:51:44,824 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 06:21:19,389 [INFO] 保存训练样本
2025-04-22 06:21:23,673 [INFO] 截断训练样本，保持长度为 200000
2025-04-22 06:21:23,787 [INFO] 使用 200000 个样本训练神经网络
2025-04-22 06:21:23,787 [INFO] Training with 200000 examples
2025-04-22 06:21:23,787 [INFO] 总训练步数: 2425, 每轮次批次数: 97
2025-04-22 06:21:24,167 [INFO] 循环学习率周期大小: 485 步
2025-04-22 06:22:01,360 [INFO] Epoch 1/25 - Policy Loss: 4.3442, Value Loss: 0.2246, Total Loss: 4.5688, LR: 0.001070
2025-04-22 06:22:38,556 [INFO] Epoch 2/25 - Policy Loss: 4.2547, Value Loss: 0.1565, Total Loss: 4.4112, LR: 0.002050
2025-04-22 06:23:15,773 [INFO] Epoch 3/25 - Policy Loss: 4.1781, Value Loss: 0.1253, Total Loss: 4.3034, LR: 0.003030
2025-04-22 06:23:52,976 [INFO] Epoch 4/25 - Policy Loss: 4.1210, Value Loss: 0.1091, Total Loss: 4.2301, LR: 0.004010
2025-04-22 06:24:30,143 [INFO] Epoch 5/25 - Policy Loss: 4.0773, Value Loss: 0.0996, Total Loss: 4.1769, LR: 0.004990
2025-04-22 06:25:07,554 [INFO] Epoch 6/25 - Policy Loss: 4.0430, Value Loss: 0.0937, Total Loss: 4.1368, LR: 0.004030
2025-04-22 06:25:45,870 [INFO] Epoch 7/25 - Policy Loss: 4.0079, Value Loss: 0.0890, Total Loss: 4.0969, LR: 0.003050
2025-04-22 06:26:23,641 [INFO] Epoch 8/25 - Policy Loss: 3.9728, Value Loss: 0.0844, Total Loss: 4.0573, LR: 0.002070
2025-04-22 06:27:01,393 [INFO] Epoch 9/25 - Policy Loss: 3.9403, Value Loss: 0.0805, Total Loss: 4.0208, LR: 0.001090
2025-04-22 06:27:39,139 [INFO] Epoch 10/25 - Policy Loss: 3.9113, Value Loss: 0.0772, Total Loss: 3.9884, LR: 0.000110
2025-04-22 06:28:16,415 [INFO] Epoch 11/25 - Policy Loss: 3.8857, Value Loss: 0.0745, Total Loss: 3.9602, LR: 0.001070
2025-04-22 06:28:53,716 [INFO] Epoch 12/25 - Policy Loss: 3.8643, Value Loss: 0.0722, Total Loss: 3.9365, LR: 0.002050
2025-04-22 06:29:31,443 [INFO] Epoch 13/25 - Policy Loss: 3.8469, Value Loss: 0.0703, Total Loss: 3.9172, LR: 0.003030
2025-04-22 06:30:09,187 [INFO] Epoch 14/25 - Policy Loss: 3.8337, Value Loss: 0.0688, Total Loss: 3.9025, LR: 0.004010
2025-04-22 06:30:46,987 [INFO] Epoch 15/25 - Policy Loss: 3.8246, Value Loss: 0.0676, Total Loss: 3.8922, LR: 0.004990
2025-04-22 06:31:24,834 [INFO] Epoch 16/25 - Policy Loss: 3.8187, Value Loss: 0.0668, Total Loss: 3.8855, LR: 0.004030
2025-04-22 06:32:02,535 [INFO] Epoch 17/25 - Policy Loss: 3.8097, Value Loss: 0.0661, Total Loss: 3.8758, LR: 0.003050
2025-04-22 06:32:39,819 [INFO] Epoch 18/25 - Policy Loss: 3.7993, Value Loss: 0.0652, Total Loss: 3.8645, LR: 0.002070
2025-04-22 06:33:17,074 [INFO] Epoch 19/25 - Policy Loss: 3.7884, Value Loss: 0.0642, Total Loss: 3.8527, LR: 0.001090
2025-04-22 06:33:54,311 [INFO] Epoch 20/25 - Policy Loss: 3.7776, Value Loss: 0.0633, Total Loss: 3.8409, LR: 0.000110
2025-04-22 06:34:31,569 [INFO] Epoch 21/25 - Policy Loss: 3.7673, Value Loss: 0.0625, Total Loss: 3.8298, LR: 0.001070
2025-04-22 06:35:08,817 [INFO] Epoch 22/25 - Policy Loss: 3.7577, Value Loss: 0.0618, Total Loss: 3.8196, LR: 0.002050
2025-04-22 06:35:46,080 [INFO] Epoch 23/25 - Policy Loss: 3.7491, Value Loss: 0.0612, Total Loss: 3.8104, LR: 0.003030
2025-04-22 06:36:23,359 [INFO] Epoch 24/25 - Policy Loss: 3.7427, Value Loss: 0.0607, Total Loss: 3.8033, LR: 0.004010
2025-04-22 06:37:00,629 [INFO] Epoch 25/25 - Policy Loss: 3.7384, Value Loss: 0.0602, Total Loss: 3.7985, LR: 0.004990
2025-04-22 06:37:00,651 [INFO] 训练完成，总损失: 3.7985
2025-04-22 06:37:00,651 [INFO] 保存迭代 3 的模型
2025-04-22 06:37:01,001 [INFO] Model saved to ./models/best.pt
2025-04-22 06:37:01,248 [INFO] Model saved to ./models/iteration_3.pt
2025-04-22 06:37:01,248 [INFO] 所有训练迭代完成
2025-04-22 06:37:01,248 [INFO] 开始迭代 4/300
2025-04-22 06:37:01,248 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 07:50:24,478 [INFO] 保存训练样本
2025-04-22 07:50:30,944 [INFO] 截断训练样本，保持长度为 200000
2025-04-22 07:50:31,644 [INFO] 使用 200000 个样本训练神经网络
2025-04-22 07:50:31,644 [INFO] Training with 200000 examples
2025-04-22 07:50:31,644 [INFO] 总训练步数: 2425, 每轮次批次数: 97
2025-04-22 07:50:31,707 [INFO] 循环学习率周期大小: 485 步
2025-04-22 07:51:09,406 [INFO] Epoch 1/25 - Policy Loss: 3.9002, Value Loss: 0.2015, Total Loss: 4.1017, LR: 0.001070
2025-04-22 07:51:47,041 [INFO] Epoch 2/25 - Policy Loss: 3.8254, Value Loss: 0.1502, Total Loss: 3.9756, LR: 0.002050
2025-04-22 07:52:25,505 [INFO] Epoch 3/25 - Policy Loss: 3.7674, Value Loss: 0.1247, Total Loss: 3.8921, LR: 0.003030
2025-04-22 07:53:03,300 [INFO] Epoch 4/25 - Policy Loss: 3.7233, Value Loss: 0.1103, Total Loss: 3.8336, LR: 0.004010
2025-04-22 07:53:41,049 [INFO] Epoch 5/25 - Policy Loss: 3.6923, Value Loss: 0.1016, Total Loss: 3.7939, LR: 0.004990
2025-04-22 07:54:18,624 [INFO] Epoch 6/25 - Policy Loss: 3.6657, Value Loss: 0.0963, Total Loss: 3.7620, LR: 0.004030
2025-04-22 07:54:55,888 [INFO] Epoch 7/25 - Policy Loss: 3.6375, Value Loss: 0.0917, Total Loss: 3.7292, LR: 0.003050
2025-04-22 07:55:33,611 [INFO] Epoch 8/25 - Policy Loss: 3.6075, Value Loss: 0.0876, Total Loss: 3.6951, LR: 0.002070
2025-04-22 07:56:11,463 [INFO] Epoch 9/25 - Policy Loss: 3.5804, Value Loss: 0.0839, Total Loss: 3.6643, LR: 0.001090
2025-04-22 07:56:49,395 [INFO] Epoch 10/25 - Policy Loss: 3.5547, Value Loss: 0.0810, Total Loss: 3.6357, LR: 0.000110
2025-04-22 07:57:26,826 [INFO] Epoch 11/25 - Policy Loss: 3.5337, Value Loss: 0.0785, Total Loss: 3.6122, LR: 0.001070
2025-04-22 07:58:04,084 [INFO] Epoch 12/25 - Policy Loss: 3.5160, Value Loss: 0.0763, Total Loss: 3.5923, LR: 0.002050
2025-04-22 07:58:41,524 [INFO] Epoch 13/25 - Policy Loss: 3.5018, Value Loss: 0.0745, Total Loss: 3.5762, LR: 0.003030
2025-04-22 07:59:18,830 [INFO] Epoch 14/25 - Policy Loss: 3.4906, Value Loss: 0.0730, Total Loss: 3.5636, LR: 0.004010
2025-04-22 07:59:56,493 [INFO] Epoch 15/25 - Policy Loss: 3.4838, Value Loss: 0.0717, Total Loss: 3.5555, LR: 0.004990
2025-04-22 08:00:34,255 [INFO] Epoch 16/25 - Policy Loss: 3.4791, Value Loss: 0.0710, Total Loss: 3.5501, LR: 0.004030
2025-04-22 08:01:12,041 [INFO] Epoch 17/25 - Policy Loss: 3.4724, Value Loss: 0.0703, Total Loss: 3.5427, LR: 0.003050
2025-04-22 08:01:49,853 [INFO] Epoch 18/25 - Policy Loss: 3.4641, Value Loss: 0.0694, Total Loss: 3.5336, LR: 0.002070
2025-04-22 08:02:27,680 [INFO] Epoch 19/25 - Policy Loss: 3.4545, Value Loss: 0.0686, Total Loss: 3.5231, LR: 0.001090
2025-04-22 08:03:05,468 [INFO] Epoch 20/25 - Policy Loss: 3.4448, Value Loss: 0.0678, Total Loss: 3.5126, LR: 0.000110
2025-04-22 08:03:43,234 [INFO] Epoch 21/25 - Policy Loss: 3.4357, Value Loss: 0.0671, Total Loss: 3.5028, LR: 0.001070
2025-04-22 08:04:20,848 [INFO] Epoch 22/25 - Policy Loss: 3.4278, Value Loss: 0.0663, Total Loss: 3.4941, LR: 0.002050
2025-04-22 08:04:58,140 [INFO] Epoch 23/25 - Policy Loss: 3.4202, Value Loss: 0.0657, Total Loss: 3.4859, LR: 0.003030
2025-04-22 08:05:35,388 [INFO] Epoch 24/25 - Policy Loss: 3.4150, Value Loss: 0.0652, Total Loss: 3.4802, LR: 0.004010
2025-04-22 08:06:13,105 [INFO] Epoch 25/25 - Policy Loss: 3.4116, Value Loss: 0.0648, Total Loss: 3.4764, LR: 0.004990
2025-04-22 08:06:13,128 [INFO] 训练完成，总损失: 3.4764
2025-04-22 08:06:13,128 [INFO] 保存迭代 4 的模型
2025-04-22 08:06:13,483 [INFO] Model saved to ./models/best.pt
2025-04-22 08:06:13,730 [INFO] Model saved to ./models/iteration_4.pt
2025-04-22 08:06:13,731 [INFO] 所有训练迭代完成
2025-04-22 08:06:13,731 [INFO] 开始迭代 5/300
2025-04-22 08:06:13,731 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 09:51:00,270 [INFO] 保存训练样本
2025-04-22 09:51:07,522 [INFO] 截断训练样本，保持长度为 200000
2025-04-22 09:51:08,359 [INFO] 使用 200000 个样本训练神经网络
2025-04-22 09:51:08,359 [INFO] Training with 200000 examples
2025-04-22 09:51:08,359 [INFO] 总训练步数: 2425, 每轮次批次数: 97
2025-04-22 09:51:08,424 [INFO] 循环学习率周期大小: 485 步
2025-04-22 09:51:46,271 [INFO] Epoch 1/25 - Policy Loss: 3.8699, Value Loss: 0.2355, Total Loss: 4.1054, LR: 0.001070
2025-04-22 09:52:24,914 [INFO] Epoch 2/25 - Policy Loss: 3.7714, Value Loss: 0.1698, Total Loss: 3.9412, LR: 0.002050
2025-04-22 09:53:02,845 [INFO] Epoch 3/25 - Policy Loss: 3.6903, Value Loss: 0.1377, Total Loss: 3.8280, LR: 0.003030
2025-04-22 09:53:40,693 [INFO] Epoch 4/25 - Policy Loss: 3.6239, Value Loss: 0.1197, Total Loss: 3.7437, LR: 0.004010
2025-04-22 09:54:18,534 [INFO] Epoch 5/25 - Policy Loss: 3.5703, Value Loss: 0.1085, Total Loss: 3.6788, LR: 0.004990
2025-04-22 09:54:56,374 [INFO] Epoch 6/25 - Policy Loss: 3.5255, Value Loss: 0.1017, Total Loss: 3.6273, LR: 0.004030
2025-04-22 09:55:34,212 [INFO] Epoch 7/25 - Policy Loss: 3.4820, Value Loss: 0.0960, Total Loss: 3.5780, LR: 0.003050
2025-04-22 09:56:12,065 [INFO] Epoch 8/25 - Policy Loss: 3.4405, Value Loss: 0.0912, Total Loss: 3.5317, LR: 0.002070
2025-04-22 09:56:49,918 [INFO] Epoch 9/25 - Policy Loss: 3.4032, Value Loss: 0.0871, Total Loss: 3.4903, LR: 0.001090
2025-04-22 09:57:27,802 [INFO] Epoch 10/25 - Policy Loss: 3.3705, Value Loss: 0.0839, Total Loss: 3.4544, LR: 0.000110
2025-04-22 09:58:05,658 [INFO] Epoch 11/25 - Policy Loss: 3.3425, Value Loss: 0.0810, Total Loss: 3.4235, LR: 0.001070
2025-04-22 09:58:43,510 [INFO] Epoch 12/25 - Policy Loss: 3.3181, Value Loss: 0.0787, Total Loss: 3.3968, LR: 0.002050
2025-04-22 09:59:21,355 [INFO] Epoch 13/25 - Policy Loss: 3.2984, Value Loss: 0.0767, Total Loss: 3.3751, LR: 0.003030
2025-04-22 09:59:59,157 [INFO] Epoch 14/25 - Policy Loss: 3.2819, Value Loss: 0.0751, Total Loss: 3.3569, LR: 0.004010
2025-04-22 10:00:37,104 [INFO] Epoch 15/25 - Policy Loss: 3.2703, Value Loss: 0.0737, Total Loss: 3.3441, LR: 0.004990
2025-04-22 10:01:14,859 [INFO] Epoch 16/25 - Policy Loss: 3.2614, Value Loss: 0.0729, Total Loss: 3.3343, LR: 0.004030
2025-04-22 10:01:52,706 [INFO] Epoch 17/25 - Policy Loss: 3.2511, Value Loss: 0.0721, Total Loss: 3.3233, LR: 0.003050
2025-04-22 10:02:30,508 [INFO] Epoch 18/25 - Policy Loss: 3.2392, Value Loss: 0.0713, Total Loss: 3.3105, LR: 0.002070
2025-04-22 10:03:08,244 [INFO] Epoch 19/25 - Policy Loss: 3.2269, Value Loss: 0.0704, Total Loss: 3.2972, LR: 0.001090
2025-04-22 10:03:46,101 [INFO] Epoch 20/25 - Policy Loss: 3.2142, Value Loss: 0.0695, Total Loss: 3.2837, LR: 0.000110
2025-04-22 10:04:23,938 [INFO] Epoch 21/25 - Policy Loss: 3.2027, Value Loss: 0.0686, Total Loss: 3.2713, LR: 0.001070
2025-04-22 10:05:01,764 [INFO] Epoch 22/25 - Policy Loss: 3.1920, Value Loss: 0.0679, Total Loss: 3.2599, LR: 0.002050
2025-04-22 10:05:39,610 [INFO] Epoch 23/25 - Policy Loss: 3.1829, Value Loss: 0.0672, Total Loss: 3.2501, LR: 0.003030
2025-04-22 10:06:17,510 [INFO] Epoch 24/25 - Policy Loss: 3.1757, Value Loss: 0.0666, Total Loss: 3.2423, LR: 0.004010
2025-04-22 10:06:55,411 [INFO] Epoch 25/25 - Policy Loss: 3.1706, Value Loss: 0.0662, Total Loss: 3.2368, LR: 0.004990
2025-04-22 10:06:55,441 [INFO] 训练完成，总损失: 3.2368
2025-04-22 10:06:55,442 [INFO] 保存迭代 5 的模型
2025-04-22 10:06:55,884 [INFO] Model saved to ./models/best.pt
2025-04-22 10:06:56,203 [INFO] Model saved to ./models/iteration_5.pt
2025-04-22 10:06:56,203 [INFO] 所有训练迭代完成
2025-04-22 10:06:56,203 [INFO] 开始迭代 6/300
2025-04-22 10:06:56,203 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 11:28:28,569 [INFO] 保存训练样本
2025-04-22 11:28:37,450 [INFO] 截断训练样本，保持长度为 200000
2025-04-22 11:28:38,441 [INFO] 使用 200000 个样本训练神经网络
2025-04-22 11:28:38,441 [INFO] Training with 200000 examples
2025-04-22 11:28:38,442 [INFO] 总训练步数: 2425, 每轮次批次数: 97
2025-04-22 11:28:38,514 [INFO] 循环学习率周期大小: 485 步
2025-04-22 11:29:16,290 [INFO] Epoch 1/25 - Policy Loss: 3.6454, Value Loss: 0.1921, Total Loss: 3.8376, LR: 0.001070
2025-04-22 11:29:54,115 [INFO] Epoch 2/25 - Policy Loss: 3.5610, Value Loss: 0.1491, Total Loss: 3.7101, LR: 0.002050
2025-04-22 11:30:31,936 [INFO] Epoch 3/25 - Policy Loss: 3.4858, Value Loss: 0.1259, Total Loss: 3.6117, LR: 0.003030
2025-04-22 11:31:09,754 [INFO] Epoch 4/25 - Policy Loss: 3.4228, Value Loss: 0.1121, Total Loss: 3.5350, LR: 0.004010
2025-04-22 11:31:47,392 [INFO] Epoch 5/25 - Policy Loss: 3.3753, Value Loss: 0.1039, Total Loss: 3.4792, LR: 0.004990
2025-04-22 11:32:24,986 [INFO] Epoch 6/25 - Policy Loss: 3.3341, Value Loss: 0.0984, Total Loss: 3.4325, LR: 0.004030
2025-04-22 11:33:03,211 [INFO] Epoch 7/25 - Policy Loss: 3.2932, Value Loss: 0.0935, Total Loss: 3.3867, LR: 0.003050
2025-04-22 11:33:40,627 [INFO] Epoch 8/25 - Policy Loss: 3.2552, Value Loss: 0.0895, Total Loss: 3.3447, LR: 0.002070
2025-04-22 11:34:18,079 [INFO] Epoch 9/25 - Policy Loss: 3.2199, Value Loss: 0.0862, Total Loss: 3.3061, LR: 0.001090
2025-04-22 11:34:55,503 [INFO] Epoch 10/25 - Policy Loss: 3.1882, Value Loss: 0.0833, Total Loss: 3.2716, LR: 0.000110
2025-04-22 11:35:32,996 [INFO] Epoch 11/25 - Policy Loss: 3.1614, Value Loss: 0.0810, Total Loss: 3.2424, LR: 0.001070
2025-04-22 11:36:10,422 [INFO] Epoch 12/25 - Policy Loss: 3.1380, Value Loss: 0.0790, Total Loss: 3.2170, LR: 0.002050
2025-04-22 11:36:47,839 [INFO] Epoch 13/25 - Policy Loss: 3.1188, Value Loss: 0.0773, Total Loss: 3.1961, LR: 0.003030
2025-04-22 11:37:25,327 [INFO] Epoch 14/25 - Policy Loss: 3.1031, Value Loss: 0.0759, Total Loss: 3.1789, LR: 0.004010
2025-04-22 11:38:02,757 [INFO] Epoch 15/25 - Policy Loss: 3.0914, Value Loss: 0.0747, Total Loss: 3.1661, LR: 0.004990
2025-04-22 11:38:40,395 [INFO] Epoch 16/25 - Policy Loss: 3.0824, Value Loss: 0.0740, Total Loss: 3.1564, LR: 0.004030
2025-04-22 11:39:17,940 [INFO] Epoch 17/25 - Policy Loss: 3.0723, Value Loss: 0.0733, Total Loss: 3.1457, LR: 0.003050
2025-04-22 11:39:55,768 [INFO] Epoch 18/25 - Policy Loss: 3.0612, Value Loss: 0.0725, Total Loss: 3.1338, LR: 0.002070
2025-04-22 11:40:33,538 [INFO] Epoch 19/25 - Policy Loss: 3.0492, Value Loss: 0.0717, Total Loss: 3.1209, LR: 0.001090
2025-04-22 11:41:11,403 [INFO] Epoch 20/25 - Policy Loss: 3.0373, Value Loss: 0.0709, Total Loss: 3.1082, LR: 0.000110
2025-04-22 11:41:49,089 [INFO] Epoch 21/25 - Policy Loss: 3.0263, Value Loss: 0.0701, Total Loss: 3.0965, LR: 0.001070
2025-04-22 11:42:26,468 [INFO] Epoch 22/25 - Policy Loss: 3.0159, Value Loss: 0.0695, Total Loss: 3.0853, LR: 0.002050
2025-04-22 11:43:03,781 [INFO] Epoch 23/25 - Policy Loss: 3.0069, Value Loss: 0.0689, Total Loss: 3.0758, LR: 0.003030
2025-04-22 11:43:41,055 [INFO] Epoch 24/25 - Policy Loss: 2.9996, Value Loss: 0.0683, Total Loss: 3.0679, LR: 0.004010
2025-04-22 11:44:18,368 [INFO] Epoch 25/25 - Policy Loss: 2.9943, Value Loss: 0.0678, Total Loss: 3.0622, LR: 0.004990
2025-04-22 11:44:18,391 [INFO] 训练完成，总损失: 3.0622
2025-04-22 11:44:18,391 [INFO] 保存迭代 6 的模型
2025-04-22 11:44:18,829 [INFO] Model saved to ./models/best.pt
2025-04-22 11:44:19,116 [INFO] Model saved to ./models/iteration_6.pt
2025-04-22 11:44:19,116 [INFO] 所有训练迭代完成
2025-04-22 11:44:19,116 [INFO] 开始迭代 7/300
2025-04-22 11:44:19,116 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 13:22:13,966 [INFO] 保存训练样本
2025-04-22 13:22:23,868 [INFO] 截断训练样本，保持长度为 200000
2025-04-22 13:22:24,054 [INFO] 使用 200000 个样本训练神经网络
2025-04-22 13:22:24,055 [INFO] Training with 200000 examples
2025-04-22 13:22:24,055 [INFO] 总训练步数: 2425, 每轮次批次数: 97
2025-04-22 13:22:25,020 [INFO] 循环学习率周期大小: 485 步
2025-04-22 13:23:02,558 [INFO] Epoch 1/25 - Policy Loss: 3.5722, Value Loss: 0.1864, Total Loss: 3.7586, LR: 0.001070
2025-04-22 13:23:39,797 [INFO] Epoch 2/25 - Policy Loss: 3.4850, Value Loss: 0.1516, Total Loss: 3.6366, LR: 0.002050
2025-04-22 13:24:17,123 [INFO] Epoch 3/25 - Policy Loss: 3.4031, Value Loss: 0.1316, Total Loss: 3.5347, LR: 0.003030
2025-04-22 13:24:54,446 [INFO] Epoch 4/25 - Policy Loss: 3.3361, Value Loss: 0.1192, Total Loss: 3.4552, LR: 0.004010
2025-04-22 13:25:32,277 [INFO] Epoch 5/25 - Policy Loss: 3.2818, Value Loss: 0.1111, Total Loss: 3.3929, LR: 0.004990
2025-04-22 13:26:10,190 [INFO] Epoch 6/25 - Policy Loss: 3.2360, Value Loss: 0.1063, Total Loss: 3.3423, LR: 0.004030
2025-04-22 13:26:48,116 [INFO] Epoch 7/25 - Policy Loss: 3.1920, Value Loss: 0.1016, Total Loss: 3.2936, LR: 0.003050
2025-04-22 13:27:47,032 [INFO] Epoch 8/25 - Policy Loss: 3.1504, Value Loss: 0.0977, Total Loss: 3.2481, LR: 0.002070
2025-04-22 13:28:53,813 [INFO] Epoch 9/25 - Policy Loss: 3.1122, Value Loss: 0.0943, Total Loss: 3.2065, LR: 0.001090
2025-04-22 13:30:00,570 [INFO] Epoch 10/25 - Policy Loss: 3.0780, Value Loss: 0.0912, Total Loss: 3.1692, LR: 0.000110
2025-04-22 13:31:13,373 [INFO] Epoch 11/25 - Policy Loss: 3.0497, Value Loss: 0.0889, Total Loss: 3.1386, LR: 0.001070
2025-04-22 13:32:18,443 [INFO] Epoch 12/25 - Policy Loss: 3.0257, Value Loss: 0.0868, Total Loss: 3.1125, LR: 0.002050
2025-04-22 13:33:28,650 [INFO] Epoch 13/25 - Policy Loss: 3.0054, Value Loss: 0.0850, Total Loss: 3.0904, LR: 0.003030
2025-04-22 13:34:32,408 [INFO] Epoch 14/25 - Policy Loss: 2.9885, Value Loss: 0.0836, Total Loss: 3.0721, LR: 0.004010
2025-04-22 13:35:47,934 [INFO] Epoch 15/25 - Policy Loss: 2.9751, Value Loss: 0.0824, Total Loss: 3.0575, LR: 0.004990
2025-04-22 13:36:49,729 [INFO] Epoch 16/25 - Policy Loss: 2.9645, Value Loss: 0.0815, Total Loss: 3.0461, LR: 0.004030
2025-04-22 13:37:54,354 [INFO] Epoch 17/25 - Policy Loss: 2.9527, Value Loss: 0.0808, Total Loss: 3.0334, LR: 0.003050
2025-04-22 13:38:55,077 [INFO] Epoch 18/25 - Policy Loss: 2.9399, Value Loss: 0.0799, Total Loss: 3.0198, LR: 0.002070
2025-04-22 13:39:59,911 [INFO] Epoch 19/25 - Policy Loss: 2.9272, Value Loss: 0.0791, Total Loss: 3.0063, LR: 0.001090
2025-04-22 13:41:10,324 [INFO] Epoch 20/25 - Policy Loss: 2.9151, Value Loss: 0.0783, Total Loss: 2.9934, LR: 0.000110
2025-04-22 13:42:15,344 [INFO] Epoch 21/25 - Policy Loss: 2.9032, Value Loss: 0.0775, Total Loss: 2.9807, LR: 0.001070
2025-04-22 13:43:22,503 [INFO] Epoch 22/25 - Policy Loss: 2.8925, Value Loss: 0.0768, Total Loss: 2.9693, LR: 0.002050
2025-04-22 13:44:30,558 [INFO] Epoch 23/25 - Policy Loss: 2.8828, Value Loss: 0.0762, Total Loss: 2.9590, LR: 0.003030
2025-04-22 13:45:38,261 [INFO] Epoch 24/25 - Policy Loss: 2.8750, Value Loss: 0.0756, Total Loss: 2.9506, LR: 0.004010
2025-04-22 13:46:40,080 [INFO] Epoch 25/25 - Policy Loss: 2.8690, Value Loss: 0.0753, Total Loss: 2.9443, LR: 0.004990
2025-04-22 13:46:40,112 [INFO] 训练完成，总损失: 2.9443
2025-04-22 13:46:40,112 [INFO] 保存迭代 7 的模型
2025-04-22 13:46:40,550 [INFO] Model saved to ./models/best.pt
2025-04-22 13:46:40,814 [INFO] Model saved to ./models/iteration_7.pt
2025-04-22 13:46:40,815 [INFO] 所有训练迭代完成
2025-04-22 13:46:40,815 [INFO] 开始迭代 8/300
2025-04-22 13:46:40,815 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 15:41:12,128 [INFO] 保存训练样本
2025-04-22 15:41:21,723 [INFO] 截断训练样本，保持长度为 200000
2025-04-22 15:41:22,596 [INFO] 使用 200000 个样本训练神经网络
2025-04-22 15:41:22,596 [INFO] Training with 200000 examples
2025-04-22 15:41:22,596 [INFO] 总训练步数: 2425, 每轮次批次数: 97
2025-04-22 15:41:22,670 [INFO] 循环学习率周期大小: 485 步
2025-04-22 15:42:21,592 [INFO] Epoch 1/25 - Policy Loss: 3.4932, Value Loss: 0.2009, Total Loss: 3.6941, LR: 0.001070
2025-04-22 15:43:23,174 [INFO] Epoch 2/25 - Policy Loss: 3.4067, Value Loss: 0.1649, Total Loss: 3.5716, LR: 0.002050
2025-04-22 15:44:32,907 [INFO] Epoch 3/25 - Policy Loss: 3.3295, Value Loss: 0.1433, Total Loss: 3.4728, LR: 0.003030
2025-04-22 15:45:34,663 [INFO] Epoch 4/25 - Policy Loss: 3.2607, Value Loss: 0.1291, Total Loss: 3.3899, LR: 0.004010
2025-04-22 15:46:42,086 [INFO] Epoch 5/25 - Policy Loss: 3.2034, Value Loss: 0.1198, Total Loss: 3.3232, LR: 0.004990
2025-04-22 15:47:43,737 [INFO] Epoch 6/25 - Policy Loss: 3.1560, Value Loss: 0.1134, Total Loss: 3.2694, LR: 0.004030
2025-04-22 15:48:48,027 [INFO] Epoch 7/25 - Policy Loss: 3.1089, Value Loss: 0.1082, Total Loss: 3.2171, LR: 0.003050
2025-04-22 15:49:58,319 [INFO] Epoch 8/25 - Policy Loss: 3.0646, Value Loss: 0.1036, Total Loss: 3.1682, LR: 0.002070
2025-04-22 15:50:57,507 [INFO] Epoch 9/25 - Policy Loss: 3.0253, Value Loss: 0.0997, Total Loss: 3.1249, LR: 0.001090
2025-04-22 15:52:07,308 [INFO] Epoch 10/25 - Policy Loss: 2.9911, Value Loss: 0.0964, Total Loss: 3.0874, LR: 0.000110
2025-04-22 15:53:11,110 [INFO] Epoch 11/25 - Policy Loss: 2.9612, Value Loss: 0.0938, Total Loss: 3.0550, LR: 0.001070
2025-04-22 15:54:21,919 [INFO] Epoch 12/25 - Policy Loss: 2.9360, Value Loss: 0.0915, Total Loss: 3.0274, LR: 0.002050
2025-04-22 15:55:28,165 [INFO] Epoch 13/25 - Policy Loss: 2.9144, Value Loss: 0.0896, Total Loss: 3.0040, LR: 0.003030
2025-04-22 15:56:36,170 [INFO] Epoch 14/25 - Policy Loss: 2.8963, Value Loss: 0.0881, Total Loss: 2.9844, LR: 0.004010
2025-04-22 15:57:40,439 [INFO] Epoch 15/25 - Policy Loss: 2.8824, Value Loss: 0.0868, Total Loss: 2.9692, LR: 0.004990
2025-04-22 15:58:46,273 [INFO] Epoch 16/25 - Policy Loss: 2.8710, Value Loss: 0.0858, Total Loss: 2.9568, LR: 0.004030
2025-04-22 15:59:44,932 [INFO] Epoch 17/25 - Policy Loss: 2.8586, Value Loss: 0.0849, Total Loss: 2.9435, LR: 0.003050
2025-04-22 16:00:49,552 [INFO] Epoch 18/25 - Policy Loss: 2.8452, Value Loss: 0.0840, Total Loss: 2.9292, LR: 0.002070
2025-04-22 16:01:51,144 [INFO] Epoch 19/25 - Policy Loss: 2.8316, Value Loss: 0.0831, Total Loss: 2.9147, LR: 0.001090
2025-04-22 16:02:50,984 [INFO] Epoch 20/25 - Policy Loss: 2.8186, Value Loss: 0.0822, Total Loss: 2.9008, LR: 0.000110
2025-04-22 16:04:00,202 [INFO] Epoch 21/25 - Policy Loss: 2.8065, Value Loss: 0.0813, Total Loss: 2.8878, LR: 0.001070
2025-04-22 16:05:00,407 [INFO] Epoch 22/25 - Policy Loss: 2.7954, Value Loss: 0.0805, Total Loss: 2.8759, LR: 0.002050
2025-04-22 16:06:00,234 [INFO] Epoch 23/25 - Policy Loss: 2.7854, Value Loss: 0.0798, Total Loss: 2.8652, LR: 0.003030
2025-04-22 16:06:59,114 [INFO] Epoch 24/25 - Policy Loss: 2.7764, Value Loss: 0.0793, Total Loss: 2.8556, LR: 0.004010
2025-04-22 16:08:13,871 [INFO] Epoch 25/25 - Policy Loss: 2.7698, Value Loss: 0.0788, Total Loss: 2.8486, LR: 0.004990
2025-04-22 16:08:13,894 [INFO] 训练完成，总损失: 2.8486
2025-04-22 16:08:13,894 [INFO] 保存迭代 8 的模型
2025-04-22 16:08:14,310 [INFO] Model saved to ./models/best.pt
2025-04-22 16:08:14,572 [INFO] Model saved to ./models/iteration_8.pt
2025-04-22 16:08:14,572 [INFO] 所有训练迭代完成
2025-04-22 16:08:14,572 [INFO] 开始迭代 9/300
2025-04-22 16:08:14,572 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 17:57:27,189 [INFO] 保存训练样本
2025-04-22 17:57:36,961 [INFO] 截断训练样本，保持长度为 200000
2025-04-22 17:57:37,755 [INFO] 使用 200000 个样本训练神经网络
2025-04-22 17:57:37,755 [INFO] Training with 200000 examples
2025-04-22 17:57:37,755 [INFO] 总训练步数: 2425, 每轮次批次数: 97
2025-04-22 17:57:37,810 [INFO] 循环学习率周期大小: 485 步
2025-04-22 17:58:56,005 [INFO] Epoch 1/25 - Policy Loss: 3.4526, Value Loss: 0.2025, Total Loss: 3.6551, LR: 0.001070
2025-04-22 18:00:09,170 [INFO] Epoch 2/25 - Policy Loss: 3.3728, Value Loss: 0.1700, Total Loss: 3.5427, LR: 0.002050
2025-04-22 18:01:33,062 [INFO] Epoch 3/25 - Policy Loss: 3.2973, Value Loss: 0.1488, Total Loss: 3.4461, LR: 0.003030
2025-04-22 18:02:51,711 [INFO] Epoch 4/25 - Policy Loss: 3.2276, Value Loss: 0.1348, Total Loss: 3.3624, LR: 0.004010
2025-04-22 18:04:11,739 [INFO] Epoch 5/25 - Policy Loss: 3.1695, Value Loss: 0.1253, Total Loss: 3.2948, LR: 0.004990
2025-04-22 18:05:19,823 [INFO] Epoch 6/25 - Policy Loss: 3.1182, Value Loss: 0.1184, Total Loss: 3.2366, LR: 0.004030
2025-04-22 18:06:37,462 [INFO] Epoch 7/25 - Policy Loss: 3.0684, Value Loss: 0.1128, Total Loss: 3.1812, LR: 0.003050
2025-04-22 18:07:41,338 [INFO] Epoch 8/25 - Policy Loss: 3.0228, Value Loss: 0.1080, Total Loss: 3.1309, LR: 0.002070
2025-04-22 18:09:00,025 [INFO] Epoch 9/25 - Policy Loss: 2.9806, Value Loss: 0.1039, Total Loss: 3.0844, LR: 0.001090
2025-04-22 18:10:16,975 [INFO] Epoch 10/25 - Policy Loss: 2.9448, Value Loss: 0.1005, Total Loss: 3.0453, LR: 0.000110
2025-04-22 18:11:36,448 [INFO] Epoch 11/25 - Policy Loss: 2.9150, Value Loss: 0.0976, Total Loss: 3.0126, LR: 0.001070
2025-04-22 18:12:54,905 [INFO] Epoch 12/25 - Policy Loss: 2.8893, Value Loss: 0.0953, Total Loss: 2.9846, LR: 0.002050
2025-04-22 18:14:16,051 [INFO] Epoch 13/25 - Policy Loss: 2.8667, Value Loss: 0.0931, Total Loss: 2.9598, LR: 0.003030
2025-04-22 18:15:26,037 [INFO] Epoch 14/25 - Policy Loss: 2.8483, Value Loss: 0.0914, Total Loss: 2.9397, LR: 0.004010
2025-04-22 18:16:46,667 [INFO] Epoch 15/25 - Policy Loss: 2.8330, Value Loss: 0.0899, Total Loss: 2.9229, LR: 0.004990
2025-04-22 18:17:57,214 [INFO] Epoch 16/25 - Policy Loss: 2.8200, Value Loss: 0.0887, Total Loss: 2.9087, LR: 0.004030
2025-04-22 18:19:16,100 [INFO] Epoch 17/25 - Policy Loss: 2.8065, Value Loss: 0.0876, Total Loss: 2.8941, LR: 0.003050
2025-04-22 18:20:31,430 [INFO] Epoch 18/25 - Policy Loss: 2.7918, Value Loss: 0.0864, Total Loss: 2.8782, LR: 0.002070
2025-04-22 18:21:50,564 [INFO] Epoch 19/25 - Policy Loss: 2.7778, Value Loss: 0.0854, Total Loss: 2.8632, LR: 0.001090
2025-04-22 18:23:10,524 [INFO] Epoch 20/25 - Policy Loss: 2.7642, Value Loss: 0.0844, Total Loss: 2.8486, LR: 0.000110
2025-04-22 18:24:27,178 [INFO] Epoch 21/25 - Policy Loss: 2.7519, Value Loss: 0.0834, Total Loss: 2.8353, LR: 0.001070
2025-04-22 18:25:49,678 [INFO] Epoch 22/25 - Policy Loss: 2.7401, Value Loss: 0.0825, Total Loss: 2.8227, LR: 0.002050
2025-04-22 18:27:08,001 [INFO] Epoch 23/25 - Policy Loss: 2.7296, Value Loss: 0.0818, Total Loss: 2.8113, LR: 0.003030
2025-04-22 18:28:25,911 [INFO] Epoch 24/25 - Policy Loss: 2.7207, Value Loss: 0.0811, Total Loss: 2.8019, LR: 0.004010
2025-04-22 18:29:44,125 [INFO] Epoch 25/25 - Policy Loss: 2.7137, Value Loss: 0.0806, Total Loss: 2.7943, LR: 0.004990
2025-04-22 18:29:44,148 [INFO] 训练完成，总损失: 2.7943
2025-04-22 18:29:44,149 [INFO] 保存迭代 9 的模型
2025-04-22 18:29:44,541 [INFO] Model saved to ./models/best.pt
2025-04-22 18:29:44,804 [INFO] Model saved to ./models/iteration_9.pt
2025-04-22 18:29:44,804 [INFO] 所有训练迭代完成
2025-04-22 18:29:44,804 [INFO] 开始迭代 10/300
2025-04-22 18:29:44,804 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 19:48:58,200 [INFO] 保存训练样本
2025-04-22 19:49:10,688 [INFO] 截断训练样本，保持长度为 200000
2025-04-22 19:49:10,849 [INFO] 使用 200000 个样本训练神经网络
2025-04-22 19:49:10,849 [INFO] Training with 200000 examples
2025-04-22 19:49:10,850 [INFO] 总训练步数: 2425, 每轮次批次数: 97
2025-04-22 19:49:10,913 [INFO] 循环学习率周期大小: 485 步
2025-04-22 19:49:48,487 [INFO] Epoch 1/25 - Policy Loss: 3.4401, Value Loss: 0.1996, Total Loss: 3.6397, LR: 0.001070
2025-04-22 19:50:26,037 [INFO] Epoch 2/25 - Policy Loss: 3.3596, Value Loss: 0.1720, Total Loss: 3.5317, LR: 0.002050
2025-04-22 19:51:03,554 [INFO] Epoch 3/25 - Policy Loss: 3.2796, Value Loss: 0.1536, Total Loss: 3.4331, LR: 0.003030
2025-04-22 19:51:41,027 [INFO] Epoch 4/25 - Policy Loss: 3.2077, Value Loss: 0.1409, Total Loss: 3.3486, LR: 0.004010
2025-04-22 19:52:18,578 [INFO] Epoch 5/25 - Policy Loss: 3.1459, Value Loss: 0.1317, Total Loss: 3.2777, LR: 0.004990
2025-04-22 19:52:55,988 [INFO] Epoch 6/25 - Policy Loss: 3.0933, Value Loss: 0.1251, Total Loss: 3.2184, LR: 0.004030
2025-04-22 19:53:33,529 [INFO] Epoch 7/25 - Policy Loss: 3.0435, Value Loss: 0.1192, Total Loss: 3.1627, LR: 0.003050
2025-04-22 19:54:11,279 [INFO] Epoch 8/25 - Policy Loss: 2.9975, Value Loss: 0.1142, Total Loss: 3.1117, LR: 0.002070
2025-04-22 19:54:48,904 [INFO] Epoch 9/25 - Policy Loss: 2.9563, Value Loss: 0.1100, Total Loss: 3.0663, LR: 0.001090
2025-04-22 19:55:27,297 [INFO] Epoch 10/25 - Policy Loss: 2.9198, Value Loss: 0.1066, Total Loss: 3.0265, LR: 0.000110
2025-04-22 19:56:04,744 [INFO] Epoch 11/25 - Policy Loss: 2.8885, Value Loss: 0.1037, Total Loss: 2.9922, LR: 0.001070
2025-04-22 19:56:42,118 [INFO] Epoch 12/25 - Policy Loss: 2.8620, Value Loss: 0.1013, Total Loss: 2.9632, LR: 0.002050
2025-04-22 19:57:19,602 [INFO] Epoch 13/25 - Policy Loss: 2.8392, Value Loss: 0.0992, Total Loss: 2.9384, LR: 0.003030
2025-04-22 19:57:57,209 [INFO] Epoch 14/25 - Policy Loss: 2.8203, Value Loss: 0.0974, Total Loss: 2.9177, LR: 0.004010
2025-04-22 19:58:34,671 [INFO] Epoch 15/25 - Policy Loss: 2.8039, Value Loss: 0.0959, Total Loss: 2.8998, LR: 0.004990
2025-04-22 19:59:12,094 [INFO] Epoch 16/25 - Policy Loss: 2.7907, Value Loss: 0.0946, Total Loss: 2.8853, LR: 0.004030
2025-04-22 19:59:50,015 [INFO] Epoch 17/25 - Policy Loss: 2.7766, Value Loss: 0.0935, Total Loss: 2.8701, LR: 0.003050
2025-04-22 20:00:28,065 [INFO] Epoch 18/25 - Policy Loss: 2.7617, Value Loss: 0.0924, Total Loss: 2.8541, LR: 0.002070
2025-04-22 20:01:06,195 [INFO] Epoch 19/25 - Policy Loss: 2.7469, Value Loss: 0.0913, Total Loss: 2.8382, LR: 0.001090
2025-04-22 20:01:44,255 [INFO] Epoch 20/25 - Policy Loss: 2.7329, Value Loss: 0.0902, Total Loss: 2.8232, LR: 0.000110
2025-04-22 20:02:22,431 [INFO] Epoch 21/25 - Policy Loss: 2.7197, Value Loss: 0.0893, Total Loss: 2.8090, LR: 0.001070
2025-04-22 20:03:00,545 [INFO] Epoch 22/25 - Policy Loss: 2.7075, Value Loss: 0.0884, Total Loss: 2.7959, LR: 0.002050
2025-04-22 20:03:38,668 [INFO] Epoch 23/25 - Policy Loss: 2.6966, Value Loss: 0.0876, Total Loss: 2.7842, LR: 0.003030
2025-04-22 20:04:16,719 [INFO] Epoch 24/25 - Policy Loss: 2.6874, Value Loss: 0.0869, Total Loss: 2.7743, LR: 0.004010
2025-04-22 20:04:55,035 [INFO] Epoch 25/25 - Policy Loss: 2.6799, Value Loss: 0.0864, Total Loss: 2.7663, LR: 0.004990
2025-04-22 20:04:55,072 [INFO] 训练完成，总损失: 2.7663
2025-04-22 20:04:55,072 [INFO] 保存迭代 10 的模型
2025-04-22 20:04:55,566 [INFO] Model saved to ./models/best.pt
2025-04-22 20:04:55,865 [INFO] Model saved to ./models/iteration_10.pt
2025-04-22 20:04:55,865 [INFO] 所有训练迭代完成
2025-04-22 20:04:55,865 [INFO] 开始迭代 11/300
2025-04-22 20:04:55,866 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-22 21:22:26,238 [INFO] 保存训练样本
2025-04-22 21:22:43,537 [INFO] 截断训练样本，保持长度为 200000
2025-04-22 21:22:43,745 [INFO] 使用 200000 个样本训练神经网络
2025-04-22 21:22:43,745 [INFO] Training with 200000 examples
2025-04-22 21:22:43,745 [INFO] 总训练步数: 2425, 每轮次批次数: 97
2025-04-22 21:22:43,821 [INFO] 循环学习率周期大小: 485 步
2025-04-22 21:23:21,828 [INFO] Epoch 1/25 - Policy Loss: 3.4060, Value Loss: 0.1923, Total Loss: 3.5983, LR: 0.001070
2025-04-22 21:23:59,529 [INFO] Epoch 2/25 - Policy Loss: 3.3304, Value Loss: 0.1694, Total Loss: 3.4998, LR: 0.002050
2025-04-22 21:24:37,640 [INFO] Epoch 3/25 - Policy Loss: 3.2493, Value Loss: 0.1523, Total Loss: 3.4016, LR: 0.003030
2025-04-22 21:25:15,866 [INFO] Epoch 4/25 - Policy Loss: 3.1796, Value Loss: 0.1406, Total Loss: 3.3201, LR: 0.004010
2025-04-22 21:25:54,036 [INFO] Epoch 5/25 - Policy Loss: 3.1181, Value Loss: 0.1321, Total Loss: 3.2502, LR: 0.004990
2025-04-22 21:26:32,188 [INFO] Epoch 6/25 - Policy Loss: 3.0633, Value Loss: 0.1257, Total Loss: 3.1890, LR: 0.004030
2025-04-22 21:27:09,736 [INFO] Epoch 7/25 - Policy Loss: 3.0105, Value Loss: 0.1200, Total Loss: 3.1306, LR: 0.003050
2025-04-22 21:27:47,331 [INFO] Epoch 8/25 - Policy Loss: 2.9634, Value Loss: 0.1150, Total Loss: 3.0784, LR: 0.002070
2025-04-22 21:28:24,705 [INFO] Epoch 9/25 - Policy Loss: 2.9199, Value Loss: 0.1109, Total Loss: 3.0307, LR: 0.001090
2025-04-22 21:29:02,184 [INFO] Epoch 10/25 - Policy Loss: 2.8824, Value Loss: 0.1073, Total Loss: 2.9897, LR: 0.000110
2025-04-22 21:29:39,697 [INFO] Epoch 11/25 - Policy Loss: 2.8513, Value Loss: 0.1042, Total Loss: 2.9555, LR: 0.001070
2025-04-22 21:30:18,218 [INFO] Epoch 12/25 - Policy Loss: 2.8237, Value Loss: 0.1017, Total Loss: 2.9255, LR: 0.002050
2025-04-22 21:30:55,703 [INFO] Epoch 13/25 - Policy Loss: 2.8004, Value Loss: 0.0997, Total Loss: 2.9000, LR: 0.003030
2025-04-22 21:31:33,246 [INFO] Epoch 14/25 - Policy Loss: 2.7800, Value Loss: 0.0978, Total Loss: 2.8778, LR: 0.004010
2025-04-22 21:32:10,733 [INFO] Epoch 15/25 - Policy Loss: 2.7636, Value Loss: 0.0963, Total Loss: 2.8599, LR: 0.004990
2025-04-22 21:32:48,024 [INFO] Epoch 16/25 - Policy Loss: 2.7486, Value Loss: 0.0950, Total Loss: 2.8436, LR: 0.004030
2025-04-22 21:33:25,351 [INFO] Epoch 17/25 - Policy Loss: 2.7341, Value Loss: 0.0938, Total Loss: 2.8279, LR: 0.003050
2025-04-22 21:34:02,743 [INFO] Epoch 18/25 - Policy Loss: 2.7192, Value Loss: 0.0927, Total Loss: 2.8118, LR: 0.002070
2025-04-22 21:34:40,098 [INFO] Epoch 19/25 - Policy Loss: 2.7038, Value Loss: 0.0916, Total Loss: 2.7953, LR: 0.001090
2025-04-22 21:35:17,658 [INFO] Epoch 20/25 - Policy Loss: 2.6895, Value Loss: 0.0906, Total Loss: 2.7800, LR: 0.000110
2025-04-22 21:35:55,036 [INFO] Epoch 21/25 - Policy Loss: 2.6759, Value Loss: 0.0897, Total Loss: 2.7655, LR: 0.001070
2025-04-22 21:36:32,378 [INFO] Epoch 22/25 - Policy Loss: 2.6635, Value Loss: 0.0887, Total Loss: 2.7523, LR: 0.002050
2025-04-22 21:37:09,781 [INFO] Epoch 23/25 - Policy Loss: 2.6521, Value Loss: 0.0880, Total Loss: 2.7400, LR: 0.003030
2025-04-22 21:37:47,132 [INFO] Epoch 24/25 - Policy Loss: 2.6422, Value Loss: 0.0872, Total Loss: 2.7294, LR: 0.004010
2025-04-22 21:38:24,529 [INFO] Epoch 25/25 - Policy Loss: 2.6341, Value Loss: 0.0866, Total Loss: 2.7207, LR: 0.004990
2025-04-22 21:38:24,554 [INFO] 训练完成，总损失: 2.7207
2025-04-22 21:38:24,554 [INFO] 保存迭代 11 的模型
2025-04-22 21:38:24,907 [INFO] Model saved to ./models/best.pt
2025-04-22 21:38:25,159 [INFO] Model saved to ./models/iteration_11.pt
2025-04-22 21:38:25,159 [INFO] 所有训练迭代完成
2025-04-22 21:38:25,159 [INFO] 开始迭代 12/300
2025-04-22 21:38:25,159 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-24 22:33:08,545 [INFO] 设置多进程启动方法为: spawn
2025-04-24 22:33:08,752 [INFO] CUDA可用，使用GPU
2025-04-24 22:33:08,753 [INFO] 配置参数:
2025-04-24 22:33:08,753 [INFO] 训练参数:
2025-04-24 22:33:08,753 [INFO]   训练轮数: 15
2025-04-24 22:33:08,753 [INFO]   批量大小: 2048
2025-04-24 22:33:08,753 [INFO]   迭代次数: 300
2025-04-24 22:33:08,753 [INFO]   每次迭代的自我对弈次数: 50
2025-04-24 22:33:08,753 [INFO]   训练样本队列最大长度: 200000
2025-04-24 22:33:08,753 [INFO]   保留的历史迭代数: 20
2025-04-24 22:33:08,753 [INFO]   新模型胜率阈值: 0.55
2025-04-24 22:33:08,753 [INFO]   竞技场比赛次数: 40
2025-04-24 22:33:08,753 [INFO]   温度阈值: 5
2025-04-24 22:33:08,753 [INFO] 神经网络参数:
2025-04-24 22:33:08,753 [INFO]   通道数: 256
2025-04-24 22:33:08,753 [INFO]   Dropout率: 0.3
2025-04-24 22:33:08,753 [INFO]   学习率范围: 5e-05 - 0.005
2025-04-24 22:33:08,753 [INFO]   梯度裁剪: 1.0
2025-04-24 22:33:08,753 [INFO]   优化器: adam
2025-04-24 22:33:08,753 [INFO] MCTS参数:
2025-04-24 22:33:08,753 [INFO]   模拟次数: 500
2025-04-24 22:33:08,753 [INFO]   PUCT常数: 4.0
2025-04-24 22:33:08,753 [INFO]   Dirichlet噪声参数: 0.3
2025-04-24 22:33:08,753 [INFO]   Dirichlet噪声权重: 0.25
2025-04-24 22:33:08,753 [INFO] 游戏参数:
2025-04-24 22:33:08,753 [INFO]   棋盘大小: 15
2025-04-24 22:33:08,753 [INFO]   获胜所需的连续棋子数: 5
2025-04-24 22:33:08,753 [INFO] 系统参数:
2025-04-24 22:33:08,753 [INFO]   使用CUDA: True
2025-04-24 22:33:08,753 [INFO]   检查点目录: ./models
2025-04-24 22:33:08,753 [INFO]   数据目录: ./data
2025-04-24 22:33:08,753 [INFO]   加载模型: False
2025-04-24 22:33:08,753 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-24 22:33:08,753 [INFO]   工作线程数: 4
2025-04-24 22:33:08,753 [INFO]   使用Weights & Biases: False
2025-04-24 22:33:08,753 [INFO] GUI参数:
2025-04-24 22:33:08,753 [INFO]   窗口宽度: 800
2025-04-24 22:33:08,753 [INFO]   窗口高度: 850
2025-04-24 22:33:08,753 [INFO]   格子大小: 40
2025-04-24 22:33:08,753 [INFO]   边距: 40
2025-04-24 22:33:08,753 [INFO]   底部边距: 80
2025-04-24 22:33:08,753 [INFO]   帧率: 30
2025-04-24 22:33:08,871 [INFO] Using device: cuda
2025-04-24 22:33:09,729 [INFO] 设置循环学习率: 最小值=5e-05, 最大值=0.005
2025-04-24 22:33:09,729 [INFO] 设置并行进程数为: 8
2025-04-24 22:33:09,729 [INFO] 开始训练
2025-04-24 22:33:09,729 [INFO] 加载之前的训练样本
2025-04-24 22:33:13,692 [INFO] 加载了 13 组训练样本
2025-04-24 22:33:13,693 [INFO] 开始迭代 1/300
2025-04-24 22:33:13,693 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-24 22:36:50,597 [INFO] 设置多进程启动方法为: spawn
2025-04-24 22:36:50,793 [INFO] CUDA可用，使用GPU
2025-04-24 22:36:50,793 [INFO] 配置参数:
2025-04-24 22:36:50,794 [INFO] 训练参数:
2025-04-24 22:36:50,794 [INFO]   训练轮数: 15
2025-04-24 22:36:50,794 [INFO]   批量大小: 2048
2025-04-24 22:36:50,794 [INFO]   迭代次数: 300
2025-04-24 22:36:50,794 [INFO]   每次迭代的自我对弈次数: 50
2025-04-24 22:36:50,794 [INFO]   训练样本队列最大长度: 200000
2025-04-24 22:36:50,794 [INFO]   保留的历史迭代数: 20
2025-04-24 22:36:50,794 [INFO]   新模型胜率阈值: 0.55
2025-04-24 22:36:50,794 [INFO]   竞技场比赛次数: 40
2025-04-24 22:36:50,794 [INFO]   温度阈值: 5
2025-04-24 22:36:50,794 [INFO] 神经网络参数:
2025-04-24 22:36:50,794 [INFO]   通道数: 256
2025-04-24 22:36:50,794 [INFO]   Dropout率: 0.3
2025-04-24 22:36:50,794 [INFO]   学习率范围: 5e-05 - 0.005
2025-04-24 22:36:50,794 [INFO]   梯度裁剪: 1.0
2025-04-24 22:36:50,794 [INFO]   优化器: adam
2025-04-24 22:36:50,794 [INFO] MCTS参数:
2025-04-24 22:36:50,794 [INFO]   模拟次数: 500
2025-04-24 22:36:50,794 [INFO]   PUCT常数: 4.0
2025-04-24 22:36:50,794 [INFO]   Dirichlet噪声参数: 0.3
2025-04-24 22:36:50,794 [INFO]   Dirichlet噪声权重: 0.25
2025-04-24 22:36:50,794 [INFO] 游戏参数:
2025-04-24 22:36:50,794 [INFO]   棋盘大小: 15
2025-04-24 22:36:50,794 [INFO]   获胜所需的连续棋子数: 5
2025-04-24 22:36:50,794 [INFO] 系统参数:
2025-04-24 22:36:50,794 [INFO]   使用CUDA: True
2025-04-24 22:36:50,794 [INFO]   检查点目录: ./models
2025-04-24 22:36:50,794 [INFO]   数据目录: ./data
2025-04-24 22:36:50,794 [INFO]   加载模型: False
2025-04-24 22:36:50,794 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-24 22:36:50,794 [INFO]   工作线程数: 4
2025-04-24 22:36:50,794 [INFO]   使用Weights & Biases: False
2025-04-24 22:36:50,794 [INFO] GUI参数:
2025-04-24 22:36:50,795 [INFO]   窗口宽度: 800
2025-04-24 22:36:50,795 [INFO]   窗口高度: 850
2025-04-24 22:36:50,795 [INFO]   格子大小: 40
2025-04-24 22:36:50,795 [INFO]   边距: 40
2025-04-24 22:36:50,795 [INFO]   底部边距: 80
2025-04-24 22:36:50,795 [INFO]   帧率: 30
2025-04-24 22:36:50,964 [INFO] Using device: cuda
2025-04-24 22:36:52,111 [INFO] 设置循环学习率: 最小值=5e-05, 最大值=0.005
2025-04-24 22:36:52,112 [INFO] 设置并行进程数为: 8
2025-04-24 22:36:52,112 [INFO] 开始训练
2025-04-24 22:36:52,112 [INFO] 加载之前的训练样本
2025-04-24 22:36:56,204 [INFO] 加载了 13 组训练样本
2025-04-24 22:36:56,205 [INFO] 开始迭代 1/300
2025-04-24 22:36:56,205 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-24 23:03:36,859 [INFO] 保存训练样本
2025-04-24 23:03:51,313 [INFO] 截断训练样本，保持长度为 200000
2025-04-24 23:03:51,493 [INFO] 使用 200000 个样本训练神经网络
2025-04-24 23:03:51,493 [INFO] Training with 200000 examples
2025-04-24 23:03:51,494 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-24 23:03:52,930 [INFO] 循环学习率周期大小: 291 步
2025-04-24 23:04:31,787 [INFO] Epoch 1/15 - Policy Loss: 5.2268, Value Loss: 0.9924, Total Loss: 6.2192, LR: 0.001683
2025-04-24 23:05:10,082 [INFO] Epoch 2/15 - Policy Loss: 5.0439, Value Loss: 0.9531, Total Loss: 5.9971, LR: 0.003333
2025-04-24 23:05:48,543 [INFO] Epoch 3/15 - Policy Loss: 4.9025, Value Loss: 0.8613, Total Loss: 5.7637, LR: 0.004983
2025-04-24 23:06:27,121 [INFO] Epoch 4/15 - Policy Loss: 4.7769, Value Loss: 0.7454, Total Loss: 5.5223, LR: 0.003367
2025-04-24 23:07:05,592 [INFO] Epoch 5/15 - Policy Loss: 4.6504, Value Loss: 0.6443, Total Loss: 5.2947, LR: 0.001717
2025-04-24 23:07:44,026 [INFO] Epoch 6/15 - Policy Loss: 4.5286, Value Loss: 0.5647, Total Loss: 5.0933, LR: 0.000067
2025-04-24 23:08:22,362 [INFO] Epoch 7/15 - Policy Loss: 4.4234, Value Loss: 0.5042, Total Loss: 4.9276, LR: 0.001683
2025-04-24 23:09:00,729 [INFO] Epoch 8/15 - Policy Loss: 4.3412, Value Loss: 0.4593, Total Loss: 4.8005, LR: 0.003333
2025-04-24 23:09:39,018 [INFO] Epoch 9/15 - Policy Loss: 4.2789, Value Loss: 0.4289, Total Loss: 4.7078, LR: 0.004983
2025-04-24 23:10:17,458 [INFO] Epoch 10/15 - Policy Loss: 4.2216, Value Loss: 0.4044, Total Loss: 4.6261, LR: 0.003367
2025-04-24 23:10:55,872 [INFO] Epoch 11/15 - Policy Loss: 4.1559, Value Loss: 0.3791, Total Loss: 4.5351, LR: 0.001717
2025-04-24 23:11:34,305 [INFO] Epoch 12/15 - Policy Loss: 4.0869, Value Loss: 0.3556, Total Loss: 4.4425, LR: 0.000067
2025-04-24 23:12:12,791 [INFO] Epoch 13/15 - Policy Loss: 4.0229, Value Loss: 0.3351, Total Loss: 4.3580, LR: 0.001683
2025-04-24 23:12:51,268 [INFO] Epoch 14/15 - Policy Loss: 3.9686, Value Loss: 0.3176, Total Loss: 4.2861, LR: 0.003333
2025-04-24 23:13:29,642 [INFO] Epoch 15/15 - Policy Loss: 3.9284, Value Loss: 0.3034, Total Loss: 4.2318, LR: 0.004983
2025-04-24 23:13:29,680 [INFO] 训练完成，总损失: 4.2318
2025-04-24 23:13:29,680 [INFO] 保存迭代 1 的模型
2025-04-24 23:13:29,944 [INFO] Model saved to ./models/best.pt
2025-04-24 23:13:30,208 [INFO] Model saved to ./models/iteration_1.pt
2025-04-24 23:13:30,208 [INFO] 所有训练迭代完成
2025-04-24 23:13:30,208 [INFO] 开始迭代 2/300
2025-04-24 23:13:30,208 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-24 23:36:26,244 [INFO] 保存训练样本
2025-04-24 23:36:40,643 [INFO] 截断训练样本，保持长度为 200000
2025-04-24 23:36:42,263 [INFO] 使用 200000 个样本训练神经网络
2025-04-24 23:36:42,263 [INFO] Training with 200000 examples
2025-04-24 23:36:42,264 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-24 23:36:42,347 [INFO] 循环学习率周期大小: 291 步
2025-04-24 23:37:20,719 [INFO] Epoch 1/15 - Policy Loss: 4.3357, Value Loss: 0.2408, Total Loss: 4.5765, LR: 0.001683
2025-04-24 23:37:59,027 [INFO] Epoch 2/15 - Policy Loss: 4.1978, Value Loss: 0.2071, Total Loss: 4.4050, LR: 0.003333
2025-04-24 23:38:37,275 [INFO] Epoch 3/15 - Policy Loss: 4.0815, Value Loss: 0.1923, Total Loss: 4.2737, LR: 0.004983
2025-04-24 23:39:15,538 [INFO] Epoch 4/15 - Policy Loss: 3.9797, Value Loss: 0.1841, Total Loss: 4.1638, LR: 0.003367
2025-04-24 23:39:53,825 [INFO] Epoch 5/15 - Policy Loss: 3.8755, Value Loss: 0.1696, Total Loss: 4.0451, LR: 0.001717
2025-04-24 23:40:32,103 [INFO] Epoch 6/15 - Policy Loss: 3.7808, Value Loss: 0.1568, Total Loss: 3.9376, LR: 0.000067
2025-04-24 23:41:10,401 [INFO] Epoch 7/15 - Policy Loss: 3.7044, Value Loss: 0.1465, Total Loss: 3.8509, LR: 0.001683
2025-04-24 23:41:48,689 [INFO] Epoch 8/15 - Policy Loss: 3.6440, Value Loss: 0.1386, Total Loss: 3.7826, LR: 0.003333
2025-04-24 23:42:26,972 [INFO] Epoch 9/15 - Policy Loss: 3.6022, Value Loss: 0.1335, Total Loss: 3.7357, LR: 0.004983
2025-04-24 23:43:05,267 [INFO] Epoch 10/15 - Policy Loss: 3.5691, Value Loss: 0.1317, Total Loss: 3.7008, LR: 0.003367
2025-04-24 23:43:43,565 [INFO] Epoch 11/15 - Policy Loss: 3.5281, Value Loss: 0.1289, Total Loss: 3.6570, LR: 0.001717
2025-04-24 23:44:21,883 [INFO] Epoch 12/15 - Policy Loss: 3.4835, Value Loss: 0.1250, Total Loss: 3.6086, LR: 0.000067
2025-04-24 23:45:00,210 [INFO] Epoch 13/15 - Policy Loss: 3.4414, Value Loss: 0.1213, Total Loss: 3.5627, LR: 0.001683
2025-04-24 23:45:38,529 [INFO] Epoch 14/15 - Policy Loss: 3.4055, Value Loss: 0.1181, Total Loss: 3.5235, LR: 0.003333
2025-04-24 23:46:16,846 [INFO] Epoch 15/15 - Policy Loss: 3.3801, Value Loss: 0.1157, Total Loss: 3.4958, LR: 0.004983
2025-04-24 23:46:16,882 [INFO] 训练完成，总损失: 3.4958
2025-04-24 23:46:16,882 [INFO] 保存迭代 2 的模型
2025-04-24 23:46:17,311 [INFO] Model saved to ./models/best.pt
2025-04-24 23:46:17,610 [INFO] Model saved to ./models/iteration_2.pt
2025-04-24 23:46:17,611 [INFO] 所有训练迭代完成
2025-04-24 23:46:17,611 [INFO] 开始迭代 3/300
2025-04-24 23:46:17,611 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 00:09:41,699 [INFO] 保存训练样本
2025-04-25 00:09:55,388 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 00:09:55,570 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 00:09:55,570 [INFO] Training with 200000 examples
2025-04-25 00:09:55,570 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 00:09:55,647 [INFO] 循环学习率周期大小: 291 步
2025-04-25 00:10:33,470 [INFO] Epoch 1/15 - Policy Loss: 4.1442, Value Loss: 0.1975, Total Loss: 4.3417, LR: 0.001683
2025-04-25 00:11:11,282 [INFO] Epoch 2/15 - Policy Loss: 4.0014, Value Loss: 0.1745, Total Loss: 4.1759, LR: 0.003333
2025-04-25 00:11:49,202 [INFO] Epoch 3/15 - Policy Loss: 3.8878, Value Loss: 0.1629, Total Loss: 4.0508, LR: 0.004983
2025-04-25 00:12:27,209 [INFO] Epoch 4/15 - Policy Loss: 3.7860, Value Loss: 0.1568, Total Loss: 3.9428, LR: 0.003367
2025-04-25 00:13:05,088 [INFO] Epoch 5/15 - Policy Loss: 3.6862, Value Loss: 0.1471, Total Loss: 3.8333, LR: 0.001717
2025-04-25 00:13:44,191 [INFO] Epoch 6/15 - Policy Loss: 3.5950, Value Loss: 0.1376, Total Loss: 3.7326, LR: 0.000067
2025-04-25 00:14:22,059 [INFO] Epoch 7/15 - Policy Loss: 3.5210, Value Loss: 0.1298, Total Loss: 3.6508, LR: 0.001683
2025-04-25 00:14:59,924 [INFO] Epoch 8/15 - Policy Loss: 3.4629, Value Loss: 0.1237, Total Loss: 3.5866, LR: 0.003333
2025-04-25 00:15:37,884 [INFO] Epoch 9/15 - Policy Loss: 3.4206, Value Loss: 0.1194, Total Loss: 3.5400, LR: 0.004983
2025-04-25 00:16:19,950 [INFO] Epoch 10/15 - Policy Loss: 3.3876, Value Loss: 0.1172, Total Loss: 3.5048, LR: 0.003367
2025-04-25 00:16:59,917 [INFO] Epoch 11/15 - Policy Loss: 3.3474, Value Loss: 0.1143, Total Loss: 3.4617, LR: 0.001717
2025-04-25 00:17:37,818 [INFO] Epoch 12/15 - Policy Loss: 3.3048, Value Loss: 0.1113, Total Loss: 3.4161, LR: 0.000067
2025-04-25 00:18:15,788 [INFO] Epoch 13/15 - Policy Loss: 3.2653, Value Loss: 0.1083, Total Loss: 3.3736, LR: 0.001683
2025-04-25 00:18:53,777 [INFO] Epoch 14/15 - Policy Loss: 3.2308, Value Loss: 0.1058, Total Loss: 3.3366, LR: 0.003333
2025-04-25 00:19:31,735 [INFO] Epoch 15/15 - Policy Loss: 3.2060, Value Loss: 0.1039, Total Loss: 3.3099, LR: 0.004983
2025-04-25 00:19:31,769 [INFO] 训练完成，总损失: 3.3099
2025-04-25 00:19:31,769 [INFO] 保存迭代 3 的模型
2025-04-25 00:19:32,178 [INFO] Model saved to ./models/best.pt
2025-04-25 00:19:32,475 [INFO] Model saved to ./models/iteration_3.pt
2025-04-25 00:19:32,476 [INFO] 所有训练迭代完成
2025-04-25 00:19:32,476 [INFO] 开始迭代 4/300
2025-04-25 00:19:32,476 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 00:41:10,389 [INFO] 保存训练样本
2025-04-25 00:41:24,150 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 00:41:24,340 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 00:41:24,340 [INFO] Training with 200000 examples
2025-04-25 00:41:24,341 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 00:41:25,645 [INFO] 循环学习率周期大小: 291 步
2025-04-25 00:42:03,571 [INFO] Epoch 1/15 - Policy Loss: 3.9954, Value Loss: 0.1770, Total Loss: 4.1724, LR: 0.001683
2025-04-25 00:42:41,580 [INFO] Epoch 2/15 - Policy Loss: 3.8571, Value Loss: 0.1579, Total Loss: 4.0150, LR: 0.003333
2025-04-25 00:43:19,460 [INFO] Epoch 3/15 - Policy Loss: 3.7409, Value Loss: 0.1481, Total Loss: 3.8890, LR: 0.004983
2025-04-25 00:43:57,590 [INFO] Epoch 4/15 - Policy Loss: 3.6453, Value Loss: 0.1436, Total Loss: 3.7889, LR: 0.003367
2025-04-25 00:44:35,892 [INFO] Epoch 5/15 - Policy Loss: 3.5483, Value Loss: 0.1359, Total Loss: 3.6842, LR: 0.001717
2025-04-25 00:45:13,726 [INFO] Epoch 6/15 - Policy Loss: 3.4609, Value Loss: 0.1279, Total Loss: 3.5888, LR: 0.000067
2025-04-25 00:45:51,494 [INFO] Epoch 7/15 - Policy Loss: 3.3899, Value Loss: 0.1213, Total Loss: 3.5112, LR: 0.001683
2025-04-25 00:46:29,405 [INFO] Epoch 8/15 - Policy Loss: 3.3326, Value Loss: 0.1162, Total Loss: 3.4488, LR: 0.003333
2025-04-25 00:47:07,441 [INFO] Epoch 9/15 - Policy Loss: 3.2920, Value Loss: 0.1126, Total Loss: 3.4047, LR: 0.004983
2025-04-25 00:47:45,368 [INFO] Epoch 10/15 - Policy Loss: 3.2654, Value Loss: 0.1112, Total Loss: 3.3766, LR: 0.003367
2025-04-25 00:48:23,224 [INFO] Epoch 11/15 - Policy Loss: 3.2300, Value Loss: 0.1089, Total Loss: 3.3388, LR: 0.001717
2025-04-25 00:49:01,074 [INFO] Epoch 12/15 - Policy Loss: 3.1918, Value Loss: 0.1061, Total Loss: 3.2979, LR: 0.000067
2025-04-25 00:49:38,896 [INFO] Epoch 13/15 - Policy Loss: 3.1560, Value Loss: 0.1036, Total Loss: 3.2596, LR: 0.001683
2025-04-25 00:50:16,725 [INFO] Epoch 14/15 - Policy Loss: 3.1251, Value Loss: 0.1014, Total Loss: 3.2265, LR: 0.003333
2025-04-25 00:50:54,564 [INFO] Epoch 15/15 - Policy Loss: 3.1014, Value Loss: 0.0996, Total Loss: 3.2010, LR: 0.004983
2025-04-25 00:50:54,596 [INFO] 训练完成，总损失: 3.2010
2025-04-25 00:50:54,596 [INFO] 保存迭代 4 的模型
2025-04-25 00:50:55,031 [INFO] Model saved to ./models/best.pt
2025-04-25 00:50:55,332 [INFO] Model saved to ./models/iteration_4.pt
2025-04-25 00:50:55,332 [INFO] 所有训练迭代完成
2025-04-25 00:50:55,332 [INFO] 开始迭代 5/300
2025-04-25 00:50:55,332 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 01:12:08,427 [INFO] 保存训练样本
2025-04-25 01:12:23,296 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 01:12:24,708 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 01:12:24,708 [INFO] Training with 200000 examples
2025-04-25 01:12:24,708 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 01:12:24,784 [INFO] 循环学习率周期大小: 291 步
2025-04-25 01:13:02,348 [INFO] Epoch 1/15 - Policy Loss: 3.8924, Value Loss: 0.1693, Total Loss: 4.0617, LR: 0.001683
2025-04-25 01:13:39,818 [INFO] Epoch 2/15 - Policy Loss: 3.7570, Value Loss: 0.1514, Total Loss: 3.9083, LR: 0.003333
2025-04-25 01:14:17,284 [INFO] Epoch 3/15 - Policy Loss: 3.6396, Value Loss: 0.1417, Total Loss: 3.7813, LR: 0.004983
2025-04-25 01:14:54,747 [INFO] Epoch 4/15 - Policy Loss: 3.5435, Value Loss: 0.1366, Total Loss: 3.6801, LR: 0.003367
2025-04-25 01:15:32,242 [INFO] Epoch 5/15 - Policy Loss: 3.4499, Value Loss: 0.1296, Total Loss: 3.5795, LR: 0.001717
2025-04-25 01:16:09,746 [INFO] Epoch 6/15 - Policy Loss: 3.3663, Value Loss: 0.1226, Total Loss: 3.4889, LR: 0.000067
2025-04-25 01:16:47,260 [INFO] Epoch 7/15 - Policy Loss: 3.2997, Value Loss: 0.1171, Total Loss: 3.4168, LR: 0.001683
2025-04-25 01:17:24,782 [INFO] Epoch 8/15 - Policy Loss: 3.2446, Value Loss: 0.1122, Total Loss: 3.3568, LR: 0.003333
2025-04-25 01:18:02,318 [INFO] Epoch 9/15 - Policy Loss: 3.2037, Value Loss: 0.1088, Total Loss: 3.3125, LR: 0.004983
2025-04-25 01:18:39,859 [INFO] Epoch 10/15 - Policy Loss: 3.1721, Value Loss: 0.1064, Total Loss: 3.2785, LR: 0.003367
2025-04-25 01:19:17,371 [INFO] Epoch 11/15 - Policy Loss: 3.1376, Value Loss: 0.1041, Total Loss: 3.2418, LR: 0.001717
2025-04-25 01:19:54,898 [INFO] Epoch 12/15 - Policy Loss: 3.1014, Value Loss: 0.1017, Total Loss: 3.2031, LR: 0.000067
2025-04-25 01:20:32,415 [INFO] Epoch 13/15 - Policy Loss: 3.0677, Value Loss: 0.0995, Total Loss: 3.1672, LR: 0.001683
2025-04-25 01:21:09,972 [INFO] Epoch 14/15 - Policy Loss: 3.0386, Value Loss: 0.0975, Total Loss: 3.1361, LR: 0.003333
2025-04-25 01:21:47,487 [INFO] Epoch 15/15 - Policy Loss: 3.0165, Value Loss: 0.0960, Total Loss: 3.1125, LR: 0.004983
2025-04-25 01:21:47,519 [INFO] 训练完成，总损失: 3.1125
2025-04-25 01:21:47,519 [INFO] 保存迭代 5 的模型
2025-04-25 01:21:47,955 [INFO] Model saved to ./models/best.pt
2025-04-25 01:21:48,259 [INFO] Model saved to ./models/iteration_5.pt
2025-04-25 01:21:48,260 [INFO] 所有训练迭代完成
2025-04-25 01:21:48,260 [INFO] 开始迭代 6/300
2025-04-25 01:21:48,260 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 01:41:08,688 [INFO] 保存训练样本
2025-04-25 01:41:23,984 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 01:41:24,171 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 01:41:24,171 [INFO] Training with 200000 examples
2025-04-25 01:41:24,172 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 01:41:24,249 [INFO] 循环学习率周期大小: 291 步
2025-04-25 01:42:01,767 [INFO] Epoch 1/15 - Policy Loss: 3.8044, Value Loss: 0.1591, Total Loss: 3.9635, LR: 0.001683
2025-04-25 01:42:39,211 [INFO] Epoch 2/15 - Policy Loss: 3.6675, Value Loss: 0.1442, Total Loss: 3.8118, LR: 0.003333
2025-04-25 01:43:16,679 [INFO] Epoch 3/15 - Policy Loss: 3.5532, Value Loss: 0.1366, Total Loss: 3.6899, LR: 0.004983
2025-04-25 01:43:54,128 [INFO] Epoch 4/15 - Policy Loss: 3.4692, Value Loss: 0.1334, Total Loss: 3.6026, LR: 0.003367
2025-04-25 01:44:31,656 [INFO] Epoch 5/15 - Policy Loss: 3.3789, Value Loss: 0.1267, Total Loss: 3.5056, LR: 0.001717
2025-04-25 01:45:09,061 [INFO] Epoch 6/15 - Policy Loss: 3.2983, Value Loss: 0.1198, Total Loss: 3.4181, LR: 0.000067
2025-04-25 01:45:46,507 [INFO] Epoch 7/15 - Policy Loss: 3.2340, Value Loss: 0.1142, Total Loss: 3.3482, LR: 0.001683
2025-04-25 01:46:24,013 [INFO] Epoch 8/15 - Policy Loss: 3.1820, Value Loss: 0.1098, Total Loss: 3.2919, LR: 0.003333
2025-04-25 01:47:01,580 [INFO] Epoch 9/15 - Policy Loss: 3.1435, Value Loss: 0.1066, Total Loss: 3.2500, LR: 0.004983
2025-04-25 01:47:40,388 [INFO] Epoch 10/15 - Policy Loss: 3.1127, Value Loss: 0.1041, Total Loss: 3.2167, LR: 0.003367
2025-04-25 01:48:17,852 [INFO] Epoch 11/15 - Policy Loss: 3.0778, Value Loss: 0.1017, Total Loss: 3.1795, LR: 0.001717
2025-04-25 01:48:55,387 [INFO] Epoch 12/15 - Policy Loss: 3.0424, Value Loss: 0.0992, Total Loss: 3.1416, LR: 0.000067
2025-04-25 01:49:32,903 [INFO] Epoch 13/15 - Policy Loss: 3.0111, Value Loss: 0.0971, Total Loss: 3.1082, LR: 0.001683
2025-04-25 01:50:10,392 [INFO] Epoch 14/15 - Policy Loss: 2.9836, Value Loss: 0.0952, Total Loss: 3.0788, LR: 0.003333
2025-04-25 01:50:47,943 [INFO] Epoch 15/15 - Policy Loss: 2.9620, Value Loss: 0.0937, Total Loss: 3.0557, LR: 0.004983
2025-04-25 01:50:47,976 [INFO] 训练完成，总损失: 3.0557
2025-04-25 01:50:47,976 [INFO] 保存迭代 6 的模型
2025-04-25 01:50:48,368 [INFO] Model saved to ./models/best.pt
2025-04-25 01:50:48,626 [INFO] Model saved to ./models/iteration_6.pt
2025-04-25 01:50:48,627 [INFO] 所有训练迭代完成
2025-04-25 01:50:48,627 [INFO] 开始迭代 7/300
2025-04-25 01:50:48,627 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 02:10:37,794 [INFO] 保存训练样本
2025-04-25 02:10:54,929 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 02:10:55,147 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 02:10:55,147 [INFO] Training with 200000 examples
2025-04-25 02:10:55,148 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 02:10:55,231 [INFO] 循环学习率周期大小: 291 步
2025-04-25 02:11:34,789 [INFO] Epoch 1/15 - Policy Loss: 3.7342, Value Loss: 0.1563, Total Loss: 3.8905, LR: 0.001683
2025-04-25 02:12:12,717 [INFO] Epoch 2/15 - Policy Loss: 3.6055, Value Loss: 0.1418, Total Loss: 3.7473, LR: 0.003333
2025-04-25 02:12:50,644 [INFO] Epoch 3/15 - Policy Loss: 3.4934, Value Loss: 0.1338, Total Loss: 3.6272, LR: 0.004983
2025-04-25 02:13:28,548 [INFO] Epoch 4/15 - Policy Loss: 3.4037, Value Loss: 0.1289, Total Loss: 3.5326, LR: 0.003367
2025-04-25 02:14:06,444 [INFO] Epoch 5/15 - Policy Loss: 3.3135, Value Loss: 0.1227, Total Loss: 3.4362, LR: 0.001717
2025-04-25 02:14:44,319 [INFO] Epoch 6/15 - Policy Loss: 3.2363, Value Loss: 0.1165, Total Loss: 3.3528, LR: 0.000067
2025-04-25 02:15:22,236 [INFO] Epoch 7/15 - Policy Loss: 3.1746, Value Loss: 0.1116, Total Loss: 3.2862, LR: 0.001683
2025-04-25 02:16:00,178 [INFO] Epoch 8/15 - Policy Loss: 3.1251, Value Loss: 0.1077, Total Loss: 3.2328, LR: 0.003333
2025-04-25 02:16:38,171 [INFO] Epoch 9/15 - Policy Loss: 3.0867, Value Loss: 0.1048, Total Loss: 3.1915, LR: 0.004983
2025-04-25 02:17:16,083 [INFO] Epoch 10/15 - Policy Loss: 3.0568, Value Loss: 0.1027, Total Loss: 3.1595, LR: 0.003367
2025-04-25 02:17:54,021 [INFO] Epoch 11/15 - Policy Loss: 3.0236, Value Loss: 0.1007, Total Loss: 3.1243, LR: 0.001717
2025-04-25 02:18:31,907 [INFO] Epoch 12/15 - Policy Loss: 2.9899, Value Loss: 0.0985, Total Loss: 3.0884, LR: 0.000067
2025-04-25 02:19:09,853 [INFO] Epoch 13/15 - Policy Loss: 2.9601, Value Loss: 0.0965, Total Loss: 3.0566, LR: 0.001683
2025-04-25 02:19:47,770 [INFO] Epoch 14/15 - Policy Loss: 2.9329, Value Loss: 0.0948, Total Loss: 3.0278, LR: 0.003333
2025-04-25 02:20:25,695 [INFO] Epoch 15/15 - Policy Loss: 2.9121, Value Loss: 0.0935, Total Loss: 3.0055, LR: 0.004983
2025-04-25 02:20:25,732 [INFO] 训练完成，总损失: 3.0055
2025-04-25 02:20:25,732 [INFO] 保存迭代 7 的模型
2025-04-25 02:20:26,137 [INFO] Model saved to ./models/best.pt
2025-04-25 02:20:26,411 [INFO] Model saved to ./models/iteration_7.pt
2025-04-25 02:20:26,412 [INFO] 所有训练迭代完成
2025-04-25 02:20:26,412 [INFO] 开始迭代 8/300
2025-04-25 02:20:26,412 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 02:38:41,712 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 02:38:41,747 [INFO] 保存训练样本
2025-04-25 02:38:55,683 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 02:38:55,888 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 02:38:55,888 [INFO] Training with 200000 examples
2025-04-25 02:38:55,889 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 02:38:57,197 [INFO] 循环学习率周期大小: 291 步
2025-04-25 02:39:34,688 [INFO] Epoch 1/15 - Policy Loss: 3.5755, Value Loss: 0.1559, Total Loss: 3.7314, LR: 0.001683
2025-04-25 02:40:12,284 [INFO] Epoch 2/15 - Policy Loss: 3.4432, Value Loss: 0.1421, Total Loss: 3.5853, LR: 0.003333
2025-04-25 02:40:49,855 [INFO] Epoch 3/15 - Policy Loss: 3.3296, Value Loss: 0.1340, Total Loss: 3.4636, LR: 0.004983
2025-04-25 02:41:27,401 [INFO] Epoch 4/15 - Policy Loss: 3.2364, Value Loss: 0.1291, Total Loss: 3.3655, LR: 0.003367
2025-04-25 02:42:04,994 [INFO] Epoch 5/15 - Policy Loss: 3.1462, Value Loss: 0.1231, Total Loss: 3.2692, LR: 0.001717
2025-04-25 02:42:42,539 [INFO] Epoch 6/15 - Policy Loss: 3.0660, Value Loss: 0.1172, Total Loss: 3.1832, LR: 0.000067
2025-04-25 02:43:20,437 [INFO] Epoch 7/15 - Policy Loss: 3.0036, Value Loss: 0.1125, Total Loss: 3.1161, LR: 0.001683
2025-04-25 02:43:58,450 [INFO] Epoch 8/15 - Policy Loss: 2.9520, Value Loss: 0.1087, Total Loss: 3.0607, LR: 0.003333
2025-04-25 02:44:36,323 [INFO] Epoch 9/15 - Policy Loss: 2.9130, Value Loss: 0.1059, Total Loss: 3.0189, LR: 0.004983
2025-04-25 02:45:13,929 [INFO] Epoch 10/15 - Policy Loss: 2.8821, Value Loss: 0.1041, Total Loss: 2.9862, LR: 0.003367
2025-04-25 02:45:51,420 [INFO] Epoch 11/15 - Policy Loss: 2.8492, Value Loss: 0.1021, Total Loss: 2.9513, LR: 0.001717
2025-04-25 02:46:28,914 [INFO] Epoch 12/15 - Policy Loss: 2.8162, Value Loss: 0.1001, Total Loss: 2.9163, LR: 0.000067
2025-04-25 02:47:06,511 [INFO] Epoch 13/15 - Policy Loss: 2.7856, Value Loss: 0.0984, Total Loss: 2.8840, LR: 0.001683
2025-04-25 02:47:44,109 [INFO] Epoch 14/15 - Policy Loss: 2.7585, Value Loss: 0.0969, Total Loss: 2.8554, LR: 0.003333
2025-04-25 02:48:21,733 [INFO] Epoch 15/15 - Policy Loss: 2.7379, Value Loss: 0.0957, Total Loss: 2.8335, LR: 0.004983
2025-04-25 02:48:21,767 [INFO] 训练完成，总损失: 2.8335
2025-04-25 02:48:21,767 [INFO] 保存迭代 8 的模型
2025-04-25 02:48:22,158 [INFO] Model saved to ./models/best.pt
2025-04-25 02:48:22,433 [INFO] Model saved to ./models/iteration_8.pt
2025-04-25 02:48:22,434 [INFO] 所有训练迭代完成
2025-04-25 02:48:22,434 [INFO] 开始迭代 9/300
2025-04-25 02:48:22,434 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 03:05:03,963 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 03:05:04,013 [INFO] 保存训练样本
2025-04-25 03:05:18,764 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 03:05:20,376 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 03:05:20,376 [INFO] Training with 200000 examples
2025-04-25 03:05:20,376 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 03:05:20,458 [INFO] 循环学习率周期大小: 291 步
2025-04-25 03:05:58,283 [INFO] Epoch 1/15 - Policy Loss: 3.3808, Value Loss: 0.1526, Total Loss: 3.5334, LR: 0.001683
2025-04-25 03:06:36,077 [INFO] Epoch 2/15 - Policy Loss: 3.2430, Value Loss: 0.1414, Total Loss: 3.3844, LR: 0.003333
2025-04-25 03:07:13,915 [INFO] Epoch 3/15 - Policy Loss: 3.1309, Value Loss: 0.1345, Total Loss: 3.2653, LR: 0.004983
2025-04-25 03:07:51,778 [INFO] Epoch 4/15 - Policy Loss: 3.0368, Value Loss: 0.1298, Total Loss: 3.1666, LR: 0.003367
2025-04-25 03:08:29,639 [INFO] Epoch 5/15 - Policy Loss: 2.9468, Value Loss: 0.1240, Total Loss: 3.0708, LR: 0.001717
2025-04-25 03:09:07,422 [INFO] Epoch 6/15 - Policy Loss: 2.8669, Value Loss: 0.1184, Total Loss: 2.9853, LR: 0.000067
2025-04-25 03:09:45,102 [INFO] Epoch 7/15 - Policy Loss: 2.8043, Value Loss: 0.1144, Total Loss: 2.9187, LR: 0.001683
2025-04-25 03:10:22,746 [INFO] Epoch 8/15 - Policy Loss: 2.7534, Value Loss: 0.1109, Total Loss: 2.8643, LR: 0.003333
2025-04-25 03:11:00,394 [INFO] Epoch 9/15 - Policy Loss: 2.7147, Value Loss: 0.1082, Total Loss: 2.8229, LR: 0.004983
2025-04-25 03:11:38,009 [INFO] Epoch 10/15 - Policy Loss: 2.6825, Value Loss: 0.1063, Total Loss: 2.7888, LR: 0.003367
2025-04-25 03:12:15,669 [INFO] Epoch 11/15 - Policy Loss: 2.6490, Value Loss: 0.1043, Total Loss: 2.7534, LR: 0.001717
2025-04-25 03:12:53,254 [INFO] Epoch 12/15 - Policy Loss: 2.6154, Value Loss: 0.1024, Total Loss: 2.7179, LR: 0.000067
2025-04-25 03:13:30,819 [INFO] Epoch 13/15 - Policy Loss: 2.5845, Value Loss: 0.1006, Total Loss: 2.6851, LR: 0.001683
2025-04-25 03:14:08,575 [INFO] Epoch 14/15 - Policy Loss: 2.5574, Value Loss: 0.0991, Total Loss: 2.6566, LR: 0.003333
2025-04-25 03:14:46,197 [INFO] Epoch 15/15 - Policy Loss: 2.5358, Value Loss: 0.0979, Total Loss: 2.6336, LR: 0.004983
2025-04-25 03:14:46,230 [INFO] 训练完成，总损失: 2.6336
2025-04-25 03:14:46,230 [INFO] 保存迭代 9 的模型
2025-04-25 03:14:46,616 [INFO] Model saved to ./models/best.pt
2025-04-25 03:14:46,885 [INFO] Model saved to ./models/iteration_9.pt
2025-04-25 03:14:46,885 [INFO] 所有训练迭代完成
2025-04-25 03:14:46,885 [INFO] 开始迭代 10/300
2025-04-25 03:14:46,885 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 03:31:14,390 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 03:31:14,442 [INFO] 保存训练样本
2025-04-25 03:31:27,072 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 03:31:27,298 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 03:31:27,298 [INFO] Training with 200000 examples
2025-04-25 03:31:27,298 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 03:31:27,376 [INFO] 循环学习率周期大小: 291 步
2025-04-25 03:32:04,920 [INFO] Epoch 1/15 - Policy Loss: 3.1548, Value Loss: 0.1575, Total Loss: 3.3124, LR: 0.001683
2025-04-25 03:32:42,441 [INFO] Epoch 2/15 - Policy Loss: 3.0189, Value Loss: 0.1436, Total Loss: 3.1625, LR: 0.003333
2025-04-25 03:33:19,967 [INFO] Epoch 3/15 - Policy Loss: 2.9029, Value Loss: 0.1358, Total Loss: 3.0387, LR: 0.004983
2025-04-25 03:33:57,542 [INFO] Epoch 4/15 - Policy Loss: 2.8075, Value Loss: 0.1308, Total Loss: 2.9383, LR: 0.003367
2025-04-25 03:34:35,115 [INFO] Epoch 5/15 - Policy Loss: 2.7137, Value Loss: 0.1250, Total Loss: 2.8387, LR: 0.001717
2025-04-25 03:35:12,693 [INFO] Epoch 6/15 - Policy Loss: 2.6345, Value Loss: 0.1197, Total Loss: 2.7542, LR: 0.000067
2025-04-25 03:35:50,263 [INFO] Epoch 7/15 - Policy Loss: 2.5703, Value Loss: 0.1153, Total Loss: 2.6856, LR: 0.001683
2025-04-25 03:36:29,043 [INFO] Epoch 8/15 - Policy Loss: 2.5193, Value Loss: 0.1119, Total Loss: 2.6312, LR: 0.003333
2025-04-25 03:37:06,630 [INFO] Epoch 9/15 - Policy Loss: 2.4785, Value Loss: 0.1095, Total Loss: 2.5879, LR: 0.004983
2025-04-25 03:37:44,158 [INFO] Epoch 10/15 - Policy Loss: 2.4462, Value Loss: 0.1077, Total Loss: 2.5539, LR: 0.003367
2025-04-25 03:38:21,709 [INFO] Epoch 11/15 - Policy Loss: 2.4122, Value Loss: 0.1059, Total Loss: 2.5181, LR: 0.001717
2025-04-25 03:38:59,257 [INFO] Epoch 12/15 - Policy Loss: 2.3775, Value Loss: 0.1040, Total Loss: 2.4815, LR: 0.000067
2025-04-25 03:39:36,821 [INFO] Epoch 13/15 - Policy Loss: 2.3466, Value Loss: 0.1024, Total Loss: 2.4490, LR: 0.001683
2025-04-25 03:40:14,350 [INFO] Epoch 14/15 - Policy Loss: 2.3186, Value Loss: 0.1009, Total Loss: 2.4196, LR: 0.003333
2025-04-25 03:40:51,902 [INFO] Epoch 15/15 - Policy Loss: 2.2970, Value Loss: 0.0998, Total Loss: 2.3968, LR: 0.004983
2025-04-25 03:40:51,934 [INFO] 训练完成，总损失: 2.3968
2025-04-25 03:40:51,934 [INFO] 保存迭代 10 的模型
2025-04-25 03:40:52,314 [INFO] Model saved to ./models/best.pt
2025-04-25 03:40:52,588 [INFO] Model saved to ./models/iteration_10.pt
2025-04-25 03:40:52,588 [INFO] 所有训练迭代完成
2025-04-25 03:40:52,588 [INFO] 开始迭代 11/300
2025-04-25 03:40:52,588 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 04:00:00,648 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 04:00:00,704 [INFO] 保存训练样本
2025-04-25 04:00:12,441 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 04:00:12,683 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 04:00:12,684 [INFO] Training with 200000 examples
2025-04-25 04:00:12,684 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 04:00:13,903 [INFO] 循环学习率周期大小: 291 步
2025-04-25 04:00:51,711 [INFO] Epoch 1/15 - Policy Loss: 3.1375, Value Loss: 0.1595, Total Loss: 3.2970, LR: 0.001683
2025-04-25 04:01:29,158 [INFO] Epoch 2/15 - Policy Loss: 3.0097, Value Loss: 0.1470, Total Loss: 3.1567, LR: 0.003333
2025-04-25 04:02:06,681 [INFO] Epoch 3/15 - Policy Loss: 2.9049, Value Loss: 0.1382, Total Loss: 3.0431, LR: 0.004983
2025-04-25 04:02:44,242 [INFO] Epoch 4/15 - Policy Loss: 2.8166, Value Loss: 0.1327, Total Loss: 2.9493, LR: 0.003367
2025-04-25 04:03:21,782 [INFO] Epoch 5/15 - Policy Loss: 2.7323, Value Loss: 0.1269, Total Loss: 2.8591, LR: 0.001717
2025-04-25 04:03:59,342 [INFO] Epoch 6/15 - Policy Loss: 2.6592, Value Loss: 0.1216, Total Loss: 2.7808, LR: 0.000067
2025-04-25 04:04:36,906 [INFO] Epoch 7/15 - Policy Loss: 2.6014, Value Loss: 0.1174, Total Loss: 2.7189, LR: 0.001683
2025-04-25 04:05:14,424 [INFO] Epoch 8/15 - Policy Loss: 2.5541, Value Loss: 0.1141, Total Loss: 2.6682, LR: 0.003333
2025-04-25 04:05:51,912 [INFO] Epoch 9/15 - Policy Loss: 2.5171, Value Loss: 0.1116, Total Loss: 2.6287, LR: 0.004983
2025-04-25 04:06:29,398 [INFO] Epoch 10/15 - Policy Loss: 2.4870, Value Loss: 0.1097, Total Loss: 2.5967, LR: 0.003367
2025-04-25 04:07:06,964 [INFO] Epoch 11/15 - Policy Loss: 2.4552, Value Loss: 0.1079, Total Loss: 2.5632, LR: 0.001717
2025-04-25 04:07:44,486 [INFO] Epoch 12/15 - Policy Loss: 2.4233, Value Loss: 0.1060, Total Loss: 2.5293, LR: 0.000067
2025-04-25 04:08:21,958 [INFO] Epoch 13/15 - Policy Loss: 2.3944, Value Loss: 0.1044, Total Loss: 2.4987, LR: 0.001683
2025-04-25 04:08:59,427 [INFO] Epoch 14/15 - Policy Loss: 2.3685, Value Loss: 0.1029, Total Loss: 2.4713, LR: 0.003333
2025-04-25 04:09:36,978 [INFO] Epoch 15/15 - Policy Loss: 2.3475, Value Loss: 0.1016, Total Loss: 2.4491, LR: 0.004983
2025-04-25 04:09:37,010 [INFO] 训练完成，总损失: 2.4491
2025-04-25 04:09:37,010 [INFO] 保存迭代 11 的模型
2025-04-25 04:09:37,448 [INFO] Model saved to ./models/best.pt
2025-04-25 04:09:37,827 [INFO] Model saved to ./models/iteration_11.pt
2025-04-25 04:09:37,828 [INFO] 所有训练迭代完成
2025-04-25 04:09:37,828 [INFO] 开始迭代 12/300
2025-04-25 04:09:37,828 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 04:20:08,855 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 04:20:08,886 [INFO] 保存训练样本
2025-04-25 04:20:20,427 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 04:20:21,683 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 04:20:21,683 [INFO] Training with 200000 examples
2025-04-25 04:20:21,684 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 04:20:21,767 [INFO] 循环学习率周期大小: 291 步
2025-04-25 04:20:59,373 [INFO] Epoch 1/15 - Policy Loss: 3.0007, Value Loss: 0.1400, Total Loss: 3.1406, LR: 0.001683
2025-04-25 04:21:36,983 [INFO] Epoch 2/15 - Policy Loss: 2.8925, Value Loss: 0.1311, Total Loss: 3.0236, LR: 0.003333
2025-04-25 04:22:14,625 [INFO] Epoch 3/15 - Policy Loss: 2.7986, Value Loss: 0.1267, Total Loss: 2.9252, LR: 0.004983
2025-04-25 04:22:52,282 [INFO] Epoch 4/15 - Policy Loss: 2.7218, Value Loss: 0.1230, Total Loss: 2.8449, LR: 0.003367
2025-04-25 04:23:29,874 [INFO] Epoch 5/15 - Policy Loss: 2.6468, Value Loss: 0.1187, Total Loss: 2.7656, LR: 0.001717
2025-04-25 04:24:07,646 [INFO] Epoch 6/15 - Policy Loss: 2.5811, Value Loss: 0.1151, Total Loss: 2.6962, LR: 0.000067
2025-04-25 04:24:45,579 [INFO] Epoch 7/15 - Policy Loss: 2.5288, Value Loss: 0.1118, Total Loss: 2.6407, LR: 0.001683
2025-04-25 04:25:23,530 [INFO] Epoch 8/15 - Policy Loss: 2.4864, Value Loss: 0.1094, Total Loss: 2.5958, LR: 0.003333
2025-04-25 04:26:01,500 [INFO] Epoch 9/15 - Policy Loss: 2.4535, Value Loss: 0.1075, Total Loss: 2.5610, LR: 0.004983
2025-04-25 04:26:39,436 [INFO] Epoch 10/15 - Policy Loss: 2.4268, Value Loss: 0.1061, Total Loss: 2.5329, LR: 0.003367
2025-04-25 04:27:17,403 [INFO] Epoch 11/15 - Policy Loss: 2.3977, Value Loss: 0.1045, Total Loss: 2.5023, LR: 0.001717
2025-04-25 04:27:55,384 [INFO] Epoch 12/15 - Policy Loss: 2.3686, Value Loss: 0.1031, Total Loss: 2.4717, LR: 0.000067
2025-04-25 04:28:33,350 [INFO] Epoch 13/15 - Policy Loss: 2.3423, Value Loss: 0.1019, Total Loss: 2.4442, LR: 0.001683
2025-04-25 04:29:11,306 [INFO] Epoch 14/15 - Policy Loss: 2.3193, Value Loss: 0.1008, Total Loss: 2.4201, LR: 0.003333
2025-04-25 04:29:49,222 [INFO] Epoch 15/15 - Policy Loss: 2.3007, Value Loss: 0.1000, Total Loss: 2.4007, LR: 0.004983
2025-04-25 04:29:49,257 [INFO] 训练完成，总损失: 2.4007
2025-04-25 04:29:49,258 [INFO] 保存迭代 12 的模型
2025-04-25 04:29:49,756 [INFO] Model saved to ./models/best.pt
2025-04-25 04:29:50,067 [INFO] Model saved to ./models/iteration_12.pt
2025-04-25 04:29:50,068 [INFO] 所有训练迭代完成
2025-04-25 04:29:50,068 [INFO] 开始迭代 13/300
2025-04-25 04:29:50,068 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 04:39:09,923 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 04:39:09,961 [INFO] 保存训练样本
2025-04-25 04:39:20,905 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 04:39:21,158 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 04:39:21,158 [INFO] Training with 200000 examples
2025-04-25 04:39:21,158 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 04:39:21,245 [INFO] 循环学习率周期大小: 291 步
2025-04-25 04:40:00,471 [INFO] Epoch 1/15 - Policy Loss: 2.8808, Value Loss: 0.1335, Total Loss: 3.0144, LR: 0.001683
2025-04-25 04:40:38,384 [INFO] Epoch 2/15 - Policy Loss: 2.7827, Value Loss: 0.1254, Total Loss: 2.9081, LR: 0.003333
2025-04-25 04:41:16,309 [INFO] Epoch 3/15 - Policy Loss: 2.6997, Value Loss: 0.1201, Total Loss: 2.8197, LR: 0.004983
2025-04-25 04:41:54,336 [INFO] Epoch 4/15 - Policy Loss: 2.6328, Value Loss: 0.1177, Total Loss: 2.7505, LR: 0.003367
2025-04-25 04:42:32,370 [INFO] Epoch 5/15 - Policy Loss: 2.5661, Value Loss: 0.1146, Total Loss: 2.6806, LR: 0.001717
2025-04-25 04:43:10,380 [INFO] Epoch 6/15 - Policy Loss: 2.5065, Value Loss: 0.1112, Total Loss: 2.6176, LR: 0.000067
2025-04-25 04:43:48,375 [INFO] Epoch 7/15 - Policy Loss: 2.4596, Value Loss: 0.1084, Total Loss: 2.5680, LR: 0.001683
2025-04-25 04:44:26,376 [INFO] Epoch 8/15 - Policy Loss: 2.4209, Value Loss: 0.1064, Total Loss: 2.5273, LR: 0.003333
2025-04-25 04:45:04,377 [INFO] Epoch 9/15 - Policy Loss: 2.3921, Value Loss: 0.1049, Total Loss: 2.4970, LR: 0.004983
2025-04-25 04:45:42,405 [INFO] Epoch 10/15 - Policy Loss: 2.3691, Value Loss: 0.1039, Total Loss: 2.4731, LR: 0.003367
2025-04-25 04:46:20,515 [INFO] Epoch 11/15 - Policy Loss: 2.3446, Value Loss: 0.1028, Total Loss: 2.4473, LR: 0.001717
2025-04-25 04:46:58,164 [INFO] Epoch 12/15 - Policy Loss: 2.3183, Value Loss: 0.1016, Total Loss: 2.4198, LR: 0.000067
2025-04-25 04:47:35,801 [INFO] Epoch 13/15 - Policy Loss: 2.2948, Value Loss: 0.1004, Total Loss: 2.3952, LR: 0.001683
2025-04-25 04:48:13,331 [INFO] Epoch 14/15 - Policy Loss: 2.2739, Value Loss: 0.0995, Total Loss: 2.3734, LR: 0.003333
2025-04-25 04:48:50,866 [INFO] Epoch 15/15 - Policy Loss: 2.2574, Value Loss: 0.0987, Total Loss: 2.3561, LR: 0.004983
2025-04-25 04:48:50,898 [INFO] 训练完成，总损失: 2.3561
2025-04-25 04:48:50,898 [INFO] 保存迭代 13 的模型
2025-04-25 04:48:51,337 [INFO] Model saved to ./models/best.pt
2025-04-25 04:48:51,639 [INFO] Model saved to ./models/iteration_13.pt
2025-04-25 04:48:51,639 [INFO] 所有训练迭代完成
2025-04-25 04:48:51,639 [INFO] 开始迭代 14/300
2025-04-25 04:48:51,639 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 05:00:13,232 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 05:00:13,263 [INFO] 保存训练样本
2025-04-25 05:00:21,983 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 05:00:23,076 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 05:00:23,076 [INFO] Training with 200000 examples
2025-04-25 05:00:23,077 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 05:00:23,156 [INFO] 循环学习率周期大小: 291 步
2025-04-25 05:01:00,635 [INFO] Epoch 1/15 - Policy Loss: 2.8090, Value Loss: 0.1383, Total Loss: 2.9473, LR: 0.001683
2025-04-25 05:01:38,201 [INFO] Epoch 2/15 - Policy Loss: 2.7171, Value Loss: 0.1302, Total Loss: 2.8473, LR: 0.003333
2025-04-25 05:02:15,742 [INFO] Epoch 3/15 - Policy Loss: 2.6425, Value Loss: 0.1255, Total Loss: 2.7680, LR: 0.004983
2025-04-25 05:02:53,253 [INFO] Epoch 4/15 - Policy Loss: 2.5829, Value Loss: 0.1227, Total Loss: 2.7056, LR: 0.003367
2025-04-25 05:03:30,815 [INFO] Epoch 5/15 - Policy Loss: 2.5230, Value Loss: 0.1195, Total Loss: 2.6424, LR: 0.001717
2025-04-25 05:04:08,465 [INFO] Epoch 6/15 - Policy Loss: 2.4691, Value Loss: 0.1164, Total Loss: 2.5856, LR: 0.000067
2025-04-25 05:04:45,952 [INFO] Epoch 7/15 - Policy Loss: 2.4259, Value Loss: 0.1138, Total Loss: 2.5397, LR: 0.001683
2025-04-25 05:05:23,429 [INFO] Epoch 8/15 - Policy Loss: 2.3909, Value Loss: 0.1118, Total Loss: 2.5027, LR: 0.003333
2025-04-25 05:06:00,899 [INFO] Epoch 9/15 - Policy Loss: 2.3649, Value Loss: 0.1103, Total Loss: 2.4752, LR: 0.004983
2025-04-25 05:06:38,434 [INFO] Epoch 10/15 - Policy Loss: 2.3443, Value Loss: 0.1093, Total Loss: 2.4536, LR: 0.003367
2025-04-25 05:07:15,981 [INFO] Epoch 11/15 - Policy Loss: 2.3213, Value Loss: 0.1081, Total Loss: 2.4294, LR: 0.001717
2025-04-25 05:07:53,510 [INFO] Epoch 12/15 - Policy Loss: 2.2974, Value Loss: 0.1069, Total Loss: 2.4043, LR: 0.000067
2025-04-25 05:08:31,044 [INFO] Epoch 13/15 - Policy Loss: 2.2760, Value Loss: 0.1058, Total Loss: 2.3817, LR: 0.001683
2025-04-25 05:09:08,586 [INFO] Epoch 14/15 - Policy Loss: 2.2568, Value Loss: 0.1048, Total Loss: 2.3616, LR: 0.003333
2025-04-25 05:09:45,997 [INFO] Epoch 15/15 - Policy Loss: 2.2420, Value Loss: 0.1041, Total Loss: 2.3461, LR: 0.004983
2025-04-25 05:09:46,029 [INFO] 训练完成，总损失: 2.3461
2025-04-25 05:09:46,029 [INFO] 保存迭代 14 的模型
2025-04-25 05:09:46,430 [INFO] Model saved to ./models/best.pt
2025-04-25 05:09:46,715 [INFO] Model saved to ./models/iteration_14.pt
2025-04-25 05:09:46,716 [INFO] 所有训练迭代完成
2025-04-25 05:09:46,716 [INFO] 开始迭代 15/300
2025-04-25 05:09:46,716 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 05:16:53,854 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 05:16:53,891 [INFO] 保存训练样本
2025-04-25 05:17:02,790 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 05:17:03,013 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 05:17:03,013 [INFO] Training with 200000 examples
2025-04-25 05:17:03,013 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 05:17:03,980 [INFO] 循环学习率周期大小: 291 步
2025-04-25 05:17:41,453 [INFO] Epoch 1/15 - Policy Loss: 2.6875, Value Loss: 0.1258, Total Loss: 2.8133, LR: 0.001683
2025-04-25 05:18:18,930 [INFO] Epoch 2/15 - Policy Loss: 2.6069, Value Loss: 0.1192, Total Loss: 2.7261, LR: 0.003333
2025-04-25 05:18:56,433 [INFO] Epoch 3/15 - Policy Loss: 2.5447, Value Loss: 0.1158, Total Loss: 2.6604, LR: 0.004983
2025-04-25 05:19:33,756 [INFO] Epoch 4/15 - Policy Loss: 2.4942, Value Loss: 0.1141, Total Loss: 2.6083, LR: 0.003367
2025-04-25 05:20:11,155 [INFO] Epoch 5/15 - Policy Loss: 2.4431, Value Loss: 0.1115, Total Loss: 2.5546, LR: 0.001717
2025-04-25 05:20:48,540 [INFO] Epoch 6/15 - Policy Loss: 2.3978, Value Loss: 0.1094, Total Loss: 2.5072, LR: 0.000067
2025-04-25 05:21:26,013 [INFO] Epoch 7/15 - Policy Loss: 2.3604, Value Loss: 0.1074, Total Loss: 2.4678, LR: 0.001683
2025-04-25 05:22:03,472 [INFO] Epoch 8/15 - Policy Loss: 2.3304, Value Loss: 0.1056, Total Loss: 2.4360, LR: 0.003333
2025-04-25 05:22:40,861 [INFO] Epoch 9/15 - Policy Loss: 2.3083, Value Loss: 0.1044, Total Loss: 2.4128, LR: 0.004983
2025-04-25 05:23:18,351 [INFO] Epoch 10/15 - Policy Loss: 2.2921, Value Loss: 0.1036, Total Loss: 2.3957, LR: 0.003367
2025-04-25 05:23:55,863 [INFO] Epoch 11/15 - Policy Loss: 2.2723, Value Loss: 0.1027, Total Loss: 2.3751, LR: 0.001717
2025-04-25 05:24:33,251 [INFO] Epoch 12/15 - Policy Loss: 2.2521, Value Loss: 0.1019, Total Loss: 2.3539, LR: 0.000067
2025-04-25 05:25:10,664 [INFO] Epoch 13/15 - Policy Loss: 2.2336, Value Loss: 0.1011, Total Loss: 2.3347, LR: 0.001683
2025-04-25 05:25:48,147 [INFO] Epoch 14/15 - Policy Loss: 2.2177, Value Loss: 0.1005, Total Loss: 2.3183, LR: 0.003333
2025-04-25 05:26:25,632 [INFO] Epoch 15/15 - Policy Loss: 2.2053, Value Loss: 0.0999, Total Loss: 2.3052, LR: 0.004983
2025-04-25 05:26:25,663 [INFO] 训练完成，总损失: 2.3052
2025-04-25 05:26:25,663 [INFO] 保存迭代 15 的模型
2025-04-25 05:26:26,033 [INFO] Model saved to ./models/best.pt
2025-04-25 05:26:26,330 [INFO] Model saved to ./models/iteration_15.pt
2025-04-25 05:26:26,330 [INFO] 所有训练迭代完成
2025-04-25 05:26:26,330 [INFO] 开始迭代 16/300
2025-04-25 05:26:26,330 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 05:33:59,016 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 05:33:59,060 [INFO] 保存训练样本
2025-04-25 05:34:06,977 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 05:34:07,933 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 05:34:07,933 [INFO] Training with 200000 examples
2025-04-25 05:34:07,933 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 05:34:08,012 [INFO] 循环学习率周期大小: 291 步
2025-04-25 05:34:45,502 [INFO] Epoch 1/15 - Policy Loss: 2.6052, Value Loss: 0.1194, Total Loss: 2.7246, LR: 0.001683
2025-04-25 05:35:22,956 [INFO] Epoch 2/15 - Policy Loss: 2.5349, Value Loss: 0.1138, Total Loss: 2.6487, LR: 0.003333
2025-04-25 05:36:00,530 [INFO] Epoch 3/15 - Policy Loss: 2.4809, Value Loss: 0.1114, Total Loss: 2.5923, LR: 0.004983
2025-04-25 05:36:38,079 [INFO] Epoch 4/15 - Policy Loss: 2.4416, Value Loss: 0.1096, Total Loss: 2.5512, LR: 0.003367
2025-04-25 05:37:15,580 [INFO] Epoch 5/15 - Policy Loss: 2.3982, Value Loss: 0.1074, Total Loss: 2.5056, LR: 0.001717
2025-04-25 05:37:53,093 [INFO] Epoch 6/15 - Policy Loss: 2.3581, Value Loss: 0.1052, Total Loss: 2.4633, LR: 0.000067
2025-04-25 05:38:31,450 [INFO] Epoch 7/15 - Policy Loss: 2.3266, Value Loss: 0.1032, Total Loss: 2.4297, LR: 0.001683
2025-04-25 05:39:09,325 [INFO] Epoch 8/15 - Policy Loss: 2.3003, Value Loss: 0.1018, Total Loss: 2.4022, LR: 0.003333
2025-04-25 05:39:47,292 [INFO] Epoch 9/15 - Policy Loss: 2.2822, Value Loss: 0.1009, Total Loss: 2.3831, LR: 0.004983
2025-04-25 05:40:25,269 [INFO] Epoch 10/15 - Policy Loss: 2.2684, Value Loss: 0.1003, Total Loss: 2.3687, LR: 0.003367
2025-04-25 05:41:02,900 [INFO] Epoch 11/15 - Policy Loss: 2.2522, Value Loss: 0.0996, Total Loss: 2.3518, LR: 0.001717
2025-04-25 05:41:40,449 [INFO] Epoch 12/15 - Policy Loss: 2.2347, Value Loss: 0.0988, Total Loss: 2.3335, LR: 0.000067
2025-04-25 05:42:17,983 [INFO] Epoch 13/15 - Policy Loss: 2.2189, Value Loss: 0.0980, Total Loss: 2.3169, LR: 0.001683
2025-04-25 05:42:55,500 [INFO] Epoch 14/15 - Policy Loss: 2.2051, Value Loss: 0.0973, Total Loss: 2.3025, LR: 0.003333
2025-04-25 05:43:33,055 [INFO] Epoch 15/15 - Policy Loss: 2.1947, Value Loss: 0.0968, Total Loss: 2.2916, LR: 0.004983
2025-04-25 05:43:33,087 [INFO] 训练完成，总损失: 2.2916
2025-04-25 05:43:33,087 [INFO] 保存迭代 16 的模型
2025-04-25 05:43:33,534 [INFO] Model saved to ./models/best.pt
2025-04-25 05:43:33,929 [INFO] Model saved to ./models/iteration_16.pt
2025-04-25 05:43:33,929 [INFO] 所有训练迭代完成
2025-04-25 05:43:33,929 [INFO] 开始迭代 17/300
2025-04-25 05:43:33,929 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 05:49:43,640 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 05:49:43,688 [INFO] 保存训练样本
2025-04-25 05:49:51,844 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 05:49:52,077 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 05:49:52,078 [INFO] Training with 200000 examples
2025-04-25 05:49:52,078 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 05:49:52,856 [INFO] 循环学习率周期大小: 291 步
2025-04-25 05:50:30,810 [INFO] Epoch 1/15 - Policy Loss: 2.4960, Value Loss: 0.1094, Total Loss: 2.6053, LR: 0.001683
2025-04-25 05:51:08,749 [INFO] Epoch 2/15 - Policy Loss: 2.4383, Value Loss: 0.1064, Total Loss: 2.5447, LR: 0.003333
2025-04-25 05:51:46,643 [INFO] Epoch 3/15 - Policy Loss: 2.3985, Value Loss: 0.1050, Total Loss: 2.5035, LR: 0.004983
2025-04-25 05:52:24,599 [INFO] Epoch 4/15 - Policy Loss: 2.3704, Value Loss: 0.1042, Total Loss: 2.4746, LR: 0.003367
2025-04-25 05:53:02,565 [INFO] Epoch 5/15 - Policy Loss: 2.3381, Value Loss: 0.1029, Total Loss: 2.4410, LR: 0.001717
2025-04-25 05:53:40,517 [INFO] Epoch 6/15 - Policy Loss: 2.3058, Value Loss: 0.1015, Total Loss: 2.4073, LR: 0.000067
2025-04-25 05:54:18,436 [INFO] Epoch 7/15 - Policy Loss: 2.2792, Value Loss: 0.0999, Total Loss: 2.3791, LR: 0.001683
2025-04-25 05:54:56,407 [INFO] Epoch 8/15 - Policy Loss: 2.2585, Value Loss: 0.0990, Total Loss: 2.3575, LR: 0.003333
2025-04-25 05:55:34,287 [INFO] Epoch 9/15 - Policy Loss: 2.2447, Value Loss: 0.0984, Total Loss: 2.3431, LR: 0.004983
2025-04-25 05:56:11,865 [INFO] Epoch 10/15 - Policy Loss: 2.2350, Value Loss: 0.0977, Total Loss: 2.3327, LR: 0.003367
2025-04-25 05:56:49,419 [INFO] Epoch 11/15 - Policy Loss: 2.2219, Value Loss: 0.0972, Total Loss: 2.3191, LR: 0.001717
2025-04-25 05:57:26,971 [INFO] Epoch 12/15 - Policy Loss: 2.2076, Value Loss: 0.0967, Total Loss: 2.3043, LR: 0.000067
2025-04-25 05:58:04,507 [INFO] Epoch 13/15 - Policy Loss: 2.1946, Value Loss: 0.0961, Total Loss: 2.2907, LR: 0.001683
2025-04-25 05:58:42,818 [INFO] Epoch 14/15 - Policy Loss: 2.1838, Value Loss: 0.0957, Total Loss: 2.2795, LR: 0.003333
2025-04-25 05:59:20,395 [INFO] Epoch 15/15 - Policy Loss: 2.1756, Value Loss: 0.0952, Total Loss: 2.2708, LR: 0.004983
2025-04-25 05:59:20,426 [INFO] 训练完成，总损失: 2.2708
2025-04-25 05:59:20,426 [INFO] 保存迭代 17 的模型
2025-04-25 05:59:20,867 [INFO] Model saved to ./models/best.pt
2025-04-25 05:59:21,148 [INFO] Model saved to ./models/iteration_17.pt
2025-04-25 05:59:21,148 [INFO] 所有训练迭代完成
2025-04-25 05:59:21,148 [INFO] 开始迭代 18/300
2025-04-25 05:59:21,148 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 06:05:21,755 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 06:05:21,786 [INFO] 保存训练样本
2025-04-25 06:05:28,326 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 06:05:28,546 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 06:05:28,546 [INFO] Training with 200000 examples
2025-04-25 06:05:28,547 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 06:05:29,268 [INFO] 循环学习率周期大小: 291 步
2025-04-25 06:06:06,874 [INFO] Epoch 1/15 - Policy Loss: 2.4031, Value Loss: 0.1081, Total Loss: 2.5112, LR: 0.001683
2025-04-25 06:06:44,496 [INFO] Epoch 2/15 - Policy Loss: 2.3568, Value Loss: 0.1053, Total Loss: 2.4622, LR: 0.003333
2025-04-25 06:07:22,058 [INFO] Epoch 3/15 - Policy Loss: 2.3288, Value Loss: 0.1037, Total Loss: 2.4326, LR: 0.004983
2025-04-25 06:07:59,620 [INFO] Epoch 4/15 - Policy Loss: 2.3102, Value Loss: 0.1042, Total Loss: 2.4144, LR: 0.003367
2025-04-25 06:08:37,180 [INFO] Epoch 5/15 - Policy Loss: 2.2854, Value Loss: 0.1033, Total Loss: 2.3887, LR: 0.001717
2025-04-25 06:09:14,754 [INFO] Epoch 6/15 - Policy Loss: 2.2608, Value Loss: 0.1021, Total Loss: 2.3630, LR: 0.000067
2025-04-25 06:09:52,339 [INFO] Epoch 7/15 - Policy Loss: 2.2408, Value Loss: 0.1012, Total Loss: 2.3419, LR: 0.001683
2025-04-25 06:10:29,884 [INFO] Epoch 8/15 - Policy Loss: 2.2243, Value Loss: 0.1003, Total Loss: 2.3247, LR: 0.003333
2025-04-25 06:11:07,447 [INFO] Epoch 9/15 - Policy Loss: 2.2140, Value Loss: 0.0997, Total Loss: 2.3137, LR: 0.004983
2025-04-25 06:11:45,018 [INFO] Epoch 10/15 - Policy Loss: 2.2078, Value Loss: 0.0995, Total Loss: 2.3073, LR: 0.003367
2025-04-25 06:12:22,582 [INFO] Epoch 11/15 - Policy Loss: 2.1984, Value Loss: 0.0990, Total Loss: 2.2974, LR: 0.001717
2025-04-25 06:13:00,165 [INFO] Epoch 12/15 - Policy Loss: 2.1871, Value Loss: 0.0986, Total Loss: 2.2857, LR: 0.000067
2025-04-25 06:13:37,724 [INFO] Epoch 13/15 - Policy Loss: 2.1763, Value Loss: 0.0980, Total Loss: 2.2743, LR: 0.001683
2025-04-25 06:14:15,294 [INFO] Epoch 14/15 - Policy Loss: 2.1669, Value Loss: 0.0976, Total Loss: 2.2646, LR: 0.003333
2025-04-25 06:14:52,871 [INFO] Epoch 15/15 - Policy Loss: 2.1609, Value Loss: 0.0974, Total Loss: 2.2583, LR: 0.004983
2025-04-25 06:14:52,902 [INFO] 训练完成，总损失: 2.2583
2025-04-25 06:14:52,902 [INFO] 保存迭代 18 的模型
2025-04-25 06:14:53,351 [INFO] Model saved to ./models/best.pt
2025-04-25 06:14:53,635 [INFO] Model saved to ./models/iteration_18.pt
2025-04-25 06:14:53,635 [INFO] 所有训练迭代完成
2025-04-25 06:14:53,635 [INFO] 开始迭代 19/300
2025-04-25 06:14:53,635 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 06:22:17,567 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 06:22:17,609 [INFO] 保存训练样本
2025-04-25 06:22:24,948 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 06:22:25,205 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 06:22:25,205 [INFO] Training with 200000 examples
2025-04-25 06:22:25,205 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 06:22:25,998 [INFO] 循环学习率周期大小: 291 步
2025-04-25 06:23:03,950 [INFO] Epoch 1/15 - Policy Loss: 2.3356, Value Loss: 0.1046, Total Loss: 2.4402, LR: 0.001683
2025-04-25 06:23:41,951 [INFO] Epoch 2/15 - Policy Loss: 2.2997, Value Loss: 0.1018, Total Loss: 2.4016, LR: 0.003333
2025-04-25 06:24:19,957 [INFO] Epoch 3/15 - Policy Loss: 2.2794, Value Loss: 0.0996, Total Loss: 2.3791, LR: 0.004983
2025-04-25 06:24:57,968 [INFO] Epoch 4/15 - Policy Loss: 2.2700, Value Loss: 0.0990, Total Loss: 2.3689, LR: 0.003367
2025-04-25 06:25:35,563 [INFO] Epoch 5/15 - Policy Loss: 2.2502, Value Loss: 0.0979, Total Loss: 2.3481, LR: 0.001717
2025-04-25 06:26:13,104 [INFO] Epoch 6/15 - Policy Loss: 2.2297, Value Loss: 0.0964, Total Loss: 2.3261, LR: 0.000067
2025-04-25 06:26:50,708 [INFO] Epoch 7/15 - Policy Loss: 2.2127, Value Loss: 0.0953, Total Loss: 2.3081, LR: 0.001683
2025-04-25 06:27:28,299 [INFO] Epoch 8/15 - Policy Loss: 2.1987, Value Loss: 0.0945, Total Loss: 2.2932, LR: 0.003333
2025-04-25 06:28:05,885 [INFO] Epoch 9/15 - Policy Loss: 2.1911, Value Loss: 0.0940, Total Loss: 2.2851, LR: 0.004983
2025-04-25 06:28:43,447 [INFO] Epoch 10/15 - Policy Loss: 2.1868, Value Loss: 0.0940, Total Loss: 2.2807, LR: 0.003367
2025-04-25 06:29:21,004 [INFO] Epoch 11/15 - Policy Loss: 2.1800, Value Loss: 0.0939, Total Loss: 2.2739, LR: 0.001717
2025-04-25 06:29:58,570 [INFO] Epoch 12/15 - Policy Loss: 2.1706, Value Loss: 0.0935, Total Loss: 2.2641, LR: 0.000067
2025-04-25 06:30:36,121 [INFO] Epoch 13/15 - Policy Loss: 2.1615, Value Loss: 0.0931, Total Loss: 2.2546, LR: 0.001683
2025-04-25 06:31:13,718 [INFO] Epoch 14/15 - Policy Loss: 2.1540, Value Loss: 0.0927, Total Loss: 2.2468, LR: 0.003333
2025-04-25 06:31:51,277 [INFO] Epoch 15/15 - Policy Loss: 2.1493, Value Loss: 0.0925, Total Loss: 2.2418, LR: 0.004983
2025-04-25 06:31:51,308 [INFO] 训练完成，总损失: 2.2418
2025-04-25 06:31:51,308 [INFO] 保存迭代 19 的模型
2025-04-25 06:31:51,693 [INFO] Model saved to ./models/best.pt
2025-04-25 06:31:51,971 [INFO] Model saved to ./models/iteration_19.pt
2025-04-25 06:31:51,972 [INFO] 所有训练迭代完成
2025-04-25 06:31:51,972 [INFO] 开始迭代 20/300
2025-04-25 06:31:51,972 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 06:37:29,814 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 06:37:29,828 [INFO] 保存训练样本
2025-04-25 06:37:35,784 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 06:37:36,024 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 06:37:36,024 [INFO] Training with 200000 examples
2025-04-25 06:37:36,024 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 06:37:36,668 [INFO] 循环学习率周期大小: 291 步
2025-04-25 06:38:14,584 [INFO] Epoch 1/15 - Policy Loss: 2.2701, Value Loss: 0.0994, Total Loss: 2.3695, LR: 0.001683
2025-04-25 06:38:52,418 [INFO] Epoch 2/15 - Policy Loss: 2.2407, Value Loss: 0.0977, Total Loss: 2.3384, LR: 0.003333
2025-04-25 06:39:29,978 [INFO] Epoch 3/15 - Policy Loss: 2.2338, Value Loss: 0.0973, Total Loss: 2.3311, LR: 0.004983
2025-04-25 06:40:07,529 [INFO] Epoch 4/15 - Policy Loss: 2.2306, Value Loss: 0.0970, Total Loss: 2.3276, LR: 0.003367
2025-04-25 06:40:45,081 [INFO] Epoch 5/15 - Policy Loss: 2.2193, Value Loss: 0.0962, Total Loss: 2.3155, LR: 0.001717
2025-04-25 06:41:22,967 [INFO] Epoch 6/15 - Policy Loss: 2.2056, Value Loss: 0.0953, Total Loss: 2.3009, LR: 0.000067
2025-04-25 06:42:00,792 [INFO] Epoch 7/15 - Policy Loss: 2.1940, Value Loss: 0.0946, Total Loss: 2.2885, LR: 0.001683
2025-04-25 06:42:38,668 [INFO] Epoch 8/15 - Policy Loss: 2.1848, Value Loss: 0.0938, Total Loss: 2.2786, LR: 0.003333
2025-04-25 06:43:16,624 [INFO] Epoch 9/15 - Policy Loss: 2.1797, Value Loss: 0.0934, Total Loss: 2.2731, LR: 0.004983
2025-04-25 06:43:54,572 [INFO] Epoch 10/15 - Policy Loss: 2.1784, Value Loss: 0.0933, Total Loss: 2.2717, LR: 0.003367
2025-04-25 06:44:32,486 [INFO] Epoch 11/15 - Policy Loss: 2.1739, Value Loss: 0.0931, Total Loss: 2.2670, LR: 0.001717
2025-04-25 06:45:10,516 [INFO] Epoch 12/15 - Policy Loss: 2.1679, Value Loss: 0.0928, Total Loss: 2.2607, LR: 0.000067
2025-04-25 06:45:48,569 [INFO] Epoch 13/15 - Policy Loss: 2.1612, Value Loss: 0.0925, Total Loss: 2.2537, LR: 0.001683
2025-04-25 06:46:26,624 [INFO] Epoch 14/15 - Policy Loss: 2.1552, Value Loss: 0.0923, Total Loss: 2.2475, LR: 0.003333
2025-04-25 06:47:04,560 [INFO] Epoch 15/15 - Policy Loss: 2.1519, Value Loss: 0.0921, Total Loss: 2.2440, LR: 0.004983
2025-04-25 06:47:04,596 [INFO] 训练完成，总损失: 2.2440
2025-04-25 06:47:04,596 [INFO] 保存迭代 20 的模型
2025-04-25 06:47:05,009 [INFO] Model saved to ./models/best.pt
2025-04-25 06:47:05,284 [INFO] Model saved to ./models/iteration_20.pt
2025-04-25 06:47:05,285 [INFO] 所有训练迭代完成
2025-04-25 06:47:05,285 [INFO] 开始迭代 21/300
2025-04-25 06:47:05,285 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 06:53:03,516 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 06:53:03,520 [INFO] 保存训练样本
2025-04-25 06:53:08,444 [INFO] 截断训练样本，保持长度为 200000
2025-04-25 06:53:08,650 [INFO] 使用 200000 个样本训练神经网络
2025-04-25 06:53:08,650 [INFO] Training with 200000 examples
2025-04-25 06:53:08,651 [INFO] 总训练步数: 1455, 每轮次批次数: 97
2025-04-25 06:53:09,209 [INFO] 循环学习率周期大小: 291 步
2025-04-25 06:53:47,177 [INFO] Epoch 1/15 - Policy Loss: 1.9088, Value Loss: 0.1034, Total Loss: 2.0122, LR: 0.001683
2025-04-25 06:54:25,112 [INFO] Epoch 2/15 - Policy Loss: 1.8805, Value Loss: 0.1004, Total Loss: 1.9809, LR: 0.003333
2025-04-25 06:55:03,111 [INFO] Epoch 3/15 - Policy Loss: 1.8744, Value Loss: 0.0998, Total Loss: 1.9742, LR: 0.004983
2025-04-25 06:55:41,021 [INFO] Epoch 4/15 - Policy Loss: 1.8756, Value Loss: 0.0995, Total Loss: 1.9752, LR: 0.003367
2025-04-25 06:56:19,007 [INFO] Epoch 5/15 - Policy Loss: 1.8695, Value Loss: 0.0989, Total Loss: 1.9685, LR: 0.001717
2025-04-25 06:56:56,797 [INFO] Epoch 6/15 - Policy Loss: 1.8587, Value Loss: 0.0982, Total Loss: 1.9569, LR: 0.000067
2025-04-25 06:57:34,756 [INFO] Epoch 7/15 - Policy Loss: 1.8483, Value Loss: 0.0977, Total Loss: 1.9461, LR: 0.001683
2025-04-25 06:58:12,747 [INFO] Epoch 8/15 - Policy Loss: 1.8406, Value Loss: 0.0971, Total Loss: 1.9377, LR: 0.003333
2025-04-25 06:58:51,372 [INFO] Epoch 9/15 - Policy Loss: 1.8372, Value Loss: 0.0966, Total Loss: 1.9337, LR: 0.004983
2025-04-25 06:59:29,200 [INFO] Epoch 10/15 - Policy Loss: 1.8370, Value Loss: 0.0964, Total Loss: 1.9333, LR: 0.003367
2025-04-25 07:00:07,282 [INFO] Epoch 11/15 - Policy Loss: 1.8341, Value Loss: 0.0962, Total Loss: 1.9304, LR: 0.001717
2025-04-25 07:00:45,383 [INFO] Epoch 12/15 - Policy Loss: 1.8291, Value Loss: 0.0958, Total Loss: 1.9249, LR: 0.000067
2025-04-25 07:01:23,361 [INFO] Epoch 13/15 - Policy Loss: 1.8236, Value Loss: 0.0955, Total Loss: 1.9191, LR: 0.001683
2025-04-25 07:02:01,306 [INFO] Epoch 14/15 - Policy Loss: 1.8192, Value Loss: 0.0953, Total Loss: 1.9145, LR: 0.003333
2025-04-25 07:02:39,373 [INFO] Epoch 15/15 - Policy Loss: 1.8170, Value Loss: 0.0950, Total Loss: 1.9121, LR: 0.004983
2025-04-25 07:02:39,412 [INFO] 训练完成，总损失: 1.9121
2025-04-25 07:02:39,412 [INFO] 保存迭代 21 的模型
2025-04-25 07:02:39,789 [INFO] Model saved to ./models/best.pt
2025-04-25 07:02:40,064 [INFO] Model saved to ./models/iteration_21.pt
2025-04-25 07:02:40,064 [INFO] 所有训练迭代完成
2025-04-25 07:02:40,064 [INFO] 开始迭代 22/300
2025-04-25 07:02:40,064 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 07:09:39,992 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 07:09:39,993 [INFO] 保存训练样本
2025-04-25 07:09:45,896 [INFO] 使用 192320 个样本训练神经网络
2025-04-25 07:09:45,896 [INFO] Training with 192320 examples
2025-04-25 07:09:45,896 [INFO] 总训练步数: 1395, 每轮次批次数: 93
2025-04-25 07:09:45,975 [INFO] 循环学习率周期大小: 279 步
2025-04-25 07:10:22,397 [INFO] Epoch 1/15 - Policy Loss: 1.8180, Value Loss: 0.1122, Total Loss: 1.9302, LR: 0.001682
2025-04-25 07:10:58,844 [INFO] Epoch 2/15 - Policy Loss: 1.7994, Value Loss: 0.1085, Total Loss: 1.9079, LR: 0.003332
2025-04-25 07:11:35,273 [INFO] Epoch 3/15 - Policy Loss: 1.7979, Value Loss: 0.1065, Total Loss: 1.9044, LR: 0.004982
2025-04-25 07:12:12,363 [INFO] Epoch 4/15 - Policy Loss: 1.8007, Value Loss: 0.1053, Total Loss: 1.9060, LR: 0.003368
2025-04-25 07:12:48,829 [INFO] Epoch 5/15 - Policy Loss: 1.7967, Value Loss: 0.1049, Total Loss: 1.9016, LR: 0.001718
2025-04-25 07:13:25,289 [INFO] Epoch 6/15 - Policy Loss: 1.7885, Value Loss: 0.1039, Total Loss: 1.8924, LR: 0.000068
2025-04-25 07:14:01,733 [INFO] Epoch 7/15 - Policy Loss: 1.7803, Value Loss: 0.1030, Total Loss: 1.8833, LR: 0.001682
2025-04-25 07:14:38,203 [INFO] Epoch 8/15 - Policy Loss: 1.7749, Value Loss: 0.1022, Total Loss: 1.8771, LR: 0.003332
2025-04-25 07:15:14,655 [INFO] Epoch 9/15 - Policy Loss: 1.7727, Value Loss: 0.1017, Total Loss: 1.8743, LR: 0.004982
2025-04-25 07:15:51,102 [INFO] Epoch 10/15 - Policy Loss: 1.7739, Value Loss: 0.1013, Total Loss: 1.8752, LR: 0.003368
2025-04-25 07:16:27,553 [INFO] Epoch 11/15 - Policy Loss: 1.7725, Value Loss: 0.1010, Total Loss: 1.8736, LR: 0.001718
2025-04-25 07:17:04,049 [INFO] Epoch 12/15 - Policy Loss: 1.7685, Value Loss: 0.1007, Total Loss: 1.8691, LR: 0.000068
2025-04-25 07:17:40,527 [INFO] Epoch 13/15 - Policy Loss: 1.7645, Value Loss: 0.1002, Total Loss: 1.8646, LR: 0.001682
2025-04-25 07:18:16,984 [INFO] Epoch 14/15 - Policy Loss: 1.7605, Value Loss: 0.0998, Total Loss: 1.8603, LR: 0.003332
2025-04-25 07:18:53,381 [INFO] Epoch 15/15 - Policy Loss: 1.7587, Value Loss: 0.0996, Total Loss: 1.8583, LR: 0.004982
2025-04-25 07:18:53,414 [INFO] 训练完成，总损失: 1.8583
2025-04-25 07:18:53,414 [INFO] 保存迭代 22 的模型
2025-04-25 07:18:53,864 [INFO] Model saved to ./models/best.pt
2025-04-25 07:18:54,165 [INFO] Model saved to ./models/iteration_22.pt
2025-04-25 07:18:54,165 [INFO] 所有训练迭代完成
2025-04-25 07:18:54,165 [INFO] 开始迭代 23/300
2025-04-25 07:18:54,165 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 07:25:22,633 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 07:25:22,635 [INFO] 保存训练样本
2025-04-25 07:25:27,111 [INFO] 使用 182120 个样本训练神经网络
2025-04-25 07:25:27,111 [INFO] Training with 182120 examples
2025-04-25 07:25:27,111 [INFO] 总训练步数: 1320, 每轮次批次数: 88
2025-04-25 07:25:27,619 [INFO] 循环学习率周期大小: 264 步
2025-04-25 07:26:02,073 [INFO] Epoch 1/15 - Policy Loss: 1.7565, Value Loss: 0.1143, Total Loss: 1.8708, LR: 0.001681
2025-04-25 07:26:36,502 [INFO] Epoch 2/15 - Policy Loss: 1.7473, Value Loss: 0.1122, Total Loss: 1.8596, LR: 0.003331
2025-04-25 07:27:10,990 [INFO] Epoch 3/15 - Policy Loss: 1.7455, Value Loss: 0.1115, Total Loss: 1.8570, LR: 0.004981
2025-04-25 07:27:45,478 [INFO] Epoch 4/15 - Policy Loss: 1.7500, Value Loss: 0.1107, Total Loss: 1.8607, LR: 0.003369
2025-04-25 07:28:19,960 [INFO] Epoch 5/15 - Policy Loss: 1.7464, Value Loss: 0.1092, Total Loss: 1.8556, LR: 0.001719
2025-04-25 07:28:54,431 [INFO] Epoch 6/15 - Policy Loss: 1.7385, Value Loss: 0.1082, Total Loss: 1.8467, LR: 0.000069
2025-04-25 07:29:28,902 [INFO] Epoch 7/15 - Policy Loss: 1.7320, Value Loss: 0.1074, Total Loss: 1.8393, LR: 0.001681
2025-04-25 07:30:03,417 [INFO] Epoch 8/15 - Policy Loss: 1.7266, Value Loss: 0.1069, Total Loss: 1.8335, LR: 0.003331
2025-04-25 07:30:37,879 [INFO] Epoch 9/15 - Policy Loss: 1.7247, Value Loss: 0.1063, Total Loss: 1.8310, LR: 0.004981
2025-04-25 07:31:12,392 [INFO] Epoch 10/15 - Policy Loss: 1.7264, Value Loss: 0.1060, Total Loss: 1.8325, LR: 0.003369
2025-04-25 07:31:46,846 [INFO] Epoch 11/15 - Policy Loss: 1.7247, Value Loss: 0.1057, Total Loss: 1.8304, LR: 0.001719
2025-04-25 07:32:21,311 [INFO] Epoch 12/15 - Policy Loss: 1.7212, Value Loss: 0.1052, Total Loss: 1.8265, LR: 0.000069
2025-04-25 07:32:55,740 [INFO] Epoch 13/15 - Policy Loss: 1.7174, Value Loss: 0.1049, Total Loss: 1.8223, LR: 0.001681
2025-04-25 07:33:30,164 [INFO] Epoch 14/15 - Policy Loss: 1.7141, Value Loss: 0.1043, Total Loss: 1.8184, LR: 0.003331
2025-04-25 07:34:04,616 [INFO] Epoch 15/15 - Policy Loss: 1.7131, Value Loss: 0.1041, Total Loss: 1.8172, LR: 0.004981
2025-04-25 07:34:04,646 [INFO] 训练完成，总损失: 1.8172
2025-04-25 07:34:04,646 [INFO] 保存迭代 23 的模型
2025-04-25 07:34:05,132 [INFO] Model saved to ./models/best.pt
2025-04-25 07:34:05,446 [INFO] Model saved to ./models/iteration_23.pt
2025-04-25 07:34:05,447 [INFO] 所有训练迭代完成
2025-04-25 07:34:05,447 [INFO] 开始迭代 24/300
2025-04-25 07:34:05,447 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 07:39:53,729 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 07:39:53,730 [INFO] 保存训练样本
2025-04-25 07:39:58,528 [INFO] 使用 172136 个样本训练神经网络
2025-04-25 07:39:58,528 [INFO] Training with 172136 examples
2025-04-25 07:39:58,529 [INFO] 总训练步数: 1260, 每轮次批次数: 84
2025-04-25 07:39:59,083 [INFO] 循环学习率周期大小: 252 步
2025-04-25 07:40:31,902 [INFO] Epoch 1/15 - Policy Loss: 1.7164, Value Loss: 0.1174, Total Loss: 1.8338, LR: 0.001680
2025-04-25 07:41:04,797 [INFO] Epoch 2/15 - Policy Loss: 1.7032, Value Loss: 0.1159, Total Loss: 1.8192, LR: 0.003330
2025-04-25 07:41:37,688 [INFO] Epoch 3/15 - Policy Loss: 1.7038, Value Loss: 0.1148, Total Loss: 1.8185, LR: 0.004980
2025-04-25 07:42:10,552 [INFO] Epoch 4/15 - Policy Loss: 1.7082, Value Loss: 0.1146, Total Loss: 1.8228, LR: 0.003370
2025-04-25 07:42:43,432 [INFO] Epoch 5/15 - Policy Loss: 1.7044, Value Loss: 0.1136, Total Loss: 1.8180, LR: 0.001720
2025-04-25 07:43:16,327 [INFO] Epoch 6/15 - Policy Loss: 1.6980, Value Loss: 0.1126, Total Loss: 1.8107, LR: 0.000070
2025-04-25 07:43:49,214 [INFO] Epoch 7/15 - Policy Loss: 1.6918, Value Loss: 0.1117, Total Loss: 1.8035, LR: 0.001680
2025-04-25 07:44:22,087 [INFO] Epoch 8/15 - Policy Loss: 1.6873, Value Loss: 0.1111, Total Loss: 1.7983, LR: 0.003330
2025-04-25 07:44:54,966 [INFO] Epoch 9/15 - Policy Loss: 1.6855, Value Loss: 0.1106, Total Loss: 1.7961, LR: 0.004980
2025-04-25 07:45:27,837 [INFO] Epoch 10/15 - Policy Loss: 1.6867, Value Loss: 0.1102, Total Loss: 1.7969, LR: 0.003370
2025-04-25 07:46:00,730 [INFO] Epoch 11/15 - Policy Loss: 1.6864, Value Loss: 0.1099, Total Loss: 1.7963, LR: 0.001720
2025-04-25 07:46:33,651 [INFO] Epoch 12/15 - Policy Loss: 1.6832, Value Loss: 0.1095, Total Loss: 1.7927, LR: 0.000070
2025-04-25 07:47:06,511 [INFO] Epoch 13/15 - Policy Loss: 1.6800, Value Loss: 0.1092, Total Loss: 1.7892, LR: 0.001680
2025-04-25 07:47:39,964 [INFO] Epoch 14/15 - Policy Loss: 1.6770, Value Loss: 0.1089, Total Loss: 1.7859, LR: 0.003330
2025-04-25 07:48:12,695 [INFO] Epoch 15/15 - Policy Loss: 1.6759, Value Loss: 0.1086, Total Loss: 1.7845, LR: 0.004980
2025-04-25 07:48:12,725 [INFO] 训练完成，总损失: 1.7845
2025-04-25 07:48:12,725 [INFO] 保存迭代 24 的模型
2025-04-25 07:48:13,143 [INFO] Model saved to ./models/best.pt
2025-04-25 07:48:13,413 [INFO] Model saved to ./models/iteration_24.pt
2025-04-25 07:48:13,413 [INFO] 所有训练迭代完成
2025-04-25 07:48:13,413 [INFO] 开始迭代 25/300
2025-04-25 07:48:13,413 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 07:54:37,385 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 07:54:37,385 [INFO] 保存训练样本
2025-04-25 07:54:41,891 [INFO] 使用 162800 个样本训练神经网络
2025-04-25 07:54:41,891 [INFO] Training with 162800 examples
2025-04-25 07:54:41,892 [INFO] 总训练步数: 1185, 每轮次批次数: 79
2025-04-25 07:54:42,424 [INFO] 循环学习率周期大小: 237 步
2025-04-25 07:55:13,344 [INFO] Epoch 1/15 - Policy Loss: 1.6911, Value Loss: 0.1235, Total Loss: 1.8146, LR: 0.001679
2025-04-25 07:55:44,337 [INFO] Epoch 2/15 - Policy Loss: 1.6797, Value Loss: 0.1211, Total Loss: 1.8008, LR: 0.003329
2025-04-25 07:56:15,287 [INFO] Epoch 3/15 - Policy Loss: 1.6785, Value Loss: 0.1199, Total Loss: 1.7985, LR: 0.004979
2025-04-25 07:56:46,178 [INFO] Epoch 4/15 - Policy Loss: 1.6810, Value Loss: 0.1189, Total Loss: 1.7999, LR: 0.003371
2025-04-25 07:57:17,061 [INFO] Epoch 5/15 - Policy Loss: 1.6781, Value Loss: 0.1186, Total Loss: 1.7967, LR: 0.001721
2025-04-25 07:57:47,978 [INFO] Epoch 6/15 - Policy Loss: 1.6722, Value Loss: 0.1177, Total Loss: 1.7899, LR: 0.000071
2025-04-25 07:58:18,897 [INFO] Epoch 7/15 - Policy Loss: 1.6652, Value Loss: 0.1167, Total Loss: 1.7819, LR: 0.001679
2025-04-25 07:58:49,766 [INFO] Epoch 8/15 - Policy Loss: 1.6604, Value Loss: 0.1161, Total Loss: 1.7765, LR: 0.003329
2025-04-25 07:59:20,590 [INFO] Epoch 9/15 - Policy Loss: 1.6588, Value Loss: 0.1159, Total Loss: 1.7746, LR: 0.004979
2025-04-25 07:59:51,529 [INFO] Epoch 10/15 - Policy Loss: 1.6595, Value Loss: 0.1155, Total Loss: 1.7750, LR: 0.003371
2025-04-25 08:00:22,894 [INFO] Epoch 11/15 - Policy Loss: 1.6578, Value Loss: 0.1152, Total Loss: 1.7730, LR: 0.001721
2025-04-25 08:00:53,749 [INFO] Epoch 12/15 - Policy Loss: 1.6542, Value Loss: 0.1148, Total Loss: 1.7690, LR: 0.000071
2025-04-25 08:01:24,688 [INFO] Epoch 13/15 - Policy Loss: 1.6509, Value Loss: 0.1144, Total Loss: 1.7653, LR: 0.001679
2025-04-25 08:01:55,610 [INFO] Epoch 14/15 - Policy Loss: 1.6481, Value Loss: 0.1141, Total Loss: 1.7622, LR: 0.003329
2025-04-25 08:02:26,567 [INFO] Epoch 15/15 - Policy Loss: 1.6471, Value Loss: 0.1140, Total Loss: 1.7611, LR: 0.004979
2025-04-25 08:02:26,595 [INFO] 训练完成，总损失: 1.7611
2025-04-25 08:02:26,595 [INFO] 保存迭代 25 的模型
2025-04-25 08:02:26,996 [INFO] Model saved to ./models/best.pt
2025-04-25 08:02:27,272 [INFO] Model saved to ./models/iteration_25.pt
2025-04-25 08:02:27,273 [INFO] 所有训练迭代完成
2025-04-25 08:02:27,273 [INFO] 开始迭代 26/300
2025-04-25 08:02:27,273 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 08:08:00,355 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 08:08:00,359 [INFO] 保存训练样本
2025-04-25 08:08:04,207 [INFO] 使用 154168 个样本训练神经网络
2025-04-25 08:08:04,207 [INFO] Training with 154168 examples
2025-04-25 08:08:04,208 [INFO] 总训练步数: 1125, 每轮次批次数: 75
2025-04-25 08:08:04,632 [INFO] 循环学习率周期大小: 225 步
2025-04-25 08:08:33,867 [INFO] Epoch 1/15 - Policy Loss: 1.6518, Value Loss: 0.1164, Total Loss: 1.7682, LR: 0.001678
2025-04-25 08:09:03,119 [INFO] Epoch 2/15 - Policy Loss: 1.6424, Value Loss: 0.1159, Total Loss: 1.7584, LR: 0.003328
2025-04-25 08:09:32,341 [INFO] Epoch 3/15 - Policy Loss: 1.6416, Value Loss: 0.1155, Total Loss: 1.7571, LR: 0.004978
2025-04-25 08:10:01,514 [INFO] Epoch 4/15 - Policy Loss: 1.6451, Value Loss: 0.1149, Total Loss: 1.7601, LR: 0.003372
2025-04-25 08:10:30,607 [INFO] Epoch 5/15 - Policy Loss: 1.6424, Value Loss: 0.1142, Total Loss: 1.7566, LR: 0.001722
2025-04-25 08:10:59,851 [INFO] Epoch 6/15 - Policy Loss: 1.6371, Value Loss: 0.1139, Total Loss: 1.7510, LR: 0.000072
2025-04-25 08:11:29,007 [INFO] Epoch 7/15 - Policy Loss: 1.6323, Value Loss: 0.1132, Total Loss: 1.7455, LR: 0.001678
2025-04-25 08:11:58,051 [INFO] Epoch 8/15 - Policy Loss: 1.6286, Value Loss: 0.1127, Total Loss: 1.7413, LR: 0.003328
2025-04-25 08:12:27,525 [INFO] Epoch 9/15 - Policy Loss: 1.6279, Value Loss: 0.1125, Total Loss: 1.7404, LR: 0.004978
2025-04-25 08:12:56,578 [INFO] Epoch 10/15 - Policy Loss: 1.6291, Value Loss: 0.1123, Total Loss: 1.7414, LR: 0.003372
2025-04-25 08:13:25,645 [INFO] Epoch 11/15 - Policy Loss: 1.6281, Value Loss: 0.1121, Total Loss: 1.7402, LR: 0.001722
2025-04-25 08:13:54,711 [INFO] Epoch 12/15 - Policy Loss: 1.6257, Value Loss: 0.1120, Total Loss: 1.7377, LR: 0.000072
2025-04-25 08:14:23,775 [INFO] Epoch 13/15 - Policy Loss: 1.6230, Value Loss: 0.1117, Total Loss: 1.7347, LR: 0.001678
2025-04-25 08:14:52,900 [INFO] Epoch 14/15 - Policy Loss: 1.6207, Value Loss: 0.1114, Total Loss: 1.7321, LR: 0.003328
2025-04-25 08:15:22,131 [INFO] Epoch 15/15 - Policy Loss: 1.6202, Value Loss: 0.1112, Total Loss: 1.7315, LR: 0.004978
2025-04-25 08:15:22,156 [INFO] 训练完成，总损失: 1.7315
2025-04-25 08:15:22,156 [INFO] 保存迭代 26 的模型
2025-04-25 08:15:22,542 [INFO] Model saved to ./models/best.pt
2025-04-25 08:15:22,840 [INFO] Model saved to ./models/iteration_26.pt
2025-04-25 08:15:22,840 [INFO] 所有训练迭代完成
2025-04-25 08:15:22,840 [INFO] 开始迭代 27/300
2025-04-25 08:15:22,840 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 08:21:07,463 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 08:21:07,464 [INFO] 保存训练样本
2025-04-25 08:21:11,651 [INFO] 使用 145288 个样本训练神经网络
2025-04-25 08:21:11,651 [INFO] Training with 145288 examples
2025-04-25 08:21:11,651 [INFO] 总训练步数: 1050, 每轮次批次数: 70
2025-04-25 08:21:11,709 [INFO] 循环学习率周期大小: 210 步
2025-04-25 08:21:38,792 [INFO] Epoch 1/15 - Policy Loss: 1.6307, Value Loss: 0.1293, Total Loss: 1.7600, LR: 0.001676
2025-04-25 08:22:05,877 [INFO] Epoch 2/15 - Policy Loss: 1.6185, Value Loss: 0.1251, Total Loss: 1.7436, LR: 0.003326
2025-04-25 08:22:32,975 [INFO] Epoch 3/15 - Policy Loss: 1.6181, Value Loss: 0.1232, Total Loss: 1.7413, LR: 0.004976
2025-04-25 08:23:00,185 [INFO] Epoch 4/15 - Policy Loss: 1.6202, Value Loss: 0.1219, Total Loss: 1.7421, LR: 0.003374
2025-04-25 08:23:27,512 [INFO] Epoch 5/15 - Policy Loss: 1.6180, Value Loss: 0.1203, Total Loss: 1.7383, LR: 0.001724
2025-04-25 08:23:55,296 [INFO] Epoch 6/15 - Policy Loss: 1.6129, Value Loss: 0.1192, Total Loss: 1.7321, LR: 0.000074
2025-04-25 08:24:22,562 [INFO] Epoch 7/15 - Policy Loss: 1.6070, Value Loss: 0.1181, Total Loss: 1.7251, LR: 0.001676
2025-04-25 08:24:49,831 [INFO] Epoch 8/15 - Policy Loss: 1.6041, Value Loss: 0.1176, Total Loss: 1.7217, LR: 0.003326
2025-04-25 08:25:17,122 [INFO] Epoch 9/15 - Policy Loss: 1.6029, Value Loss: 0.1170, Total Loss: 1.7199, LR: 0.004976
2025-04-25 08:25:44,478 [INFO] Epoch 10/15 - Policy Loss: 1.6029, Value Loss: 0.1166, Total Loss: 1.7195, LR: 0.003374
2025-04-25 08:26:11,833 [INFO] Epoch 11/15 - Policy Loss: 1.6019, Value Loss: 0.1165, Total Loss: 1.7183, LR: 0.001724
2025-04-25 08:26:39,222 [INFO] Epoch 12/15 - Policy Loss: 1.5998, Value Loss: 0.1161, Total Loss: 1.7160, LR: 0.000074
2025-04-25 08:27:06,487 [INFO] Epoch 13/15 - Policy Loss: 1.5974, Value Loss: 0.1157, Total Loss: 1.7131, LR: 0.001676
2025-04-25 08:27:33,848 [INFO] Epoch 14/15 - Policy Loss: 1.5951, Value Loss: 0.1155, Total Loss: 1.7106, LR: 0.003326
2025-04-25 08:28:01,284 [INFO] Epoch 15/15 - Policy Loss: 1.5935, Value Loss: 0.1152, Total Loss: 1.7088, LR: 0.004976
2025-04-25 08:28:01,306 [INFO] 训练完成，总损失: 1.7088
2025-04-25 08:28:01,306 [INFO] 保存迭代 27 的模型
2025-04-25 08:28:01,700 [INFO] Model saved to ./models/best.pt
2025-04-25 08:28:02,006 [INFO] Model saved to ./models/iteration_27.pt
2025-04-25 08:28:02,007 [INFO] 所有训练迭代完成
2025-04-25 08:28:02,007 [INFO] 开始迭代 28/300
2025-04-25 08:28:02,007 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 08:33:28,043 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 08:33:28,044 [INFO] 保存训练样本
2025-04-25 08:33:32,172 [INFO] 使用 137432 个样本训练神经网络
2025-04-25 08:33:32,172 [INFO] Training with 137432 examples
2025-04-25 08:33:32,172 [INFO] 总训练步数: 1005, 每轮次批次数: 67
2025-04-25 08:33:32,227 [INFO] 循环学习率周期大小: 201 步
2025-04-25 08:33:58,295 [INFO] Epoch 1/15 - Policy Loss: 1.5966, Value Loss: 0.1232, Total Loss: 1.7198, LR: 0.001675
2025-04-25 08:34:24,404 [INFO] Epoch 2/15 - Policy Loss: 1.5883, Value Loss: 0.1189, Total Loss: 1.7072, LR: 0.003325
2025-04-25 08:34:51,022 [INFO] Epoch 3/15 - Policy Loss: 1.5873, Value Loss: 0.1180, Total Loss: 1.7053, LR: 0.004975
2025-04-25 08:35:17,225 [INFO] Epoch 4/15 - Policy Loss: 1.5903, Value Loss: 0.1180, Total Loss: 1.7084, LR: 0.003375
2025-04-25 08:35:43,312 [INFO] Epoch 5/15 - Policy Loss: 1.5888, Value Loss: 0.1172, Total Loss: 1.7059, LR: 0.001725
2025-04-25 08:36:09,372 [INFO] Epoch 6/15 - Policy Loss: 1.5843, Value Loss: 0.1163, Total Loss: 1.7006, LR: 0.000075
2025-04-25 08:36:35,518 [INFO] Epoch 7/15 - Policy Loss: 1.5797, Value Loss: 0.1157, Total Loss: 1.6954, LR: 0.001675
2025-04-25 08:37:01,575 [INFO] Epoch 8/15 - Policy Loss: 1.5763, Value Loss: 0.1151, Total Loss: 1.6914, LR: 0.003325
2025-04-25 08:37:27,716 [INFO] Epoch 9/15 - Policy Loss: 1.5740, Value Loss: 0.1145, Total Loss: 1.6885, LR: 0.004975
2025-04-25 08:37:53,794 [INFO] Epoch 10/15 - Policy Loss: 1.5740, Value Loss: 0.1143, Total Loss: 1.6883, LR: 0.003375
2025-04-25 08:38:19,840 [INFO] Epoch 11/15 - Policy Loss: 1.5736, Value Loss: 0.1141, Total Loss: 1.6877, LR: 0.001725
2025-04-25 08:38:45,926 [INFO] Epoch 12/15 - Policy Loss: 1.5718, Value Loss: 0.1139, Total Loss: 1.6857, LR: 0.000075
2025-04-25 08:39:12,098 [INFO] Epoch 13/15 - Policy Loss: 1.5697, Value Loss: 0.1137, Total Loss: 1.6834, LR: 0.001675
2025-04-25 08:39:38,261 [INFO] Epoch 14/15 - Policy Loss: 1.5674, Value Loss: 0.1135, Total Loss: 1.6810, LR: 0.003325
2025-04-25 08:40:04,388 [INFO] Epoch 15/15 - Policy Loss: 1.5664, Value Loss: 0.1133, Total Loss: 1.6797, LR: 0.004975
2025-04-25 08:40:04,411 [INFO] 训练完成，总损失: 1.6797
2025-04-25 08:40:04,411 [INFO] 保存迭代 28 的模型
2025-04-25 08:40:04,864 [INFO] Model saved to ./models/best.pt
2025-04-25 08:40:05,345 [INFO] Model saved to ./models/iteration_28.pt
2025-04-25 08:40:05,345 [INFO] 所有训练迭代完成
2025-04-25 08:40:05,345 [INFO] 开始迭代 29/300
2025-04-25 08:40:05,345 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 08:45:42,054 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 08:45:42,055 [INFO] 保存训练样本
2025-04-25 08:45:44,896 [INFO] 使用 130744 个样本训练神经网络
2025-04-25 08:45:44,896 [INFO] Training with 130744 examples
2025-04-25 08:45:44,896 [INFO] 总训练步数: 945, 每轮次批次数: 63
2025-04-25 08:45:45,210 [INFO] 循环学习率周期大小: 189 步
2025-04-25 08:46:09,562 [INFO] Epoch 1/15 - Policy Loss: 1.5889, Value Loss: 0.1341, Total Loss: 1.7230, LR: 0.001674
2025-04-25 08:46:33,962 [INFO] Epoch 2/15 - Policy Loss: 1.5804, Value Loss: 0.1307, Total Loss: 1.7111, LR: 0.003324
2025-04-25 08:46:58,333 [INFO] Epoch 3/15 - Policy Loss: 1.5767, Value Loss: 0.1283, Total Loss: 1.7050, LR: 0.004974
2025-04-25 08:47:22,673 [INFO] Epoch 4/15 - Policy Loss: 1.5756, Value Loss: 0.1270, Total Loss: 1.7026, LR: 0.003376
2025-04-25 08:47:47,031 [INFO] Epoch 5/15 - Policy Loss: 1.5729, Value Loss: 0.1247, Total Loss: 1.6976, LR: 0.001726
2025-04-25 08:48:11,413 [INFO] Epoch 6/15 - Policy Loss: 1.5688, Value Loss: 0.1229, Total Loss: 1.6917, LR: 0.000076
2025-04-25 08:48:35,817 [INFO] Epoch 7/15 - Policy Loss: 1.5644, Value Loss: 0.1218, Total Loss: 1.6862, LR: 0.001674
2025-04-25 08:49:00,241 [INFO] Epoch 8/15 - Policy Loss: 1.5614, Value Loss: 0.1211, Total Loss: 1.6825, LR: 0.003324
2025-04-25 08:49:24,604 [INFO] Epoch 9/15 - Policy Loss: 1.5599, Value Loss: 0.1207, Total Loss: 1.6806, LR: 0.004974
2025-04-25 08:49:48,968 [INFO] Epoch 10/15 - Policy Loss: 1.5598, Value Loss: 0.1201, Total Loss: 1.6799, LR: 0.003376
2025-04-25 08:50:13,325 [INFO] Epoch 11/15 - Policy Loss: 1.5584, Value Loss: 0.1193, Total Loss: 1.6777, LR: 0.001726
2025-04-25 08:50:37,691 [INFO] Epoch 12/15 - Policy Loss: 1.5560, Value Loss: 0.1187, Total Loss: 1.6747, LR: 0.000076
2025-04-25 08:51:02,199 [INFO] Epoch 13/15 - Policy Loss: 1.5536, Value Loss: 0.1182, Total Loss: 1.6717, LR: 0.001674
2025-04-25 08:51:26,704 [INFO] Epoch 14/15 - Policy Loss: 1.5514, Value Loss: 0.1178, Total Loss: 1.6692, LR: 0.003324
2025-04-25 08:51:51,074 [INFO] Epoch 15/15 - Policy Loss: 1.5502, Value Loss: 0.1174, Total Loss: 1.6676, LR: 0.004974
2025-04-25 08:51:51,093 [INFO] 训练完成，总损失: 1.6676
2025-04-25 08:51:51,093 [INFO] 保存迭代 29 的模型
2025-04-25 08:51:51,480 [INFO] Model saved to ./models/best.pt
2025-04-25 08:51:51,762 [INFO] Model saved to ./models/iteration_29.pt
2025-04-25 08:51:51,762 [INFO] 所有训练迭代完成
2025-04-25 08:51:51,762 [INFO] 开始迭代 30/300
2025-04-25 08:51:51,762 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 08:56:11,330 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 08:56:11,331 [INFO] 保存训练样本
2025-04-25 08:56:14,892 [INFO] 使用 123232 个样本训练神经网络
2025-04-25 08:56:14,892 [INFO] Training with 123232 examples
2025-04-25 08:56:14,893 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-25 08:56:15,268 [INFO] 循环学习率周期大小: 180 步
2025-04-25 08:56:38,539 [INFO] Epoch 1/15 - Policy Loss: 1.5510, Value Loss: 0.1138, Total Loss: 1.6647, LR: 0.001673
2025-04-25 08:57:01,754 [INFO] Epoch 2/15 - Policy Loss: 1.5452, Value Loss: 0.1128, Total Loss: 1.6580, LR: 0.003323
2025-04-25 08:57:25,048 [INFO] Epoch 3/15 - Policy Loss: 1.5420, Value Loss: 0.1129, Total Loss: 1.6549, LR: 0.004973
2025-04-25 08:57:48,406 [INFO] Epoch 4/15 - Policy Loss: 1.5448, Value Loss: 0.1133, Total Loss: 1.6581, LR: 0.003377
2025-04-25 08:58:11,750 [INFO] Epoch 5/15 - Policy Loss: 1.5416, Value Loss: 0.1127, Total Loss: 1.6542, LR: 0.001727
2025-04-25 08:58:35,082 [INFO] Epoch 6/15 - Policy Loss: 1.5374, Value Loss: 0.1124, Total Loss: 1.6498, LR: 0.000077
2025-04-25 08:58:58,431 [INFO] Epoch 7/15 - Policy Loss: 1.5336, Value Loss: 0.1117, Total Loss: 1.6453, LR: 0.001673
2025-04-25 08:59:21,765 [INFO] Epoch 8/15 - Policy Loss: 1.5312, Value Loss: 0.1114, Total Loss: 1.6426, LR: 0.003323
2025-04-25 08:59:45,125 [INFO] Epoch 9/15 - Policy Loss: 1.5309, Value Loss: 0.1115, Total Loss: 1.6423, LR: 0.004973
2025-04-25 09:00:08,525 [INFO] Epoch 10/15 - Policy Loss: 1.5319, Value Loss: 0.1113, Total Loss: 1.6432, LR: 0.003377
2025-04-25 09:00:31,903 [INFO] Epoch 11/15 - Policy Loss: 1.5311, Value Loss: 0.1114, Total Loss: 1.6425, LR: 0.001727
2025-04-25 09:00:55,221 [INFO] Epoch 12/15 - Policy Loss: 1.5292, Value Loss: 0.1110, Total Loss: 1.6402, LR: 0.000077
2025-04-25 09:01:18,645 [INFO] Epoch 13/15 - Policy Loss: 1.5275, Value Loss: 0.1109, Total Loss: 1.6384, LR: 0.001673
2025-04-25 09:01:42,008 [INFO] Epoch 14/15 - Policy Loss: 1.5256, Value Loss: 0.1106, Total Loss: 1.6362, LR: 0.003323
2025-04-25 09:02:05,396 [INFO] Epoch 15/15 - Policy Loss: 1.5247, Value Loss: 0.1105, Total Loss: 1.6352, LR: 0.004973
2025-04-25 09:02:05,416 [INFO] 训练完成，总损失: 1.6352
2025-04-25 09:02:05,416 [INFO] 保存迭代 30 的模型
2025-04-25 09:02:05,810 [INFO] Model saved to ./models/best.pt
2025-04-25 09:02:06,080 [INFO] Model saved to ./models/iteration_30.pt
2025-04-25 09:02:06,080 [INFO] 所有训练迭代完成
2025-04-25 09:02:06,080 [INFO] 开始迭代 31/300
2025-04-25 09:02:06,080 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 09:07:09,260 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 09:07:09,261 [INFO] 保存训练样本
2025-04-25 09:07:12,218 [INFO] 使用 114480 个样本训练神经网络
2025-04-25 09:07:12,218 [INFO] Training with 114480 examples
2025-04-25 09:07:12,219 [INFO] 总训练步数: 825, 每轮次批次数: 55
2025-04-25 09:07:12,597 [INFO] 循环学习率周期大小: 165 步
2025-04-25 09:07:34,101 [INFO] Epoch 1/15 - Policy Loss: 1.5452, Value Loss: 0.1272, Total Loss: 1.6724, LR: 0.001670
2025-04-25 09:07:55,597 [INFO] Epoch 2/15 - Policy Loss: 1.5412, Value Loss: 0.1253, Total Loss: 1.6666, LR: 0.003320
2025-04-25 09:08:17,023 [INFO] Epoch 3/15 - Policy Loss: 1.5374, Value Loss: 0.1242, Total Loss: 1.6616, LR: 0.004970
2025-04-25 09:08:38,459 [INFO] Epoch 4/15 - Policy Loss: 1.5365, Value Loss: 0.1227, Total Loss: 1.6592, LR: 0.003380
2025-04-25 09:08:59,937 [INFO] Epoch 5/15 - Policy Loss: 1.5343, Value Loss: 0.1215, Total Loss: 1.6558, LR: 0.001730
2025-04-25 09:09:21,420 [INFO] Epoch 6/15 - Policy Loss: 1.5289, Value Loss: 0.1209, Total Loss: 1.6499, LR: 0.000080
2025-04-25 09:09:42,882 [INFO] Epoch 7/15 - Policy Loss: 1.5248, Value Loss: 0.1199, Total Loss: 1.6446, LR: 0.001670
2025-04-25 09:10:04,302 [INFO] Epoch 8/15 - Policy Loss: 1.5214, Value Loss: 0.1189, Total Loss: 1.6403, LR: 0.003320
2025-04-25 09:10:25,798 [INFO] Epoch 9/15 - Policy Loss: 1.5201, Value Loss: 0.1185, Total Loss: 1.6385, LR: 0.004970
2025-04-25 09:10:47,325 [INFO] Epoch 10/15 - Policy Loss: 1.5204, Value Loss: 0.1182, Total Loss: 1.6386, LR: 0.003380
2025-04-25 09:11:08,854 [INFO] Epoch 11/15 - Policy Loss: 1.5191, Value Loss: 0.1179, Total Loss: 1.6369, LR: 0.001730
2025-04-25 09:11:30,384 [INFO] Epoch 12/15 - Policy Loss: 1.5173, Value Loss: 0.1175, Total Loss: 1.6348, LR: 0.000080
2025-04-25 09:11:51,849 [INFO] Epoch 13/15 - Policy Loss: 1.5157, Value Loss: 0.1171, Total Loss: 1.6328, LR: 0.001670
2025-04-25 09:12:13,354 [INFO] Epoch 14/15 - Policy Loss: 1.5140, Value Loss: 0.1167, Total Loss: 1.6308, LR: 0.003320
2025-04-25 09:12:34,887 [INFO] Epoch 15/15 - Policy Loss: 1.5133, Value Loss: 0.1166, Total Loss: 1.6298, LR: 0.004970
2025-04-25 09:12:34,906 [INFO] 训练完成，总损失: 1.6298
2025-04-25 09:12:34,906 [INFO] 保存迭代 31 的模型
2025-04-25 09:12:35,297 [INFO] Model saved to ./models/best.pt
2025-04-25 09:12:35,574 [INFO] Model saved to ./models/iteration_31.pt
2025-04-25 09:12:35,575 [INFO] 所有训练迭代完成
2025-04-25 09:12:35,575 [INFO] 开始迭代 32/300
2025-04-25 09:12:35,575 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 09:17:36,847 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 09:17:36,848 [INFO] 保存训练样本
2025-04-25 09:17:39,588 [INFO] 使用 111144 个样本训练神经网络
2025-04-25 09:17:39,589 [INFO] Training with 111144 examples
2025-04-25 09:17:39,589 [INFO] 总训练步数: 810, 每轮次批次数: 54
2025-04-25 09:17:39,909 [INFO] 循环学习率周期大小: 162 步
2025-04-25 09:18:00,762 [INFO] Epoch 1/15 - Policy Loss: 1.5167, Value Loss: 0.1133, Total Loss: 1.6300, LR: 0.001669
2025-04-25 09:18:21,590 [INFO] Epoch 2/15 - Policy Loss: 1.5073, Value Loss: 0.1121, Total Loss: 1.6194, LR: 0.003319
2025-04-25 09:18:42,415 [INFO] Epoch 3/15 - Policy Loss: 1.5054, Value Loss: 0.1102, Total Loss: 1.6155, LR: 0.004969
2025-04-25 09:19:03,269 [INFO] Epoch 4/15 - Policy Loss: 1.5059, Value Loss: 0.1094, Total Loss: 1.6153, LR: 0.003381
2025-04-25 09:19:24,131 [INFO] Epoch 5/15 - Policy Loss: 1.5023, Value Loss: 0.1091, Total Loss: 1.6114, LR: 0.001731
2025-04-25 09:19:45,006 [INFO] Epoch 6/15 - Policy Loss: 1.4974, Value Loss: 0.1086, Total Loss: 1.6060, LR: 0.000081
2025-04-25 09:20:05,815 [INFO] Epoch 7/15 - Policy Loss: 1.4946, Value Loss: 0.1085, Total Loss: 1.6032, LR: 0.001669
2025-04-25 09:20:26,655 [INFO] Epoch 8/15 - Policy Loss: 1.4922, Value Loss: 0.1084, Total Loss: 1.6006, LR: 0.003319
2025-04-25 09:20:47,480 [INFO] Epoch 9/15 - Policy Loss: 1.4900, Value Loss: 0.1082, Total Loss: 1.5982, LR: 0.004969
2025-04-25 09:21:08,308 [INFO] Epoch 10/15 - Policy Loss: 1.4906, Value Loss: 0.1083, Total Loss: 1.5989, LR: 0.003381
2025-04-25 09:21:29,148 [INFO] Epoch 11/15 - Policy Loss: 1.4891, Value Loss: 0.1079, Total Loss: 1.5970, LR: 0.001731
2025-04-25 09:21:49,994 [INFO] Epoch 12/15 - Policy Loss: 1.4874, Value Loss: 0.1081, Total Loss: 1.5955, LR: 0.000081
2025-04-25 09:22:10,822 [INFO] Epoch 13/15 - Policy Loss: 1.4855, Value Loss: 0.1079, Total Loss: 1.5935, LR: 0.001669
2025-04-25 09:22:31,663 [INFO] Epoch 14/15 - Policy Loss: 1.4846, Value Loss: 0.1079, Total Loss: 1.5925, LR: 0.003319
2025-04-25 09:22:52,821 [INFO] Epoch 15/15 - Policy Loss: 1.4839, Value Loss: 0.1079, Total Loss: 1.5917, LR: 0.004969
2025-04-25 09:22:52,836 [INFO] 训练完成，总损失: 1.5917
2025-04-25 09:22:52,836 [INFO] 保存迭代 32 的模型
2025-04-25 09:22:53,278 [INFO] Model saved to ./models/best.pt
2025-04-25 09:22:53,577 [INFO] Model saved to ./models/iteration_32.pt
2025-04-25 09:22:53,577 [INFO] 所有训练迭代完成
2025-04-25 09:22:53,577 [INFO] 开始迭代 33/300
2025-04-25 09:22:53,577 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 09:28:02,624 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 09:28:02,625 [INFO] 保存训练样本
2025-04-25 09:28:05,311 [INFO] 使用 108640 个样本训练神经网络
2025-04-25 09:28:05,311 [INFO] Training with 108640 examples
2025-04-25 09:28:05,312 [INFO] 总训练步数: 795, 每轮次批次数: 53
2025-04-25 09:28:05,685 [INFO] 循环学习率周期大小: 159 步
2025-04-25 09:28:26,415 [INFO] Epoch 1/15 - Policy Loss: 1.4957, Value Loss: 0.1100, Total Loss: 1.6057, LR: 0.001669
2025-04-25 09:28:47,181 [INFO] Epoch 2/15 - Policy Loss: 1.4878, Value Loss: 0.1058, Total Loss: 1.5936, LR: 0.003319
2025-04-25 09:29:07,952 [INFO] Epoch 3/15 - Policy Loss: 1.4826, Value Loss: 0.1050, Total Loss: 1.5876, LR: 0.004969
2025-04-25 09:29:28,680 [INFO] Epoch 4/15 - Policy Loss: 1.4832, Value Loss: 0.1047, Total Loss: 1.5879, LR: 0.003381
2025-04-25 09:29:49,420 [INFO] Epoch 5/15 - Policy Loss: 1.4783, Value Loss: 0.1037, Total Loss: 1.5820, LR: 0.001731
2025-04-25 09:30:10,169 [INFO] Epoch 6/15 - Policy Loss: 1.4752, Value Loss: 0.1032, Total Loss: 1.5784, LR: 0.000081
2025-04-25 09:30:30,913 [INFO] Epoch 7/15 - Policy Loss: 1.4709, Value Loss: 0.1029, Total Loss: 1.5738, LR: 0.001669
2025-04-25 09:30:51,639 [INFO] Epoch 8/15 - Policy Loss: 1.4680, Value Loss: 0.1024, Total Loss: 1.5704, LR: 0.003319
2025-04-25 09:31:12,385 [INFO] Epoch 9/15 - Policy Loss: 1.4673, Value Loss: 0.1022, Total Loss: 1.5695, LR: 0.004969
2025-04-25 09:31:33,124 [INFO] Epoch 10/15 - Policy Loss: 1.4674, Value Loss: 0.1023, Total Loss: 1.5697, LR: 0.003381
2025-04-25 09:31:53,852 [INFO] Epoch 11/15 - Policy Loss: 1.4664, Value Loss: 0.1020, Total Loss: 1.5684, LR: 0.001731
2025-04-25 09:32:14,574 [INFO] Epoch 12/15 - Policy Loss: 1.4645, Value Loss: 0.1018, Total Loss: 1.5663, LR: 0.000081
2025-04-25 09:32:35,304 [INFO] Epoch 13/15 - Policy Loss: 1.4632, Value Loss: 0.1014, Total Loss: 1.5646, LR: 0.001669
2025-04-25 09:32:56,019 [INFO] Epoch 14/15 - Policy Loss: 1.4623, Value Loss: 0.1012, Total Loss: 1.5635, LR: 0.003319
2025-04-25 09:33:16,747 [INFO] Epoch 15/15 - Policy Loss: 1.4611, Value Loss: 0.1008, Total Loss: 1.5619, LR: 0.004969
2025-04-25 09:33:16,764 [INFO] 训练完成，总损失: 1.5619
2025-04-25 09:33:16,764 [INFO] 保存迭代 33 的模型
2025-04-25 09:33:17,288 [INFO] Model saved to ./models/best.pt
2025-04-25 09:33:17,927 [INFO] Model saved to ./models/iteration_33.pt
2025-04-25 09:33:17,928 [INFO] 所有训练迭代完成
2025-04-25 09:33:17,928 [INFO] 开始迭代 34/300
2025-04-25 09:33:17,928 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 09:38:59,761 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 09:38:59,764 [INFO] 保存训练样本
2025-04-25 09:39:02,089 [INFO] 使用 105048 个样本训练神经网络
2025-04-25 09:39:02,089 [INFO] Training with 105048 examples
2025-04-25 09:39:02,090 [INFO] 总训练步数: 765, 每轮次批次数: 51
2025-04-25 09:39:02,411 [INFO] 循环学习率周期大小: 153 步
2025-04-25 09:39:22,314 [INFO] Epoch 1/15 - Policy Loss: 1.4777, Value Loss: 0.1032, Total Loss: 1.5809, LR: 0.001668
2025-04-25 09:39:42,273 [INFO] Epoch 2/15 - Policy Loss: 1.4704, Value Loss: 0.1038, Total Loss: 1.5742, LR: 0.003318
2025-04-25 09:40:02,202 [INFO] Epoch 3/15 - Policy Loss: 1.4668, Value Loss: 0.1027, Total Loss: 1.5695, LR: 0.004968
2025-04-25 09:40:22,145 [INFO] Epoch 4/15 - Policy Loss: 1.4663, Value Loss: 0.1028, Total Loss: 1.5690, LR: 0.003382
2025-04-25 09:40:42,088 [INFO] Epoch 5/15 - Policy Loss: 1.4645, Value Loss: 0.1023, Total Loss: 1.5668, LR: 0.001732
2025-04-25 09:41:02,012 [INFO] Epoch 6/15 - Policy Loss: 1.4607, Value Loss: 0.1015, Total Loss: 1.5622, LR: 0.000082
2025-04-25 09:41:21,947 [INFO] Epoch 7/15 - Policy Loss: 1.4564, Value Loss: 0.1007, Total Loss: 1.5570, LR: 0.001668
2025-04-25 09:41:41,889 [INFO] Epoch 8/15 - Policy Loss: 1.4539, Value Loss: 0.1007, Total Loss: 1.5546, LR: 0.003318
2025-04-25 09:42:01,822 [INFO] Epoch 9/15 - Policy Loss: 1.4523, Value Loss: 0.1004, Total Loss: 1.5527, LR: 0.004968
2025-04-25 09:42:21,771 [INFO] Epoch 10/15 - Policy Loss: 1.4525, Value Loss: 0.1004, Total Loss: 1.5529, LR: 0.003382
2025-04-25 09:42:41,729 [INFO] Epoch 11/15 - Policy Loss: 1.4514, Value Loss: 0.1002, Total Loss: 1.5516, LR: 0.001732
2025-04-25 09:43:01,647 [INFO] Epoch 12/15 - Policy Loss: 1.4501, Value Loss: 0.0999, Total Loss: 1.5500, LR: 0.000082
2025-04-25 09:43:21,934 [INFO] Epoch 13/15 - Policy Loss: 1.4482, Value Loss: 0.0998, Total Loss: 1.5479, LR: 0.001668
2025-04-25 09:43:41,898 [INFO] Epoch 14/15 - Policy Loss: 1.4467, Value Loss: 0.0997, Total Loss: 1.5463, LR: 0.003318
2025-04-25 09:44:01,849 [INFO] Epoch 15/15 - Policy Loss: 1.4454, Value Loss: 0.0995, Total Loss: 1.5449, LR: 0.004968
2025-04-25 09:44:01,866 [INFO] 训练完成，总损失: 1.5449
2025-04-25 09:44:01,866 [INFO] 保存迭代 34 的模型
2025-04-25 09:44:02,333 [INFO] Model saved to ./models/best.pt
2025-04-25 09:44:02,631 [INFO] Model saved to ./models/iteration_34.pt
2025-04-25 09:44:02,631 [INFO] 所有训练迭代完成
2025-04-25 09:44:02,631 [INFO] 开始迭代 35/300
2025-04-25 09:44:02,631 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 09:48:39,910 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 09:48:39,913 [INFO] 保存训练样本
2025-04-25 09:48:42,414 [INFO] 使用 103464 个样本训练神经网络
2025-04-25 09:48:42,415 [INFO] Training with 103464 examples
2025-04-25 09:48:42,415 [INFO] 总训练步数: 750, 每轮次批次数: 50
2025-04-25 09:48:42,752 [INFO] 循环学习率周期大小: 150 步
2025-04-25 09:49:02,241 [INFO] Epoch 1/15 - Policy Loss: 1.4468, Value Loss: 0.1094, Total Loss: 1.5562, LR: 0.001667
2025-04-25 09:49:21,762 [INFO] Epoch 2/15 - Policy Loss: 1.4397, Value Loss: 0.1067, Total Loss: 1.5464, LR: 0.003317
2025-04-25 09:49:41,257 [INFO] Epoch 3/15 - Policy Loss: 1.4404, Value Loss: 0.1057, Total Loss: 1.5461, LR: 0.004967
2025-04-25 09:50:00,776 [INFO] Epoch 4/15 - Policy Loss: 1.4431, Value Loss: 0.1048, Total Loss: 1.5479, LR: 0.003383
2025-04-25 09:50:20,269 [INFO] Epoch 5/15 - Policy Loss: 1.4413, Value Loss: 0.1042, Total Loss: 1.5455, LR: 0.001733
2025-04-25 09:50:39,758 [INFO] Epoch 6/15 - Policy Loss: 1.4388, Value Loss: 0.1032, Total Loss: 1.5420, LR: 0.000083
2025-04-25 09:50:59,320 [INFO] Epoch 7/15 - Policy Loss: 1.4361, Value Loss: 0.1022, Total Loss: 1.5383, LR: 0.001667
2025-04-25 09:51:18,860 [INFO] Epoch 8/15 - Policy Loss: 1.4340, Value Loss: 0.1014, Total Loss: 1.5353, LR: 0.003317
2025-04-25 09:51:38,360 [INFO] Epoch 9/15 - Policy Loss: 1.4332, Value Loss: 0.1009, Total Loss: 1.5341, LR: 0.004967
2025-04-25 09:51:57,881 [INFO] Epoch 10/15 - Policy Loss: 1.4327, Value Loss: 0.1005, Total Loss: 1.5332, LR: 0.003383
2025-04-25 09:52:17,416 [INFO] Epoch 11/15 - Policy Loss: 1.4323, Value Loss: 0.1001, Total Loss: 1.5325, LR: 0.001733
2025-04-25 09:52:36,904 [INFO] Epoch 12/15 - Policy Loss: 1.4312, Value Loss: 0.0998, Total Loss: 1.5310, LR: 0.000083
2025-04-25 09:52:56,416 [INFO] Epoch 13/15 - Policy Loss: 1.4298, Value Loss: 0.0996, Total Loss: 1.5294, LR: 0.001667
2025-04-25 09:53:16,194 [INFO] Epoch 14/15 - Policy Loss: 1.4289, Value Loss: 0.0992, Total Loss: 1.5281, LR: 0.003317
2025-04-25 09:53:35,687 [INFO] Epoch 15/15 - Policy Loss: 1.4282, Value Loss: 0.0989, Total Loss: 1.5271, LR: 0.004967
2025-04-25 09:53:35,703 [INFO] 训练完成，总损失: 1.5271
2025-04-25 09:53:35,703 [INFO] 保存迭代 35 的模型
2025-04-25 09:53:36,111 [INFO] Model saved to ./models/best.pt
2025-04-25 09:53:36,384 [INFO] Model saved to ./models/iteration_35.pt
2025-04-25 09:53:36,385 [INFO] 所有训练迭代完成
2025-04-25 09:53:36,385 [INFO] 开始迭代 36/300
2025-04-25 09:53:36,385 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 09:58:48,449 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 09:58:48,450 [INFO] 保存训练样本
2025-04-25 09:58:51,052 [INFO] 使用 102096 个样本训练神经网络
2025-04-25 09:58:51,052 [INFO] Training with 102096 examples
2025-04-25 09:58:51,052 [INFO] 总训练步数: 735, 每轮次批次数: 49
2025-04-25 09:58:51,418 [INFO] 循环学习率周期大小: 147 步
2025-04-25 09:59:10,535 [INFO] Epoch 1/15 - Policy Loss: 1.4406, Value Loss: 0.0898, Total Loss: 1.5304, LR: 0.001666
2025-04-25 09:59:29,651 [INFO] Epoch 2/15 - Policy Loss: 1.4295, Value Loss: 0.0876, Total Loss: 1.5171, LR: 0.003316
2025-04-25 09:59:48,748 [INFO] Epoch 3/15 - Policy Loss: 1.4266, Value Loss: 0.0873, Total Loss: 1.5139, LR: 0.004966
2025-04-25 10:00:07,860 [INFO] Epoch 4/15 - Policy Loss: 1.4262, Value Loss: 0.0876, Total Loss: 1.5138, LR: 0.003384
2025-04-25 10:00:26,932 [INFO] Epoch 5/15 - Policy Loss: 1.4255, Value Loss: 0.0873, Total Loss: 1.5128, LR: 0.001734
2025-04-25 10:00:45,996 [INFO] Epoch 6/15 - Policy Loss: 1.4232, Value Loss: 0.0867, Total Loss: 1.5100, LR: 0.000084
2025-04-25 10:01:04,997 [INFO] Epoch 7/15 - Policy Loss: 1.4209, Value Loss: 0.0868, Total Loss: 1.5076, LR: 0.001666
2025-04-25 10:01:24,077 [INFO] Epoch 8/15 - Policy Loss: 1.4181, Value Loss: 0.0865, Total Loss: 1.5046, LR: 0.003316
2025-04-25 10:01:43,211 [INFO] Epoch 9/15 - Policy Loss: 1.4173, Value Loss: 0.0863, Total Loss: 1.5036, LR: 0.004966
2025-04-25 10:02:02,328 [INFO] Epoch 10/15 - Policy Loss: 1.4173, Value Loss: 0.0859, Total Loss: 1.5033, LR: 0.003384
2025-04-25 10:02:21,468 [INFO] Epoch 11/15 - Policy Loss: 1.4164, Value Loss: 0.0861, Total Loss: 1.5025, LR: 0.001734
2025-04-25 10:02:40,529 [INFO] Epoch 12/15 - Policy Loss: 1.4145, Value Loss: 0.0860, Total Loss: 1.5004, LR: 0.000084
2025-04-25 10:02:59,610 [INFO] Epoch 13/15 - Policy Loss: 1.4133, Value Loss: 0.0858, Total Loss: 1.4990, LR: 0.001666
2025-04-25 10:03:18,707 [INFO] Epoch 14/15 - Policy Loss: 1.4123, Value Loss: 0.0859, Total Loss: 1.4981, LR: 0.003316
2025-04-25 10:03:38,056 [INFO] Epoch 15/15 - Policy Loss: 1.4116, Value Loss: 0.0857, Total Loss: 1.4973, LR: 0.004966
2025-04-25 10:03:38,074 [INFO] 训练完成，总损失: 1.4973
2025-04-25 10:03:38,074 [INFO] 保存迭代 36 的模型
2025-04-25 10:03:38,623 [INFO] Model saved to ./models/best.pt
2025-04-25 10:03:39,013 [INFO] Model saved to ./models/iteration_36.pt
2025-04-25 10:03:39,014 [INFO] 所有训练迭代完成
2025-04-25 10:03:39,014 [INFO] 开始迭代 37/300
2025-04-25 10:03:39,014 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 10:08:20,536 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 10:08:20,536 [INFO] 保存训练样本
2025-04-25 10:08:23,025 [INFO] 使用 101256 个样本训练神经网络
2025-04-25 10:08:23,026 [INFO] Training with 101256 examples
2025-04-25 10:08:23,026 [INFO] 总训练步数: 735, 每轮次批次数: 49
2025-04-25 10:08:23,327 [INFO] 循环学习率周期大小: 147 步
2025-04-25 10:08:42,473 [INFO] Epoch 1/15 - Policy Loss: 1.4049, Value Loss: 0.0962, Total Loss: 1.5011, LR: 0.001666
2025-04-25 10:09:01,615 [INFO] Epoch 2/15 - Policy Loss: 1.4049, Value Loss: 0.0934, Total Loss: 1.4983, LR: 0.003316
2025-04-25 10:09:20,753 [INFO] Epoch 3/15 - Policy Loss: 1.4047, Value Loss: 0.0923, Total Loss: 1.4970, LR: 0.004966
2025-04-25 10:09:39,812 [INFO] Epoch 4/15 - Policy Loss: 1.4038, Value Loss: 0.0913, Total Loss: 1.4950, LR: 0.003384
2025-04-25 10:09:58,943 [INFO] Epoch 5/15 - Policy Loss: 1.4028, Value Loss: 0.0904, Total Loss: 1.4933, LR: 0.001734
2025-04-25 10:10:18,095 [INFO] Epoch 6/15 - Policy Loss: 1.3994, Value Loss: 0.0898, Total Loss: 1.4892, LR: 0.000084
2025-04-25 10:10:37,207 [INFO] Epoch 7/15 - Policy Loss: 1.3962, Value Loss: 0.0893, Total Loss: 1.4855, LR: 0.001666
2025-04-25 10:10:56,322 [INFO] Epoch 8/15 - Policy Loss: 1.3940, Value Loss: 0.0886, Total Loss: 1.4826, LR: 0.003316
2025-04-25 10:11:15,415 [INFO] Epoch 9/15 - Policy Loss: 1.3935, Value Loss: 0.0884, Total Loss: 1.4819, LR: 0.004966
2025-04-25 10:11:34,504 [INFO] Epoch 10/15 - Policy Loss: 1.3938, Value Loss: 0.0881, Total Loss: 1.4819, LR: 0.003384
2025-04-25 10:11:53,600 [INFO] Epoch 11/15 - Policy Loss: 1.3944, Value Loss: 0.0880, Total Loss: 1.4824, LR: 0.001734
2025-04-25 10:12:12,741 [INFO] Epoch 12/15 - Policy Loss: 1.3935, Value Loss: 0.0877, Total Loss: 1.4812, LR: 0.000084
2025-04-25 10:12:31,763 [INFO] Epoch 13/15 - Policy Loss: 1.3921, Value Loss: 0.0876, Total Loss: 1.4796, LR: 0.001666
2025-04-25 10:12:50,925 [INFO] Epoch 14/15 - Policy Loss: 1.3911, Value Loss: 0.0873, Total Loss: 1.4785, LR: 0.003316
2025-04-25 10:13:10,037 [INFO] Epoch 15/15 - Policy Loss: 1.3906, Value Loss: 0.0874, Total Loss: 1.4780, LR: 0.004966
2025-04-25 10:13:10,053 [INFO] 训练完成，总损失: 1.4780
2025-04-25 10:13:10,053 [INFO] 保存迭代 37 的模型
2025-04-25 10:13:10,455 [INFO] Model saved to ./models/best.pt
2025-04-25 10:13:10,731 [INFO] Model saved to ./models/iteration_37.pt
2025-04-25 10:13:10,731 [INFO] 所有训练迭代完成
2025-04-25 10:13:10,731 [INFO] 开始迭代 38/300
2025-04-25 10:13:10,731 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 10:17:24,534 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 10:17:24,535 [INFO] 保存训练样本
2025-04-25 10:17:26,479 [INFO] 使用 100304 个样本训练神经网络
2025-04-25 10:17:26,479 [INFO] Training with 100304 examples
2025-04-25 10:17:26,480 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-25 10:17:26,764 [INFO] 循环学习率周期大小: 144 步
2025-04-25 10:17:45,332 [INFO] Epoch 1/15 - Policy Loss: 1.3974, Value Loss: 0.0882, Total Loss: 1.4856, LR: 0.001666
2025-04-25 10:18:03,857 [INFO] Epoch 2/15 - Policy Loss: 1.3905, Value Loss: 0.0877, Total Loss: 1.4782, LR: 0.003316
2025-04-25 10:18:22,412 [INFO] Epoch 3/15 - Policy Loss: 1.3879, Value Loss: 0.0871, Total Loss: 1.4749, LR: 0.004966
2025-04-25 10:18:40,954 [INFO] Epoch 4/15 - Policy Loss: 1.3895, Value Loss: 0.0874, Total Loss: 1.4769, LR: 0.003384
2025-04-25 10:18:59,515 [INFO] Epoch 5/15 - Policy Loss: 1.3875, Value Loss: 0.0870, Total Loss: 1.4745, LR: 0.001734
2025-04-25 10:19:18,073 [INFO] Epoch 6/15 - Policy Loss: 1.3859, Value Loss: 0.0868, Total Loss: 1.4727, LR: 0.000084
2025-04-25 10:19:36,622 [INFO] Epoch 7/15 - Policy Loss: 1.3833, Value Loss: 0.0864, Total Loss: 1.4697, LR: 0.001666
2025-04-25 10:19:55,216 [INFO] Epoch 8/15 - Policy Loss: 1.3812, Value Loss: 0.0860, Total Loss: 1.4672, LR: 0.003316
2025-04-25 10:20:13,795 [INFO] Epoch 9/15 - Policy Loss: 1.3805, Value Loss: 0.0860, Total Loss: 1.4666, LR: 0.004966
2025-04-25 10:20:32,362 [INFO] Epoch 10/15 - Policy Loss: 1.3809, Value Loss: 0.0861, Total Loss: 1.4669, LR: 0.003384
2025-04-25 10:20:50,918 [INFO] Epoch 11/15 - Policy Loss: 1.3791, Value Loss: 0.0859, Total Loss: 1.4650, LR: 0.001734
2025-04-25 10:21:09,461 [INFO] Epoch 12/15 - Policy Loss: 1.3780, Value Loss: 0.0859, Total Loss: 1.4639, LR: 0.000084
2025-04-25 10:21:28,025 [INFO] Epoch 13/15 - Policy Loss: 1.3770, Value Loss: 0.0854, Total Loss: 1.4624, LR: 0.001666
2025-04-25 10:21:46,584 [INFO] Epoch 14/15 - Policy Loss: 1.3761, Value Loss: 0.0853, Total Loss: 1.4614, LR: 0.003316
2025-04-25 10:22:05,176 [INFO] Epoch 15/15 - Policy Loss: 1.3756, Value Loss: 0.0853, Total Loss: 1.4609, LR: 0.004966
2025-04-25 10:22:05,189 [INFO] 训练完成，总损失: 1.4609
2025-04-25 10:22:05,190 [INFO] 保存迭代 38 的模型
2025-04-25 10:22:05,527 [INFO] Model saved to ./models/best.pt
2025-04-25 10:22:05,777 [INFO] Model saved to ./models/iteration_38.pt
2025-04-25 10:22:05,778 [INFO] 所有训练迭代完成
2025-04-25 10:22:05,778 [INFO] 开始迭代 39/300
2025-04-25 10:22:05,778 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 10:27:20,919 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 10:27:20,920 [INFO] 保存训练样本
2025-04-25 10:27:23,407 [INFO] 使用 98656 个样本训练神经网络
2025-04-25 10:27:23,407 [INFO] Training with 98656 examples
2025-04-25 10:27:23,408 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-25 10:27:23,679 [INFO] 循环学习率周期大小: 144 步
2025-04-25 10:27:42,370 [INFO] Epoch 1/15 - Policy Loss: 1.3870, Value Loss: 0.0826, Total Loss: 1.4696, LR: 0.001666
2025-04-25 10:28:00,957 [INFO] Epoch 2/15 - Policy Loss: 1.3865, Value Loss: 0.0826, Total Loss: 1.4691, LR: 0.003316
2025-04-25 10:28:19,622 [INFO] Epoch 3/15 - Policy Loss: 1.3859, Value Loss: 0.0831, Total Loss: 1.4690, LR: 0.004966
2025-04-25 10:28:38,339 [INFO] Epoch 4/15 - Policy Loss: 1.3835, Value Loss: 0.0834, Total Loss: 1.4669, LR: 0.003384
2025-04-25 10:28:56,925 [INFO] Epoch 5/15 - Policy Loss: 1.3818, Value Loss: 0.0829, Total Loss: 1.4647, LR: 0.001734
2025-04-25 10:29:15,533 [INFO] Epoch 6/15 - Policy Loss: 1.3789, Value Loss: 0.0831, Total Loss: 1.4620, LR: 0.000084
2025-04-25 10:29:34,141 [INFO] Epoch 7/15 - Policy Loss: 1.3757, Value Loss: 0.0827, Total Loss: 1.4584, LR: 0.001666
2025-04-25 10:29:52,691 [INFO] Epoch 8/15 - Policy Loss: 1.3730, Value Loss: 0.0822, Total Loss: 1.4552, LR: 0.003316
2025-04-25 10:30:11,328 [INFO] Epoch 9/15 - Policy Loss: 1.3720, Value Loss: 0.0822, Total Loss: 1.4543, LR: 0.004966
2025-04-25 10:30:29,975 [INFO] Epoch 10/15 - Policy Loss: 1.3726, Value Loss: 0.0825, Total Loss: 1.4551, LR: 0.003384
2025-04-25 10:30:48,640 [INFO] Epoch 11/15 - Policy Loss: 1.3725, Value Loss: 0.0823, Total Loss: 1.4548, LR: 0.001734
2025-04-25 10:31:07,304 [INFO] Epoch 12/15 - Policy Loss: 1.3714, Value Loss: 0.0822, Total Loss: 1.4537, LR: 0.000084
2025-04-25 10:31:25,907 [INFO] Epoch 13/15 - Policy Loss: 1.3703, Value Loss: 0.0822, Total Loss: 1.4524, LR: 0.001666
2025-04-25 10:31:44,501 [INFO] Epoch 14/15 - Policy Loss: 1.3692, Value Loss: 0.0823, Total Loss: 1.4515, LR: 0.003316
2025-04-25 10:32:03,369 [INFO] Epoch 15/15 - Policy Loss: 1.3691, Value Loss: 0.0821, Total Loss: 1.4512, LR: 0.004966
2025-04-25 10:32:03,386 [INFO] 训练完成，总损失: 1.4512
2025-04-25 10:32:03,387 [INFO] 保存迭代 39 的模型
2025-04-25 10:32:03,934 [INFO] Model saved to ./models/best.pt
2025-04-25 10:32:04,316 [INFO] Model saved to ./models/iteration_39.pt
2025-04-25 10:32:04,316 [INFO] 所有训练迭代完成
2025-04-25 10:32:04,317 [INFO] 开始迭代 40/300
2025-04-25 10:32:04,317 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 10:37:02,130 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 10:37:02,131 [INFO] 保存训练样本
2025-04-25 10:37:04,619 [INFO] 使用 98264 个样本训练神经网络
2025-04-25 10:37:04,620 [INFO] Training with 98264 examples
2025-04-25 10:37:04,620 [INFO] 总训练步数: 705, 每轮次批次数: 47
2025-04-25 10:37:04,938 [INFO] 循环学习率周期大小: 141 步
2025-04-25 10:37:23,318 [INFO] Epoch 1/15 - Policy Loss: 1.3723, Value Loss: 0.0777, Total Loss: 1.4500, LR: 0.001665
2025-04-25 10:37:41,689 [INFO] Epoch 2/15 - Policy Loss: 1.3673, Value Loss: 0.0778, Total Loss: 1.4452, LR: 0.003315
2025-04-25 10:37:59,917 [INFO] Epoch 3/15 - Policy Loss: 1.3686, Value Loss: 0.0775, Total Loss: 1.4461, LR: 0.004965
2025-04-25 10:38:18,182 [INFO] Epoch 4/15 - Policy Loss: 1.3672, Value Loss: 0.0777, Total Loss: 1.4449, LR: 0.003385
2025-04-25 10:38:36,495 [INFO] Epoch 5/15 - Policy Loss: 1.3660, Value Loss: 0.0777, Total Loss: 1.4437, LR: 0.001735
2025-04-25 10:38:54,759 [INFO] Epoch 6/15 - Policy Loss: 1.3629, Value Loss: 0.0777, Total Loss: 1.4406, LR: 0.000085
2025-04-25 10:39:13,075 [INFO] Epoch 7/15 - Policy Loss: 1.3611, Value Loss: 0.0777, Total Loss: 1.4388, LR: 0.001665
2025-04-25 10:39:31,377 [INFO] Epoch 8/15 - Policy Loss: 1.3596, Value Loss: 0.0775, Total Loss: 1.4371, LR: 0.003315
2025-04-25 10:39:49,708 [INFO] Epoch 9/15 - Policy Loss: 1.3593, Value Loss: 0.0773, Total Loss: 1.4366, LR: 0.004965
2025-04-25 10:40:08,085 [INFO] Epoch 10/15 - Policy Loss: 1.3590, Value Loss: 0.0773, Total Loss: 1.4363, LR: 0.003385
2025-04-25 10:40:26,424 [INFO] Epoch 11/15 - Policy Loss: 1.3585, Value Loss: 0.0773, Total Loss: 1.4357, LR: 0.001735
2025-04-25 10:40:44,812 [INFO] Epoch 12/15 - Policy Loss: 1.3583, Value Loss: 0.0772, Total Loss: 1.4356, LR: 0.000085
2025-04-25 10:41:03,155 [INFO] Epoch 13/15 - Policy Loss: 1.3565, Value Loss: 0.0772, Total Loss: 1.4337, LR: 0.001665
2025-04-25 10:41:21,486 [INFO] Epoch 14/15 - Policy Loss: 1.3550, Value Loss: 0.0773, Total Loss: 1.4323, LR: 0.003315
2025-04-25 10:41:39,804 [INFO] Epoch 15/15 - Policy Loss: 1.3543, Value Loss: 0.0774, Total Loss: 1.4317, LR: 0.004965
2025-04-25 10:41:39,819 [INFO] 训练完成，总损失: 1.4317
2025-04-25 10:41:39,819 [INFO] 保存迭代 40 的模型
2025-04-25 10:41:40,283 [INFO] Model saved to ./models/best.pt
2025-04-25 10:41:40,589 [INFO] Model saved to ./models/iteration_40.pt
2025-04-25 10:41:40,589 [INFO] 所有训练迭代完成
2025-04-25 10:41:40,589 [INFO] 开始迭代 41/300
2025-04-25 10:41:40,589 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 10:45:45,942 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 10:45:45,942 [INFO] 保存训练样本
2025-04-25 10:45:48,202 [INFO] 使用 97088 个样本训练神经网络
2025-04-25 10:45:48,203 [INFO] Training with 97088 examples
2025-04-25 10:45:48,203 [INFO] 总训练步数: 705, 每轮次批次数: 47
2025-04-25 10:45:48,505 [INFO] 循环学习率周期大小: 141 步
2025-04-25 10:46:06,680 [INFO] Epoch 1/15 - Policy Loss: 1.3556, Value Loss: 0.0842, Total Loss: 1.4399, LR: 0.001665
2025-04-25 10:46:24,843 [INFO] Epoch 2/15 - Policy Loss: 1.3485, Value Loss: 0.0834, Total Loss: 1.4319, LR: 0.003315
2025-04-25 10:46:42,993 [INFO] Epoch 3/15 - Policy Loss: 1.3479, Value Loss: 0.0822, Total Loss: 1.4300, LR: 0.004965
2025-04-25 10:47:01,140 [INFO] Epoch 4/15 - Policy Loss: 1.3474, Value Loss: 0.0822, Total Loss: 1.4296, LR: 0.003385
2025-04-25 10:47:19,278 [INFO] Epoch 5/15 - Policy Loss: 1.3471, Value Loss: 0.0817, Total Loss: 1.4287, LR: 0.001735
2025-04-25 10:47:37,431 [INFO] Epoch 6/15 - Policy Loss: 1.3469, Value Loss: 0.0815, Total Loss: 1.4284, LR: 0.000085
2025-04-25 10:47:55,589 [INFO] Epoch 7/15 - Policy Loss: 1.3441, Value Loss: 0.0809, Total Loss: 1.4251, LR: 0.001665
2025-04-25 10:48:13,771 [INFO] Epoch 8/15 - Policy Loss: 1.3426, Value Loss: 0.0806, Total Loss: 1.4232, LR: 0.003315
2025-04-25 10:48:31,922 [INFO] Epoch 9/15 - Policy Loss: 1.3434, Value Loss: 0.0804, Total Loss: 1.4238, LR: 0.004965
2025-04-25 10:48:50,100 [INFO] Epoch 10/15 - Policy Loss: 1.3447, Value Loss: 0.0803, Total Loss: 1.4250, LR: 0.003385
2025-04-25 10:49:08,289 [INFO] Epoch 11/15 - Policy Loss: 1.3446, Value Loss: 0.0804, Total Loss: 1.4250, LR: 0.001735
2025-04-25 10:49:26,464 [INFO] Epoch 12/15 - Policy Loss: 1.3433, Value Loss: 0.0802, Total Loss: 1.4235, LR: 0.000085
2025-04-25 10:49:44,638 [INFO] Epoch 13/15 - Policy Loss: 1.3419, Value Loss: 0.0800, Total Loss: 1.4219, LR: 0.001665
2025-04-25 10:50:02,806 [INFO] Epoch 14/15 - Policy Loss: 1.3416, Value Loss: 0.0800, Total Loss: 1.4216, LR: 0.003315
2025-04-25 10:50:20,989 [INFO] Epoch 15/15 - Policy Loss: 1.3409, Value Loss: 0.0798, Total Loss: 1.4207, LR: 0.004965
2025-04-25 10:50:21,001 [INFO] 训练完成，总损失: 1.4207
2025-04-25 10:50:21,001 [INFO] 保存迭代 41 的模型
2025-04-25 10:50:21,440 [INFO] Model saved to ./models/best.pt
2025-04-25 10:50:21,734 [INFO] Model saved to ./models/iteration_41.pt
2025-04-25 10:50:21,734 [INFO] 所有训练迭代完成
2025-04-25 10:50:21,734 [INFO] 开始迭代 42/300
2025-04-25 10:50:21,734 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 10:54:15,601 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 10:54:15,601 [INFO] 保存训练样本
2025-04-25 10:54:17,713 [INFO] 使用 95336 个样本训练神经网络
2025-04-25 10:54:17,713 [INFO] Training with 95336 examples
2025-04-25 10:54:17,714 [INFO] 总训练步数: 690, 每轮次批次数: 46
2025-04-25 10:54:17,944 [INFO] 循环学习率周期大小: 138 步
2025-04-25 10:54:35,692 [INFO] Epoch 1/15 - Policy Loss: 1.3529, Value Loss: 0.0824, Total Loss: 1.4353, LR: 0.001664
2025-04-25 10:54:53,465 [INFO] Epoch 2/15 - Policy Loss: 1.3435, Value Loss: 0.0796, Total Loss: 1.4231, LR: 0.003314
2025-04-25 10:55:11,216 [INFO] Epoch 3/15 - Policy Loss: 1.3388, Value Loss: 0.0798, Total Loss: 1.4186, LR: 0.004964
2025-04-25 10:55:28,977 [INFO] Epoch 4/15 - Policy Loss: 1.3372, Value Loss: 0.0783, Total Loss: 1.4155, LR: 0.003386
2025-04-25 10:55:46,720 [INFO] Epoch 5/15 - Policy Loss: 1.3371, Value Loss: 0.0783, Total Loss: 1.4154, LR: 0.001736
2025-04-25 10:56:04,454 [INFO] Epoch 6/15 - Policy Loss: 1.3346, Value Loss: 0.0782, Total Loss: 1.4128, LR: 0.000086
2025-04-25 10:56:22,210 [INFO] Epoch 7/15 - Policy Loss: 1.3334, Value Loss: 0.0779, Total Loss: 1.4113, LR: 0.001664
2025-04-25 10:56:39,957 [INFO] Epoch 8/15 - Policy Loss: 1.3322, Value Loss: 0.0776, Total Loss: 1.4097, LR: 0.003314
2025-04-25 10:56:57,690 [INFO] Epoch 9/15 - Policy Loss: 1.3333, Value Loss: 0.0773, Total Loss: 1.4106, LR: 0.004964
2025-04-25 10:57:15,443 [INFO] Epoch 10/15 - Policy Loss: 1.3330, Value Loss: 0.0772, Total Loss: 1.4102, LR: 0.003386
2025-04-25 10:57:33,199 [INFO] Epoch 11/15 - Policy Loss: 1.3313, Value Loss: 0.0771, Total Loss: 1.4085, LR: 0.001736
2025-04-25 10:57:50,954 [INFO] Epoch 12/15 - Policy Loss: 1.3309, Value Loss: 0.0771, Total Loss: 1.4080, LR: 0.000086
2025-04-25 10:58:08,714 [INFO] Epoch 13/15 - Policy Loss: 1.3300, Value Loss: 0.0768, Total Loss: 1.4068, LR: 0.001664
2025-04-25 10:58:26,467 [INFO] Epoch 14/15 - Policy Loss: 1.3289, Value Loss: 0.0767, Total Loss: 1.4056, LR: 0.003314
2025-04-25 10:58:44,221 [INFO] Epoch 15/15 - Policy Loss: 1.3281, Value Loss: 0.0764, Total Loss: 1.4044, LR: 0.004964
2025-04-25 10:58:44,233 [INFO] 训练完成，总损失: 1.4044
2025-04-25 10:58:44,233 [INFO] 保存迭代 42 的模型
2025-04-25 10:58:44,652 [INFO] Model saved to ./models/best.pt
2025-04-25 10:58:44,938 [INFO] Model saved to ./models/iteration_42.pt
2025-04-25 10:58:44,938 [INFO] 所有训练迭代完成
2025-04-25 10:58:44,938 [INFO] 开始迭代 43/300
2025-04-25 10:58:44,938 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 11:02:42,094 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 11:02:42,095 [INFO] 保存训练样本
2025-04-25 11:02:43,850 [INFO] 使用 93904 个样本训练神经网络
2025-04-25 11:02:43,850 [INFO] Training with 93904 examples
2025-04-25 11:02:43,850 [INFO] 总训练步数: 675, 每轮次批次数: 45
2025-04-25 11:02:44,073 [INFO] 循环学习率周期大小: 135 步
2025-04-25 11:03:01,432 [INFO] Epoch 1/15 - Policy Loss: 1.3455, Value Loss: 0.0702, Total Loss: 1.4157, LR: 0.001663
2025-04-25 11:03:18,798 [INFO] Epoch 2/15 - Policy Loss: 1.3340, Value Loss: 0.0700, Total Loss: 1.4040, LR: 0.003313
2025-04-25 11:03:36,147 [INFO] Epoch 3/15 - Policy Loss: 1.3323, Value Loss: 0.0702, Total Loss: 1.4025, LR: 0.004963
2025-04-25 11:03:53,491 [INFO] Epoch 4/15 - Policy Loss: 1.3318, Value Loss: 0.0697, Total Loss: 1.4015, LR: 0.003387
2025-04-25 11:04:10,844 [INFO] Epoch 5/15 - Policy Loss: 1.3310, Value Loss: 0.0690, Total Loss: 1.4000, LR: 0.001737
2025-04-25 11:04:28,186 [INFO] Epoch 6/15 - Policy Loss: 1.3299, Value Loss: 0.0687, Total Loss: 1.3986, LR: 0.000087
2025-04-25 11:04:45,531 [INFO] Epoch 7/15 - Policy Loss: 1.3279, Value Loss: 0.0680, Total Loss: 1.3959, LR: 0.001663
2025-04-25 11:05:02,870 [INFO] Epoch 8/15 - Policy Loss: 1.3256, Value Loss: 0.0678, Total Loss: 1.3934, LR: 0.003313
2025-04-25 11:05:20,221 [INFO] Epoch 9/15 - Policy Loss: 1.3249, Value Loss: 0.0673, Total Loss: 1.3922, LR: 0.004963
2025-04-25 11:05:37,583 [INFO] Epoch 10/15 - Policy Loss: 1.3252, Value Loss: 0.0672, Total Loss: 1.3923, LR: 0.003387
2025-04-25 11:05:54,958 [INFO] Epoch 11/15 - Policy Loss: 1.3243, Value Loss: 0.0670, Total Loss: 1.3913, LR: 0.001737
2025-04-25 11:06:12,327 [INFO] Epoch 12/15 - Policy Loss: 1.3232, Value Loss: 0.0669, Total Loss: 1.3901, LR: 0.000087
2025-04-25 11:06:29,693 [INFO] Epoch 13/15 - Policy Loss: 1.3222, Value Loss: 0.0667, Total Loss: 1.3890, LR: 0.001663
2025-04-25 11:06:47,059 [INFO] Epoch 14/15 - Policy Loss: 1.3211, Value Loss: 0.0666, Total Loss: 1.3877, LR: 0.003313
2025-04-25 11:07:04,425 [INFO] Epoch 15/15 - Policy Loss: 1.3205, Value Loss: 0.0664, Total Loss: 1.3870, LR: 0.004963
2025-04-25 11:07:04,437 [INFO] 训练完成，总损失: 1.3870
2025-04-25 11:07:04,437 [INFO] 保存迭代 43 的模型
2025-04-25 11:07:04,871 [INFO] Model saved to ./models/best.pt
2025-04-25 11:07:05,177 [INFO] Model saved to ./models/iteration_43.pt
2025-04-25 11:07:05,177 [INFO] 所有训练迭代完成
2025-04-25 11:07:05,177 [INFO] 开始迭代 44/300
2025-04-25 11:07:05,177 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 11:11:29,587 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 11:11:29,587 [INFO] 保存训练样本
2025-04-25 11:11:31,715 [INFO] 使用 93104 个样本训练神经网络
2025-04-25 11:11:31,715 [INFO] Training with 93104 examples
2025-04-25 11:11:31,716 [INFO] 总训练步数: 675, 每轮次批次数: 45
2025-04-25 11:11:31,966 [INFO] 循环学习率周期大小: 135 步
2025-04-25 11:11:49,441 [INFO] Epoch 1/15 - Policy Loss: 1.3466, Value Loss: 0.0759, Total Loss: 1.4225, LR: 0.001663
2025-04-25 11:12:06,910 [INFO] Epoch 2/15 - Policy Loss: 1.3378, Value Loss: 0.0711, Total Loss: 1.4088, LR: 0.003313
2025-04-25 11:12:24,291 [INFO] Epoch 3/15 - Policy Loss: 1.3384, Value Loss: 0.0689, Total Loss: 1.4073, LR: 0.004963
2025-04-25 11:12:41,657 [INFO] Epoch 4/15 - Policy Loss: 1.3342, Value Loss: 0.0675, Total Loss: 1.4017, LR: 0.003387
2025-04-25 11:12:59,039 [INFO] Epoch 5/15 - Policy Loss: 1.3319, Value Loss: 0.0664, Total Loss: 1.3983, LR: 0.001737
2025-04-25 11:13:16,480 [INFO] Epoch 6/15 - Policy Loss: 1.3287, Value Loss: 0.0655, Total Loss: 1.3942, LR: 0.000087
2025-04-25 11:13:34,055 [INFO] Epoch 7/15 - Policy Loss: 1.3260, Value Loss: 0.0650, Total Loss: 1.3910, LR: 0.001663
2025-04-25 11:13:51,587 [INFO] Epoch 8/15 - Policy Loss: 1.3249, Value Loss: 0.0644, Total Loss: 1.3893, LR: 0.003313
2025-04-25 11:14:09,115 [INFO] Epoch 9/15 - Policy Loss: 1.3231, Value Loss: 0.0639, Total Loss: 1.3870, LR: 0.004963
2025-04-25 11:14:26,600 [INFO] Epoch 10/15 - Policy Loss: 1.3226, Value Loss: 0.0636, Total Loss: 1.3863, LR: 0.003387
2025-04-25 11:14:44,011 [INFO] Epoch 11/15 - Policy Loss: 1.3217, Value Loss: 0.0636, Total Loss: 1.3853, LR: 0.001737
2025-04-25 11:15:01,410 [INFO] Epoch 12/15 - Policy Loss: 1.3210, Value Loss: 0.0633, Total Loss: 1.3843, LR: 0.000087
2025-04-25 11:15:18,841 [INFO] Epoch 13/15 - Policy Loss: 1.3201, Value Loss: 0.0631, Total Loss: 1.3831, LR: 0.001663
2025-04-25 11:15:36,248 [INFO] Epoch 14/15 - Policy Loss: 1.3191, Value Loss: 0.0628, Total Loss: 1.3819, LR: 0.003313
2025-04-25 11:15:53,549 [INFO] Epoch 15/15 - Policy Loss: 1.3196, Value Loss: 0.0628, Total Loss: 1.3824, LR: 0.004963
2025-04-25 11:15:53,561 [INFO] 训练完成，总损失: 1.3824
2025-04-25 11:15:53,561 [INFO] 保存迭代 44 的模型
2025-04-25 11:15:53,960 [INFO] Model saved to ./models/best.pt
2025-04-25 11:15:54,244 [INFO] Model saved to ./models/iteration_44.pt
2025-04-25 11:15:54,245 [INFO] 所有训练迭代完成
2025-04-25 11:15:54,245 [INFO] 开始迭代 45/300
2025-04-25 11:15:54,245 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 11:20:17,926 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 11:20:17,926 [INFO] 保存训练样本
2025-04-25 11:20:20,105 [INFO] 使用 92048 个样本训练神经网络
2025-04-25 11:20:20,106 [INFO] Training with 92048 examples
2025-04-25 11:20:20,106 [INFO] 总训练步数: 660, 每轮次批次数: 44
2025-04-25 11:20:20,374 [INFO] 循环学习率周期大小: 132 步
2025-04-25 11:20:37,408 [INFO] Epoch 1/15 - Policy Loss: 1.3242, Value Loss: 0.0691, Total Loss: 1.3933, LR: 0.001662
2025-04-25 11:20:54,427 [INFO] Epoch 2/15 - Policy Loss: 1.3168, Value Loss: 0.0670, Total Loss: 1.3838, LR: 0.003313
2025-04-25 11:21:11,439 [INFO] Epoch 3/15 - Policy Loss: 1.3152, Value Loss: 0.0671, Total Loss: 1.3823, LR: 0.004962
2025-04-25 11:21:28,419 [INFO] Epoch 4/15 - Policy Loss: 1.3171, Value Loss: 0.0664, Total Loss: 1.3835, LR: 0.003387
2025-04-25 11:21:45,375 [INFO] Epoch 5/15 - Policy Loss: 1.3152, Value Loss: 0.0657, Total Loss: 1.3809, LR: 0.001737
2025-04-25 11:22:02,313 [INFO] Epoch 6/15 - Policy Loss: 1.3133, Value Loss: 0.0652, Total Loss: 1.3785, LR: 0.000087
2025-04-25 11:22:19,252 [INFO] Epoch 7/15 - Policy Loss: 1.3109, Value Loss: 0.0651, Total Loss: 1.3759, LR: 0.001662
2025-04-25 11:22:36,231 [INFO] Epoch 8/15 - Policy Loss: 1.3100, Value Loss: 0.0653, Total Loss: 1.3754, LR: 0.003313
2025-04-25 11:22:53,200 [INFO] Epoch 9/15 - Policy Loss: 1.3098, Value Loss: 0.0651, Total Loss: 1.3749, LR: 0.004962
2025-04-25 11:23:10,182 [INFO] Epoch 10/15 - Policy Loss: 1.3090, Value Loss: 0.0650, Total Loss: 1.3740, LR: 0.003387
2025-04-25 11:23:27,167 [INFO] Epoch 11/15 - Policy Loss: 1.3090, Value Loss: 0.0648, Total Loss: 1.3738, LR: 0.001737
2025-04-25 11:23:44,172 [INFO] Epoch 12/15 - Policy Loss: 1.3088, Value Loss: 0.0647, Total Loss: 1.3735, LR: 0.000087
2025-04-25 11:24:01,158 [INFO] Epoch 13/15 - Policy Loss: 1.3074, Value Loss: 0.0646, Total Loss: 1.3720, LR: 0.001662
2025-04-25 11:24:18,355 [INFO] Epoch 14/15 - Policy Loss: 1.3068, Value Loss: 0.0645, Total Loss: 1.3714, LR: 0.003313
2025-04-25 11:24:35,373 [INFO] Epoch 15/15 - Policy Loss: 1.3064, Value Loss: 0.0645, Total Loss: 1.3709, LR: 0.004962
2025-04-25 11:24:35,385 [INFO] 训练完成，总损失: 1.3709
2025-04-25 11:24:35,385 [INFO] 保存迭代 45 的模型
2025-04-25 11:24:35,829 [INFO] Model saved to ./models/best.pt
2025-04-25 11:24:36,137 [INFO] Model saved to ./models/iteration_45.pt
2025-04-25 11:24:36,138 [INFO] 所有训练迭代完成
2025-04-25 11:24:36,138 [INFO] 开始迭代 46/300
2025-04-25 11:24:36,138 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 11:29:25,182 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 11:29:25,182 [INFO] 保存训练样本
2025-04-25 11:29:27,282 [INFO] 使用 91856 个样本训练神经网络
2025-04-25 11:29:27,282 [INFO] Training with 91856 examples
2025-04-25 11:29:27,282 [INFO] 总训练步数: 660, 每轮次批次数: 44
2025-04-25 11:29:27,525 [INFO] 循环学习率周期大小: 132 步
2025-04-25 11:29:44,501 [INFO] Epoch 1/15 - Policy Loss: 1.3173, Value Loss: 0.0730, Total Loss: 1.3903, LR: 0.001662
2025-04-25 11:30:01,456 [INFO] Epoch 2/15 - Policy Loss: 1.3114, Value Loss: 0.0708, Total Loss: 1.3822, LR: 0.003313
2025-04-25 11:30:18,427 [INFO] Epoch 3/15 - Policy Loss: 1.3098, Value Loss: 0.0696, Total Loss: 1.3794, LR: 0.004962
2025-04-25 11:30:35,428 [INFO] Epoch 4/15 - Policy Loss: 1.3081, Value Loss: 0.0683, Total Loss: 1.3764, LR: 0.003387
2025-04-25 11:30:52,457 [INFO] Epoch 5/15 - Policy Loss: 1.3072, Value Loss: 0.0670, Total Loss: 1.3741, LR: 0.001737
2025-04-25 11:31:09,569 [INFO] Epoch 6/15 - Policy Loss: 1.3042, Value Loss: 0.0661, Total Loss: 1.3703, LR: 0.000087
2025-04-25 11:31:26,653 [INFO] Epoch 7/15 - Policy Loss: 1.3012, Value Loss: 0.0657, Total Loss: 1.3668, LR: 0.001662
2025-04-25 11:31:43,696 [INFO] Epoch 8/15 - Policy Loss: 1.2994, Value Loss: 0.0653, Total Loss: 1.3647, LR: 0.003313
2025-04-25 11:32:00,736 [INFO] Epoch 9/15 - Policy Loss: 1.2987, Value Loss: 0.0648, Total Loss: 1.3635, LR: 0.004962
2025-04-25 11:32:17,769 [INFO] Epoch 10/15 - Policy Loss: 1.2993, Value Loss: 0.0648, Total Loss: 1.3641, LR: 0.003387
2025-04-25 11:32:34,797 [INFO] Epoch 11/15 - Policy Loss: 1.2982, Value Loss: 0.0645, Total Loss: 1.3627, LR: 0.001737
2025-04-25 11:32:51,839 [INFO] Epoch 12/15 - Policy Loss: 1.2980, Value Loss: 0.0643, Total Loss: 1.3624, LR: 0.000087
2025-04-25 11:33:08,814 [INFO] Epoch 13/15 - Policy Loss: 1.2960, Value Loss: 0.0640, Total Loss: 1.3599, LR: 0.001662
2025-04-25 11:33:25,849 [INFO] Epoch 14/15 - Policy Loss: 1.2951, Value Loss: 0.0638, Total Loss: 1.3589, LR: 0.003313
2025-04-25 11:33:42,855 [INFO] Epoch 15/15 - Policy Loss: 1.2945, Value Loss: 0.0635, Total Loss: 1.3580, LR: 0.004962
2025-04-25 11:33:42,867 [INFO] 训练完成，总损失: 1.3580
2025-04-25 11:33:42,867 [INFO] 保存迭代 46 的模型
2025-04-25 11:33:43,293 [INFO] Model saved to ./models/best.pt
2025-04-25 11:33:43,581 [INFO] Model saved to ./models/iteration_46.pt
2025-04-25 11:33:43,581 [INFO] 所有训练迭代完成
2025-04-25 11:33:43,581 [INFO] 开始迭代 47/300
2025-04-25 11:33:43,581 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 11:39:05,097 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 11:39:05,098 [INFO] 保存训练样本
2025-04-25 11:39:07,230 [INFO] 使用 91824 个样本训练神经网络
2025-04-25 11:39:07,230 [INFO] Training with 91824 examples
2025-04-25 11:39:07,231 [INFO] 总训练步数: 660, 每轮次批次数: 44
2025-04-25 11:39:07,492 [INFO] 循环学习率周期大小: 132 步
2025-04-25 11:39:24,468 [INFO] Epoch 1/15 - Policy Loss: 1.3277, Value Loss: 0.0835, Total Loss: 1.4112, LR: 0.001662
2025-04-25 11:39:41,498 [INFO] Epoch 2/15 - Policy Loss: 1.3175, Value Loss: 0.0800, Total Loss: 1.3975, LR: 0.003313
2025-04-25 11:39:58,511 [INFO] Epoch 3/15 - Policy Loss: 1.3167, Value Loss: 0.0767, Total Loss: 1.3934, LR: 0.004962
2025-04-25 11:40:15,500 [INFO] Epoch 4/15 - Policy Loss: 1.3149, Value Loss: 0.0748, Total Loss: 1.3896, LR: 0.003387
2025-04-25 11:40:32,518 [INFO] Epoch 5/15 - Policy Loss: 1.3116, Value Loss: 0.0733, Total Loss: 1.3849, LR: 0.001737
2025-04-25 11:40:49,517 [INFO] Epoch 6/15 - Policy Loss: 1.3076, Value Loss: 0.0719, Total Loss: 1.3795, LR: 0.000087
2025-04-25 11:41:06,500 [INFO] Epoch 7/15 - Policy Loss: 1.3051, Value Loss: 0.0708, Total Loss: 1.3760, LR: 0.001662
2025-04-25 11:41:23,479 [INFO] Epoch 8/15 - Policy Loss: 1.3021, Value Loss: 0.0696, Total Loss: 1.3717, LR: 0.003313
2025-04-25 11:41:40,453 [INFO] Epoch 9/15 - Policy Loss: 1.3009, Value Loss: 0.0690, Total Loss: 1.3698, LR: 0.004962
2025-04-25 11:41:57,382 [INFO] Epoch 10/15 - Policy Loss: 1.2998, Value Loss: 0.0683, Total Loss: 1.3681, LR: 0.003387
2025-04-25 11:42:14,338 [INFO] Epoch 11/15 - Policy Loss: 1.2988, Value Loss: 0.0679, Total Loss: 1.3667, LR: 0.001737
2025-04-25 11:42:31,304 [INFO] Epoch 12/15 - Policy Loss: 1.2978, Value Loss: 0.0674, Total Loss: 1.3652, LR: 0.000087
2025-04-25 11:42:48,257 [INFO] Epoch 13/15 - Policy Loss: 1.2966, Value Loss: 0.0671, Total Loss: 1.3637, LR: 0.001662
2025-04-25 11:43:05,822 [INFO] Epoch 14/15 - Policy Loss: 1.2952, Value Loss: 0.0668, Total Loss: 1.3620, LR: 0.003313
2025-04-25 11:43:22,992 [INFO] Epoch 15/15 - Policy Loss: 1.2941, Value Loss: 0.0664, Total Loss: 1.3605, LR: 0.004962
2025-04-25 11:43:23,006 [INFO] 训练完成，总损失: 1.3605
2025-04-25 11:43:23,006 [INFO] 保存迭代 47 的模型
2025-04-25 11:43:23,432 [INFO] Model saved to ./models/best.pt
2025-04-25 11:43:23,717 [INFO] Model saved to ./models/iteration_47.pt
2025-04-25 11:43:23,717 [INFO] 所有训练迭代完成
2025-04-25 11:43:23,717 [INFO] 开始迭代 48/300
2025-04-25 11:43:23,717 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 11:49:04,531 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 11:49:04,531 [INFO] 保存训练样本
2025-04-25 11:49:06,508 [INFO] 使用 92208 个样本训练神经网络
2025-04-25 11:49:06,509 [INFO] Training with 92208 examples
2025-04-25 11:49:06,509 [INFO] 总训练步数: 675, 每轮次批次数: 45
2025-04-25 11:49:06,788 [INFO] 循环学习率周期大小: 135 步
2025-04-25 11:49:24,378 [INFO] Epoch 1/15 - Policy Loss: 1.3388, Value Loss: 0.0985, Total Loss: 1.4373, LR: 0.001663
2025-04-25 11:49:41,964 [INFO] Epoch 2/15 - Policy Loss: 1.3288, Value Loss: 0.0907, Total Loss: 1.4195, LR: 0.003313
2025-04-25 11:49:59,546 [INFO] Epoch 3/15 - Policy Loss: 1.3256, Value Loss: 0.0868, Total Loss: 1.4124, LR: 0.004963
2025-04-25 11:50:17,141 [INFO] Epoch 4/15 - Policy Loss: 1.3205, Value Loss: 0.0840, Total Loss: 1.4045, LR: 0.003387
2025-04-25 11:50:34,731 [INFO] Epoch 5/15 - Policy Loss: 1.3158, Value Loss: 0.0817, Total Loss: 1.3975, LR: 0.001737
2025-04-25 11:50:52,284 [INFO] Epoch 6/15 - Policy Loss: 1.3108, Value Loss: 0.0798, Total Loss: 1.3906, LR: 0.000087
2025-04-25 11:51:09,841 [INFO] Epoch 7/15 - Policy Loss: 1.3059, Value Loss: 0.0783, Total Loss: 1.3842, LR: 0.001663
2025-04-25 11:51:27,428 [INFO] Epoch 8/15 - Policy Loss: 1.3032, Value Loss: 0.0775, Total Loss: 1.3807, LR: 0.003313
2025-04-25 11:51:44,965 [INFO] Epoch 9/15 - Policy Loss: 1.3005, Value Loss: 0.0767, Total Loss: 1.3772, LR: 0.004963
2025-04-25 11:52:02,500 [INFO] Epoch 10/15 - Policy Loss: 1.2986, Value Loss: 0.0762, Total Loss: 1.3748, LR: 0.003387
2025-04-25 11:52:20,041 [INFO] Epoch 11/15 - Policy Loss: 1.2967, Value Loss: 0.0755, Total Loss: 1.3723, LR: 0.001737
2025-04-25 11:52:37,593 [INFO] Epoch 12/15 - Policy Loss: 1.2947, Value Loss: 0.0750, Total Loss: 1.3697, LR: 0.000087
2025-04-25 11:52:55,141 [INFO] Epoch 13/15 - Policy Loss: 1.2935, Value Loss: 0.0747, Total Loss: 1.3683, LR: 0.001663
2025-04-25 11:53:12,683 [INFO] Epoch 14/15 - Policy Loss: 1.2922, Value Loss: 0.0744, Total Loss: 1.3665, LR: 0.003313
2025-04-25 11:53:30,242 [INFO] Epoch 15/15 - Policy Loss: 1.2907, Value Loss: 0.0739, Total Loss: 1.3647, LR: 0.004963
2025-04-25 11:53:30,256 [INFO] 训练完成，总损失: 1.3647
2025-04-25 11:53:30,256 [INFO] 保存迭代 48 的模型
2025-04-25 11:53:30,693 [INFO] Model saved to ./models/best.pt
2025-04-25 11:53:30,997 [INFO] Model saved to ./models/iteration_48.pt
2025-04-25 11:53:30,998 [INFO] 所有训练迭代完成
2025-04-25 11:53:30,998 [INFO] 开始迭代 49/300
2025-04-25 11:53:30,998 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 11:57:50,289 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 11:57:50,290 [INFO] 保存训练样本
2025-04-25 11:57:52,581 [INFO] 使用 91568 个样本训练神经网络
2025-04-25 11:57:52,581 [INFO] Training with 91568 examples
2025-04-25 11:57:52,581 [INFO] 总训练步数: 660, 每轮次批次数: 44
2025-04-25 11:57:52,862 [INFO] 循环学习率周期大小: 132 步
2025-04-25 11:58:10,058 [INFO] Epoch 1/15 - Policy Loss: 1.2956, Value Loss: 0.0759, Total Loss: 1.3715, LR: 0.001662
2025-04-25 11:58:27,198 [INFO] Epoch 2/15 - Policy Loss: 1.2921, Value Loss: 0.0757, Total Loss: 1.3677, LR: 0.003313
2025-04-25 11:58:44,383 [INFO] Epoch 3/15 - Policy Loss: 1.2871, Value Loss: 0.0749, Total Loss: 1.3620, LR: 0.004962
2025-04-25 11:59:01,572 [INFO] Epoch 4/15 - Policy Loss: 1.2870, Value Loss: 0.0747, Total Loss: 1.3617, LR: 0.003387
2025-04-25 11:59:18,759 [INFO] Epoch 5/15 - Policy Loss: 1.2853, Value Loss: 0.0739, Total Loss: 1.3593, LR: 0.001737
2025-04-25 11:59:35,904 [INFO] Epoch 6/15 - Policy Loss: 1.2823, Value Loss: 0.0734, Total Loss: 1.3557, LR: 0.000087
2025-04-25 11:59:53,022 [INFO] Epoch 7/15 - Policy Loss: 1.2808, Value Loss: 0.0731, Total Loss: 1.3539, LR: 0.001662
2025-04-25 12:00:10,142 [INFO] Epoch 8/15 - Policy Loss: 1.2781, Value Loss: 0.0732, Total Loss: 1.3512, LR: 0.003313
2025-04-25 12:00:27,279 [INFO] Epoch 9/15 - Policy Loss: 1.2774, Value Loss: 0.0728, Total Loss: 1.3502, LR: 0.004962
2025-04-25 12:00:44,388 [INFO] Epoch 10/15 - Policy Loss: 1.2772, Value Loss: 0.0730, Total Loss: 1.3502, LR: 0.003387
2025-04-25 12:01:01,493 [INFO] Epoch 11/15 - Policy Loss: 1.2771, Value Loss: 0.0728, Total Loss: 1.3500, LR: 0.001737
2025-04-25 12:01:18,628 [INFO] Epoch 12/15 - Policy Loss: 1.2767, Value Loss: 0.0726, Total Loss: 1.3493, LR: 0.000087
2025-04-25 12:01:35,785 [INFO] Epoch 13/15 - Policy Loss: 1.2762, Value Loss: 0.0724, Total Loss: 1.3486, LR: 0.001662
2025-04-25 12:01:52,937 [INFO] Epoch 14/15 - Policy Loss: 1.2751, Value Loss: 0.0724, Total Loss: 1.3476, LR: 0.003313
2025-04-25 12:02:10,340 [INFO] Epoch 15/15 - Policy Loss: 1.2751, Value Loss: 0.0724, Total Loss: 1.3475, LR: 0.004962
2025-04-25 12:02:10,353 [INFO] 训练完成，总损失: 1.3475
2025-04-25 12:02:10,353 [INFO] 保存迭代 49 的模型
2025-04-25 12:02:10,819 [INFO] Model saved to ./models/best.pt
2025-04-25 12:02:11,224 [INFO] Model saved to ./models/iteration_49.pt
2025-04-25 12:02:11,224 [INFO] 所有训练迭代完成
2025-04-25 12:02:11,224 [INFO] 开始迭代 50/300
2025-04-25 12:02:11,225 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 12:07:02,449 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 12:07:02,450 [INFO] 保存训练样本
2025-04-25 12:07:04,657 [INFO] 使用 91984 个样本训练神经网络
2025-04-25 12:07:04,657 [INFO] Training with 91984 examples
2025-04-25 12:07:04,658 [INFO] 总训练步数: 660, 每轮次批次数: 44
2025-04-25 12:07:04,955 [INFO] 循环学习率周期大小: 132 步
2025-04-25 12:07:22,140 [INFO] Epoch 1/15 - Policy Loss: 1.2899, Value Loss: 0.0938, Total Loss: 1.3837, LR: 0.001662
2025-04-25 12:07:39,329 [INFO] Epoch 2/15 - Policy Loss: 1.2860, Value Loss: 0.0912, Total Loss: 1.3772, LR: 0.003313
2025-04-25 12:07:56,528 [INFO] Epoch 3/15 - Policy Loss: 1.2810, Value Loss: 0.0894, Total Loss: 1.3704, LR: 0.004962
2025-04-25 12:08:13,694 [INFO] Epoch 4/15 - Policy Loss: 1.2803, Value Loss: 0.0896, Total Loss: 1.3699, LR: 0.003387
2025-04-25 12:08:30,869 [INFO] Epoch 5/15 - Policy Loss: 1.2794, Value Loss: 0.0884, Total Loss: 1.3678, LR: 0.001737
2025-04-25 12:08:48,055 [INFO] Epoch 6/15 - Policy Loss: 1.2782, Value Loss: 0.0874, Total Loss: 1.3655, LR: 0.000087
2025-04-25 12:09:05,208 [INFO] Epoch 7/15 - Policy Loss: 1.2757, Value Loss: 0.0865, Total Loss: 1.3622, LR: 0.001662
2025-04-25 12:09:22,413 [INFO] Epoch 8/15 - Policy Loss: 1.2739, Value Loss: 0.0856, Total Loss: 1.3595, LR: 0.003313
2025-04-25 12:09:39,606 [INFO] Epoch 9/15 - Policy Loss: 1.2716, Value Loss: 0.0850, Total Loss: 1.3566, LR: 0.004962
2025-04-25 12:09:56,797 [INFO] Epoch 10/15 - Policy Loss: 1.2711, Value Loss: 0.0843, Total Loss: 1.3555, LR: 0.003387
2025-04-25 12:10:13,980 [INFO] Epoch 11/15 - Policy Loss: 1.2705, Value Loss: 0.0836, Total Loss: 1.3541, LR: 0.001737
2025-04-25 12:10:31,146 [INFO] Epoch 12/15 - Policy Loss: 1.2688, Value Loss: 0.0831, Total Loss: 1.3519, LR: 0.000087
2025-04-25 12:10:48,205 [INFO] Epoch 13/15 - Policy Loss: 1.2686, Value Loss: 0.0828, Total Loss: 1.3513, LR: 0.001662
2025-04-25 12:11:05,377 [INFO] Epoch 14/15 - Policy Loss: 1.2679, Value Loss: 0.0824, Total Loss: 1.3503, LR: 0.003313
2025-04-25 12:11:22,584 [INFO] Epoch 15/15 - Policy Loss: 1.2671, Value Loss: 0.0822, Total Loss: 1.3493, LR: 0.004962
2025-04-25 12:11:22,598 [INFO] 训练完成，总损失: 1.3493
2025-04-25 12:11:22,598 [INFO] 保存迭代 50 的模型
2025-04-25 12:11:23,031 [INFO] Model saved to ./models/best.pt
2025-04-25 12:11:23,333 [INFO] Model saved to ./models/iteration_50.pt
2025-04-25 12:11:23,334 [INFO] 所有训练迭代完成
2025-04-25 12:11:23,334 [INFO] 开始迭代 51/300
2025-04-25 12:11:23,334 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 12:17:09,170 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 12:17:09,171 [INFO] 保存训练样本
2025-04-25 12:17:11,474 [INFO] 使用 92704 个样本训练神经网络
2025-04-25 12:17:11,474 [INFO] Training with 92704 examples
2025-04-25 12:17:11,475 [INFO] 总训练步数: 675, 每轮次批次数: 45
2025-04-25 12:17:11,786 [INFO] 循环学习率周期大小: 135 步
2025-04-25 12:17:29,372 [INFO] Epoch 1/15 - Policy Loss: 1.2954, Value Loss: 0.1137, Total Loss: 1.4091, LR: 0.001663
2025-04-25 12:17:46,884 [INFO] Epoch 2/15 - Policy Loss: 1.2822, Value Loss: 0.1055, Total Loss: 1.3877, LR: 0.003313
2025-04-25 12:18:04,467 [INFO] Epoch 3/15 - Policy Loss: 1.2784, Value Loss: 0.0999, Total Loss: 1.3783, LR: 0.004963
2025-04-25 12:18:22,028 [INFO] Epoch 4/15 - Policy Loss: 1.2768, Value Loss: 0.0971, Total Loss: 1.3739, LR: 0.003387
2025-04-25 12:18:39,593 [INFO] Epoch 5/15 - Policy Loss: 1.2736, Value Loss: 0.0948, Total Loss: 1.3684, LR: 0.001737
2025-04-25 12:18:57,163 [INFO] Epoch 6/15 - Policy Loss: 1.2715, Value Loss: 0.0932, Total Loss: 1.3647, LR: 0.000087
2025-04-25 12:19:14,723 [INFO] Epoch 7/15 - Policy Loss: 1.2692, Value Loss: 0.0915, Total Loss: 1.3607, LR: 0.001663
2025-04-25 12:19:32,284 [INFO] Epoch 8/15 - Policy Loss: 1.2666, Value Loss: 0.0904, Total Loss: 1.3570, LR: 0.003313
2025-04-25 12:19:49,834 [INFO] Epoch 9/15 - Policy Loss: 1.2656, Value Loss: 0.0897, Total Loss: 1.3553, LR: 0.004963
2025-04-25 12:20:07,291 [INFO] Epoch 10/15 - Policy Loss: 1.2646, Value Loss: 0.0889, Total Loss: 1.3536, LR: 0.003387
2025-04-25 12:20:24,707 [INFO] Epoch 11/15 - Policy Loss: 1.2638, Value Loss: 0.0887, Total Loss: 1.3525, LR: 0.001737
2025-04-25 12:20:42,118 [INFO] Epoch 12/15 - Policy Loss: 1.2621, Value Loss: 0.0882, Total Loss: 1.3503, LR: 0.000087
2025-04-25 12:20:59,523 [INFO] Epoch 13/15 - Policy Loss: 1.2611, Value Loss: 0.0878, Total Loss: 1.3489, LR: 0.001663
2025-04-25 12:21:16,925 [INFO] Epoch 14/15 - Policy Loss: 1.2600, Value Loss: 0.0872, Total Loss: 1.3472, LR: 0.003313
2025-04-25 12:21:34,331 [INFO] Epoch 15/15 - Policy Loss: 1.2597, Value Loss: 0.0869, Total Loss: 1.3466, LR: 0.004963
2025-04-25 12:21:34,342 [INFO] 训练完成，总损失: 1.3466
2025-04-25 12:21:34,342 [INFO] 保存迭代 51 的模型
2025-04-25 12:21:34,749 [INFO] Model saved to ./models/best.pt
2025-04-25 12:21:35,031 [INFO] Model saved to ./models/iteration_51.pt
2025-04-25 12:21:35,031 [INFO] 所有训练迭代完成
2025-04-25 12:21:35,032 [INFO] 开始迭代 52/300
2025-04-25 12:21:35,032 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 12:26:21,524 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 12:26:21,524 [INFO] 保存训练样本
2025-04-25 12:26:23,587 [INFO] 使用 92792 个样本训练神经网络
2025-04-25 12:26:23,587 [INFO] Training with 92792 examples
2025-04-25 12:26:23,588 [INFO] 总训练步数: 675, 每轮次批次数: 45
2025-04-25 12:26:23,830 [INFO] 循环学习率周期大小: 135 步
2025-04-25 12:26:41,179 [INFO] Epoch 1/15 - Policy Loss: 1.2816, Value Loss: 0.1083, Total Loss: 1.3898, LR: 0.001663
2025-04-25 12:26:58,554 [INFO] Epoch 2/15 - Policy Loss: 1.2677, Value Loss: 0.1037, Total Loss: 1.3714, LR: 0.003313
2025-04-25 12:27:15,930 [INFO] Epoch 3/15 - Policy Loss: 1.2643, Value Loss: 0.1014, Total Loss: 1.3658, LR: 0.004963
2025-04-25 12:27:33,307 [INFO] Epoch 4/15 - Policy Loss: 1.2626, Value Loss: 0.0992, Total Loss: 1.3617, LR: 0.003387
2025-04-25 12:27:50,691 [INFO] Epoch 5/15 - Policy Loss: 1.2601, Value Loss: 0.0980, Total Loss: 1.3581, LR: 0.001737
2025-04-25 12:28:08,115 [INFO] Epoch 6/15 - Policy Loss: 1.2573, Value Loss: 0.0973, Total Loss: 1.3546, LR: 0.000087
2025-04-25 12:28:25,519 [INFO] Epoch 7/15 - Policy Loss: 1.2543, Value Loss: 0.0961, Total Loss: 1.3504, LR: 0.001663
2025-04-25 12:28:42,929 [INFO] Epoch 8/15 - Policy Loss: 1.2529, Value Loss: 0.0956, Total Loss: 1.3485, LR: 0.003313
2025-04-25 12:29:00,335 [INFO] Epoch 9/15 - Policy Loss: 1.2516, Value Loss: 0.0953, Total Loss: 1.3469, LR: 0.004963
2025-04-25 12:29:17,740 [INFO] Epoch 10/15 - Policy Loss: 1.2507, Value Loss: 0.0947, Total Loss: 1.3454, LR: 0.003387
2025-04-25 12:29:35,112 [INFO] Epoch 11/15 - Policy Loss: 1.2509, Value Loss: 0.0943, Total Loss: 1.3452, LR: 0.001737
2025-04-25 12:29:52,521 [INFO] Epoch 12/15 - Policy Loss: 1.2491, Value Loss: 0.0937, Total Loss: 1.3429, LR: 0.000087
2025-04-25 12:30:09,930 [INFO] Epoch 13/15 - Policy Loss: 1.2482, Value Loss: 0.0933, Total Loss: 1.3416, LR: 0.001663
2025-04-25 12:30:27,331 [INFO] Epoch 14/15 - Policy Loss: 1.2469, Value Loss: 0.0930, Total Loss: 1.3399, LR: 0.003313
2025-04-25 12:30:44,742 [INFO] Epoch 15/15 - Policy Loss: 1.2460, Value Loss: 0.0927, Total Loss: 1.3386, LR: 0.004963
2025-04-25 12:30:44,755 [INFO] 训练完成，总损失: 1.3386
2025-04-25 12:30:44,755 [INFO] 保存迭代 52 的模型
2025-04-25 12:30:45,139 [INFO] Model saved to ./models/best.pt
2025-04-25 12:30:45,413 [INFO] Model saved to ./models/iteration_52.pt
2025-04-25 12:30:45,413 [INFO] 所有训练迭代完成
2025-04-25 12:30:45,413 [INFO] 开始迭代 53/300
2025-04-25 12:30:45,413 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 12:35:46,374 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 12:35:46,374 [INFO] 保存训练样本
2025-04-25 12:35:48,108 [INFO] 使用 92848 个样本训练神经网络
2025-04-25 12:35:48,108 [INFO] Training with 92848 examples
2025-04-25 12:35:48,108 [INFO] 总训练步数: 675, 每轮次批次数: 45
2025-04-25 12:35:48,337 [INFO] 循环学习率周期大小: 135 步
2025-04-25 12:36:05,715 [INFO] Epoch 1/15 - Policy Loss: 1.2681, Value Loss: 0.1209, Total Loss: 1.3890, LR: 0.001663
2025-04-25 12:36:23,116 [INFO] Epoch 2/15 - Policy Loss: 1.2591, Value Loss: 0.1135, Total Loss: 1.3727, LR: 0.003313
2025-04-25 12:36:40,513 [INFO] Epoch 3/15 - Policy Loss: 1.2557, Value Loss: 0.1117, Total Loss: 1.3674, LR: 0.004963
2025-04-25 12:36:57,908 [INFO] Epoch 4/15 - Policy Loss: 1.2530, Value Loss: 0.1092, Total Loss: 1.3622, LR: 0.003387
2025-04-25 12:37:15,320 [INFO] Epoch 5/15 - Policy Loss: 1.2500, Value Loss: 0.1082, Total Loss: 1.3582, LR: 0.001737
2025-04-25 12:37:32,706 [INFO] Epoch 6/15 - Policy Loss: 1.2467, Value Loss: 0.1069, Total Loss: 1.3536, LR: 0.000087
2025-04-25 12:37:50,119 [INFO] Epoch 7/15 - Policy Loss: 1.2439, Value Loss: 0.1062, Total Loss: 1.3502, LR: 0.001663
2025-04-25 12:38:07,515 [INFO] Epoch 8/15 - Policy Loss: 1.2425, Value Loss: 0.1055, Total Loss: 1.3480, LR: 0.003313
2025-04-25 12:38:24,923 [INFO] Epoch 9/15 - Policy Loss: 1.2411, Value Loss: 0.1051, Total Loss: 1.3461, LR: 0.004963
2025-04-25 12:38:42,328 [INFO] Epoch 10/15 - Policy Loss: 1.2408, Value Loss: 0.1046, Total Loss: 1.3454, LR: 0.003387
2025-04-25 12:38:59,733 [INFO] Epoch 11/15 - Policy Loss: 1.2395, Value Loss: 0.1041, Total Loss: 1.3435, LR: 0.001737
2025-04-25 12:39:17,136 [INFO] Epoch 12/15 - Policy Loss: 1.2382, Value Loss: 0.1037, Total Loss: 1.3420, LR: 0.000087
2025-04-25 12:39:34,525 [INFO] Epoch 13/15 - Policy Loss: 1.2373, Value Loss: 0.1034, Total Loss: 1.3408, LR: 0.001663
2025-04-25 12:39:51,923 [INFO] Epoch 14/15 - Policy Loss: 1.2365, Value Loss: 0.1032, Total Loss: 1.3397, LR: 0.003313
2025-04-25 12:40:09,333 [INFO] Epoch 15/15 - Policy Loss: 1.2361, Value Loss: 0.1029, Total Loss: 1.3390, LR: 0.004963
2025-04-25 12:40:09,345 [INFO] 训练完成，总损失: 1.3390
2025-04-25 12:40:09,345 [INFO] 保存迭代 53 的模型
2025-04-25 12:40:09,725 [INFO] Model saved to ./models/best.pt
2025-04-25 12:40:09,989 [INFO] Model saved to ./models/iteration_53.pt
2025-04-25 12:40:09,989 [INFO] 所有训练迭代完成
2025-04-25 12:40:09,989 [INFO] 开始迭代 54/300
2025-04-25 12:40:09,989 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 12:45:13,313 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 12:45:13,313 [INFO] 保存训练样本
2025-04-25 12:45:15,305 [INFO] 使用 92808 个样本训练神经网络
2025-04-25 12:45:15,305 [INFO] Training with 92808 examples
2025-04-25 12:45:15,305 [INFO] 总训练步数: 675, 每轮次批次数: 45
2025-04-25 12:45:15,553 [INFO] 循环学习率周期大小: 135 步
2025-04-25 12:45:33,099 [INFO] Epoch 1/15 - Policy Loss: 1.2496, Value Loss: 0.1292, Total Loss: 1.3788, LR: 0.001663
2025-04-25 12:45:50,521 [INFO] Epoch 2/15 - Policy Loss: 1.2387, Value Loss: 0.1238, Total Loss: 1.3625, LR: 0.003313
2025-04-25 12:46:07,899 [INFO] Epoch 3/15 - Policy Loss: 1.2372, Value Loss: 0.1211, Total Loss: 1.3583, LR: 0.004963
2025-04-25 12:46:25,256 [INFO] Epoch 4/15 - Policy Loss: 1.2365, Value Loss: 0.1194, Total Loss: 1.3559, LR: 0.003387
2025-04-25 12:46:42,636 [INFO] Epoch 5/15 - Policy Loss: 1.2352, Value Loss: 0.1185, Total Loss: 1.3537, LR: 0.001737
2025-04-25 12:47:00,109 [INFO] Epoch 6/15 - Policy Loss: 1.2331, Value Loss: 0.1174, Total Loss: 1.3505, LR: 0.000087
2025-04-25 12:47:17,512 [INFO] Epoch 7/15 - Policy Loss: 1.2315, Value Loss: 0.1164, Total Loss: 1.3479, LR: 0.001663
2025-04-25 12:47:34,905 [INFO] Epoch 8/15 - Policy Loss: 1.2307, Value Loss: 0.1158, Total Loss: 1.3464, LR: 0.003313
2025-04-25 12:47:52,276 [INFO] Epoch 9/15 - Policy Loss: 1.2298, Value Loss: 0.1154, Total Loss: 1.3452, LR: 0.004963
2025-04-25 12:48:09,734 [INFO] Epoch 10/15 - Policy Loss: 1.2309, Value Loss: 0.1155, Total Loss: 1.3465, LR: 0.003387
2025-04-25 12:48:27,309 [INFO] Epoch 11/15 - Policy Loss: 1.2298, Value Loss: 0.1152, Total Loss: 1.3450, LR: 0.001737
2025-04-25 12:48:44,914 [INFO] Epoch 12/15 - Policy Loss: 1.2284, Value Loss: 0.1149, Total Loss: 1.3432, LR: 0.000087
2025-04-25 12:49:02,472 [INFO] Epoch 13/15 - Policy Loss: 1.2269, Value Loss: 0.1144, Total Loss: 1.3413, LR: 0.001663
2025-04-25 12:49:20,038 [INFO] Epoch 14/15 - Policy Loss: 1.2257, Value Loss: 0.1139, Total Loss: 1.3397, LR: 0.003313
2025-04-25 12:49:37,585 [INFO] Epoch 15/15 - Policy Loss: 1.2254, Value Loss: 0.1139, Total Loss: 1.3393, LR: 0.004963
2025-04-25 12:49:37,597 [INFO] 训练完成，总损失: 1.3393
2025-04-25 12:49:37,597 [INFO] 保存迭代 54 的模型
2025-04-25 12:49:38,063 [INFO] Model saved to ./models/best.pt
2025-04-25 12:49:38,401 [INFO] Model saved to ./models/iteration_54.pt
2025-04-25 12:49:38,401 [INFO] 所有训练迭代完成
2025-04-25 12:49:38,401 [INFO] 开始迭代 55/300
2025-04-25 12:49:38,401 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 12:55:32,625 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 12:55:32,625 [INFO] 保存训练样本
2025-04-25 12:55:34,958 [INFO] 使用 93928 个样本训练神经网络
2025-04-25 12:55:34,958 [INFO] Training with 93928 examples
2025-04-25 12:55:34,958 [INFO] 总训练步数: 675, 每轮次批次数: 45
2025-04-25 12:55:35,238 [INFO] 循环学习率周期大小: 135 步
2025-04-25 12:55:52,832 [INFO] Epoch 1/15 - Policy Loss: 1.2735, Value Loss: 0.1381, Total Loss: 1.4116, LR: 0.001663
2025-04-25 12:56:10,389 [INFO] Epoch 2/15 - Policy Loss: 1.2573, Value Loss: 0.1321, Total Loss: 1.3894, LR: 0.003313
2025-04-25 12:56:27,953 [INFO] Epoch 3/15 - Policy Loss: 1.2525, Value Loss: 0.1300, Total Loss: 1.3825, LR: 0.004963
2025-04-25 12:56:45,511 [INFO] Epoch 4/15 - Policy Loss: 1.2456, Value Loss: 0.1286, Total Loss: 1.3742, LR: 0.003387
2025-04-25 12:57:03,062 [INFO] Epoch 5/15 - Policy Loss: 1.2417, Value Loss: 0.1270, Total Loss: 1.3687, LR: 0.001737
2025-04-25 12:57:20,597 [INFO] Epoch 6/15 - Policy Loss: 1.2368, Value Loss: 0.1251, Total Loss: 1.3619, LR: 0.000087
2025-04-25 12:57:38,125 [INFO] Epoch 7/15 - Policy Loss: 1.2346, Value Loss: 0.1243, Total Loss: 1.3589, LR: 0.001663
2025-04-25 12:57:55,684 [INFO] Epoch 8/15 - Policy Loss: 1.2320, Value Loss: 0.1236, Total Loss: 1.3556, LR: 0.003313
2025-04-25 12:58:13,185 [INFO] Epoch 9/15 - Policy Loss: 1.2298, Value Loss: 0.1230, Total Loss: 1.3528, LR: 0.004963
2025-04-25 12:58:30,705 [INFO] Epoch 10/15 - Policy Loss: 1.2295, Value Loss: 0.1225, Total Loss: 1.3521, LR: 0.003387
2025-04-25 12:58:48,271 [INFO] Epoch 11/15 - Policy Loss: 1.2290, Value Loss: 0.1222, Total Loss: 1.3511, LR: 0.001737
2025-04-25 12:59:05,814 [INFO] Epoch 12/15 - Policy Loss: 1.2278, Value Loss: 0.1217, Total Loss: 1.3495, LR: 0.000087
2025-04-25 12:59:23,371 [INFO] Epoch 13/15 - Policy Loss: 1.2263, Value Loss: 0.1214, Total Loss: 1.3477, LR: 0.001663
2025-04-25 12:59:40,939 [INFO] Epoch 14/15 - Policy Loss: 1.2248, Value Loss: 0.1211, Total Loss: 1.3459, LR: 0.003313
2025-04-25 12:59:58,804 [INFO] Epoch 15/15 - Policy Loss: 1.2243, Value Loss: 0.1210, Total Loss: 1.3453, LR: 0.004963
2025-04-25 12:59:58,817 [INFO] 训练完成，总损失: 1.3453
2025-04-25 12:59:58,817 [INFO] 保存迭代 55 的模型
2025-04-25 12:59:59,269 [INFO] Model saved to ./models/best.pt
2025-04-25 12:59:59,574 [INFO] Model saved to ./models/iteration_55.pt
2025-04-25 12:59:59,574 [INFO] 所有训练迭代完成
2025-04-25 12:59:59,574 [INFO] 开始迭代 56/300
2025-04-25 12:59:59,574 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 13:05:44,072 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 13:05:44,073 [INFO] 保存训练样本
2025-04-25 13:05:46,428 [INFO] 使用 94344 个样本训练神经网络
2025-04-25 13:05:46,428 [INFO] Training with 94344 examples
2025-04-25 13:05:46,428 [INFO] 总训练步数: 690, 每轮次批次数: 46
2025-04-25 13:05:46,774 [INFO] 循环学习率周期大小: 138 步
2025-04-25 13:06:04,723 [INFO] Epoch 1/15 - Policy Loss: 1.2396, Value Loss: 0.1529, Total Loss: 1.3926, LR: 0.001664
2025-04-25 13:06:22,653 [INFO] Epoch 2/15 - Policy Loss: 1.2331, Value Loss: 0.1474, Total Loss: 1.3805, LR: 0.003314
2025-04-25 13:06:40,631 [INFO] Epoch 3/15 - Policy Loss: 1.2311, Value Loss: 0.1446, Total Loss: 1.3757, LR: 0.004964
2025-04-25 13:06:58,616 [INFO] Epoch 4/15 - Policy Loss: 1.2301, Value Loss: 0.1430, Total Loss: 1.3731, LR: 0.003386
2025-04-25 13:07:16,563 [INFO] Epoch 5/15 - Policy Loss: 1.2262, Value Loss: 0.1409, Total Loss: 1.3671, LR: 0.001736
2025-04-25 13:07:34,508 [INFO] Epoch 6/15 - Policy Loss: 1.2224, Value Loss: 0.1397, Total Loss: 1.3621, LR: 0.000086
2025-04-25 13:07:52,458 [INFO] Epoch 7/15 - Policy Loss: 1.2214, Value Loss: 0.1386, Total Loss: 1.3600, LR: 0.001664
2025-04-25 13:08:10,412 [INFO] Epoch 8/15 - Policy Loss: 1.2199, Value Loss: 0.1374, Total Loss: 1.3572, LR: 0.003314
2025-04-25 13:08:28,344 [INFO] Epoch 9/15 - Policy Loss: 1.2191, Value Loss: 0.1366, Total Loss: 1.3557, LR: 0.004964
2025-04-25 13:08:46,287 [INFO] Epoch 10/15 - Policy Loss: 1.2197, Value Loss: 0.1362, Total Loss: 1.3559, LR: 0.003386
2025-04-25 13:09:04,231 [INFO] Epoch 11/15 - Policy Loss: 1.2189, Value Loss: 0.1358, Total Loss: 1.3547, LR: 0.001736
2025-04-25 13:09:22,164 [INFO] Epoch 12/15 - Policy Loss: 1.2172, Value Loss: 0.1353, Total Loss: 1.3525, LR: 0.000086
2025-04-25 13:09:40,105 [INFO] Epoch 13/15 - Policy Loss: 1.2159, Value Loss: 0.1348, Total Loss: 1.3506, LR: 0.001664
2025-04-25 13:09:58,062 [INFO] Epoch 14/15 - Policy Loss: 1.2145, Value Loss: 0.1342, Total Loss: 1.3487, LR: 0.003314
2025-04-25 13:10:16,020 [INFO] Epoch 15/15 - Policy Loss: 1.2140, Value Loss: 0.1338, Total Loss: 1.3478, LR: 0.004964
2025-04-25 13:10:16,033 [INFO] 训练完成，总损失: 1.3478
2025-04-25 13:10:16,033 [INFO] 保存迭代 56 的模型
2025-04-25 13:10:16,480 [INFO] Model saved to ./models/best.pt
2025-04-25 13:10:16,788 [INFO] Model saved to ./models/iteration_56.pt
2025-04-25 13:10:16,789 [INFO] 所有训练迭代完成
2025-04-25 13:10:16,789 [INFO] 开始迭代 57/300
2025-04-25 13:10:16,789 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 13:15:53,827 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 13:15:53,827 [INFO] 保存训练样本
2025-04-25 13:15:55,726 [INFO] 使用 95152 个样本训练神经网络
2025-04-25 13:15:55,726 [INFO] Training with 95152 examples
2025-04-25 13:15:55,727 [INFO] 总训练步数: 690, 每轮次批次数: 46
2025-04-25 13:15:55,958 [INFO] 循环学习率周期大小: 138 步
2025-04-25 13:16:13,754 [INFO] Epoch 1/15 - Policy Loss: 1.2271, Value Loss: 0.1441, Total Loss: 1.3713, LR: 0.001664
2025-04-25 13:16:31,528 [INFO] Epoch 2/15 - Policy Loss: 1.2142, Value Loss: 0.1386, Total Loss: 1.3527, LR: 0.003314
2025-04-25 13:16:49,365 [INFO] Epoch 3/15 - Policy Loss: 1.2106, Value Loss: 0.1381, Total Loss: 1.3488, LR: 0.004964
2025-04-25 13:17:07,110 [INFO] Epoch 4/15 - Policy Loss: 1.2108, Value Loss: 0.1370, Total Loss: 1.3478, LR: 0.003386
2025-04-25 13:17:24,882 [INFO] Epoch 5/15 - Policy Loss: 1.2068, Value Loss: 0.1372, Total Loss: 1.3440, LR: 0.001736
2025-04-25 13:17:42,669 [INFO] Epoch 6/15 - Policy Loss: 1.2036, Value Loss: 0.1364, Total Loss: 1.3399, LR: 0.000086
2025-04-25 13:18:00,446 [INFO] Epoch 7/15 - Policy Loss: 1.2015, Value Loss: 0.1357, Total Loss: 1.3372, LR: 0.001664
2025-04-25 13:18:18,225 [INFO] Epoch 8/15 - Policy Loss: 1.1997, Value Loss: 0.1356, Total Loss: 1.3352, LR: 0.003314
2025-04-25 13:18:36,009 [INFO] Epoch 9/15 - Policy Loss: 1.1983, Value Loss: 0.1354, Total Loss: 1.3336, LR: 0.004964
2025-04-25 13:18:53,786 [INFO] Epoch 10/15 - Policy Loss: 1.1975, Value Loss: 0.1352, Total Loss: 1.3327, LR: 0.003386
2025-04-25 13:19:11,535 [INFO] Epoch 11/15 - Policy Loss: 1.1969, Value Loss: 0.1351, Total Loss: 1.3320, LR: 0.001736
2025-04-25 13:19:29,299 [INFO] Epoch 12/15 - Policy Loss: 1.1966, Value Loss: 0.1346, Total Loss: 1.3312, LR: 0.000086
2025-04-25 13:19:47,079 [INFO] Epoch 13/15 - Policy Loss: 1.1962, Value Loss: 0.1343, Total Loss: 1.3305, LR: 0.001664
2025-04-25 13:20:04,856 [INFO] Epoch 14/15 - Policy Loss: 1.1957, Value Loss: 0.1343, Total Loss: 1.3300, LR: 0.003314
2025-04-25 13:20:22,887 [INFO] Epoch 15/15 - Policy Loss: 1.1946, Value Loss: 0.1342, Total Loss: 1.3288, LR: 0.004964
2025-04-25 13:20:22,900 [INFO] 训练完成，总损失: 1.3288
2025-04-25 13:20:22,900 [INFO] 保存迭代 57 的模型
2025-04-25 13:20:23,304 [INFO] Model saved to ./models/best.pt
2025-04-25 13:20:23,586 [INFO] Model saved to ./models/iteration_57.pt
2025-04-25 13:20:23,587 [INFO] 所有训练迭代完成
2025-04-25 13:20:23,587 [INFO] 开始迭代 58/300
2025-04-25 13:20:23,587 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 13:25:25,247 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 13:25:25,247 [INFO] 保存训练样本
2025-04-25 13:25:27,542 [INFO] 使用 95808 个样本训练神经网络
2025-04-25 13:25:27,542 [INFO] Training with 95808 examples
2025-04-25 13:25:27,543 [INFO] 总训练步数: 690, 每轮次批次数: 46
2025-04-25 13:25:27,782 [INFO] 循环学习率周期大小: 138 步
2025-04-25 13:25:45,593 [INFO] Epoch 1/15 - Policy Loss: 1.2199, Value Loss: 0.1646, Total Loss: 1.3846, LR: 0.001664
2025-04-25 13:26:03,402 [INFO] Epoch 2/15 - Policy Loss: 1.2058, Value Loss: 0.1563, Total Loss: 1.3621, LR: 0.003314
2025-04-25 13:26:21,202 [INFO] Epoch 3/15 - Policy Loss: 1.2028, Value Loss: 0.1545, Total Loss: 1.3573, LR: 0.004964
2025-04-25 13:26:39,127 [INFO] Epoch 4/15 - Policy Loss: 1.2004, Value Loss: 0.1528, Total Loss: 1.3531, LR: 0.003386
2025-04-25 13:26:56,894 [INFO] Epoch 5/15 - Policy Loss: 1.1979, Value Loss: 0.1510, Total Loss: 1.3489, LR: 0.001736
2025-04-25 13:27:14,683 [INFO] Epoch 6/15 - Policy Loss: 1.1955, Value Loss: 0.1496, Total Loss: 1.3451, LR: 0.000086
2025-04-25 13:27:32,443 [INFO] Epoch 7/15 - Policy Loss: 1.1935, Value Loss: 0.1489, Total Loss: 1.3424, LR: 0.001664
2025-04-25 13:27:50,267 [INFO] Epoch 8/15 - Policy Loss: 1.1915, Value Loss: 0.1476, Total Loss: 1.3391, LR: 0.003314
2025-04-25 13:28:08,052 [INFO] Epoch 9/15 - Policy Loss: 1.1902, Value Loss: 0.1469, Total Loss: 1.3371, LR: 0.004964
2025-04-25 13:28:25,796 [INFO] Epoch 10/15 - Policy Loss: 1.1897, Value Loss: 0.1470, Total Loss: 1.3367, LR: 0.003386
2025-04-25 13:28:43,571 [INFO] Epoch 11/15 - Policy Loss: 1.1892, Value Loss: 0.1465, Total Loss: 1.3357, LR: 0.001736
2025-04-25 13:29:01,352 [INFO] Epoch 12/15 - Policy Loss: 1.1881, Value Loss: 0.1460, Total Loss: 1.3341, LR: 0.000086
2025-04-25 13:29:19,101 [INFO] Epoch 13/15 - Policy Loss: 1.1867, Value Loss: 0.1454, Total Loss: 1.3321, LR: 0.001664
2025-04-25 13:29:36,892 [INFO] Epoch 14/15 - Policy Loss: 1.1853, Value Loss: 0.1451, Total Loss: 1.3304, LR: 0.003314
2025-04-25 13:29:54,655 [INFO] Epoch 15/15 - Policy Loss: 1.1849, Value Loss: 0.1447, Total Loss: 1.3296, LR: 0.004964
2025-04-25 13:29:54,667 [INFO] 训练完成，总损失: 1.3296
2025-04-25 13:29:54,667 [INFO] 保存迭代 58 的模型
2025-04-25 13:29:55,105 [INFO] Model saved to ./models/best.pt
2025-04-25 13:29:55,412 [INFO] Model saved to ./models/iteration_58.pt
2025-04-25 13:29:55,412 [INFO] 所有训练迭代完成
2025-04-25 13:29:55,412 [INFO] 开始迭代 59/300
2025-04-25 13:29:55,412 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 13:35:13,894 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 13:35:13,895 [INFO] 保存训练样本
2025-04-25 13:35:16,316 [INFO] 使用 96312 个样本训练神经网络
2025-04-25 13:35:16,316 [INFO] Training with 96312 examples
2025-04-25 13:35:16,316 [INFO] 总训练步数: 705, 每轮次批次数: 47
2025-04-25 13:35:16,622 [INFO] 循环学习率周期大小: 141 步
2025-04-25 13:35:35,027 [INFO] Epoch 1/15 - Policy Loss: 1.2044, Value Loss: 0.1679, Total Loss: 1.3723, LR: 0.001665
2025-04-25 13:35:53,305 [INFO] Epoch 2/15 - Policy Loss: 1.1939, Value Loss: 0.1617, Total Loss: 1.3556, LR: 0.003315
2025-04-25 13:36:11,658 [INFO] Epoch 3/15 - Policy Loss: 1.1911, Value Loss: 0.1599, Total Loss: 1.3511, LR: 0.004965
2025-04-25 13:36:30,052 [INFO] Epoch 4/15 - Policy Loss: 1.1880, Value Loss: 0.1582, Total Loss: 1.3462, LR: 0.003385
2025-04-25 13:36:48,419 [INFO] Epoch 5/15 - Policy Loss: 1.1857, Value Loss: 0.1580, Total Loss: 1.3437, LR: 0.001735
2025-04-25 13:37:06,758 [INFO] Epoch 6/15 - Policy Loss: 1.1833, Value Loss: 0.1567, Total Loss: 1.3400, LR: 0.000085
2025-04-25 13:37:25,113 [INFO] Epoch 7/15 - Policy Loss: 1.1810, Value Loss: 0.1556, Total Loss: 1.3366, LR: 0.001665
2025-04-25 13:37:43,519 [INFO] Epoch 8/15 - Policy Loss: 1.1797, Value Loss: 0.1551, Total Loss: 1.3348, LR: 0.003315
2025-04-25 13:38:01,996 [INFO] Epoch 9/15 - Policy Loss: 1.1788, Value Loss: 0.1546, Total Loss: 1.3334, LR: 0.004965
2025-04-25 13:38:20,417 [INFO] Epoch 10/15 - Policy Loss: 1.1787, Value Loss: 0.1542, Total Loss: 1.3329, LR: 0.003385
2025-04-25 13:38:38,803 [INFO] Epoch 11/15 - Policy Loss: 1.1782, Value Loss: 0.1535, Total Loss: 1.3316, LR: 0.001735
2025-04-25 13:38:57,249 [INFO] Epoch 12/15 - Policy Loss: 1.1774, Value Loss: 0.1534, Total Loss: 1.3308, LR: 0.000085
2025-04-25 13:39:15,662 [INFO] Epoch 13/15 - Policy Loss: 1.1759, Value Loss: 0.1528, Total Loss: 1.3287, LR: 0.001665
2025-04-25 13:39:34,332 [INFO] Epoch 14/15 - Policy Loss: 1.1756, Value Loss: 0.1524, Total Loss: 1.3280, LR: 0.003315
2025-04-25 13:39:52,706 [INFO] Epoch 15/15 - Policy Loss: 1.1751, Value Loss: 0.1523, Total Loss: 1.3274, LR: 0.004965
2025-04-25 13:39:52,724 [INFO] 训练完成，总损失: 1.3274
2025-04-25 13:39:52,724 [INFO] 保存迭代 59 的模型
2025-04-25 13:39:53,149 [INFO] Model saved to ./models/best.pt
2025-04-25 13:39:53,530 [INFO] Model saved to ./models/iteration_59.pt
2025-04-25 13:39:53,530 [INFO] 所有训练迭代完成
2025-04-25 13:39:53,531 [INFO] 开始迭代 60/300
2025-04-25 13:39:53,531 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 13:44:29,404 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 13:44:29,404 [INFO] 保存训练样本
2025-04-25 13:44:31,855 [INFO] 使用 96200 个样本训练神经网络
2025-04-25 13:44:31,855 [INFO] Training with 96200 examples
2025-04-25 13:44:31,856 [INFO] 总训练步数: 690, 每轮次批次数: 46
2025-04-25 13:44:32,165 [INFO] 循环学习率周期大小: 138 步
2025-04-25 13:44:50,203 [INFO] Epoch 1/15 - Policy Loss: 1.1764, Value Loss: 0.1607, Total Loss: 1.3371, LR: 0.001664
2025-04-25 13:45:08,195 [INFO] Epoch 2/15 - Policy Loss: 1.1726, Value Loss: 0.1600, Total Loss: 1.3326, LR: 0.003314
2025-04-25 13:45:26,191 [INFO] Epoch 3/15 - Policy Loss: 1.1737, Value Loss: 0.1597, Total Loss: 1.3334, LR: 0.004964
2025-04-25 13:45:44,132 [INFO] Epoch 4/15 - Policy Loss: 1.1729, Value Loss: 0.1583, Total Loss: 1.3313, LR: 0.003386
2025-04-25 13:46:01,965 [INFO] Epoch 5/15 - Policy Loss: 1.1724, Value Loss: 0.1572, Total Loss: 1.3296, LR: 0.001736
2025-04-25 13:46:19,809 [INFO] Epoch 6/15 - Policy Loss: 1.1707, Value Loss: 0.1564, Total Loss: 1.3271, LR: 0.000086
2025-04-25 13:46:37,592 [INFO] Epoch 7/15 - Policy Loss: 1.1697, Value Loss: 0.1558, Total Loss: 1.3255, LR: 0.001664
2025-04-25 13:46:55,420 [INFO] Epoch 8/15 - Policy Loss: 1.1683, Value Loss: 0.1550, Total Loss: 1.3233, LR: 0.003314
2025-04-25 13:47:13,240 [INFO] Epoch 9/15 - Policy Loss: 1.1685, Value Loss: 0.1545, Total Loss: 1.3230, LR: 0.004964
2025-04-25 13:47:31,040 [INFO] Epoch 10/15 - Policy Loss: 1.1684, Value Loss: 0.1541, Total Loss: 1.3226, LR: 0.003386
2025-04-25 13:47:48,892 [INFO] Epoch 11/15 - Policy Loss: 1.1677, Value Loss: 0.1539, Total Loss: 1.3216, LR: 0.001736
2025-04-25 13:48:06,964 [INFO] Epoch 12/15 - Policy Loss: 1.1669, Value Loss: 0.1535, Total Loss: 1.3205, LR: 0.000086
2025-04-25 13:48:25,089 [INFO] Epoch 13/15 - Policy Loss: 1.1657, Value Loss: 0.1535, Total Loss: 1.3192, LR: 0.001664
2025-04-25 13:48:43,136 [INFO] Epoch 14/15 - Policy Loss: 1.1652, Value Loss: 0.1535, Total Loss: 1.3187, LR: 0.003314
2025-04-25 13:49:01,229 [INFO] Epoch 15/15 - Policy Loss: 1.1649, Value Loss: 0.1534, Total Loss: 1.3182, LR: 0.004964
2025-04-25 13:49:01,243 [INFO] 训练完成，总损失: 1.3182
2025-04-25 13:49:01,243 [INFO] 保存迭代 60 的模型
2025-04-25 13:49:01,631 [INFO] Model saved to ./models/best.pt
2025-04-25 13:49:01,899 [INFO] Model saved to ./models/iteration_60.pt
2025-04-25 13:49:01,899 [INFO] 所有训练迭代完成
2025-04-25 13:49:01,899 [INFO] 开始迭代 61/300
2025-04-25 13:49:01,899 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 13:53:51,626 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 13:53:51,627 [INFO] 保存训练样本
2025-04-25 13:53:53,851 [INFO] 使用 97000 个样本训练神经网络
2025-04-25 13:53:53,851 [INFO] Training with 97000 examples
2025-04-25 13:53:53,852 [INFO] 总训练步数: 705, 每轮次批次数: 47
2025-04-25 13:53:54,118 [INFO] 循环学习率周期大小: 141 步
2025-04-25 13:54:12,320 [INFO] Epoch 1/15 - Policy Loss: 1.1753, Value Loss: 0.1746, Total Loss: 1.3499, LR: 0.001665
2025-04-25 13:54:30,465 [INFO] Epoch 2/15 - Policy Loss: 1.1713, Value Loss: 0.1698, Total Loss: 1.3411, LR: 0.003315
2025-04-25 13:54:48,609 [INFO] Epoch 3/15 - Policy Loss: 1.1715, Value Loss: 0.1676, Total Loss: 1.3391, LR: 0.004965
2025-04-25 13:55:06,764 [INFO] Epoch 4/15 - Policy Loss: 1.1688, Value Loss: 0.1670, Total Loss: 1.3358, LR: 0.003385
2025-04-25 13:55:24,894 [INFO] Epoch 5/15 - Policy Loss: 1.1665, Value Loss: 0.1659, Total Loss: 1.3325, LR: 0.001735
2025-04-25 13:55:43,018 [INFO] Epoch 6/15 - Policy Loss: 1.1633, Value Loss: 0.1644, Total Loss: 1.3278, LR: 0.000085
2025-04-25 13:56:01,154 [INFO] Epoch 7/15 - Policy Loss: 1.1619, Value Loss: 0.1642, Total Loss: 1.3260, LR: 0.001665
2025-04-25 13:56:19,303 [INFO] Epoch 8/15 - Policy Loss: 1.1601, Value Loss: 0.1637, Total Loss: 1.3238, LR: 0.003315
2025-04-25 13:56:37,475 [INFO] Epoch 9/15 - Policy Loss: 1.1588, Value Loss: 0.1633, Total Loss: 1.3221, LR: 0.004965
2025-04-25 13:56:55,597 [INFO] Epoch 10/15 - Policy Loss: 1.1581, Value Loss: 0.1629, Total Loss: 1.3210, LR: 0.003385
2025-04-25 13:57:13,700 [INFO] Epoch 11/15 - Policy Loss: 1.1573, Value Loss: 0.1628, Total Loss: 1.3202, LR: 0.001735
2025-04-25 13:57:31,878 [INFO] Epoch 12/15 - Policy Loss: 1.1561, Value Loss: 0.1628, Total Loss: 1.3188, LR: 0.000085
2025-04-25 13:57:50,281 [INFO] Epoch 13/15 - Policy Loss: 1.1559, Value Loss: 0.1624, Total Loss: 1.3183, LR: 0.001665
2025-04-25 13:58:08,427 [INFO] Epoch 14/15 - Policy Loss: 1.1546, Value Loss: 0.1623, Total Loss: 1.3169, LR: 0.003315
2025-04-25 13:58:26,614 [INFO] Epoch 15/15 - Policy Loss: 1.1542, Value Loss: 0.1622, Total Loss: 1.3164, LR: 0.004965
2025-04-25 13:58:26,626 [INFO] 训练完成，总损失: 1.3164
2025-04-25 13:58:26,626 [INFO] 保存迭代 61 的模型
2025-04-25 13:58:27,016 [INFO] Model saved to ./models/best.pt
2025-04-25 13:58:27,283 [INFO] Model saved to ./models/iteration_61.pt
2025-04-25 13:58:27,283 [INFO] 所有训练迭代完成
2025-04-25 13:58:27,283 [INFO] 开始迭代 62/300
2025-04-25 13:58:27,283 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 14:04:20,676 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 14:04:20,677 [INFO] 保存训练样本
2025-04-25 14:04:22,964 [INFO] 使用 98232 个样本训练神经网络
2025-04-25 14:04:22,964 [INFO] Training with 98232 examples
2025-04-25 14:04:22,965 [INFO] 总训练步数: 705, 每轮次批次数: 47
2025-04-25 14:04:23,236 [INFO] 循环学习率周期大小: 141 步
2025-04-25 14:04:41,443 [INFO] Epoch 1/15 - Policy Loss: 1.1667, Value Loss: 0.1768, Total Loss: 1.3435, LR: 0.001665
2025-04-25 14:04:59,641 [INFO] Epoch 2/15 - Policy Loss: 1.1648, Value Loss: 0.1747, Total Loss: 1.3395, LR: 0.003315
2025-04-25 14:05:17,792 [INFO] Epoch 3/15 - Policy Loss: 1.1635, Value Loss: 0.1739, Total Loss: 1.3373, LR: 0.004965
2025-04-25 14:05:35,952 [INFO] Epoch 4/15 - Policy Loss: 1.1631, Value Loss: 0.1732, Total Loss: 1.3363, LR: 0.003385
2025-04-25 14:05:54,113 [INFO] Epoch 5/15 - Policy Loss: 1.1611, Value Loss: 0.1724, Total Loss: 1.3335, LR: 0.001735
2025-04-25 14:06:12,312 [INFO] Epoch 6/15 - Policy Loss: 1.1577, Value Loss: 0.1720, Total Loss: 1.3297, LR: 0.000085
2025-04-25 14:06:30,535 [INFO] Epoch 7/15 - Policy Loss: 1.1549, Value Loss: 0.1713, Total Loss: 1.3262, LR: 0.001665
2025-04-25 14:06:48,762 [INFO] Epoch 8/15 - Policy Loss: 1.1526, Value Loss: 0.1707, Total Loss: 1.3232, LR: 0.003315
2025-04-25 14:07:06,996 [INFO] Epoch 9/15 - Policy Loss: 1.1505, Value Loss: 0.1704, Total Loss: 1.3209, LR: 0.004965
2025-04-25 14:07:25,217 [INFO] Epoch 10/15 - Policy Loss: 1.1511, Value Loss: 0.1704, Total Loss: 1.3215, LR: 0.003385
2025-04-25 14:07:43,454 [INFO] Epoch 11/15 - Policy Loss: 1.1506, Value Loss: 0.1702, Total Loss: 1.3208, LR: 0.001735
2025-04-25 14:08:01,683 [INFO] Epoch 12/15 - Policy Loss: 1.1491, Value Loss: 0.1697, Total Loss: 1.3188, LR: 0.000085
2025-04-25 14:08:19,910 [INFO] Epoch 13/15 - Policy Loss: 1.1483, Value Loss: 0.1694, Total Loss: 1.3176, LR: 0.001665
2025-04-25 14:08:38,416 [INFO] Epoch 14/15 - Policy Loss: 1.1473, Value Loss: 0.1690, Total Loss: 1.3162, LR: 0.003315
2025-04-25 14:08:56,632 [INFO] Epoch 15/15 - Policy Loss: 1.1464, Value Loss: 0.1688, Total Loss: 1.3152, LR: 0.004965
2025-04-25 14:08:56,645 [INFO] 训练完成，总损失: 1.3152
2025-04-25 14:08:56,645 [INFO] 保存迭代 62 的模型
2025-04-25 14:08:57,029 [INFO] Model saved to ./models/best.pt
2025-04-25 14:08:57,307 [INFO] Model saved to ./models/iteration_62.pt
2025-04-25 14:08:57,308 [INFO] 所有训练迭代完成
2025-04-25 14:08:57,308 [INFO] 开始迭代 63/300
2025-04-25 14:08:57,308 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 14:14:27,572 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 14:14:27,572 [INFO] 保存训练样本
2025-04-25 14:14:29,935 [INFO] 使用 99408 个样本训练神经网络
2025-04-25 14:14:29,935 [INFO] Training with 99408 examples
2025-04-25 14:14:29,936 [INFO] 总训练步数: 720, 每轮次批次数: 48
2025-04-25 14:14:30,283 [INFO] 循环学习率周期大小: 144 步
2025-04-25 14:14:48,875 [INFO] Epoch 1/15 - Policy Loss: 1.1607, Value Loss: 0.1866, Total Loss: 1.3473, LR: 0.001666
2025-04-25 14:15:07,408 [INFO] Epoch 2/15 - Policy Loss: 1.1552, Value Loss: 0.1797, Total Loss: 1.3349, LR: 0.003316
2025-04-25 14:15:25,948 [INFO] Epoch 3/15 - Policy Loss: 1.1479, Value Loss: 0.1782, Total Loss: 1.3261, LR: 0.004966
2025-04-25 14:15:44,479 [INFO] Epoch 4/15 - Policy Loss: 1.1484, Value Loss: 0.1766, Total Loss: 1.3250, LR: 0.003384
2025-04-25 14:16:02,985 [INFO] Epoch 5/15 - Policy Loss: 1.1451, Value Loss: 0.1761, Total Loss: 1.3212, LR: 0.001734
2025-04-25 14:16:21,518 [INFO] Epoch 6/15 - Policy Loss: 1.1441, Value Loss: 0.1751, Total Loss: 1.3191, LR: 0.000084
2025-04-25 14:16:40,031 [INFO] Epoch 7/15 - Policy Loss: 1.1417, Value Loss: 0.1737, Total Loss: 1.3155, LR: 0.001666
2025-04-25 14:16:58,568 [INFO] Epoch 8/15 - Policy Loss: 1.1401, Value Loss: 0.1738, Total Loss: 1.3139, LR: 0.003316
2025-04-25 14:17:17,102 [INFO] Epoch 9/15 - Policy Loss: 1.1397, Value Loss: 0.1734, Total Loss: 1.3131, LR: 0.004966
2025-04-25 14:17:35,655 [INFO] Epoch 10/15 - Policy Loss: 1.1395, Value Loss: 0.1729, Total Loss: 1.3124, LR: 0.003384
2025-04-25 14:17:54,210 [INFO] Epoch 11/15 - Policy Loss: 1.1390, Value Loss: 0.1724, Total Loss: 1.3114, LR: 0.001734
2025-04-25 14:18:12,767 [INFO] Epoch 12/15 - Policy Loss: 1.1379, Value Loss: 0.1722, Total Loss: 1.3101, LR: 0.000084
2025-04-25 14:18:31,326 [INFO] Epoch 13/15 - Policy Loss: 1.1368, Value Loss: 0.1719, Total Loss: 1.3087, LR: 0.001666
2025-04-25 14:18:50,109 [INFO] Epoch 14/15 - Policy Loss: 1.1356, Value Loss: 0.1718, Total Loss: 1.3074, LR: 0.003316
2025-04-25 14:19:08,685 [INFO] Epoch 15/15 - Policy Loss: 1.1357, Value Loss: 0.1718, Total Loss: 1.3074, LR: 0.004966
2025-04-25 14:19:08,698 [INFO] 训练完成，总损失: 1.3074
2025-04-25 14:19:08,698 [INFO] 保存迭代 63 的模型
2025-04-25 14:19:09,082 [INFO] Model saved to ./models/best.pt
2025-04-25 14:19:09,370 [INFO] Model saved to ./models/iteration_63.pt
2025-04-25 14:19:09,370 [INFO] 所有训练迭代完成
2025-04-25 14:19:09,370 [INFO] 开始迭代 64/300
2025-04-25 14:19:09,370 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 14:25:04,083 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 14:25:04,084 [INFO] 保存训练样本
2025-04-25 14:25:06,606 [INFO] 使用 100488 个样本训练神经网络
2025-04-25 14:25:06,606 [INFO] Training with 100488 examples
2025-04-25 14:25:06,607 [INFO] 总训练步数: 735, 每轮次批次数: 49
2025-04-25 14:25:06,887 [INFO] 循环学习率周期大小: 147 步
2025-04-25 14:25:26,043 [INFO] Epoch 1/15 - Policy Loss: 1.1623, Value Loss: 0.2191, Total Loss: 1.3814, LR: 0.001666
2025-04-25 14:25:45,170 [INFO] Epoch 2/15 - Policy Loss: 1.1519, Value Loss: 0.2131, Total Loss: 1.3651, LR: 0.003316
2025-04-25 14:26:04,299 [INFO] Epoch 3/15 - Policy Loss: 1.1489, Value Loss: 0.2089, Total Loss: 1.3578, LR: 0.004966
2025-04-25 14:26:23,420 [INFO] Epoch 4/15 - Policy Loss: 1.1440, Value Loss: 0.2070, Total Loss: 1.3510, LR: 0.003384
2025-04-25 14:26:42,557 [INFO] Epoch 5/15 - Policy Loss: 1.1417, Value Loss: 0.2042, Total Loss: 1.3459, LR: 0.001734
2025-04-25 14:27:01,703 [INFO] Epoch 6/15 - Policy Loss: 1.1390, Value Loss: 0.2027, Total Loss: 1.3418, LR: 0.000084
2025-04-25 14:27:20,840 [INFO] Epoch 7/15 - Policy Loss: 1.1376, Value Loss: 0.2012, Total Loss: 1.3388, LR: 0.001666
2025-04-25 14:27:39,989 [INFO] Epoch 8/15 - Policy Loss: 1.1360, Value Loss: 0.2003, Total Loss: 1.3363, LR: 0.003316
2025-04-25 14:27:59,120 [INFO] Epoch 9/15 - Policy Loss: 1.1352, Value Loss: 0.1992, Total Loss: 1.3344, LR: 0.004966
2025-04-25 14:28:18,250 [INFO] Epoch 10/15 - Policy Loss: 1.1349, Value Loss: 0.1986, Total Loss: 1.3336, LR: 0.003384
2025-04-25 14:28:37,389 [INFO] Epoch 11/15 - Policy Loss: 1.1334, Value Loss: 0.1980, Total Loss: 1.3314, LR: 0.001734
2025-04-25 14:28:56,523 [INFO] Epoch 12/15 - Policy Loss: 1.1327, Value Loss: 0.1972, Total Loss: 1.3299, LR: 0.000084
2025-04-25 14:29:15,955 [INFO] Epoch 13/15 - Policy Loss: 1.1308, Value Loss: 0.1968, Total Loss: 1.3276, LR: 0.001666
2025-04-25 14:29:35,093 [INFO] Epoch 14/15 - Policy Loss: 1.1296, Value Loss: 0.1960, Total Loss: 1.3256, LR: 0.003316
2025-04-25 14:29:54,249 [INFO] Epoch 15/15 - Policy Loss: 1.1288, Value Loss: 0.1955, Total Loss: 1.3243, LR: 0.004966
2025-04-25 14:29:54,263 [INFO] 训练完成，总损失: 1.3243
2025-04-25 14:29:54,263 [INFO] 保存迭代 64 的模型
2025-04-25 14:29:54,652 [INFO] Model saved to ./models/best.pt
2025-04-25 14:29:54,936 [INFO] Model saved to ./models/iteration_64.pt
2025-04-25 14:29:54,936 [INFO] 所有训练迭代完成
2025-04-25 14:29:54,936 [INFO] 开始迭代 65/300
2025-04-25 14:29:54,936 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 14:36:06,214 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 14:36:06,215 [INFO] 保存训练样本
2025-04-25 14:36:08,754 [INFO] 使用 101408 个样本训练神经网络
2025-04-25 14:36:08,754 [INFO] Training with 101408 examples
2025-04-25 14:36:08,755 [INFO] 总训练步数: 735, 每轮次批次数: 49
2025-04-25 14:36:09,152 [INFO] 循环学习率周期大小: 147 步
2025-04-25 14:36:28,303 [INFO] Epoch 1/15 - Policy Loss: 1.1573, Value Loss: 0.2137, Total Loss: 1.3710, LR: 0.001666
2025-04-25 14:36:47,482 [INFO] Epoch 2/15 - Policy Loss: 1.1467, Value Loss: 0.2084, Total Loss: 1.3550, LR: 0.003316
2025-04-25 14:37:06,630 [INFO] Epoch 3/15 - Policy Loss: 1.1423, Value Loss: 0.2069, Total Loss: 1.3491, LR: 0.004966
2025-04-25 14:37:25,779 [INFO] Epoch 4/15 - Policy Loss: 1.1399, Value Loss: 0.2058, Total Loss: 1.3458, LR: 0.003384
2025-04-25 14:37:44,936 [INFO] Epoch 5/15 - Policy Loss: 1.1371, Value Loss: 0.2050, Total Loss: 1.3421, LR: 0.001734
2025-04-25 14:38:04,102 [INFO] Epoch 6/15 - Policy Loss: 1.1343, Value Loss: 0.2043, Total Loss: 1.3386, LR: 0.000084
2025-04-25 14:38:23,249 [INFO] Epoch 7/15 - Policy Loss: 1.1310, Value Loss: 0.2030, Total Loss: 1.3340, LR: 0.001666
2025-04-25 14:38:42,444 [INFO] Epoch 8/15 - Policy Loss: 1.1292, Value Loss: 0.2017, Total Loss: 1.3309, LR: 0.003316
2025-04-25 14:39:01,614 [INFO] Epoch 9/15 - Policy Loss: 1.1281, Value Loss: 0.2010, Total Loss: 1.3291, LR: 0.004966
2025-04-25 14:39:20,786 [INFO] Epoch 10/15 - Policy Loss: 1.1281, Value Loss: 0.2007, Total Loss: 1.3288, LR: 0.003384
2025-04-25 14:39:39,971 [INFO] Epoch 11/15 - Policy Loss: 1.1274, Value Loss: 0.2006, Total Loss: 1.3281, LR: 0.001734
2025-04-25 14:39:59,146 [INFO] Epoch 12/15 - Policy Loss: 1.1264, Value Loss: 0.2001, Total Loss: 1.3266, LR: 0.000084
2025-04-25 14:40:18,674 [INFO] Epoch 13/15 - Policy Loss: 1.1249, Value Loss: 0.1996, Total Loss: 1.3245, LR: 0.001666
2025-04-25 14:40:37,857 [INFO] Epoch 14/15 - Policy Loss: 1.1238, Value Loss: 0.1991, Total Loss: 1.3229, LR: 0.003316
2025-04-25 14:40:57,040 [INFO] Epoch 15/15 - Policy Loss: 1.1227, Value Loss: 0.1989, Total Loss: 1.3216, LR: 0.004966
2025-04-25 14:40:57,054 [INFO] 训练完成，总损失: 1.3216
2025-04-25 14:40:57,054 [INFO] 保存迭代 65 的模型
2025-04-25 14:40:57,451 [INFO] Model saved to ./models/best.pt
2025-04-25 14:40:57,746 [INFO] Model saved to ./models/iteration_65.pt
2025-04-25 14:40:57,746 [INFO] 所有训练迭代完成
2025-04-25 14:40:57,746 [INFO] 开始迭代 66/300
2025-04-25 14:40:57,746 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 14:47:55,276 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 14:47:55,276 [INFO] 保存训练样本
2025-04-25 14:47:57,631 [INFO] 使用 102672 个样本训练神经网络
2025-04-25 14:47:57,631 [INFO] Training with 102672 examples
2025-04-25 14:47:57,632 [INFO] 总训练步数: 750, 每轮次批次数: 50
2025-04-25 14:47:57,923 [INFO] 循环学习率周期大小: 150 步
2025-04-25 14:48:17,357 [INFO] Epoch 1/15 - Policy Loss: 1.1550, Value Loss: 0.2307, Total Loss: 1.3857, LR: 0.001667
2025-04-25 14:48:36,691 [INFO] Epoch 2/15 - Policy Loss: 1.1458, Value Loss: 0.2266, Total Loss: 1.3724, LR: 0.003317
2025-04-25 14:48:56,011 [INFO] Epoch 3/15 - Policy Loss: 1.1411, Value Loss: 0.2248, Total Loss: 1.3659, LR: 0.004967
2025-04-25 14:49:15,341 [INFO] Epoch 4/15 - Policy Loss: 1.1384, Value Loss: 0.2238, Total Loss: 1.3622, LR: 0.003383
2025-04-25 14:49:34,665 [INFO] Epoch 5/15 - Policy Loss: 1.1353, Value Loss: 0.2217, Total Loss: 1.3570, LR: 0.001733
2025-04-25 14:49:53,992 [INFO] Epoch 6/15 - Policy Loss: 1.1321, Value Loss: 0.2204, Total Loss: 1.3526, LR: 0.000083
2025-04-25 14:50:13,334 [INFO] Epoch 7/15 - Policy Loss: 1.1291, Value Loss: 0.2189, Total Loss: 1.3479, LR: 0.001667
2025-04-25 14:50:32,686 [INFO] Epoch 8/15 - Policy Loss: 1.1266, Value Loss: 0.2173, Total Loss: 1.3439, LR: 0.003317
2025-04-25 14:50:52,049 [INFO] Epoch 9/15 - Policy Loss: 1.1253, Value Loss: 0.2167, Total Loss: 1.3419, LR: 0.004967
2025-04-25 14:51:11,394 [INFO] Epoch 10/15 - Policy Loss: 1.1243, Value Loss: 0.2162, Total Loss: 1.3406, LR: 0.003383
2025-04-25 14:51:30,735 [INFO] Epoch 11/15 - Policy Loss: 1.1234, Value Loss: 0.2157, Total Loss: 1.3391, LR: 0.001733
2025-04-25 14:51:50,061 [INFO] Epoch 12/15 - Policy Loss: 1.1218, Value Loss: 0.2152, Total Loss: 1.3371, LR: 0.000083
2025-04-25 14:52:09,662 [INFO] Epoch 13/15 - Policy Loss: 1.1195, Value Loss: 0.2148, Total Loss: 1.3343, LR: 0.001667
2025-04-25 14:52:28,953 [INFO] Epoch 14/15 - Policy Loss: 1.1180, Value Loss: 0.2142, Total Loss: 1.3323, LR: 0.003317
2025-04-25 14:52:48,251 [INFO] Epoch 15/15 - Policy Loss: 1.1177, Value Loss: 0.2139, Total Loss: 1.3316, LR: 0.004967
2025-04-25 14:52:48,264 [INFO] 训练完成，总损失: 1.3316
2025-04-25 14:52:48,264 [INFO] 保存迭代 66 的模型
2025-04-25 14:52:48,653 [INFO] Model saved to ./models/best.pt
2025-04-25 14:52:48,921 [INFO] Model saved to ./models/iteration_66.pt
2025-04-25 14:52:48,921 [INFO] 所有训练迭代完成
2025-04-25 14:52:48,921 [INFO] 开始迭代 67/300
2025-04-25 14:52:48,921 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 14:59:29,074 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 14:59:29,074 [INFO] 保存训练样本
2025-04-25 14:59:31,750 [INFO] 使用 103464 个样本训练神经网络
2025-04-25 14:59:31,750 [INFO] Training with 103464 examples
2025-04-25 14:59:31,751 [INFO] 总训练步数: 750, 每轮次批次数: 50
2025-04-25 14:59:32,051 [INFO] 循环学习率周期大小: 150 步
2025-04-25 14:59:51,645 [INFO] Epoch 1/15 - Policy Loss: 1.1389, Value Loss: 0.2330, Total Loss: 1.3719, LR: 0.001667
2025-04-25 15:00:11,321 [INFO] Epoch 2/15 - Policy Loss: 1.1356, Value Loss: 0.2281, Total Loss: 1.3637, LR: 0.003317
2025-04-25 15:00:30,890 [INFO] Epoch 3/15 - Policy Loss: 1.1300, Value Loss: 0.2258, Total Loss: 1.3559, LR: 0.004967
2025-04-25 15:00:50,448 [INFO] Epoch 4/15 - Policy Loss: 1.1273, Value Loss: 0.2240, Total Loss: 1.3513, LR: 0.003383
2025-04-25 15:01:09,883 [INFO] Epoch 5/15 - Policy Loss: 1.1244, Value Loss: 0.2220, Total Loss: 1.3464, LR: 0.001733
2025-04-25 15:01:29,252 [INFO] Epoch 6/15 - Policy Loss: 1.1217, Value Loss: 0.2206, Total Loss: 1.3423, LR: 0.000083
2025-04-25 15:01:48,667 [INFO] Epoch 7/15 - Policy Loss: 1.1183, Value Loss: 0.2195, Total Loss: 1.3378, LR: 0.001667
2025-04-25 15:02:08,229 [INFO] Epoch 8/15 - Policy Loss: 1.1165, Value Loss: 0.2185, Total Loss: 1.3350, LR: 0.003317
2025-04-25 15:02:27,878 [INFO] Epoch 9/15 - Policy Loss: 1.1157, Value Loss: 0.2180, Total Loss: 1.3337, LR: 0.004967
2025-04-25 15:02:47,603 [INFO] Epoch 10/15 - Policy Loss: 1.1152, Value Loss: 0.2177, Total Loss: 1.3329, LR: 0.003383
2025-04-25 15:03:07,219 [INFO] Epoch 11/15 - Policy Loss: 1.1144, Value Loss: 0.2171, Total Loss: 1.3315, LR: 0.001733
2025-04-25 15:03:27,058 [INFO] Epoch 12/15 - Policy Loss: 1.1128, Value Loss: 0.2164, Total Loss: 1.3291, LR: 0.000083
2025-04-25 15:03:46,595 [INFO] Epoch 13/15 - Policy Loss: 1.1110, Value Loss: 0.2161, Total Loss: 1.3271, LR: 0.001667
2025-04-25 15:04:06,078 [INFO] Epoch 14/15 - Policy Loss: 1.1099, Value Loss: 0.2153, Total Loss: 1.3252, LR: 0.003317
2025-04-25 15:04:25,543 [INFO] Epoch 15/15 - Policy Loss: 1.1090, Value Loss: 0.2149, Total Loss: 1.3239, LR: 0.004967
2025-04-25 15:04:25,559 [INFO] 训练完成，总损失: 1.3239
2025-04-25 15:04:25,559 [INFO] 保存迭代 67 的模型
2025-04-25 15:04:25,944 [INFO] Model saved to ./models/best.pt
2025-04-25 15:04:26,296 [INFO] Model saved to ./models/iteration_67.pt
2025-04-25 15:04:26,297 [INFO] 所有训练迭代完成
2025-04-25 15:04:26,297 [INFO] 开始迭代 68/300
2025-04-25 15:04:26,297 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 15:09:23,427 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 15:09:23,427 [INFO] 保存训练样本
2025-04-25 15:09:26,020 [INFO] 使用 102992 个样本训练神经网络
2025-04-25 15:09:26,020 [INFO] Training with 102992 examples
2025-04-25 15:09:26,020 [INFO] 总训练步数: 750, 每轮次批次数: 50
2025-04-25 15:09:26,308 [INFO] 循环学习率周期大小: 150 步
2025-04-25 15:09:45,874 [INFO] Epoch 1/15 - Policy Loss: 1.1231, Value Loss: 0.2319, Total Loss: 1.3550, LR: 0.001667
2025-04-25 15:10:05,380 [INFO] Epoch 2/15 - Policy Loss: 1.1166, Value Loss: 0.2284, Total Loss: 1.3450, LR: 0.003317
2025-04-25 15:10:24,871 [INFO] Epoch 3/15 - Policy Loss: 1.1134, Value Loss: 0.2251, Total Loss: 1.3386, LR: 0.004967
2025-04-25 15:10:44,406 [INFO] Epoch 4/15 - Policy Loss: 1.1109, Value Loss: 0.2237, Total Loss: 1.3346, LR: 0.003383
2025-04-25 15:11:03,908 [INFO] Epoch 5/15 - Policy Loss: 1.1079, Value Loss: 0.2223, Total Loss: 1.3301, LR: 0.001733
2025-04-25 15:11:23,444 [INFO] Epoch 6/15 - Policy Loss: 1.1058, Value Loss: 0.2205, Total Loss: 1.3263, LR: 0.000083
2025-04-25 15:11:42,982 [INFO] Epoch 7/15 - Policy Loss: 1.1033, Value Loss: 0.2194, Total Loss: 1.3227, LR: 0.001667
2025-04-25 15:12:02,506 [INFO] Epoch 8/15 - Policy Loss: 1.1011, Value Loss: 0.2187, Total Loss: 1.3198, LR: 0.003317
2025-04-25 15:12:22,059 [INFO] Epoch 9/15 - Policy Loss: 1.1002, Value Loss: 0.2181, Total Loss: 1.3183, LR: 0.004967
2025-04-25 15:12:41,627 [INFO] Epoch 10/15 - Policy Loss: 1.1006, Value Loss: 0.2179, Total Loss: 1.3185, LR: 0.003383
2025-04-25 15:13:01,173 [INFO] Epoch 11/15 - Policy Loss: 1.1000, Value Loss: 0.2174, Total Loss: 1.3174, LR: 0.001733
2025-04-25 15:13:21,017 [INFO] Epoch 12/15 - Policy Loss: 1.0994, Value Loss: 0.2173, Total Loss: 1.3167, LR: 0.000083
2025-04-25 15:13:40,583 [INFO] Epoch 13/15 - Policy Loss: 1.0982, Value Loss: 0.2172, Total Loss: 1.3154, LR: 0.001667
2025-04-25 15:14:00,151 [INFO] Epoch 14/15 - Policy Loss: 1.0978, Value Loss: 0.2168, Total Loss: 1.3147, LR: 0.003317
2025-04-25 15:14:19,717 [INFO] Epoch 15/15 - Policy Loss: 1.0971, Value Loss: 0.2165, Total Loss: 1.3136, LR: 0.004967
2025-04-25 15:14:19,733 [INFO] 训练完成，总损失: 1.3136
2025-04-25 15:14:19,733 [INFO] 保存迭代 68 的模型
2025-04-25 15:14:20,098 [INFO] Model saved to ./models/best.pt
2025-04-25 15:14:20,377 [INFO] Model saved to ./models/iteration_68.pt
2025-04-25 15:14:20,378 [INFO] 所有训练迭代完成
2025-04-25 15:14:20,378 [INFO] 开始迭代 69/300
2025-04-25 15:14:20,378 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 15:20:32,470 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 15:20:32,471 [INFO] 保存训练样本
2025-04-25 15:20:34,908 [INFO] 使用 104344 个样本训练神经网络
2025-04-25 15:20:34,909 [INFO] Training with 104344 examples
2025-04-25 15:20:34,909 [INFO] 总训练步数: 750, 每轮次批次数: 50
2025-04-25 15:20:35,173 [INFO] 循环学习率周期大小: 150 步
2025-04-25 15:20:54,761 [INFO] Epoch 1/15 - Policy Loss: 1.1328, Value Loss: 0.2316, Total Loss: 1.3644, LR: 0.001667
2025-04-25 15:21:14,384 [INFO] Epoch 2/15 - Policy Loss: 1.1240, Value Loss: 0.2261, Total Loss: 1.3501, LR: 0.003317
2025-04-25 15:21:33,886 [INFO] Epoch 3/15 - Policy Loss: 1.1185, Value Loss: 0.2230, Total Loss: 1.3415, LR: 0.004967
2025-04-25 15:21:53,452 [INFO] Epoch 4/15 - Policy Loss: 1.1160, Value Loss: 0.2217, Total Loss: 1.3377, LR: 0.003383
2025-04-25 15:22:13,045 [INFO] Epoch 5/15 - Policy Loss: 1.1110, Value Loss: 0.2211, Total Loss: 1.3321, LR: 0.001733
2025-04-25 15:22:32,565 [INFO] Epoch 6/15 - Policy Loss: 1.1064, Value Loss: 0.2196, Total Loss: 1.3260, LR: 0.000083
2025-04-25 15:22:52,298 [INFO] Epoch 7/15 - Policy Loss: 1.1039, Value Loss: 0.2190, Total Loss: 1.3229, LR: 0.001667
2025-04-25 15:23:11,890 [INFO] Epoch 8/15 - Policy Loss: 1.1017, Value Loss: 0.2186, Total Loss: 1.3203, LR: 0.003317
2025-04-25 15:23:31,487 [INFO] Epoch 9/15 - Policy Loss: 1.0996, Value Loss: 0.2183, Total Loss: 1.3179, LR: 0.004967
2025-04-25 15:23:51,173 [INFO] Epoch 10/15 - Policy Loss: 1.0982, Value Loss: 0.2179, Total Loss: 1.3162, LR: 0.003383
2025-04-25 15:24:11,031 [INFO] Epoch 11/15 - Policy Loss: 1.0975, Value Loss: 0.2174, Total Loss: 1.3149, LR: 0.001733
2025-04-25 15:24:30,642 [INFO] Epoch 12/15 - Policy Loss: 1.0958, Value Loss: 0.2169, Total Loss: 1.3127, LR: 0.000083
2025-04-25 15:24:50,301 [INFO] Epoch 13/15 - Policy Loss: 1.0948, Value Loss: 0.2166, Total Loss: 1.3115, LR: 0.001667
2025-04-25 15:25:09,927 [INFO] Epoch 14/15 - Policy Loss: 1.0933, Value Loss: 0.2164, Total Loss: 1.3097, LR: 0.003317
2025-04-25 15:25:29,451 [INFO] Epoch 15/15 - Policy Loss: 1.0927, Value Loss: 0.2162, Total Loss: 1.3089, LR: 0.004967
2025-04-25 15:25:29,464 [INFO] 训练完成，总损失: 1.3089
2025-04-25 15:25:29,465 [INFO] 保存迭代 69 的模型
2025-04-25 15:25:30,030 [INFO] Model saved to ./models/best.pt
2025-04-25 15:25:30,438 [INFO] Model saved to ./models/iteration_69.pt
2025-04-25 15:25:30,438 [INFO] 所有训练迭代完成
2025-04-25 15:25:30,438 [INFO] 开始迭代 70/300
2025-04-25 15:25:30,438 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 15:31:10,216 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 15:31:10,216 [INFO] 保存训练样本
2025-04-25 15:31:12,982 [INFO] 使用 105216 个样本训练神经网络
2025-04-25 15:31:12,983 [INFO] Training with 105216 examples
2025-04-25 15:31:12,983 [INFO] 总训练步数: 765, 每轮次批次数: 51
2025-04-25 15:31:13,019 [INFO] 循环学习率周期大小: 153 步
2025-04-25 15:31:32,932 [INFO] Epoch 1/15 - Policy Loss: 1.1046, Value Loss: 0.2269, Total Loss: 1.3316, LR: 0.001668
2025-04-25 15:31:52,909 [INFO] Epoch 2/15 - Policy Loss: 1.0984, Value Loss: 0.2241, Total Loss: 1.3225, LR: 0.003318
2025-04-25 15:32:12,858 [INFO] Epoch 3/15 - Policy Loss: 1.0949, Value Loss: 0.2222, Total Loss: 1.3171, LR: 0.004968
2025-04-25 15:32:32,826 [INFO] Epoch 4/15 - Policy Loss: 1.0952, Value Loss: 0.2211, Total Loss: 1.3164, LR: 0.003382
2025-04-25 15:32:52,777 [INFO] Epoch 5/15 - Policy Loss: 1.0932, Value Loss: 0.2203, Total Loss: 1.3136, LR: 0.001732
2025-04-25 15:33:12,664 [INFO] Epoch 6/15 - Policy Loss: 1.0905, Value Loss: 0.2194, Total Loss: 1.3099, LR: 0.000082
2025-04-25 15:33:32,368 [INFO] Epoch 7/15 - Policy Loss: 1.0887, Value Loss: 0.2186, Total Loss: 1.3073, LR: 0.001668
2025-04-25 15:33:52,074 [INFO] Epoch 8/15 - Policy Loss: 1.0871, Value Loss: 0.2181, Total Loss: 1.3052, LR: 0.003318
2025-04-25 15:34:11,825 [INFO] Epoch 9/15 - Policy Loss: 1.0857, Value Loss: 0.2177, Total Loss: 1.3035, LR: 0.004968
2025-04-25 15:34:31,835 [INFO] Epoch 10/15 - Policy Loss: 1.0862, Value Loss: 0.2177, Total Loss: 1.3039, LR: 0.003382
2025-04-25 15:34:51,583 [INFO] Epoch 11/15 - Policy Loss: 1.0850, Value Loss: 0.2174, Total Loss: 1.3024, LR: 0.001732
2025-04-25 15:35:11,344 [INFO] Epoch 12/15 - Policy Loss: 1.0843, Value Loss: 0.2173, Total Loss: 1.3016, LR: 0.000082
2025-04-25 15:35:31,091 [INFO] Epoch 13/15 - Policy Loss: 1.0823, Value Loss: 0.2169, Total Loss: 1.2992, LR: 0.001668
2025-04-25 15:35:50,847 [INFO] Epoch 14/15 - Policy Loss: 1.0811, Value Loss: 0.2164, Total Loss: 1.2974, LR: 0.003318
2025-04-25 15:36:10,601 [INFO] Epoch 15/15 - Policy Loss: 1.0802, Value Loss: 0.2163, Total Loss: 1.2964, LR: 0.004968
2025-04-25 15:36:10,615 [INFO] 训练完成，总损失: 1.2964
2025-04-25 15:36:10,615 [INFO] 保存迭代 70 的模型
2025-04-25 15:36:11,065 [INFO] Model saved to ./models/best.pt
2025-04-25 15:36:11,366 [INFO] Model saved to ./models/iteration_70.pt
2025-04-25 15:36:11,366 [INFO] 所有训练迭代完成
2025-04-25 15:36:11,366 [INFO] 开始迭代 71/300
2025-04-25 15:36:11,366 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 15:41:02,002 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 15:41:02,002 [INFO] 保存训练样本
2025-04-25 15:41:04,614 [INFO] 使用 104728 个样本训练神经网络
2025-04-25 15:41:04,614 [INFO] Training with 104728 examples
2025-04-25 15:41:04,614 [INFO] 总训练步数: 765, 每轮次批次数: 51
2025-04-25 15:41:04,648 [INFO] 循环学习率周期大小: 153 步
2025-04-25 15:41:24,480 [INFO] Epoch 1/15 - Policy Loss: 1.1002, Value Loss: 0.2287, Total Loss: 1.3289, LR: 0.001668
2025-04-25 15:41:44,253 [INFO] Epoch 2/15 - Policy Loss: 1.0970, Value Loss: 0.2271, Total Loss: 1.3241, LR: 0.003318
2025-04-25 15:42:04,135 [INFO] Epoch 3/15 - Policy Loss: 1.0945, Value Loss: 0.2265, Total Loss: 1.3210, LR: 0.004968
2025-04-25 15:42:23,892 [INFO] Epoch 4/15 - Policy Loss: 1.0916, Value Loss: 0.2255, Total Loss: 1.3171, LR: 0.003382
2025-04-25 15:42:43,677 [INFO] Epoch 5/15 - Policy Loss: 1.0888, Value Loss: 0.2242, Total Loss: 1.3129, LR: 0.001732
2025-04-25 15:43:03,448 [INFO] Epoch 6/15 - Policy Loss: 1.0866, Value Loss: 0.2228, Total Loss: 1.3094, LR: 0.000082
2025-04-25 15:43:23,344 [INFO] Epoch 7/15 - Policy Loss: 1.0844, Value Loss: 0.2222, Total Loss: 1.3065, LR: 0.001668
2025-04-25 15:43:43,106 [INFO] Epoch 8/15 - Policy Loss: 1.0833, Value Loss: 0.2215, Total Loss: 1.3048, LR: 0.003318
2025-04-25 15:44:03,131 [INFO] Epoch 9/15 - Policy Loss: 1.0824, Value Loss: 0.2213, Total Loss: 1.3037, LR: 0.004968
2025-04-25 15:44:22,851 [INFO] Epoch 10/15 - Policy Loss: 1.0819, Value Loss: 0.2210, Total Loss: 1.3030, LR: 0.003382
2025-04-25 15:44:42,561 [INFO] Epoch 11/15 - Policy Loss: 1.0814, Value Loss: 0.2211, Total Loss: 1.3025, LR: 0.001732
2025-04-25 15:45:02,269 [INFO] Epoch 12/15 - Policy Loss: 1.0797, Value Loss: 0.2205, Total Loss: 1.3002, LR: 0.000082
2025-04-25 15:45:22,038 [INFO] Epoch 13/15 - Policy Loss: 1.0790, Value Loss: 0.2202, Total Loss: 1.2993, LR: 0.001668
2025-04-25 15:45:41,779 [INFO] Epoch 14/15 - Policy Loss: 1.0783, Value Loss: 0.2200, Total Loss: 1.2983, LR: 0.003318
2025-04-25 15:46:01,551 [INFO] Epoch 15/15 - Policy Loss: 1.0778, Value Loss: 0.2199, Total Loss: 1.2978, LR: 0.004968
2025-04-25 15:46:01,564 [INFO] 训练完成，总损失: 1.2978
2025-04-25 15:46:01,564 [INFO] 保存迭代 71 的模型
2025-04-25 15:46:01,982 [INFO] Model saved to ./models/best.pt
2025-04-25 15:46:02,257 [INFO] Model saved to ./models/iteration_71.pt
2025-04-25 15:46:02,258 [INFO] 所有训练迭代完成
2025-04-25 15:46:02,258 [INFO] 开始迭代 72/300
2025-04-25 15:46:02,258 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 15:51:35,819 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 15:51:35,819 [INFO] 保存训练样本
2025-04-25 15:51:38,469 [INFO] 使用 105224 个样本训练神经网络
2025-04-25 15:51:38,470 [INFO] Training with 105224 examples
2025-04-25 15:51:38,471 [INFO] 总训练步数: 765, 每轮次批次数: 51
2025-04-25 15:51:38,505 [INFO] 循环学习率周期大小: 153 步
2025-04-25 15:51:58,238 [INFO] Epoch 1/15 - Policy Loss: 1.1084, Value Loss: 0.2396, Total Loss: 1.3480, LR: 0.001668
2025-04-25 15:52:17,967 [INFO] Epoch 2/15 - Policy Loss: 1.0956, Value Loss: 0.2379, Total Loss: 1.3335, LR: 0.003318
2025-04-25 15:52:37,691 [INFO] Epoch 3/15 - Policy Loss: 1.0930, Value Loss: 0.2350, Total Loss: 1.3280, LR: 0.004968
2025-04-25 15:52:57,430 [INFO] Epoch 4/15 - Policy Loss: 1.0920, Value Loss: 0.2339, Total Loss: 1.3259, LR: 0.003382
2025-04-25 15:53:17,197 [INFO] Epoch 5/15 - Policy Loss: 1.0892, Value Loss: 0.2324, Total Loss: 1.3216, LR: 0.001732
2025-04-25 15:53:36,955 [INFO] Epoch 6/15 - Policy Loss: 1.0855, Value Loss: 0.2308, Total Loss: 1.3163, LR: 0.000082
2025-04-25 15:53:56,701 [INFO] Epoch 7/15 - Policy Loss: 1.0829, Value Loss: 0.2299, Total Loss: 1.3128, LR: 0.001668
2025-04-25 15:54:16,444 [INFO] Epoch 8/15 - Policy Loss: 1.0815, Value Loss: 0.2290, Total Loss: 1.3104, LR: 0.003318
2025-04-25 15:54:36,425 [INFO] Epoch 9/15 - Policy Loss: 1.0806, Value Loss: 0.2287, Total Loss: 1.3093, LR: 0.004968
2025-04-25 15:54:56,167 [INFO] Epoch 10/15 - Policy Loss: 1.0804, Value Loss: 0.2280, Total Loss: 1.3084, LR: 0.003382
2025-04-25 15:55:15,905 [INFO] Epoch 11/15 - Policy Loss: 1.0800, Value Loss: 0.2274, Total Loss: 1.3074, LR: 0.001732
2025-04-25 15:55:35,635 [INFO] Epoch 12/15 - Policy Loss: 1.0790, Value Loss: 0.2269, Total Loss: 1.3059, LR: 0.000082
2025-04-25 15:55:55,373 [INFO] Epoch 13/15 - Policy Loss: 1.0775, Value Loss: 0.2263, Total Loss: 1.3038, LR: 0.001668
2025-04-25 15:56:15,126 [INFO] Epoch 14/15 - Policy Loss: 1.0768, Value Loss: 0.2258, Total Loss: 1.3027, LR: 0.003318
2025-04-25 15:56:34,898 [INFO] Epoch 15/15 - Policy Loss: 1.0761, Value Loss: 0.2254, Total Loss: 1.3015, LR: 0.004968
2025-04-25 15:56:34,911 [INFO] 训练完成，总损失: 1.3015
2025-04-25 15:56:34,912 [INFO] 保存迭代 72 的模型
2025-04-25 15:56:35,333 [INFO] Model saved to ./models/best.pt
2025-04-25 15:56:35,617 [INFO] Model saved to ./models/iteration_72.pt
2025-04-25 15:56:35,618 [INFO] 所有训练迭代完成
2025-04-25 15:56:35,618 [INFO] 开始迭代 73/300
2025-04-25 15:56:35,618 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 16:02:53,111 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 16:02:53,112 [INFO] 保存训练样本
2025-04-25 16:02:55,309 [INFO] 使用 106096 个样本训练神经网络
2025-04-25 16:02:55,309 [INFO] Training with 106096 examples
2025-04-25 16:02:55,310 [INFO] 总训练步数: 765, 每轮次批次数: 51
2025-04-25 16:02:55,338 [INFO] 循环学习率周期大小: 153 步
2025-04-25 16:03:15,070 [INFO] Epoch 1/15 - Policy Loss: 1.1135, Value Loss: 0.2355, Total Loss: 1.3490, LR: 0.001668
2025-04-25 16:03:34,792 [INFO] Epoch 2/15 - Policy Loss: 1.1045, Value Loss: 0.2306, Total Loss: 1.3350, LR: 0.003318
2025-04-25 16:03:54,546 [INFO] Epoch 3/15 - Policy Loss: 1.0993, Value Loss: 0.2283, Total Loss: 1.3275, LR: 0.004968
2025-04-25 16:04:14,292 [INFO] Epoch 4/15 - Policy Loss: 1.0947, Value Loss: 0.2270, Total Loss: 1.3216, LR: 0.003382
2025-04-25 16:04:34,026 [INFO] Epoch 5/15 - Policy Loss: 1.0904, Value Loss: 0.2261, Total Loss: 1.3166, LR: 0.001732
2025-04-25 16:04:53,764 [INFO] Epoch 6/15 - Policy Loss: 1.0870, Value Loss: 0.2251, Total Loss: 1.3122, LR: 0.000082
2025-04-25 16:05:13,504 [INFO] Epoch 7/15 - Policy Loss: 1.0839, Value Loss: 0.2239, Total Loss: 1.3079, LR: 0.001668
2025-04-25 16:05:33,476 [INFO] Epoch 8/15 - Policy Loss: 1.0815, Value Loss: 0.2231, Total Loss: 1.3046, LR: 0.003318
2025-04-25 16:05:53,200 [INFO] Epoch 9/15 - Policy Loss: 1.0799, Value Loss: 0.2225, Total Loss: 1.3024, LR: 0.004968
2025-04-25 16:06:12,935 [INFO] Epoch 10/15 - Policy Loss: 1.0787, Value Loss: 0.2225, Total Loss: 1.3012, LR: 0.003382
2025-04-25 16:06:32,668 [INFO] Epoch 11/15 - Policy Loss: 1.0778, Value Loss: 0.2225, Total Loss: 1.3003, LR: 0.001732
2025-04-25 16:06:52,412 [INFO] Epoch 12/15 - Policy Loss: 1.0770, Value Loss: 0.2225, Total Loss: 1.2995, LR: 0.000082
2025-04-25 16:07:12,133 [INFO] Epoch 13/15 - Policy Loss: 1.0758, Value Loss: 0.2222, Total Loss: 1.2981, LR: 0.001668
2025-04-25 16:07:31,869 [INFO] Epoch 14/15 - Policy Loss: 1.0746, Value Loss: 0.2218, Total Loss: 1.2964, LR: 0.003318
2025-04-25 16:07:51,640 [INFO] Epoch 15/15 - Policy Loss: 1.0738, Value Loss: 0.2215, Total Loss: 1.2953, LR: 0.004968
2025-04-25 16:07:51,653 [INFO] 训练完成，总损失: 1.2953
2025-04-25 16:07:51,654 [INFO] 保存迭代 73 的模型
2025-04-25 16:07:52,082 [INFO] Model saved to ./models/best.pt
2025-04-25 16:07:52,369 [INFO] Model saved to ./models/iteration_73.pt
2025-04-25 16:07:52,369 [INFO] 所有训练迭代完成
2025-04-25 16:07:52,369 [INFO] 开始迭代 74/300
2025-04-25 16:07:52,369 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 16:13:35,089 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 16:13:35,089 [INFO] 保存训练样本
2025-04-25 16:13:38,220 [INFO] 使用 106520 个样本训练神经网络
2025-04-25 16:13:38,220 [INFO] Training with 106520 examples
2025-04-25 16:13:38,221 [INFO] 总训练步数: 780, 每轮次批次数: 52
2025-04-25 16:13:38,265 [INFO] 循环学习率周期大小: 156 步
2025-04-25 16:13:58,662 [INFO] Epoch 1/15 - Policy Loss: 1.0916, Value Loss: 0.2271, Total Loss: 1.3187, LR: 0.001668
2025-04-25 16:14:19,064 [INFO] Epoch 2/15 - Policy Loss: 1.0889, Value Loss: 0.2245, Total Loss: 1.3134, LR: 0.003318
2025-04-25 16:14:39,468 [INFO] Epoch 3/15 - Policy Loss: 1.0831, Value Loss: 0.2228, Total Loss: 1.3059, LR: 0.004968
2025-04-25 16:14:59,880 [INFO] Epoch 4/15 - Policy Loss: 1.0835, Value Loss: 0.2232, Total Loss: 1.3067, LR: 0.003382
2025-04-25 16:15:20,224 [INFO] Epoch 5/15 - Policy Loss: 1.0812, Value Loss: 0.2221, Total Loss: 1.3034, LR: 0.001732
2025-04-25 16:15:40,885 [INFO] Epoch 6/15 - Policy Loss: 1.0773, Value Loss: 0.2211, Total Loss: 1.2983, LR: 0.000082
2025-04-25 16:16:01,116 [INFO] Epoch 7/15 - Policy Loss: 1.0742, Value Loss: 0.2203, Total Loss: 1.2945, LR: 0.001668
2025-04-25 16:16:21,317 [INFO] Epoch 8/15 - Policy Loss: 1.0721, Value Loss: 0.2192, Total Loss: 1.2913, LR: 0.003318
2025-04-25 16:16:41,518 [INFO] Epoch 9/15 - Policy Loss: 1.0705, Value Loss: 0.2187, Total Loss: 1.2892, LR: 0.004968
2025-04-25 16:17:01,731 [INFO] Epoch 10/15 - Policy Loss: 1.0709, Value Loss: 0.2187, Total Loss: 1.2895, LR: 0.003382
2025-04-25 16:17:21,934 [INFO] Epoch 11/15 - Policy Loss: 1.0696, Value Loss: 0.2182, Total Loss: 1.2878, LR: 0.001732
2025-04-25 16:17:42,079 [INFO] Epoch 12/15 - Policy Loss: 1.0687, Value Loss: 0.2176, Total Loss: 1.2863, LR: 0.000082
2025-04-25 16:18:02,463 [INFO] Epoch 13/15 - Policy Loss: 1.0673, Value Loss: 0.2173, Total Loss: 1.2846, LR: 0.001668
2025-04-25 16:18:22,855 [INFO] Epoch 14/15 - Policy Loss: 1.0669, Value Loss: 0.2170, Total Loss: 1.2839, LR: 0.003318
2025-04-25 16:18:43,213 [INFO] Epoch 15/15 - Policy Loss: 1.0664, Value Loss: 0.2168, Total Loss: 1.2832, LR: 0.004968
2025-04-25 16:18:43,228 [INFO] 训练完成，总损失: 1.2832
2025-04-25 16:18:43,228 [INFO] 保存迭代 74 的模型
2025-04-25 16:18:43,616 [INFO] Model saved to ./models/best.pt
2025-04-25 16:18:43,933 [INFO] Model saved to ./models/iteration_74.pt
2025-04-25 16:18:43,933 [INFO] 所有训练迭代完成
2025-04-25 16:18:43,933 [INFO] 开始迭代 75/300
2025-04-25 16:18:43,933 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 16:24:58,126 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 16:24:58,126 [INFO] 保存训练样本
2025-04-25 16:25:01,130 [INFO] 使用 106784 个样本训练神经网络
2025-04-25 16:25:01,131 [INFO] Training with 106784 examples
2025-04-25 16:25:01,131 [INFO] 总训练步数: 780, 每轮次批次数: 52
2025-04-25 16:25:01,169 [INFO] 循环学习率周期大小: 156 步
2025-04-25 16:25:21,491 [INFO] Epoch 1/15 - Policy Loss: 1.0973, Value Loss: 0.2401, Total Loss: 1.3374, LR: 0.001668
2025-04-25 16:25:42,060 [INFO] Epoch 2/15 - Policy Loss: 1.0902, Value Loss: 0.2348, Total Loss: 1.3249, LR: 0.003318
2025-04-25 16:26:02,246 [INFO] Epoch 3/15 - Policy Loss: 1.0856, Value Loss: 0.2318, Total Loss: 1.3174, LR: 0.004968
2025-04-25 16:26:22,397 [INFO] Epoch 4/15 - Policy Loss: 1.0845, Value Loss: 0.2316, Total Loss: 1.3160, LR: 0.003382
2025-04-25 16:26:42,738 [INFO] Epoch 5/15 - Policy Loss: 1.0802, Value Loss: 0.2299, Total Loss: 1.3101, LR: 0.001732
2025-04-25 16:27:02,908 [INFO] Epoch 6/15 - Policy Loss: 1.0767, Value Loss: 0.2289, Total Loss: 1.3056, LR: 0.000082
2025-04-25 16:27:23,042 [INFO] Epoch 7/15 - Policy Loss: 1.0735, Value Loss: 0.2278, Total Loss: 1.3013, LR: 0.001668
2025-04-25 16:27:43,206 [INFO] Epoch 8/15 - Policy Loss: 1.0715, Value Loss: 0.2269, Total Loss: 1.2984, LR: 0.003318
2025-04-25 16:28:03,367 [INFO] Epoch 9/15 - Policy Loss: 1.0697, Value Loss: 0.2264, Total Loss: 1.2961, LR: 0.004968
2025-04-25 16:28:23,522 [INFO] Epoch 10/15 - Policy Loss: 1.0684, Value Loss: 0.2257, Total Loss: 1.2941, LR: 0.003382
2025-04-25 16:28:43,687 [INFO] Epoch 11/15 - Policy Loss: 1.0667, Value Loss: 0.2250, Total Loss: 1.2918, LR: 0.001732
2025-04-25 16:29:03,825 [INFO] Epoch 12/15 - Policy Loss: 1.0653, Value Loss: 0.2244, Total Loss: 1.2898, LR: 0.000082
2025-04-25 16:29:23,975 [INFO] Epoch 13/15 - Policy Loss: 1.0638, Value Loss: 0.2239, Total Loss: 1.2877, LR: 0.001668
2025-04-25 16:29:44,132 [INFO] Epoch 14/15 - Policy Loss: 1.0626, Value Loss: 0.2236, Total Loss: 1.2862, LR: 0.003318
2025-04-25 16:30:04,299 [INFO] Epoch 15/15 - Policy Loss: 1.0622, Value Loss: 0.2232, Total Loss: 1.2854, LR: 0.004968
2025-04-25 16:30:04,312 [INFO] 训练完成，总损失: 1.2854
2025-04-25 16:30:04,313 [INFO] 保存迭代 75 的模型
2025-04-25 16:30:04,664 [INFO] Model saved to ./models/best.pt
2025-04-25 16:30:04,920 [INFO] Model saved to ./models/iteration_75.pt
2025-04-25 16:30:04,920 [INFO] 所有训练迭代完成
2025-04-25 16:30:04,920 [INFO] 开始迭代 76/300
2025-04-25 16:30:04,920 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 16:35:48,699 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 16:35:48,699 [INFO] 保存训练样本
2025-04-25 16:35:51,486 [INFO] 使用 106696 个样本训练神经网络
2025-04-25 16:35:51,487 [INFO] Training with 106696 examples
2025-04-25 16:35:51,487 [INFO] 总训练步数: 780, 每轮次批次数: 52
2025-04-25 16:35:51,771 [INFO] 循环学习率周期大小: 156 步
2025-04-25 16:36:12,043 [INFO] Epoch 1/15 - Policy Loss: 1.0814, Value Loss: 0.2351, Total Loss: 1.3166, LR: 0.001668
2025-04-25 16:36:32,335 [INFO] Epoch 2/15 - Policy Loss: 1.0748, Value Loss: 0.2316, Total Loss: 1.3065, LR: 0.003318
2025-04-25 16:36:52,670 [INFO] Epoch 3/15 - Policy Loss: 1.0711, Value Loss: 0.2298, Total Loss: 1.3008, LR: 0.004968
2025-04-25 16:37:12,927 [INFO] Epoch 4/15 - Policy Loss: 1.0694, Value Loss: 0.2281, Total Loss: 1.2975, LR: 0.003382
2025-04-25 16:37:33,261 [INFO] Epoch 5/15 - Policy Loss: 1.0662, Value Loss: 0.2274, Total Loss: 1.2936, LR: 0.001732
2025-04-25 16:37:53,592 [INFO] Epoch 6/15 - Policy Loss: 1.0643, Value Loss: 0.2266, Total Loss: 1.2909, LR: 0.000082
2025-04-25 16:38:13,937 [INFO] Epoch 7/15 - Policy Loss: 1.0629, Value Loss: 0.2256, Total Loss: 1.2885, LR: 0.001668
2025-04-25 16:38:34,229 [INFO] Epoch 8/15 - Policy Loss: 1.0612, Value Loss: 0.2248, Total Loss: 1.2860, LR: 0.003318
2025-04-25 16:38:54,577 [INFO] Epoch 9/15 - Policy Loss: 1.0604, Value Loss: 0.2242, Total Loss: 1.2846, LR: 0.004968
2025-04-25 16:39:14,913 [INFO] Epoch 10/15 - Policy Loss: 1.0603, Value Loss: 0.2238, Total Loss: 1.2841, LR: 0.003382
2025-04-25 16:39:35,273 [INFO] Epoch 11/15 - Policy Loss: 1.0594, Value Loss: 0.2236, Total Loss: 1.2830, LR: 0.001732
2025-04-25 16:39:55,584 [INFO] Epoch 12/15 - Policy Loss: 1.0584, Value Loss: 0.2230, Total Loss: 1.2814, LR: 0.000082
2025-04-25 16:40:15,927 [INFO] Epoch 13/15 - Policy Loss: 1.0575, Value Loss: 0.2229, Total Loss: 1.2803, LR: 0.001668
2025-04-25 16:40:36,273 [INFO] Epoch 14/15 - Policy Loss: 1.0569, Value Loss: 0.2224, Total Loss: 1.2793, LR: 0.003318
2025-04-25 16:40:56,643 [INFO] Epoch 15/15 - Policy Loss: 1.0565, Value Loss: 0.2224, Total Loss: 1.2789, LR: 0.004968
2025-04-25 16:40:56,664 [INFO] 训练完成，总损失: 1.2789
2025-04-25 16:40:56,664 [INFO] 保存迭代 76 的模型
2025-04-25 16:40:57,140 [INFO] Model saved to ./models/best.pt
2025-04-25 16:40:57,520 [INFO] Model saved to ./models/iteration_76.pt
2025-04-25 16:40:57,521 [INFO] 所有训练迭代完成
2025-04-25 16:40:57,521 [INFO] 开始迭代 77/300
2025-04-25 16:40:57,521 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 16:48:24,616 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 16:48:24,617 [INFO] 保存训练样本
2025-04-25 16:48:28,052 [INFO] 使用 107936 个样本训练神经网络
2025-04-25 16:48:28,052 [INFO] Training with 107936 examples
2025-04-25 16:48:28,052 [INFO] 总训练步数: 780, 每轮次批次数: 52
2025-04-25 16:48:28,413 [INFO] 循环学习率周期大小: 156 步
2025-04-25 16:48:48,823 [INFO] Epoch 1/15 - Policy Loss: 1.1016, Value Loss: 0.2403, Total Loss: 1.3419, LR: 0.001668
2025-04-25 16:49:09,160 [INFO] Epoch 2/15 - Policy Loss: 1.0919, Value Loss: 0.2353, Total Loss: 1.3273, LR: 0.003318
2025-04-25 16:49:29,513 [INFO] Epoch 3/15 - Policy Loss: 1.0871, Value Loss: 0.2326, Total Loss: 1.3197, LR: 0.004968
2025-04-25 16:49:49,833 [INFO] Epoch 4/15 - Policy Loss: 1.0831, Value Loss: 0.2307, Total Loss: 1.3139, LR: 0.003382
2025-04-25 16:50:10,182 [INFO] Epoch 5/15 - Policy Loss: 1.0798, Value Loss: 0.2288, Total Loss: 1.3086, LR: 0.001732
2025-04-25 16:50:30,534 [INFO] Epoch 6/15 - Policy Loss: 1.0756, Value Loss: 0.2278, Total Loss: 1.3034, LR: 0.000082
2025-04-25 16:50:50,872 [INFO] Epoch 7/15 - Policy Loss: 1.0722, Value Loss: 0.2263, Total Loss: 1.2985, LR: 0.001668
2025-04-25 16:51:11,197 [INFO] Epoch 8/15 - Policy Loss: 1.0694, Value Loss: 0.2257, Total Loss: 1.2952, LR: 0.003318
2025-04-25 16:51:31,526 [INFO] Epoch 9/15 - Policy Loss: 1.0686, Value Loss: 0.2255, Total Loss: 1.2941, LR: 0.004968
2025-04-25 16:51:51,894 [INFO] Epoch 10/15 - Policy Loss: 1.0677, Value Loss: 0.2250, Total Loss: 1.2927, LR: 0.003382
2025-04-25 16:52:12,204 [INFO] Epoch 11/15 - Policy Loss: 1.0665, Value Loss: 0.2245, Total Loss: 1.2911, LR: 0.001732
2025-04-25 16:52:32,421 [INFO] Epoch 12/15 - Policy Loss: 1.0652, Value Loss: 0.2241, Total Loss: 1.2892, LR: 0.000082
2025-04-25 16:52:52,696 [INFO] Epoch 13/15 - Policy Loss: 1.0636, Value Loss: 0.2235, Total Loss: 1.2871, LR: 0.001668
2025-04-25 16:53:12,980 [INFO] Epoch 14/15 - Policy Loss: 1.0631, Value Loss: 0.2236, Total Loss: 1.2867, LR: 0.003318
2025-04-25 16:53:33,298 [INFO] Epoch 15/15 - Policy Loss: 1.0619, Value Loss: 0.2235, Total Loss: 1.2854, LR: 0.004968
2025-04-25 16:53:33,314 [INFO] 训练完成，总损失: 1.2854
2025-04-25 16:53:33,314 [INFO] 保存迭代 77 的模型
2025-04-25 16:53:33,770 [INFO] Model saved to ./models/best.pt
2025-04-25 16:53:34,080 [INFO] Model saved to ./models/iteration_77.pt
2025-04-25 16:53:34,080 [INFO] 所有训练迭代完成
2025-04-25 16:53:34,080 [INFO] 开始迭代 78/300
2025-04-25 16:53:34,080 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 17:00:10,606 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 17:00:10,607 [INFO] 保存训练样本
2025-04-25 17:00:13,147 [INFO] 使用 109112 个样本训练神经网络
2025-04-25 17:00:13,148 [INFO] Training with 109112 examples
2025-04-25 17:00:13,148 [INFO] 总训练步数: 795, 每轮次批次数: 53
2025-04-25 17:00:13,464 [INFO] 循环学习率周期大小: 159 步
2025-04-25 17:00:34,011 [INFO] Epoch 1/15 - Policy Loss: 1.1065, Value Loss: 0.2424, Total Loss: 1.3490, LR: 0.001669
2025-04-25 17:00:54,569 [INFO] Epoch 2/15 - Policy Loss: 1.0943, Value Loss: 0.2390, Total Loss: 1.3332, LR: 0.003319
2025-04-25 17:01:15,069 [INFO] Epoch 3/15 - Policy Loss: 1.0871, Value Loss: 0.2353, Total Loss: 1.3224, LR: 0.004969
2025-04-25 17:01:35,595 [INFO] Epoch 4/15 - Policy Loss: 1.0833, Value Loss: 0.2328, Total Loss: 1.3161, LR: 0.003381
2025-04-25 17:01:56,147 [INFO] Epoch 5/15 - Policy Loss: 1.0794, Value Loss: 0.2307, Total Loss: 1.3101, LR: 0.001731
2025-04-25 17:02:16,674 [INFO] Epoch 6/15 - Policy Loss: 1.0748, Value Loss: 0.2290, Total Loss: 1.3038, LR: 0.000081
2025-04-25 17:02:37,284 [INFO] Epoch 7/15 - Policy Loss: 1.0711, Value Loss: 0.2271, Total Loss: 1.2982, LR: 0.001669
2025-04-25 17:02:58,075 [INFO] Epoch 8/15 - Policy Loss: 1.0692, Value Loss: 0.2266, Total Loss: 1.2958, LR: 0.003319
2025-04-25 17:03:18,746 [INFO] Epoch 9/15 - Policy Loss: 1.0672, Value Loss: 0.2257, Total Loss: 1.2929, LR: 0.004969
2025-04-25 17:03:39,433 [INFO] Epoch 10/15 - Policy Loss: 1.0667, Value Loss: 0.2253, Total Loss: 1.2920, LR: 0.003381
2025-04-25 17:04:00,130 [INFO] Epoch 11/15 - Policy Loss: 1.0655, Value Loss: 0.2249, Total Loss: 1.2905, LR: 0.001731
2025-04-25 17:04:20,861 [INFO] Epoch 12/15 - Policy Loss: 1.0641, Value Loss: 0.2242, Total Loss: 1.2882, LR: 0.000081
2025-04-25 17:04:41,627 [INFO] Epoch 13/15 - Policy Loss: 1.0628, Value Loss: 0.2236, Total Loss: 1.2864, LR: 0.001669
2025-04-25 17:05:02,377 [INFO] Epoch 14/15 - Policy Loss: 1.0620, Value Loss: 0.2234, Total Loss: 1.2854, LR: 0.003319
2025-04-25 17:05:23,163 [INFO] Epoch 15/15 - Policy Loss: 1.0612, Value Loss: 0.2233, Total Loss: 1.2845, LR: 0.004969
2025-04-25 17:05:23,179 [INFO] 训练完成，总损失: 1.2845
2025-04-25 17:05:23,179 [INFO] 保存迭代 78 的模型
2025-04-25 17:05:23,604 [INFO] Model saved to ./models/best.pt
2025-04-25 17:05:23,889 [INFO] Model saved to ./models/iteration_78.pt
2025-04-25 17:05:23,889 [INFO] 所有训练迭代完成
2025-04-25 17:05:23,889 [INFO] 开始迭代 79/300
2025-04-25 17:05:23,889 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 17:11:35,203 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 17:11:35,204 [INFO] 保存训练样本
2025-04-25 17:11:37,907 [INFO] 使用 109648 个样本训练神经网络
2025-04-25 17:11:37,907 [INFO] Training with 109648 examples
2025-04-25 17:11:37,908 [INFO] 总训练步数: 795, 每轮次批次数: 53
2025-04-25 17:11:38,243 [INFO] 循环学习率周期大小: 159 步
2025-04-25 17:11:58,962 [INFO] Epoch 1/15 - Policy Loss: 1.1085, Value Loss: 0.2332, Total Loss: 1.3417, LR: 0.001669
2025-04-25 17:12:19,644 [INFO] Epoch 2/15 - Policy Loss: 1.0998, Value Loss: 0.2300, Total Loss: 1.3299, LR: 0.003319
2025-04-25 17:12:40,350 [INFO] Epoch 3/15 - Policy Loss: 1.0924, Value Loss: 0.2269, Total Loss: 1.3193, LR: 0.004969
2025-04-25 17:13:01,062 [INFO] Epoch 4/15 - Policy Loss: 1.0877, Value Loss: 0.2262, Total Loss: 1.3139, LR: 0.003381
2025-04-25 17:13:21,785 [INFO] Epoch 5/15 - Policy Loss: 1.0832, Value Loss: 0.2243, Total Loss: 1.3075, LR: 0.001731
2025-04-25 17:13:42,488 [INFO] Epoch 6/15 - Policy Loss: 1.0781, Value Loss: 0.2228, Total Loss: 1.3009, LR: 0.000081
2025-04-25 17:14:03,202 [INFO] Epoch 7/15 - Policy Loss: 1.0748, Value Loss: 0.2220, Total Loss: 1.2968, LR: 0.001669
2025-04-25 17:14:23,915 [INFO] Epoch 8/15 - Policy Loss: 1.0723, Value Loss: 0.2215, Total Loss: 1.2938, LR: 0.003319
2025-04-25 17:14:44,606 [INFO] Epoch 9/15 - Policy Loss: 1.0708, Value Loss: 0.2210, Total Loss: 1.2918, LR: 0.004969
2025-04-25 17:15:05,281 [INFO] Epoch 10/15 - Policy Loss: 1.0693, Value Loss: 0.2212, Total Loss: 1.2905, LR: 0.003381
2025-04-25 17:15:25,975 [INFO] Epoch 11/15 - Policy Loss: 1.0678, Value Loss: 0.2207, Total Loss: 1.2885, LR: 0.001731
2025-04-25 17:15:46,578 [INFO] Epoch 12/15 - Policy Loss: 1.0663, Value Loss: 0.2201, Total Loss: 1.2864, LR: 0.000081
2025-04-25 17:16:07,103 [INFO] Epoch 13/15 - Policy Loss: 1.0643, Value Loss: 0.2197, Total Loss: 1.2840, LR: 0.001669
2025-04-25 17:16:27,623 [INFO] Epoch 14/15 - Policy Loss: 1.0630, Value Loss: 0.2193, Total Loss: 1.2823, LR: 0.003319
2025-04-25 17:16:48,441 [INFO] Epoch 15/15 - Policy Loss: 1.0622, Value Loss: 0.2188, Total Loss: 1.2810, LR: 0.004969
2025-04-25 17:16:48,456 [INFO] 训练完成，总损失: 1.2810
2025-04-25 17:16:48,456 [INFO] 保存迭代 79 的模型
2025-04-25 17:16:49,063 [INFO] Model saved to ./models/best.pt
2025-04-25 17:16:49,379 [INFO] Model saved to ./models/iteration_79.pt
2025-04-25 17:16:49,379 [INFO] 所有训练迭代完成
2025-04-25 17:16:49,379 [INFO] 开始迭代 80/300
2025-04-25 17:16:49,379 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 17:24:33,551 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 17:24:33,552 [INFO] 保存训练样本
2025-04-25 17:24:36,560 [INFO] 使用 111760 个样本训练神经网络
2025-04-25 17:24:36,560 [INFO] Training with 111760 examples
2025-04-25 17:24:36,561 [INFO] 总训练步数: 810, 每轮次批次数: 54
2025-04-25 17:24:36,903 [INFO] 循环学习率周期大小: 162 步
2025-04-25 17:24:58,056 [INFO] Epoch 1/15 - Policy Loss: 1.1312, Value Loss: 0.2615, Total Loss: 1.3927, LR: 0.001669
2025-04-25 17:25:19,200 [INFO] Epoch 2/15 - Policy Loss: 1.1172, Value Loss: 0.2528, Total Loss: 1.3699, LR: 0.003319
2025-04-25 17:25:40,350 [INFO] Epoch 3/15 - Policy Loss: 1.1048, Value Loss: 0.2474, Total Loss: 1.3522, LR: 0.004969
2025-04-25 17:26:01,493 [INFO] Epoch 4/15 - Policy Loss: 1.0983, Value Loss: 0.2444, Total Loss: 1.3427, LR: 0.003381
2025-04-25 17:26:22,625 [INFO] Epoch 5/15 - Policy Loss: 1.0916, Value Loss: 0.2411, Total Loss: 1.3327, LR: 0.001731
2025-04-25 17:26:43,757 [INFO] Epoch 6/15 - Policy Loss: 1.0861, Value Loss: 0.2384, Total Loss: 1.3245, LR: 0.000081
2025-04-25 17:27:04,849 [INFO] Epoch 7/15 - Policy Loss: 1.0818, Value Loss: 0.2363, Total Loss: 1.3182, LR: 0.001669
2025-04-25 17:27:25,952 [INFO] Epoch 8/15 - Policy Loss: 1.0790, Value Loss: 0.2346, Total Loss: 1.3136, LR: 0.003319
2025-04-25 17:27:47,062 [INFO] Epoch 9/15 - Policy Loss: 1.0770, Value Loss: 0.2338, Total Loss: 1.3109, LR: 0.004969
2025-04-25 17:28:08,198 [INFO] Epoch 10/15 - Policy Loss: 1.0761, Value Loss: 0.2333, Total Loss: 1.3094, LR: 0.003381
2025-04-25 17:28:29,343 [INFO] Epoch 11/15 - Policy Loss: 1.0738, Value Loss: 0.2321, Total Loss: 1.3059, LR: 0.001731
2025-04-25 17:28:50,466 [INFO] Epoch 12/15 - Policy Loss: 1.0719, Value Loss: 0.2315, Total Loss: 1.3034, LR: 0.000081
2025-04-25 17:29:11,593 [INFO] Epoch 13/15 - Policy Loss: 1.0702, Value Loss: 0.2305, Total Loss: 1.3006, LR: 0.001669
2025-04-25 17:29:33,018 [INFO] Epoch 14/15 - Policy Loss: 1.0684, Value Loss: 0.2298, Total Loss: 1.2982, LR: 0.003319
2025-04-25 17:29:54,131 [INFO] Epoch 15/15 - Policy Loss: 1.0670, Value Loss: 0.2294, Total Loss: 1.2964, LR: 0.004969
2025-04-25 17:29:54,147 [INFO] 训练完成，总损失: 1.2964
2025-04-25 17:29:54,147 [INFO] 保存迭代 80 的模型
2025-04-25 17:29:54,586 [INFO] Model saved to ./models/best.pt
2025-04-25 17:29:54,887 [INFO] Model saved to ./models/iteration_80.pt
2025-04-25 17:29:54,887 [INFO] 所有训练迭代完成
2025-04-25 17:29:54,887 [INFO] 开始迭代 81/300
2025-04-25 17:29:54,887 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 17:36:34,195 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 17:36:34,196 [INFO] 保存训练样本
2025-04-25 17:36:37,126 [INFO] 使用 112672 个样本训练神经网络
2025-04-25 17:36:37,126 [INFO] Training with 112672 examples
2025-04-25 17:36:37,126 [INFO] 总训练步数: 825, 每轮次批次数: 55
2025-04-25 17:36:37,486 [INFO] 循环学习率周期大小: 165 步
2025-04-25 17:36:59,116 [INFO] Epoch 1/15 - Policy Loss: 1.1020, Value Loss: 0.2499, Total Loss: 1.3519, LR: 0.001670
2025-04-25 17:37:20,669 [INFO] Epoch 2/15 - Policy Loss: 1.0903, Value Loss: 0.2451, Total Loss: 1.3354, LR: 0.003320
2025-04-25 17:37:42,340 [INFO] Epoch 3/15 - Policy Loss: 1.0845, Value Loss: 0.2435, Total Loss: 1.3280, LR: 0.004970
2025-04-25 17:38:03,914 [INFO] Epoch 4/15 - Policy Loss: 1.0814, Value Loss: 0.2418, Total Loss: 1.3232, LR: 0.003380
2025-04-25 17:38:25,479 [INFO] Epoch 5/15 - Policy Loss: 1.0781, Value Loss: 0.2405, Total Loss: 1.3186, LR: 0.001730
2025-04-25 17:38:47,039 [INFO] Epoch 6/15 - Policy Loss: 1.0753, Value Loss: 0.2383, Total Loss: 1.3136, LR: 0.000080
2025-04-25 17:39:08,673 [INFO] Epoch 7/15 - Policy Loss: 1.0723, Value Loss: 0.2373, Total Loss: 1.3097, LR: 0.001670
2025-04-25 17:39:30,317 [INFO] Epoch 8/15 - Policy Loss: 1.0698, Value Loss: 0.2362, Total Loss: 1.3060, LR: 0.003320
2025-04-25 17:39:51,891 [INFO] Epoch 9/15 - Policy Loss: 1.0684, Value Loss: 0.2351, Total Loss: 1.3035, LR: 0.004970
2025-04-25 17:40:13,490 [INFO] Epoch 10/15 - Policy Loss: 1.0678, Value Loss: 0.2344, Total Loss: 1.3022, LR: 0.003380
2025-04-25 17:40:35,079 [INFO] Epoch 11/15 - Policy Loss: 1.0662, Value Loss: 0.2337, Total Loss: 1.2999, LR: 0.001730
2025-04-25 17:40:56,701 [INFO] Epoch 12/15 - Policy Loss: 1.0648, Value Loss: 0.2326, Total Loss: 1.2974, LR: 0.000080
2025-04-25 17:41:18,673 [INFO] Epoch 13/15 - Policy Loss: 1.0633, Value Loss: 0.2318, Total Loss: 1.2951, LR: 0.001670
2025-04-25 17:41:40,257 [INFO] Epoch 14/15 - Policy Loss: 1.0624, Value Loss: 0.2316, Total Loss: 1.2940, LR: 0.003320
2025-04-25 17:42:01,861 [INFO] Epoch 15/15 - Policy Loss: 1.0616, Value Loss: 0.2311, Total Loss: 1.2927, LR: 0.004970
2025-04-25 17:42:01,877 [INFO] 训练完成，总损失: 1.2927
2025-04-25 17:42:01,877 [INFO] 保存迭代 81 的模型
2025-04-25 17:42:02,271 [INFO] Model saved to ./models/best.pt
2025-04-25 17:42:02,616 [INFO] Model saved to ./models/iteration_81.pt
2025-04-25 17:42:02,616 [INFO] 所有训练迭代完成
2025-04-25 17:42:02,616 [INFO] 开始迭代 82/300
2025-04-25 17:42:02,616 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 17:48:29,819 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 17:48:29,819 [INFO] 保存训练样本
2025-04-25 17:48:32,743 [INFO] 使用 113000 个样本训练神经网络
2025-04-25 17:48:32,743 [INFO] Training with 113000 examples
2025-04-25 17:48:32,744 [INFO] 总训练步数: 825, 每轮次批次数: 55
2025-04-25 17:48:33,040 [INFO] 循环学习率周期大小: 165 步
2025-04-25 17:48:54,357 [INFO] Epoch 1/15 - Policy Loss: 1.1155, Value Loss: 0.2455, Total Loss: 1.3610, LR: 0.001670
2025-04-25 17:49:15,698 [INFO] Epoch 2/15 - Policy Loss: 1.1043, Value Loss: 0.2415, Total Loss: 1.3458, LR: 0.003320
2025-04-25 17:49:37,028 [INFO] Epoch 3/15 - Policy Loss: 1.0970, Value Loss: 0.2389, Total Loss: 1.3359, LR: 0.004970
2025-04-25 17:49:58,367 [INFO] Epoch 4/15 - Policy Loss: 1.0925, Value Loss: 0.2355, Total Loss: 1.3280, LR: 0.003380
2025-04-25 17:50:19,858 [INFO] Epoch 5/15 - Policy Loss: 1.0876, Value Loss: 0.2338, Total Loss: 1.3214, LR: 0.001730
2025-04-25 17:50:41,340 [INFO] Epoch 6/15 - Policy Loss: 1.0843, Value Loss: 0.2326, Total Loss: 1.3169, LR: 0.000080
2025-04-25 17:51:02,682 [INFO] Epoch 7/15 - Policy Loss: 1.0801, Value Loss: 0.2314, Total Loss: 1.3114, LR: 0.001670
2025-04-25 17:51:24,040 [INFO] Epoch 8/15 - Policy Loss: 1.0770, Value Loss: 0.2307, Total Loss: 1.3078, LR: 0.003320
2025-04-25 17:51:45,407 [INFO] Epoch 9/15 - Policy Loss: 1.0753, Value Loss: 0.2297, Total Loss: 1.3050, LR: 0.004970
2025-04-25 17:52:06,728 [INFO] Epoch 10/15 - Policy Loss: 1.0746, Value Loss: 0.2294, Total Loss: 1.3040, LR: 0.003380
2025-04-25 17:52:28,131 [INFO] Epoch 11/15 - Policy Loss: 1.0735, Value Loss: 0.2289, Total Loss: 1.3024, LR: 0.001730
2025-04-25 17:52:49,872 [INFO] Epoch 12/15 - Policy Loss: 1.0711, Value Loss: 0.2286, Total Loss: 1.2997, LR: 0.000080
2025-04-25 17:53:11,479 [INFO] Epoch 13/15 - Policy Loss: 1.0693, Value Loss: 0.2278, Total Loss: 1.2971, LR: 0.001670
2025-04-25 17:53:33,030 [INFO] Epoch 14/15 - Policy Loss: 1.0681, Value Loss: 0.2274, Total Loss: 1.2955, LR: 0.003320
2025-04-25 17:53:54,587 [INFO] Epoch 15/15 - Policy Loss: 1.0673, Value Loss: 0.2270, Total Loss: 1.2943, LR: 0.004970
2025-04-25 17:53:54,604 [INFO] 训练完成，总损失: 1.2943
2025-04-25 17:53:54,604 [INFO] 保存迭代 82 的模型
2025-04-25 17:53:54,956 [INFO] Model saved to ./models/best.pt
2025-04-25 17:53:55,224 [INFO] Model saved to ./models/iteration_82.pt
2025-04-25 17:53:55,224 [INFO] 所有训练迭代完成
2025-04-25 17:53:55,224 [INFO] 开始迭代 83/300
2025-04-25 17:53:55,224 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 17:59:02,964 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 17:59:02,965 [INFO] 保存训练样本
2025-04-25 17:59:05,979 [INFO] 使用 112664 个样本训练神经网络
2025-04-25 17:59:05,979 [INFO] Training with 112664 examples
2025-04-25 17:59:05,980 [INFO] 总训练步数: 825, 每轮次批次数: 55
2025-04-25 17:59:06,293 [INFO] 循环学习率周期大小: 165 步
2025-04-25 17:59:27,804 [INFO] Epoch 1/15 - Policy Loss: 1.0916, Value Loss: 0.2441, Total Loss: 1.3357, LR: 0.001670
2025-04-25 17:59:49,326 [INFO] Epoch 2/15 - Policy Loss: 1.0825, Value Loss: 0.2379, Total Loss: 1.3204, LR: 0.003320
2025-04-25 18:00:10,863 [INFO] Epoch 3/15 - Policy Loss: 1.0769, Value Loss: 0.2345, Total Loss: 1.3114, LR: 0.004970
2025-04-25 18:00:32,362 [INFO] Epoch 4/15 - Policy Loss: 1.0749, Value Loss: 0.2323, Total Loss: 1.3072, LR: 0.003380
2025-04-25 18:00:53,855 [INFO] Epoch 5/15 - Policy Loss: 1.0727, Value Loss: 0.2304, Total Loss: 1.3031, LR: 0.001730
2025-04-25 18:01:15,358 [INFO] Epoch 6/15 - Policy Loss: 1.0706, Value Loss: 0.2289, Total Loss: 1.2996, LR: 0.000080
2025-04-25 18:01:36,851 [INFO] Epoch 7/15 - Policy Loss: 1.0688, Value Loss: 0.2279, Total Loss: 1.2966, LR: 0.001670
2025-04-25 18:01:58,403 [INFO] Epoch 8/15 - Policy Loss: 1.0669, Value Loss: 0.2270, Total Loss: 1.2939, LR: 0.003320
2025-04-25 18:02:19,947 [INFO] Epoch 9/15 - Policy Loss: 1.0656, Value Loss: 0.2264, Total Loss: 1.2920, LR: 0.004970
2025-04-25 18:02:41,836 [INFO] Epoch 10/15 - Policy Loss: 1.0658, Value Loss: 0.2265, Total Loss: 1.2922, LR: 0.003380
2025-04-25 18:03:03,394 [INFO] Epoch 11/15 - Policy Loss: 1.0653, Value Loss: 0.2263, Total Loss: 1.2916, LR: 0.001730
2025-04-25 18:03:24,953 [INFO] Epoch 12/15 - Policy Loss: 1.0642, Value Loss: 0.2259, Total Loss: 1.2901, LR: 0.000080
2025-04-25 18:03:46,540 [INFO] Epoch 13/15 - Policy Loss: 1.0628, Value Loss: 0.2253, Total Loss: 1.2881, LR: 0.001670
2025-04-25 18:04:08,072 [INFO] Epoch 14/15 - Policy Loss: 1.0620, Value Loss: 0.2249, Total Loss: 1.2869, LR: 0.003320
2025-04-25 18:04:29,617 [INFO] Epoch 15/15 - Policy Loss: 1.0611, Value Loss: 0.2247, Total Loss: 1.2858, LR: 0.004970
2025-04-25 18:04:29,640 [INFO] 训练完成，总损失: 1.2858
2025-04-25 18:04:29,640 [INFO] 保存迭代 83 的模型
2025-04-25 18:04:30,021 [INFO] Model saved to ./models/best.pt
2025-04-25 18:04:30,292 [INFO] Model saved to ./models/iteration_83.pt
2025-04-25 18:04:30,293 [INFO] 所有训练迭代完成
2025-04-25 18:04:30,293 [INFO] 开始迭代 84/300
2025-04-25 18:04:30,293 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 18:13:37,471 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 18:13:37,471 [INFO] 保存训练样本
2025-04-25 18:13:40,893 [INFO] 使用 115056 个样本训练神经网络
2025-04-25 18:13:40,893 [INFO] Training with 115056 examples
2025-04-25 18:13:40,894 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 18:13:40,936 [INFO] 循环学习率周期大小: 168 步
2025-04-25 18:14:02,844 [INFO] Epoch 1/15 - Policy Loss: 1.1495, Value Loss: 0.2780, Total Loss: 1.4275, LR: 0.001671
2025-04-25 18:14:24,738 [INFO] Epoch 2/15 - Policy Loss: 1.1220, Value Loss: 0.2672, Total Loss: 1.3892, LR: 0.003321
2025-04-25 18:14:46,617 [INFO] Epoch 3/15 - Policy Loss: 1.1087, Value Loss: 0.2600, Total Loss: 1.3687, LR: 0.004971
2025-04-25 18:15:08,501 [INFO] Epoch 4/15 - Policy Loss: 1.1015, Value Loss: 0.2556, Total Loss: 1.3570, LR: 0.003379
2025-04-25 18:15:30,387 [INFO] Epoch 5/15 - Policy Loss: 1.0956, Value Loss: 0.2520, Total Loss: 1.3476, LR: 0.001729
2025-04-25 18:15:52,339 [INFO] Epoch 6/15 - Policy Loss: 1.0893, Value Loss: 0.2488, Total Loss: 1.3381, LR: 0.000079
2025-04-25 18:16:14,223 [INFO] Epoch 7/15 - Policy Loss: 1.0844, Value Loss: 0.2466, Total Loss: 1.3310, LR: 0.001671
2025-04-25 18:16:36,194 [INFO] Epoch 8/15 - Policy Loss: 1.0809, Value Loss: 0.2447, Total Loss: 1.3256, LR: 0.003321
2025-04-25 18:16:58,161 [INFO] Epoch 9/15 - Policy Loss: 1.0786, Value Loss: 0.2432, Total Loss: 1.3218, LR: 0.004971
2025-04-25 18:17:20,105 [INFO] Epoch 10/15 - Policy Loss: 1.0766, Value Loss: 0.2421, Total Loss: 1.3188, LR: 0.003379
2025-04-25 18:17:42,079 [INFO] Epoch 11/15 - Policy Loss: 1.0745, Value Loss: 0.2412, Total Loss: 1.3158, LR: 0.001729
2025-04-25 18:18:04,039 [INFO] Epoch 12/15 - Policy Loss: 1.0729, Value Loss: 0.2404, Total Loss: 1.3134, LR: 0.000079
2025-04-25 18:18:25,758 [INFO] Epoch 13/15 - Policy Loss: 1.0709, Value Loss: 0.2398, Total Loss: 1.3107, LR: 0.001671
2025-04-25 18:18:47,417 [INFO] Epoch 14/15 - Policy Loss: 1.0693, Value Loss: 0.2391, Total Loss: 1.3084, LR: 0.003321
2025-04-25 18:19:09,124 [INFO] Epoch 15/15 - Policy Loss: 1.0682, Value Loss: 0.2383, Total Loss: 1.3065, LR: 0.004971
2025-04-25 18:19:09,139 [INFO] 训练完成，总损失: 1.3065
2025-04-25 18:19:09,139 [INFO] 保存迭代 84 的模型
2025-04-25 18:19:09,583 [INFO] Model saved to ./models/best.pt
2025-04-25 18:19:09,887 [INFO] Model saved to ./models/iteration_84.pt
2025-04-25 18:19:09,887 [INFO] 所有训练迭代完成
2025-04-25 18:19:09,887 [INFO] 开始迭代 85/300
2025-04-25 18:19:09,887 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 18:26:06,478 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 18:26:06,478 [INFO] 保存训练样本
2025-04-25 18:26:09,538 [INFO] 使用 115912 个样本训练神经网络
2025-04-25 18:26:09,538 [INFO] Training with 115912 examples
2025-04-25 18:26:09,538 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 18:26:09,582 [INFO] 循环学习率周期大小: 168 步
2025-04-25 18:26:31,498 [INFO] Epoch 1/15 - Policy Loss: 1.1013, Value Loss: 0.2381, Total Loss: 1.3394, LR: 0.001671
2025-04-25 18:26:53,309 [INFO] Epoch 2/15 - Policy Loss: 1.0940, Value Loss: 0.2349, Total Loss: 1.3289, LR: 0.003321
2025-04-25 18:27:15,282 [INFO] Epoch 3/15 - Policy Loss: 1.0858, Value Loss: 0.2321, Total Loss: 1.3179, LR: 0.004971
2025-04-25 18:27:36,963 [INFO] Epoch 4/15 - Policy Loss: 1.0826, Value Loss: 0.2307, Total Loss: 1.3133, LR: 0.003379
2025-04-25 18:27:58,665 [INFO] Epoch 5/15 - Policy Loss: 1.0786, Value Loss: 0.2290, Total Loss: 1.3076, LR: 0.001729
2025-04-25 18:28:20,430 [INFO] Epoch 6/15 - Policy Loss: 1.0746, Value Loss: 0.2279, Total Loss: 1.3025, LR: 0.000079
2025-04-25 18:28:42,333 [INFO] Epoch 7/15 - Policy Loss: 1.0712, Value Loss: 0.2272, Total Loss: 1.2984, LR: 0.001671
2025-04-25 18:29:04,179 [INFO] Epoch 8/15 - Policy Loss: 1.0689, Value Loss: 0.2265, Total Loss: 1.2954, LR: 0.003321
2025-04-25 18:29:26,002 [INFO] Epoch 9/15 - Policy Loss: 1.0674, Value Loss: 0.2260, Total Loss: 1.2934, LR: 0.004971
2025-04-25 18:29:47,804 [INFO] Epoch 10/15 - Policy Loss: 1.0653, Value Loss: 0.2254, Total Loss: 1.2907, LR: 0.003379
2025-04-25 18:30:09,668 [INFO] Epoch 11/15 - Policy Loss: 1.0640, Value Loss: 0.2248, Total Loss: 1.2887, LR: 0.001729
2025-04-25 18:30:31,534 [INFO] Epoch 12/15 - Policy Loss: 1.0627, Value Loss: 0.2243, Total Loss: 1.2870, LR: 0.000079
2025-04-25 18:30:53,389 [INFO] Epoch 13/15 - Policy Loss: 1.0612, Value Loss: 0.2240, Total Loss: 1.2852, LR: 0.001671
2025-04-25 18:31:15,227 [INFO] Epoch 14/15 - Policy Loss: 1.0599, Value Loss: 0.2235, Total Loss: 1.2834, LR: 0.003321
2025-04-25 18:31:37,077 [INFO] Epoch 15/15 - Policy Loss: 1.0590, Value Loss: 0.2234, Total Loss: 1.2824, LR: 0.004971
2025-04-25 18:31:37,095 [INFO] 训练完成，总损失: 1.2824
2025-04-25 18:31:37,095 [INFO] 保存迭代 85 的模型
2025-04-25 18:31:37,509 [INFO] Model saved to ./models/best.pt
2025-04-25 18:31:37,791 [INFO] Model saved to ./models/iteration_85.pt
2025-04-25 18:31:37,792 [INFO] 所有训练迭代完成
2025-04-25 18:31:37,792 [INFO] 开始迭代 86/300
2025-04-25 18:31:37,792 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 18:37:59,282 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 18:37:59,283 [INFO] 保存训练样本
2025-04-25 18:38:02,650 [INFO] 使用 115680 个样本训练神经网络
2025-04-25 18:38:02,650 [INFO] Training with 115680 examples
2025-04-25 18:38:02,651 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 18:38:02,701 [INFO] 循环学习率周期大小: 168 步
2025-04-25 18:38:25,055 [INFO] Epoch 1/15 - Policy Loss: 1.1079, Value Loss: 0.2522, Total Loss: 1.3602, LR: 0.001671
2025-04-25 18:38:46,957 [INFO] Epoch 2/15 - Policy Loss: 1.0942, Value Loss: 0.2382, Total Loss: 1.3324, LR: 0.003321
2025-04-25 18:39:08,853 [INFO] Epoch 3/15 - Policy Loss: 1.0864, Value Loss: 0.2324, Total Loss: 1.3188, LR: 0.004971
2025-04-25 18:39:30,824 [INFO] Epoch 4/15 - Policy Loss: 1.0817, Value Loss: 0.2292, Total Loss: 1.3109, LR: 0.003379
2025-04-25 18:39:52,730 [INFO] Epoch 5/15 - Policy Loss: 1.0780, Value Loss: 0.2267, Total Loss: 1.3048, LR: 0.001729
2025-04-25 18:40:14,686 [INFO] Epoch 6/15 - Policy Loss: 1.0738, Value Loss: 0.2250, Total Loss: 1.2988, LR: 0.000079
2025-04-25 18:40:36,651 [INFO] Epoch 7/15 - Policy Loss: 1.0706, Value Loss: 0.2238, Total Loss: 1.2944, LR: 0.001671
2025-04-25 18:40:58,556 [INFO] Epoch 8/15 - Policy Loss: 1.0685, Value Loss: 0.2229, Total Loss: 1.2914, LR: 0.003321
2025-04-25 18:41:20,545 [INFO] Epoch 9/15 - Policy Loss: 1.0671, Value Loss: 0.2222, Total Loss: 1.2893, LR: 0.004971
2025-04-25 18:41:42,419 [INFO] Epoch 10/15 - Policy Loss: 1.0658, Value Loss: 0.2214, Total Loss: 1.2872, LR: 0.003379
2025-04-25 18:42:04,301 [INFO] Epoch 11/15 - Policy Loss: 1.0637, Value Loss: 0.2207, Total Loss: 1.2844, LR: 0.001729
2025-04-25 18:42:26,201 [INFO] Epoch 12/15 - Policy Loss: 1.0622, Value Loss: 0.2200, Total Loss: 1.2821, LR: 0.000079
2025-04-25 18:42:48,036 [INFO] Epoch 13/15 - Policy Loss: 1.0610, Value Loss: 0.2193, Total Loss: 1.2803, LR: 0.001671
2025-04-25 18:43:09,733 [INFO] Epoch 14/15 - Policy Loss: 1.0602, Value Loss: 0.2190, Total Loss: 1.2791, LR: 0.003321
2025-04-25 18:43:31,495 [INFO] Epoch 15/15 - Policy Loss: 1.0595, Value Loss: 0.2186, Total Loss: 1.2781, LR: 0.004971
2025-04-25 18:43:31,510 [INFO] 训练完成，总损失: 1.2781
2025-04-25 18:43:31,510 [INFO] 保存迭代 86 的模型
2025-04-25 18:43:31,962 [INFO] Model saved to ./models/best.pt
2025-04-25 18:43:32,266 [INFO] Model saved to ./models/iteration_86.pt
2025-04-25 18:43:32,266 [INFO] 所有训练迭代完成
2025-04-25 18:43:32,266 [INFO] 开始迭代 87/300
2025-04-25 18:43:32,266 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 18:50:49,984 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 18:50:49,985 [INFO] 保存训练样本
2025-04-25 18:50:53,366 [INFO] 使用 116128 个样本训练神经网络
2025-04-25 18:50:53,366 [INFO] Training with 116128 examples
2025-04-25 18:50:53,367 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 18:50:53,756 [INFO] 循环学习率周期大小: 168 步
2025-04-25 18:51:15,669 [INFO] Epoch 1/15 - Policy Loss: 1.0970, Value Loss: 0.2286, Total Loss: 1.3256, LR: 0.001671
2025-04-25 18:51:37,538 [INFO] Epoch 2/15 - Policy Loss: 1.0923, Value Loss: 0.2265, Total Loss: 1.3188, LR: 0.003321
2025-04-25 18:51:59,405 [INFO] Epoch 3/15 - Policy Loss: 1.0882, Value Loss: 0.2239, Total Loss: 1.3120, LR: 0.004971
2025-04-25 18:52:21,289 [INFO] Epoch 4/15 - Policy Loss: 1.0850, Value Loss: 0.2228, Total Loss: 1.3079, LR: 0.003379
2025-04-25 18:52:43,150 [INFO] Epoch 5/15 - Policy Loss: 1.0806, Value Loss: 0.2219, Total Loss: 1.3026, LR: 0.001729
2025-04-25 18:53:05,036 [INFO] Epoch 6/15 - Policy Loss: 1.0768, Value Loss: 0.2209, Total Loss: 1.2977, LR: 0.000079
2025-04-25 18:53:26,916 [INFO] Epoch 7/15 - Policy Loss: 1.0749, Value Loss: 0.2206, Total Loss: 1.2955, LR: 0.001671
2025-04-25 18:53:48,882 [INFO] Epoch 8/15 - Policy Loss: 1.0734, Value Loss: 0.2197, Total Loss: 1.2932, LR: 0.003321
2025-04-25 18:54:10,764 [INFO] Epoch 9/15 - Policy Loss: 1.0715, Value Loss: 0.2192, Total Loss: 1.2907, LR: 0.004971
2025-04-25 18:54:32,653 [INFO] Epoch 10/15 - Policy Loss: 1.0706, Value Loss: 0.2189, Total Loss: 1.2894, LR: 0.003379
2025-04-25 18:54:54,574 [INFO] Epoch 11/15 - Policy Loss: 1.0689, Value Loss: 0.2187, Total Loss: 1.2876, LR: 0.001729
2025-04-25 18:55:16,460 [INFO] Epoch 12/15 - Policy Loss: 1.0675, Value Loss: 0.2182, Total Loss: 1.2856, LR: 0.000079
2025-04-25 18:55:38,177 [INFO] Epoch 13/15 - Policy Loss: 1.0662, Value Loss: 0.2177, Total Loss: 1.2839, LR: 0.001671
2025-04-25 18:55:59,911 [INFO] Epoch 14/15 - Policy Loss: 1.0650, Value Loss: 0.2176, Total Loss: 1.2826, LR: 0.003321
2025-04-25 18:56:21,703 [INFO] Epoch 15/15 - Policy Loss: 1.0647, Value Loss: 0.2175, Total Loss: 1.2822, LR: 0.004971
2025-04-25 18:56:21,718 [INFO] 训练完成，总损失: 1.2822
2025-04-25 18:56:21,718 [INFO] 保存迭代 87 的模型
2025-04-25 18:56:22,104 [INFO] Model saved to ./models/best.pt
2025-04-25 18:56:22,382 [INFO] Model saved to ./models/iteration_87.pt
2025-04-25 18:56:22,382 [INFO] 所有训练迭代完成
2025-04-25 18:56:22,382 [INFO] 开始迭代 88/300
2025-04-25 18:56:22,382 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 19:02:27,280 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 19:02:27,281 [INFO] 保存训练样本
2025-04-25 19:02:30,428 [INFO] 使用 116816 个样本训练神经网络
2025-04-25 19:02:30,428 [INFO] Training with 116816 examples
2025-04-25 19:02:30,429 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-25 19:02:30,795 [INFO] 循环学习率周期大小: 171 步
2025-04-25 19:02:53,090 [INFO] Epoch 1/15 - Policy Loss: 1.0992, Value Loss: 0.2181, Total Loss: 1.3173, LR: 0.001671
2025-04-25 19:03:15,352 [INFO] Epoch 2/15 - Policy Loss: 1.0916, Value Loss: 0.2165, Total Loss: 1.3081, LR: 0.003321
2025-04-25 19:03:37,631 [INFO] Epoch 3/15 - Policy Loss: 1.0845, Value Loss: 0.2155, Total Loss: 1.3000, LR: 0.004971
2025-04-25 19:04:00,017 [INFO] Epoch 4/15 - Policy Loss: 1.0803, Value Loss: 0.2144, Total Loss: 1.2947, LR: 0.003379
2025-04-25 19:04:22,321 [INFO] Epoch 5/15 - Policy Loss: 1.0767, Value Loss: 0.2147, Total Loss: 1.2914, LR: 0.001729
2025-04-25 19:04:44,458 [INFO] Epoch 6/15 - Policy Loss: 1.0740, Value Loss: 0.2140, Total Loss: 1.2880, LR: 0.000079
2025-04-25 19:05:06,618 [INFO] Epoch 7/15 - Policy Loss: 1.0710, Value Loss: 0.2134, Total Loss: 1.2844, LR: 0.001671
2025-04-25 19:05:28,786 [INFO] Epoch 8/15 - Policy Loss: 1.0686, Value Loss: 0.2130, Total Loss: 1.2816, LR: 0.003321
2025-04-25 19:05:51,106 [INFO] Epoch 9/15 - Policy Loss: 1.0671, Value Loss: 0.2129, Total Loss: 1.2800, LR: 0.004971
2025-04-25 19:06:13,248 [INFO] Epoch 10/15 - Policy Loss: 1.0667, Value Loss: 0.2129, Total Loss: 1.2796, LR: 0.003379
2025-04-25 19:06:35,415 [INFO] Epoch 11/15 - Policy Loss: 1.0655, Value Loss: 0.2128, Total Loss: 1.2783, LR: 0.001729
2025-04-25 19:06:57,611 [INFO] Epoch 12/15 - Policy Loss: 1.0643, Value Loss: 0.2126, Total Loss: 1.2769, LR: 0.000079
2025-04-25 19:07:19,870 [INFO] Epoch 13/15 - Policy Loss: 1.0633, Value Loss: 0.2121, Total Loss: 1.2754, LR: 0.001671
2025-04-25 19:07:42,067 [INFO] Epoch 14/15 - Policy Loss: 1.0623, Value Loss: 0.2121, Total Loss: 1.2744, LR: 0.003321
2025-04-25 19:08:04,613 [INFO] Epoch 15/15 - Policy Loss: 1.0616, Value Loss: 0.2121, Total Loss: 1.2737, LR: 0.004971
2025-04-25 19:08:04,628 [INFO] 训练完成，总损失: 1.2737
2025-04-25 19:08:04,628 [INFO] 保存迭代 88 的模型
2025-04-25 19:08:05,054 [INFO] Model saved to ./models/best.pt
2025-04-25 19:08:05,325 [INFO] Model saved to ./models/iteration_88.pt
2025-04-25 19:08:05,326 [INFO] 所有训练迭代完成
2025-04-25 19:08:05,326 [INFO] 开始迭代 89/300
2025-04-25 19:08:05,326 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 19:15:36,823 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 19:15:36,824 [INFO] 保存训练样本
2025-04-25 19:15:39,738 [INFO] 使用 117400 个样本训练神经网络
2025-04-25 19:15:39,738 [INFO] Training with 117400 examples
2025-04-25 19:15:39,738 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-25 19:15:40,066 [INFO] 循环学习率周期大小: 171 步
2025-04-25 19:16:02,269 [INFO] Epoch 1/15 - Policy Loss: 1.1033, Value Loss: 0.2226, Total Loss: 1.3259, LR: 0.001671
2025-04-25 19:16:24,447 [INFO] Epoch 2/15 - Policy Loss: 1.0970, Value Loss: 0.2188, Total Loss: 1.3158, LR: 0.003321
2025-04-25 19:16:46,516 [INFO] Epoch 3/15 - Policy Loss: 1.0931, Value Loss: 0.2176, Total Loss: 1.3107, LR: 0.004971
2025-04-25 19:17:08,672 [INFO] Epoch 4/15 - Policy Loss: 1.0879, Value Loss: 0.2171, Total Loss: 1.3050, LR: 0.003379
2025-04-25 19:17:30,783 [INFO] Epoch 5/15 - Policy Loss: 1.0837, Value Loss: 0.2163, Total Loss: 1.3001, LR: 0.001729
2025-04-25 19:17:52,994 [INFO] Epoch 6/15 - Policy Loss: 1.0800, Value Loss: 0.2155, Total Loss: 1.2955, LR: 0.000079
2025-04-25 19:18:15,334 [INFO] Epoch 7/15 - Policy Loss: 1.0764, Value Loss: 0.2147, Total Loss: 1.2911, LR: 0.001671
2025-04-25 19:18:37,626 [INFO] Epoch 8/15 - Policy Loss: 1.0734, Value Loss: 0.2138, Total Loss: 1.2872, LR: 0.003321
2025-04-25 19:18:59,925 [INFO] Epoch 9/15 - Policy Loss: 1.0723, Value Loss: 0.2134, Total Loss: 1.2857, LR: 0.004971
2025-04-25 19:19:22,264 [INFO] Epoch 10/15 - Policy Loss: 1.0715, Value Loss: 0.2135, Total Loss: 1.2850, LR: 0.003379
2025-04-25 19:19:44,535 [INFO] Epoch 11/15 - Policy Loss: 1.0698, Value Loss: 0.2134, Total Loss: 1.2832, LR: 0.001729
2025-04-25 19:20:06,818 [INFO] Epoch 12/15 - Policy Loss: 1.0679, Value Loss: 0.2131, Total Loss: 1.2810, LR: 0.000079
2025-04-25 19:20:29,090 [INFO] Epoch 13/15 - Policy Loss: 1.0663, Value Loss: 0.2127, Total Loss: 1.2790, LR: 0.001671
2025-04-25 19:20:51,415 [INFO] Epoch 14/15 - Policy Loss: 1.0652, Value Loss: 0.2123, Total Loss: 1.2775, LR: 0.003321
2025-04-25 19:21:14,091 [INFO] Epoch 15/15 - Policy Loss: 1.0645, Value Loss: 0.2122, Total Loss: 1.2767, LR: 0.004971
2025-04-25 19:21:14,108 [INFO] 训练完成，总损失: 1.2767
2025-04-25 19:21:14,108 [INFO] 保存迭代 89 的模型
2025-04-25 19:21:14,489 [INFO] Model saved to ./models/best.pt
2025-04-25 19:21:14,758 [INFO] Model saved to ./models/iteration_89.pt
2025-04-25 19:21:14,758 [INFO] 所有训练迭代完成
2025-04-25 19:21:14,758 [INFO] 开始迭代 90/300
2025-04-25 19:21:14,758 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 19:27:15,413 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 19:27:15,414 [INFO] 保存训练样本
2025-04-25 19:27:18,480 [INFO] 使用 117352 个样本训练神经网络
2025-04-25 19:27:18,480 [INFO] Training with 117352 examples
2025-04-25 19:27:18,480 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-25 19:27:18,838 [INFO] 循环学习率周期大小: 171 步
2025-04-25 19:27:41,175 [INFO] Epoch 1/15 - Policy Loss: 1.0918, Value Loss: 0.2219, Total Loss: 1.3138, LR: 0.001671
2025-04-25 19:28:03,622 [INFO] Epoch 2/15 - Policy Loss: 1.0861, Value Loss: 0.2210, Total Loss: 1.3071, LR: 0.003321
2025-04-25 19:28:26,084 [INFO] Epoch 3/15 - Policy Loss: 1.0808, Value Loss: 0.2200, Total Loss: 1.3008, LR: 0.004971
2025-04-25 19:28:48,569 [INFO] Epoch 4/15 - Policy Loss: 1.0780, Value Loss: 0.2184, Total Loss: 1.2964, LR: 0.003379
2025-04-25 19:29:10,837 [INFO] Epoch 5/15 - Policy Loss: 1.0748, Value Loss: 0.2176, Total Loss: 1.2923, LR: 0.001729
2025-04-25 19:29:33,015 [INFO] Epoch 6/15 - Policy Loss: 1.0724, Value Loss: 0.2163, Total Loss: 1.2887, LR: 0.000079
2025-04-25 19:29:55,286 [INFO] Epoch 7/15 - Policy Loss: 1.0702, Value Loss: 0.2150, Total Loss: 1.2852, LR: 0.001671
2025-04-25 19:30:17,869 [INFO] Epoch 8/15 - Policy Loss: 1.0686, Value Loss: 0.2142, Total Loss: 1.2828, LR: 0.003321
2025-04-25 19:30:40,420 [INFO] Epoch 9/15 - Policy Loss: 1.0669, Value Loss: 0.2137, Total Loss: 1.2806, LR: 0.004971
2025-04-25 19:31:03,036 [INFO] Epoch 10/15 - Policy Loss: 1.0663, Value Loss: 0.2134, Total Loss: 1.2797, LR: 0.003379
2025-04-25 19:31:25,546 [INFO] Epoch 11/15 - Policy Loss: 1.0656, Value Loss: 0.2132, Total Loss: 1.2788, LR: 0.001729
2025-04-25 19:31:47,861 [INFO] Epoch 12/15 - Policy Loss: 1.0645, Value Loss: 0.2129, Total Loss: 1.2774, LR: 0.000079
2025-04-25 19:32:10,070 [INFO] Epoch 13/15 - Policy Loss: 1.0635, Value Loss: 0.2127, Total Loss: 1.2762, LR: 0.001671
2025-04-25 19:32:32,766 [INFO] Epoch 14/15 - Policy Loss: 1.0626, Value Loss: 0.2125, Total Loss: 1.2751, LR: 0.003321
2025-04-25 19:32:55,318 [INFO] Epoch 15/15 - Policy Loss: 1.0616, Value Loss: 0.2121, Total Loss: 1.2737, LR: 0.004971
2025-04-25 19:32:55,335 [INFO] 训练完成，总损失: 1.2737
2025-04-25 19:32:55,336 [INFO] 保存迭代 90 的模型
2025-04-25 19:32:55,717 [INFO] Model saved to ./models/best.pt
2025-04-25 19:32:55,997 [INFO] Model saved to ./models/iteration_90.pt
2025-04-25 19:32:55,998 [INFO] 所有训练迭代完成
2025-04-25 19:32:55,998 [INFO] 开始迭代 91/300
2025-04-25 19:32:55,998 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 19:39:59,947 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 19:39:59,947 [INFO] 保存训练样本
2025-04-25 19:40:02,957 [INFO] 使用 118552 个样本训练神经网络
2025-04-25 19:40:02,957 [INFO] Training with 118552 examples
2025-04-25 19:40:02,958 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-25 19:40:03,348 [INFO] 循环学习率周期大小: 171 步
2025-04-25 19:40:25,485 [INFO] Epoch 1/15 - Policy Loss: 1.0943, Value Loss: 0.2239, Total Loss: 1.3182, LR: 0.001671
2025-04-25 19:40:47,581 [INFO] Epoch 2/15 - Policy Loss: 1.0838, Value Loss: 0.2190, Total Loss: 1.3028, LR: 0.003321
2025-04-25 19:41:09,705 [INFO] Epoch 3/15 - Policy Loss: 1.0827, Value Loss: 0.2167, Total Loss: 1.2995, LR: 0.004971
2025-04-25 19:41:31,822 [INFO] Epoch 4/15 - Policy Loss: 1.0797, Value Loss: 0.2150, Total Loss: 1.2948, LR: 0.003379
2025-04-25 19:41:53,919 [INFO] Epoch 5/15 - Policy Loss: 1.0770, Value Loss: 0.2137, Total Loss: 1.2907, LR: 0.001729
2025-04-25 19:42:16,038 [INFO] Epoch 6/15 - Policy Loss: 1.0731, Value Loss: 0.2129, Total Loss: 1.2859, LR: 0.000079
2025-04-25 19:42:38,237 [INFO] Epoch 7/15 - Policy Loss: 1.0709, Value Loss: 0.2122, Total Loss: 1.2831, LR: 0.001671
2025-04-25 19:43:00,477 [INFO] Epoch 8/15 - Policy Loss: 1.0689, Value Loss: 0.2115, Total Loss: 1.2804, LR: 0.003321
2025-04-25 19:43:22,779 [INFO] Epoch 9/15 - Policy Loss: 1.0673, Value Loss: 0.2109, Total Loss: 1.2782, LR: 0.004971
2025-04-25 19:43:45,029 [INFO] Epoch 10/15 - Policy Loss: 1.0666, Value Loss: 0.2106, Total Loss: 1.2772, LR: 0.003379
2025-04-25 19:44:07,237 [INFO] Epoch 11/15 - Policy Loss: 1.0656, Value Loss: 0.2103, Total Loss: 1.2759, LR: 0.001729
2025-04-25 19:44:29,709 [INFO] Epoch 12/15 - Policy Loss: 1.0644, Value Loss: 0.2096, Total Loss: 1.2741, LR: 0.000079
2025-04-25 19:44:51,882 [INFO] Epoch 13/15 - Policy Loss: 1.0634, Value Loss: 0.2092, Total Loss: 1.2726, LR: 0.001671
2025-04-25 19:45:14,254 [INFO] Epoch 14/15 - Policy Loss: 1.0628, Value Loss: 0.2089, Total Loss: 1.2718, LR: 0.003321
2025-04-25 19:45:36,567 [INFO] Epoch 15/15 - Policy Loss: 1.0617, Value Loss: 0.2089, Total Loss: 1.2706, LR: 0.004971
2025-04-25 19:45:36,583 [INFO] 训练完成，总损失: 1.2706
2025-04-25 19:45:36,583 [INFO] 保存迭代 91 的模型
2025-04-25 19:45:36,976 [INFO] Model saved to ./models/best.pt
2025-04-25 19:45:37,260 [INFO] Model saved to ./models/iteration_91.pt
2025-04-25 19:45:37,260 [INFO] 所有训练迭代完成
2025-04-25 19:45:37,260 [INFO] 开始迭代 92/300
2025-04-25 19:45:37,260 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 19:52:30,307 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 19:52:30,308 [INFO] 保存训练样本
2025-04-25 19:52:33,371 [INFO] 使用 119320 个样本训练神经网络
2025-04-25 19:52:33,371 [INFO] Training with 119320 examples
2025-04-25 19:52:33,371 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-25 19:52:33,727 [INFO] 循环学习率周期大小: 174 步
2025-04-25 19:52:56,418 [INFO] Epoch 1/15 - Policy Loss: 1.0938, Value Loss: 0.2239, Total Loss: 1.3177, LR: 0.001672
2025-04-25 19:53:19,088 [INFO] Epoch 2/15 - Policy Loss: 1.0907, Value Loss: 0.2200, Total Loss: 1.3107, LR: 0.003322
2025-04-25 19:53:41,756 [INFO] Epoch 3/15 - Policy Loss: 1.0836, Value Loss: 0.2171, Total Loss: 1.3007, LR: 0.004972
2025-04-25 19:54:04,381 [INFO] Epoch 4/15 - Policy Loss: 1.0808, Value Loss: 0.2155, Total Loss: 1.2963, LR: 0.003378
2025-04-25 19:54:26,877 [INFO] Epoch 5/15 - Policy Loss: 1.0772, Value Loss: 0.2136, Total Loss: 1.2908, LR: 0.001728
2025-04-25 19:54:49,351 [INFO] Epoch 6/15 - Policy Loss: 1.0738, Value Loss: 0.2124, Total Loss: 1.2862, LR: 0.000078
2025-04-25 19:55:11,859 [INFO] Epoch 7/15 - Policy Loss: 1.0701, Value Loss: 0.2108, Total Loss: 1.2810, LR: 0.001672
2025-04-25 19:55:34,577 [INFO] Epoch 8/15 - Policy Loss: 1.0675, Value Loss: 0.2098, Total Loss: 1.2773, LR: 0.003322
2025-04-25 19:55:57,277 [INFO] Epoch 9/15 - Policy Loss: 1.0660, Value Loss: 0.2091, Total Loss: 1.2751, LR: 0.004972
2025-04-25 19:56:20,290 [INFO] Epoch 10/15 - Policy Loss: 1.0655, Value Loss: 0.2086, Total Loss: 1.2741, LR: 0.003378
2025-04-25 19:56:42,937 [INFO] Epoch 11/15 - Policy Loss: 1.0648, Value Loss: 0.2081, Total Loss: 1.2729, LR: 0.001728
2025-04-25 19:57:05,576 [INFO] Epoch 12/15 - Policy Loss: 1.0636, Value Loss: 0.2075, Total Loss: 1.2711, LR: 0.000078
2025-04-25 19:57:28,243 [INFO] Epoch 13/15 - Policy Loss: 1.0623, Value Loss: 0.2070, Total Loss: 1.2693, LR: 0.001672
2025-04-25 19:57:50,916 [INFO] Epoch 14/15 - Policy Loss: 1.0613, Value Loss: 0.2065, Total Loss: 1.2678, LR: 0.003322
2025-04-25 19:58:13,567 [INFO] Epoch 15/15 - Policy Loss: 1.0609, Value Loss: 0.2061, Total Loss: 1.2670, LR: 0.004972
2025-04-25 19:58:13,585 [INFO] 训练完成，总损失: 1.2670
2025-04-25 19:58:13,585 [INFO] 保存迭代 92 的模型
2025-04-25 19:58:14,009 [INFO] Model saved to ./models/best.pt
2025-04-25 19:58:14,314 [INFO] Model saved to ./models/iteration_92.pt
2025-04-25 19:58:14,314 [INFO] 所有训练迭代完成
2025-04-25 19:58:14,314 [INFO] 开始迭代 93/300
2025-04-25 19:58:14,314 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 20:04:19,684 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 20:04:19,684 [INFO] 保存训练样本
2025-04-25 20:04:23,311 [INFO] 使用 119176 个样本训练神经网络
2025-04-25 20:04:23,311 [INFO] Training with 119176 examples
2025-04-25 20:04:23,312 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-25 20:04:23,361 [INFO] 循环学习率周期大小: 174 步
2025-04-25 20:04:46,105 [INFO] Epoch 1/15 - Policy Loss: 1.0757, Value Loss: 0.2181, Total Loss: 1.2939, LR: 0.001672
2025-04-25 20:05:08,849 [INFO] Epoch 2/15 - Policy Loss: 1.0747, Value Loss: 0.2155, Total Loss: 1.2902, LR: 0.003322
2025-04-25 20:05:31,542 [INFO] Epoch 3/15 - Policy Loss: 1.0708, Value Loss: 0.2135, Total Loss: 1.2843, LR: 0.004972
2025-04-25 20:05:54,261 [INFO] Epoch 4/15 - Policy Loss: 1.0707, Value Loss: 0.2128, Total Loss: 1.2835, LR: 0.003378
2025-04-25 20:06:16,983 [INFO] Epoch 5/15 - Policy Loss: 1.0683, Value Loss: 0.2115, Total Loss: 1.2798, LR: 0.001728
2025-04-25 20:06:39,615 [INFO] Epoch 6/15 - Policy Loss: 1.0650, Value Loss: 0.2104, Total Loss: 1.2754, LR: 0.000078
2025-04-25 20:07:02,622 [INFO] Epoch 7/15 - Policy Loss: 1.0630, Value Loss: 0.2092, Total Loss: 1.2722, LR: 0.001672
2025-04-25 20:07:25,347 [INFO] Epoch 8/15 - Policy Loss: 1.0611, Value Loss: 0.2085, Total Loss: 1.2696, LR: 0.003322
2025-04-25 20:07:48,035 [INFO] Epoch 9/15 - Policy Loss: 1.0595, Value Loss: 0.2079, Total Loss: 1.2674, LR: 0.004972
2025-04-25 20:08:10,735 [INFO] Epoch 10/15 - Policy Loss: 1.0586, Value Loss: 0.2071, Total Loss: 1.2656, LR: 0.003378
2025-04-25 20:08:33,424 [INFO] Epoch 11/15 - Policy Loss: 1.0578, Value Loss: 0.2069, Total Loss: 1.2647, LR: 0.001728
2025-04-25 20:08:56,156 [INFO] Epoch 12/15 - Policy Loss: 1.0570, Value Loss: 0.2064, Total Loss: 1.2634, LR: 0.000078
2025-04-25 20:09:18,852 [INFO] Epoch 13/15 - Policy Loss: 1.0562, Value Loss: 0.2062, Total Loss: 1.2624, LR: 0.001672
2025-04-25 20:09:41,552 [INFO] Epoch 14/15 - Policy Loss: 1.0547, Value Loss: 0.2055, Total Loss: 1.2602, LR: 0.003322
2025-04-25 20:10:04,235 [INFO] Epoch 15/15 - Policy Loss: 1.0548, Value Loss: 0.2054, Total Loss: 1.2602, LR: 0.004972
2025-04-25 20:10:04,252 [INFO] 训练完成，总损失: 1.2602
2025-04-25 20:10:04,253 [INFO] 保存迭代 93 的模型
2025-04-25 20:10:04,715 [INFO] Model saved to ./models/best.pt
2025-04-25 20:10:05,060 [INFO] Model saved to ./models/iteration_93.pt
2025-04-25 20:10:05,061 [INFO] 所有训练迭代完成
2025-04-25 20:10:05,061 [INFO] 开始迭代 94/300
2025-04-25 20:10:05,061 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 20:17:55,161 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 20:17:55,162 [INFO] 保存训练样本
2025-04-25 20:17:58,403 [INFO] 使用 120672 个样本训练神经网络
2025-04-25 20:17:58,403 [INFO] Training with 120672 examples
2025-04-25 20:17:58,404 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-25 20:17:58,444 [INFO] 循环学习率周期大小: 174 步
2025-04-25 20:18:21,061 [INFO] Epoch 1/15 - Policy Loss: 1.1067, Value Loss: 0.2183, Total Loss: 1.3250, LR: 0.001672
2025-04-25 20:18:43,934 [INFO] Epoch 2/15 - Policy Loss: 1.0985, Value Loss: 0.2143, Total Loss: 1.3128, LR: 0.003322
2025-04-25 20:19:06,476 [INFO] Epoch 3/15 - Policy Loss: 1.0905, Value Loss: 0.2112, Total Loss: 1.3017, LR: 0.004972
2025-04-25 20:19:29,148 [INFO] Epoch 4/15 - Policy Loss: 1.0864, Value Loss: 0.2097, Total Loss: 1.2960, LR: 0.003378
2025-04-25 20:19:51,646 [INFO] Epoch 5/15 - Policy Loss: 1.0807, Value Loss: 0.2074, Total Loss: 1.2881, LR: 0.001728
2025-04-25 20:20:14,126 [INFO] Epoch 6/15 - Policy Loss: 1.0768, Value Loss: 0.2055, Total Loss: 1.2823, LR: 0.000078
2025-04-25 20:20:36,605 [INFO] Epoch 7/15 - Policy Loss: 1.0726, Value Loss: 0.2041, Total Loss: 1.2767, LR: 0.001672
2025-04-25 20:20:59,017 [INFO] Epoch 8/15 - Policy Loss: 1.0698, Value Loss: 0.2036, Total Loss: 1.2734, LR: 0.003322
2025-04-25 20:21:21,542 [INFO] Epoch 9/15 - Policy Loss: 1.0671, Value Loss: 0.2029, Total Loss: 1.2700, LR: 0.004972
2025-04-25 20:21:44,039 [INFO] Epoch 10/15 - Policy Loss: 1.0670, Value Loss: 0.2030, Total Loss: 1.2700, LR: 0.003378
2025-04-25 20:22:06,533 [INFO] Epoch 11/15 - Policy Loss: 1.0655, Value Loss: 0.2023, Total Loss: 1.2678, LR: 0.001728
2025-04-25 20:22:29,028 [INFO] Epoch 12/15 - Policy Loss: 1.0634, Value Loss: 0.2017, Total Loss: 1.2651, LR: 0.000078
2025-04-25 20:22:51,560 [INFO] Epoch 13/15 - Policy Loss: 1.0621, Value Loss: 0.2012, Total Loss: 1.2633, LR: 0.001672
2025-04-25 20:23:14,063 [INFO] Epoch 14/15 - Policy Loss: 1.0605, Value Loss: 0.2008, Total Loss: 1.2613, LR: 0.003322
2025-04-25 20:23:36,622 [INFO] Epoch 15/15 - Policy Loss: 1.0594, Value Loss: 0.2005, Total Loss: 1.2600, LR: 0.004972
2025-04-25 20:23:36,639 [INFO] 训练完成，总损失: 1.2600
2025-04-25 20:23:36,640 [INFO] 保存迭代 94 的模型
2025-04-25 20:23:37,026 [INFO] Model saved to ./models/best.pt
2025-04-25 20:23:37,295 [INFO] Model saved to ./models/iteration_94.pt
2025-04-25 20:23:37,295 [INFO] 所有训练迭代完成
2025-04-25 20:23:37,295 [INFO] 开始迭代 95/300
2025-04-25 20:23:37,295 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 20:30:09,823 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 20:30:09,824 [INFO] 保存训练样本
2025-04-25 20:30:13,356 [INFO] 使用 120704 个样本训练神经网络
2025-04-25 20:30:13,356 [INFO] Training with 120704 examples
2025-04-25 20:30:13,357 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-25 20:30:13,713 [INFO] 循环学习率周期大小: 174 步
2025-04-25 20:30:36,432 [INFO] Epoch 1/15 - Policy Loss: 1.0782, Value Loss: 0.2068, Total Loss: 1.2850, LR: 0.001672
2025-04-25 20:30:59,149 [INFO] Epoch 2/15 - Policy Loss: 1.0721, Value Loss: 0.2019, Total Loss: 1.2740, LR: 0.003322
2025-04-25 20:31:21,793 [INFO] Epoch 3/15 - Policy Loss: 1.0700, Value Loss: 0.2003, Total Loss: 1.2703, LR: 0.004972
2025-04-25 20:31:44,436 [INFO] Epoch 4/15 - Policy Loss: 1.0698, Value Loss: 0.1994, Total Loss: 1.2692, LR: 0.003378
2025-04-25 20:32:06,952 [INFO] Epoch 5/15 - Policy Loss: 1.0659, Value Loss: 0.1981, Total Loss: 1.2640, LR: 0.001728
2025-04-25 20:32:29,452 [INFO] Epoch 6/15 - Policy Loss: 1.0634, Value Loss: 0.1974, Total Loss: 1.2608, LR: 0.000078
2025-04-25 20:32:52,063 [INFO] Epoch 7/15 - Policy Loss: 1.0615, Value Loss: 0.1963, Total Loss: 1.2578, LR: 0.001672
2025-04-25 20:33:14,621 [INFO] Epoch 8/15 - Policy Loss: 1.0601, Value Loss: 0.1957, Total Loss: 1.2559, LR: 0.003322
2025-04-25 20:33:37,182 [INFO] Epoch 9/15 - Policy Loss: 1.0587, Value Loss: 0.1952, Total Loss: 1.2539, LR: 0.004972
2025-04-25 20:33:59,879 [INFO] Epoch 10/15 - Policy Loss: 1.0576, Value Loss: 0.1945, Total Loss: 1.2521, LR: 0.003378
2025-04-25 20:34:22,498 [INFO] Epoch 11/15 - Policy Loss: 1.0568, Value Loss: 0.1939, Total Loss: 1.2507, LR: 0.001728
2025-04-25 20:34:45,053 [INFO] Epoch 12/15 - Policy Loss: 1.0558, Value Loss: 0.1934, Total Loss: 1.2493, LR: 0.000078
2025-04-25 20:35:07,590 [INFO] Epoch 13/15 - Policy Loss: 1.0546, Value Loss: 0.1932, Total Loss: 1.2478, LR: 0.001672
2025-04-25 20:35:30,114 [INFO] Epoch 14/15 - Policy Loss: 1.0539, Value Loss: 0.1931, Total Loss: 1.2470, LR: 0.003322
2025-04-25 20:35:52,733 [INFO] Epoch 15/15 - Policy Loss: 1.0533, Value Loss: 0.1925, Total Loss: 1.2458, LR: 0.004972
2025-04-25 20:35:52,749 [INFO] 训练完成，总损失: 1.2458
2025-04-25 20:35:52,749 [INFO] 保存迭代 95 的模型
2025-04-25 20:35:53,136 [INFO] Model saved to ./models/best.pt
2025-04-25 20:35:53,414 [INFO] Model saved to ./models/iteration_95.pt
2025-04-25 20:35:53,414 [INFO] 所有训练迭代完成
2025-04-25 20:35:53,414 [INFO] 开始迭代 96/300
2025-04-25 20:35:53,414 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 20:42:18,947 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 20:42:18,947 [INFO] 保存训练样本
2025-04-25 20:42:22,486 [INFO] 使用 121408 个样本训练神经网络
2025-04-25 20:42:22,486 [INFO] Training with 121408 examples
2025-04-25 20:42:22,487 [INFO] 总训练步数: 885, 每轮次批次数: 59
2025-04-25 20:42:22,816 [INFO] 循环学习率周期大小: 177 步
2025-04-25 20:42:45,792 [INFO] Epoch 1/15 - Policy Loss: 1.0723, Value Loss: 0.1973, Total Loss: 1.2696, LR: 0.001672
2025-04-25 20:43:08,706 [INFO] Epoch 2/15 - Policy Loss: 1.0680, Value Loss: 0.1963, Total Loss: 1.2643, LR: 0.003322
2025-04-25 20:43:31,555 [INFO] Epoch 3/15 - Policy Loss: 1.0668, Value Loss: 0.1966, Total Loss: 1.2634, LR: 0.004972
2025-04-25 20:43:54,446 [INFO] Epoch 4/15 - Policy Loss: 1.0670, Value Loss: 0.1961, Total Loss: 1.2631, LR: 0.003378
2025-04-25 20:44:17,307 [INFO] Epoch 5/15 - Policy Loss: 1.0636, Value Loss: 0.1950, Total Loss: 1.2586, LR: 0.001728
2025-04-25 20:44:40,179 [INFO] Epoch 6/15 - Policy Loss: 1.0614, Value Loss: 0.1943, Total Loss: 1.2557, LR: 0.000078
2025-04-25 20:45:03,041 [INFO] Epoch 7/15 - Policy Loss: 1.0595, Value Loss: 0.1937, Total Loss: 1.2533, LR: 0.001672
2025-04-25 20:45:25,948 [INFO] Epoch 8/15 - Policy Loss: 1.0575, Value Loss: 0.1931, Total Loss: 1.2506, LR: 0.003322
2025-04-25 20:45:48,895 [INFO] Epoch 9/15 - Policy Loss: 1.0566, Value Loss: 0.1924, Total Loss: 1.2491, LR: 0.004972
2025-04-25 20:46:11,813 [INFO] Epoch 10/15 - Policy Loss: 1.0557, Value Loss: 0.1921, Total Loss: 1.2478, LR: 0.003378
2025-04-25 20:46:34,679 [INFO] Epoch 11/15 - Policy Loss: 1.0552, Value Loss: 0.1920, Total Loss: 1.2472, LR: 0.001728
2025-04-25 20:46:57,528 [INFO] Epoch 12/15 - Policy Loss: 1.0538, Value Loss: 0.1912, Total Loss: 1.2450, LR: 0.000078
2025-04-25 20:47:20,438 [INFO] Epoch 13/15 - Policy Loss: 1.0528, Value Loss: 0.1908, Total Loss: 1.2436, LR: 0.001672
2025-04-25 20:47:43,363 [INFO] Epoch 14/15 - Policy Loss: 1.0522, Value Loss: 0.1905, Total Loss: 1.2427, LR: 0.003322
2025-04-25 20:48:06,373 [INFO] Epoch 15/15 - Policy Loss: 1.0514, Value Loss: 0.1903, Total Loss: 1.2417, LR: 0.004972
2025-04-25 20:48:06,391 [INFO] 训练完成，总损失: 1.2417
2025-04-25 20:48:06,392 [INFO] 保存迭代 96 的模型
2025-04-25 20:48:06,853 [INFO] Model saved to ./models/best.pt
2025-04-25 20:48:07,217 [INFO] Model saved to ./models/iteration_96.pt
2025-04-25 20:48:07,217 [INFO] 所有训练迭代完成
2025-04-25 20:48:07,217 [INFO] 开始迭代 97/300
2025-04-25 20:48:07,217 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 20:53:31,406 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 20:53:31,406 [INFO] 保存训练样本
2025-04-25 20:53:34,557 [INFO] 使用 120128 个样本训练神经网络
2025-04-25 20:53:34,557 [INFO] Training with 120128 examples
2025-04-25 20:53:34,558 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-25 20:53:34,903 [INFO] 循环学习率周期大小: 174 步
2025-04-25 20:53:57,822 [INFO] Epoch 1/15 - Policy Loss: 1.0644, Value Loss: 0.1964, Total Loss: 1.2608, LR: 0.001672
2025-04-25 20:54:20,603 [INFO] Epoch 2/15 - Policy Loss: 1.0625, Value Loss: 0.1944, Total Loss: 1.2569, LR: 0.003322
2025-04-25 20:54:43,356 [INFO] Epoch 3/15 - Policy Loss: 1.0608, Value Loss: 0.1929, Total Loss: 1.2537, LR: 0.004972
2025-04-25 20:55:06,088 [INFO] Epoch 4/15 - Policy Loss: 1.0590, Value Loss: 0.1919, Total Loss: 1.2509, LR: 0.003378
2025-04-25 20:55:28,746 [INFO] Epoch 5/15 - Policy Loss: 1.0581, Value Loss: 0.1916, Total Loss: 1.2497, LR: 0.001728
2025-04-25 20:55:51,319 [INFO] Epoch 6/15 - Policy Loss: 1.0565, Value Loss: 0.1911, Total Loss: 1.2477, LR: 0.000078
2025-04-25 20:56:13,792 [INFO] Epoch 7/15 - Policy Loss: 1.0552, Value Loss: 0.1901, Total Loss: 1.2453, LR: 0.001672
2025-04-25 20:56:36,247 [INFO] Epoch 8/15 - Policy Loss: 1.0534, Value Loss: 0.1896, Total Loss: 1.2430, LR: 0.003322
2025-04-25 20:56:58,682 [INFO] Epoch 9/15 - Policy Loss: 1.0529, Value Loss: 0.1892, Total Loss: 1.2420, LR: 0.004972
2025-04-25 20:57:21,154 [INFO] Epoch 10/15 - Policy Loss: 1.0530, Value Loss: 0.1890, Total Loss: 1.2419, LR: 0.003378
2025-04-25 20:57:43,634 [INFO] Epoch 11/15 - Policy Loss: 1.0524, Value Loss: 0.1889, Total Loss: 1.2413, LR: 0.001728
2025-04-25 20:58:06,103 [INFO] Epoch 12/15 - Policy Loss: 1.0518, Value Loss: 0.1888, Total Loss: 1.2406, LR: 0.000078
2025-04-25 20:58:28,573 [INFO] Epoch 13/15 - Policy Loss: 1.0511, Value Loss: 0.1886, Total Loss: 1.2397, LR: 0.001672
2025-04-25 20:58:51,044 [INFO] Epoch 14/15 - Policy Loss: 1.0503, Value Loss: 0.1884, Total Loss: 1.2387, LR: 0.003322
2025-04-25 20:59:13,965 [INFO] Epoch 15/15 - Policy Loss: 1.0495, Value Loss: 0.1882, Total Loss: 1.2377, LR: 0.004972
2025-04-25 20:59:13,981 [INFO] 训练完成，总损失: 1.2377
2025-04-25 20:59:13,981 [INFO] 保存迭代 97 的模型
2025-04-25 20:59:14,437 [INFO] Model saved to ./models/best.pt
2025-04-25 20:59:14,752 [INFO] Model saved to ./models/iteration_97.pt
2025-04-25 20:59:14,752 [INFO] 所有训练迭代完成
2025-04-25 20:59:14,752 [INFO] 开始迭代 98/300
2025-04-25 20:59:14,752 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 21:05:25,092 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 21:05:25,092 [INFO] 保存训练样本
2025-04-25 21:05:27,407 [INFO] 使用 119768 个样本训练神经网络
2025-04-25 21:05:27,407 [INFO] Training with 119768 examples
2025-04-25 21:05:27,407 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-25 21:05:27,697 [INFO] 循环学习率周期大小: 174 步
2025-04-25 21:05:50,179 [INFO] Epoch 1/15 - Policy Loss: 1.0788, Value Loss: 0.2003, Total Loss: 1.2791, LR: 0.001672
2025-04-25 21:06:12,665 [INFO] Epoch 2/15 - Policy Loss: 1.0749, Value Loss: 0.1978, Total Loss: 1.2727, LR: 0.003322
2025-04-25 21:06:35,114 [INFO] Epoch 3/15 - Policy Loss: 1.0735, Value Loss: 0.1975, Total Loss: 1.2709, LR: 0.004972
2025-04-25 21:06:57,571 [INFO] Epoch 4/15 - Policy Loss: 1.0698, Value Loss: 0.1958, Total Loss: 1.2656, LR: 0.003378
2025-04-25 21:07:20,055 [INFO] Epoch 5/15 - Policy Loss: 1.0681, Value Loss: 0.1945, Total Loss: 1.2626, LR: 0.001728
2025-04-25 21:07:42,539 [INFO] Epoch 6/15 - Policy Loss: 1.0638, Value Loss: 0.1936, Total Loss: 1.2575, LR: 0.000078
2025-04-25 21:08:04,999 [INFO] Epoch 7/15 - Policy Loss: 1.0607, Value Loss: 0.1934, Total Loss: 1.2542, LR: 0.001672
2025-04-25 21:08:27,460 [INFO] Epoch 8/15 - Policy Loss: 1.0589, Value Loss: 0.1928, Total Loss: 1.2517, LR: 0.003322
2025-04-25 21:08:49,900 [INFO] Epoch 9/15 - Policy Loss: 1.0578, Value Loss: 0.1925, Total Loss: 1.2503, LR: 0.004972
2025-04-25 21:09:12,366 [INFO] Epoch 10/15 - Policy Loss: 1.0572, Value Loss: 0.1923, Total Loss: 1.2495, LR: 0.003378
2025-04-25 21:09:34,827 [INFO] Epoch 11/15 - Policy Loss: 1.0566, Value Loss: 0.1921, Total Loss: 1.2487, LR: 0.001728
2025-04-25 21:09:57,314 [INFO] Epoch 12/15 - Policy Loss: 1.0551, Value Loss: 0.1916, Total Loss: 1.2467, LR: 0.000078
2025-04-25 21:10:19,809 [INFO] Epoch 13/15 - Policy Loss: 1.0538, Value Loss: 0.1912, Total Loss: 1.2450, LR: 0.001672
2025-04-25 21:10:42,575 [INFO] Epoch 14/15 - Policy Loss: 1.0530, Value Loss: 0.1908, Total Loss: 1.2437, LR: 0.003322
2025-04-25 21:11:05,074 [INFO] Epoch 15/15 - Policy Loss: 1.0525, Value Loss: 0.1905, Total Loss: 1.2430, LR: 0.004972
2025-04-25 21:11:05,089 [INFO] 训练完成，总损失: 1.2430
2025-04-25 21:11:05,089 [INFO] 保存迭代 98 的模型
2025-04-25 21:11:05,535 [INFO] Model saved to ./models/best.pt
2025-04-25 21:11:05,835 [INFO] Model saved to ./models/iteration_98.pt
2025-04-25 21:11:05,835 [INFO] 所有训练迭代完成
2025-04-25 21:11:05,835 [INFO] 开始迭代 99/300
2025-04-25 21:11:05,835 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 21:17:16,750 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 21:17:16,751 [INFO] 保存训练样本
2025-04-25 21:17:19,754 [INFO] 使用 119712 个样本训练神经网络
2025-04-25 21:17:19,755 [INFO] Training with 119712 examples
2025-04-25 21:17:19,755 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-25 21:17:20,090 [INFO] 循环学习率周期大小: 174 步
2025-04-25 21:17:42,578 [INFO] Epoch 1/15 - Policy Loss: 1.0666, Value Loss: 0.2009, Total Loss: 1.2674, LR: 0.001672
2025-04-25 21:18:05,041 [INFO] Epoch 2/15 - Policy Loss: 1.0648, Value Loss: 0.1974, Total Loss: 1.2622, LR: 0.003322
2025-04-25 21:18:27,505 [INFO] Epoch 3/15 - Policy Loss: 1.0634, Value Loss: 0.1948, Total Loss: 1.2582, LR: 0.004972
2025-04-25 21:18:50,027 [INFO] Epoch 4/15 - Policy Loss: 1.0618, Value Loss: 0.1939, Total Loss: 1.2557, LR: 0.003378
2025-04-25 21:19:12,533 [INFO] Epoch 5/15 - Policy Loss: 1.0598, Value Loss: 0.1928, Total Loss: 1.2526, LR: 0.001728
2025-04-25 21:19:35,030 [INFO] Epoch 6/15 - Policy Loss: 1.0575, Value Loss: 0.1924, Total Loss: 1.2498, LR: 0.000078
2025-04-25 21:19:57,573 [INFO] Epoch 7/15 - Policy Loss: 1.0555, Value Loss: 0.1919, Total Loss: 1.2474, LR: 0.001672
2025-04-25 21:20:20,078 [INFO] Epoch 8/15 - Policy Loss: 1.0542, Value Loss: 0.1914, Total Loss: 1.2456, LR: 0.003322
2025-04-25 21:20:42,590 [INFO] Epoch 9/15 - Policy Loss: 1.0529, Value Loss: 0.1910, Total Loss: 1.2439, LR: 0.004972
2025-04-25 21:21:05,106 [INFO] Epoch 10/15 - Policy Loss: 1.0533, Value Loss: 0.1911, Total Loss: 1.2444, LR: 0.003378
2025-04-25 21:21:27,614 [INFO] Epoch 11/15 - Policy Loss: 1.0523, Value Loss: 0.1909, Total Loss: 1.2431, LR: 0.001728
2025-04-25 21:21:50,454 [INFO] Epoch 12/15 - Policy Loss: 1.0514, Value Loss: 0.1904, Total Loss: 1.2418, LR: 0.000078
2025-04-25 21:22:12,983 [INFO] Epoch 13/15 - Policy Loss: 1.0503, Value Loss: 0.1903, Total Loss: 1.2406, LR: 0.001672
2025-04-25 21:22:35,535 [INFO] Epoch 14/15 - Policy Loss: 1.0498, Value Loss: 0.1899, Total Loss: 1.2397, LR: 0.003322
2025-04-25 21:22:58,001 [INFO] Epoch 15/15 - Policy Loss: 1.0493, Value Loss: 0.1897, Total Loss: 1.2389, LR: 0.004972
2025-04-25 21:22:58,024 [INFO] 训练完成，总损失: 1.2389
2025-04-25 21:22:58,024 [INFO] 保存迭代 99 的模型
2025-04-25 21:22:58,547 [INFO] Model saved to ./models/best.pt
2025-04-25 21:22:58,909 [INFO] Model saved to ./models/iteration_99.pt
2025-04-25 21:22:58,910 [INFO] 所有训练迭代完成
2025-04-25 21:22:58,910 [INFO] 开始迭代 100/300
2025-04-25 21:22:58,910 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 21:28:30,457 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 21:28:30,457 [INFO] 保存训练样本
2025-04-25 21:28:33,577 [INFO] 使用 118200 个样本训练神经网络
2025-04-25 21:28:33,577 [INFO] Training with 118200 examples
2025-04-25 21:28:33,577 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-25 21:28:33,930 [INFO] 循环学习率周期大小: 171 步
2025-04-25 21:28:56,091 [INFO] Epoch 1/15 - Policy Loss: 1.0541, Value Loss: 0.1942, Total Loss: 1.2483, LR: 0.001671
2025-04-25 21:29:18,160 [INFO] Epoch 2/15 - Policy Loss: 1.0550, Value Loss: 0.1913, Total Loss: 1.2462, LR: 0.003321
2025-04-25 21:29:40,237 [INFO] Epoch 3/15 - Policy Loss: 1.0536, Value Loss: 0.1907, Total Loss: 1.2443, LR: 0.004971
2025-04-25 21:30:02,342 [INFO] Epoch 4/15 - Policy Loss: 1.0560, Value Loss: 0.1906, Total Loss: 1.2466, LR: 0.003379
2025-04-25 21:30:24,476 [INFO] Epoch 5/15 - Policy Loss: 1.0557, Value Loss: 0.1901, Total Loss: 1.2458, LR: 0.001729
2025-04-25 21:30:46,615 [INFO] Epoch 6/15 - Policy Loss: 1.0545, Value Loss: 0.1891, Total Loss: 1.2436, LR: 0.000079
2025-04-25 21:31:08,917 [INFO] Epoch 7/15 - Policy Loss: 1.0528, Value Loss: 0.1883, Total Loss: 1.2412, LR: 0.001671
2025-04-25 21:31:31,199 [INFO] Epoch 8/15 - Policy Loss: 1.0510, Value Loss: 0.1877, Total Loss: 1.2387, LR: 0.003321
2025-04-25 21:31:53,525 [INFO] Epoch 9/15 - Policy Loss: 1.0495, Value Loss: 0.1872, Total Loss: 1.2367, LR: 0.004971
2025-04-25 21:32:15,890 [INFO] Epoch 10/15 - Policy Loss: 1.0494, Value Loss: 0.1871, Total Loss: 1.2365, LR: 0.003379
2025-04-25 21:32:38,461 [INFO] Epoch 11/15 - Policy Loss: 1.0489, Value Loss: 0.1865, Total Loss: 1.2354, LR: 0.001729
2025-04-25 21:33:00,721 [INFO] Epoch 12/15 - Policy Loss: 1.0487, Value Loss: 0.1863, Total Loss: 1.2350, LR: 0.000079
2025-04-25 21:33:22,961 [INFO] Epoch 13/15 - Policy Loss: 1.0475, Value Loss: 0.1860, Total Loss: 1.2335, LR: 0.001671
2025-04-25 21:33:45,208 [INFO] Epoch 14/15 - Policy Loss: 1.0470, Value Loss: 0.1856, Total Loss: 1.2326, LR: 0.003321
2025-04-25 21:34:07,472 [INFO] Epoch 15/15 - Policy Loss: 1.0464, Value Loss: 0.1853, Total Loss: 1.2317, LR: 0.004971
2025-04-25 21:34:07,490 [INFO] 训练完成，总损失: 1.2317
2025-04-25 21:34:07,490 [INFO] 保存迭代 100 的模型
2025-04-25 21:34:07,883 [INFO] Model saved to ./models/best.pt
2025-04-25 21:34:08,159 [INFO] Model saved to ./models/iteration_100.pt
2025-04-25 21:34:08,160 [INFO] 所有训练迭代完成
2025-04-25 21:34:08,160 [INFO] 开始迭代 101/300
2025-04-25 21:34:08,160 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 21:40:20,723 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 21:40:20,723 [INFO] 保存训练样本
2025-04-25 21:40:23,698 [INFO] 使用 118024 个样本训练神经网络
2025-04-25 21:40:23,698 [INFO] Training with 118024 examples
2025-04-25 21:40:23,698 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-25 21:40:23,749 [INFO] 循环学习率周期大小: 171 步
2025-04-25 21:40:45,822 [INFO] Epoch 1/15 - Policy Loss: 1.0854, Value Loss: 0.1926, Total Loss: 1.2780, LR: 0.001671
2025-04-25 21:41:07,884 [INFO] Epoch 2/15 - Policy Loss: 1.0759, Value Loss: 0.1907, Total Loss: 1.2666, LR: 0.003321
2025-04-25 21:41:30,000 [INFO] Epoch 3/15 - Policy Loss: 1.0717, Value Loss: 0.1884, Total Loss: 1.2601, LR: 0.004971
2025-04-25 21:41:52,111 [INFO] Epoch 4/15 - Policy Loss: 1.0712, Value Loss: 0.1882, Total Loss: 1.2594, LR: 0.003379
2025-04-25 21:42:14,242 [INFO] Epoch 5/15 - Policy Loss: 1.0680, Value Loss: 0.1874, Total Loss: 1.2554, LR: 0.001729
2025-04-25 21:42:36,392 [INFO] Epoch 6/15 - Policy Loss: 1.0648, Value Loss: 0.1861, Total Loss: 1.2510, LR: 0.000079
2025-04-25 21:42:58,596 [INFO] Epoch 7/15 - Policy Loss: 1.0614, Value Loss: 0.1851, Total Loss: 1.2465, LR: 0.001671
2025-04-25 21:43:20,877 [INFO] Epoch 8/15 - Policy Loss: 1.0593, Value Loss: 0.1844, Total Loss: 1.2437, LR: 0.003321
2025-04-25 21:43:43,397 [INFO] Epoch 9/15 - Policy Loss: 1.0582, Value Loss: 0.1840, Total Loss: 1.2423, LR: 0.004971
2025-04-25 21:44:05,599 [INFO] Epoch 10/15 - Policy Loss: 1.0579, Value Loss: 0.1835, Total Loss: 1.2415, LR: 0.003379
2025-04-25 21:44:27,746 [INFO] Epoch 11/15 - Policy Loss: 1.0573, Value Loss: 0.1834, Total Loss: 1.2407, LR: 0.001729
2025-04-25 21:44:49,917 [INFO] Epoch 12/15 - Policy Loss: 1.0561, Value Loss: 0.1832, Total Loss: 1.2394, LR: 0.000079
2025-04-25 21:45:12,115 [INFO] Epoch 13/15 - Policy Loss: 1.0547, Value Loss: 0.1828, Total Loss: 1.2375, LR: 0.001671
2025-04-25 21:45:34,238 [INFO] Epoch 14/15 - Policy Loss: 1.0537, Value Loss: 0.1821, Total Loss: 1.2358, LR: 0.003321
2025-04-25 21:45:56,394 [INFO] Epoch 15/15 - Policy Loss: 1.0530, Value Loss: 0.1820, Total Loss: 1.2350, LR: 0.004971
2025-04-25 21:45:56,409 [INFO] 训练完成，总损失: 1.2350
2025-04-25 21:45:56,409 [INFO] 保存迭代 101 的模型
2025-04-25 21:45:56,852 [INFO] Model saved to ./models/best.pt
2025-04-25 21:45:57,167 [INFO] Model saved to ./models/iteration_101.pt
2025-04-25 21:45:57,168 [INFO] 所有训练迭代完成
2025-04-25 21:45:57,168 [INFO] 开始迭代 102/300
2025-04-25 21:45:57,168 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 21:51:49,681 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 21:51:49,682 [INFO] 保存训练样本
2025-04-25 21:51:52,872 [INFO] 使用 117760 个样本训练神经网络
2025-04-25 21:51:52,872 [INFO] Training with 117760 examples
2025-04-25 21:51:52,873 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-25 21:51:52,912 [INFO] 循环学习率周期大小: 171 步
2025-04-25 21:52:15,046 [INFO] Epoch 1/15 - Policy Loss: 1.0749, Value Loss: 0.1973, Total Loss: 1.2722, LR: 0.001671
2025-04-25 21:52:37,162 [INFO] Epoch 2/15 - Policy Loss: 1.0676, Value Loss: 0.1967, Total Loss: 1.2642, LR: 0.003321
2025-04-25 21:52:59,327 [INFO] Epoch 3/15 - Policy Loss: 1.0661, Value Loss: 0.1943, Total Loss: 1.2604, LR: 0.004971
2025-04-25 21:53:21,477 [INFO] Epoch 4/15 - Policy Loss: 1.0632, Value Loss: 0.1924, Total Loss: 1.2556, LR: 0.003379
2025-04-25 21:53:43,566 [INFO] Epoch 5/15 - Policy Loss: 1.0614, Value Loss: 0.1910, Total Loss: 1.2524, LR: 0.001729
2025-04-25 21:54:06,007 [INFO] Epoch 6/15 - Policy Loss: 1.0579, Value Loss: 0.1894, Total Loss: 1.2473, LR: 0.000079
2025-04-25 21:54:28,181 [INFO] Epoch 7/15 - Policy Loss: 1.0554, Value Loss: 0.1880, Total Loss: 1.2434, LR: 0.001671
2025-04-25 21:54:50,579 [INFO] Epoch 8/15 - Policy Loss: 1.0539, Value Loss: 0.1871, Total Loss: 1.2410, LR: 0.003321
2025-04-25 21:55:12,917 [INFO] Epoch 9/15 - Policy Loss: 1.0533, Value Loss: 0.1865, Total Loss: 1.2398, LR: 0.004971
2025-04-25 21:55:35,263 [INFO] Epoch 10/15 - Policy Loss: 1.0534, Value Loss: 0.1863, Total Loss: 1.2397, LR: 0.003379
2025-04-25 21:55:57,604 [INFO] Epoch 11/15 - Policy Loss: 1.0527, Value Loss: 0.1858, Total Loss: 1.2384, LR: 0.001729
2025-04-25 21:56:19,925 [INFO] Epoch 12/15 - Policy Loss: 1.0518, Value Loss: 0.1852, Total Loss: 1.2371, LR: 0.000079
2025-04-25 21:56:42,252 [INFO] Epoch 13/15 - Policy Loss: 1.0505, Value Loss: 0.1846, Total Loss: 1.2352, LR: 0.001671
2025-04-25 21:57:04,401 [INFO] Epoch 14/15 - Policy Loss: 1.0490, Value Loss: 0.1843, Total Loss: 1.2334, LR: 0.003321
2025-04-25 21:57:26,567 [INFO] Epoch 15/15 - Policy Loss: 1.0487, Value Loss: 0.1841, Total Loss: 1.2328, LR: 0.004971
2025-04-25 21:57:26,583 [INFO] 训练完成，总损失: 1.2328
2025-04-25 21:57:26,583 [INFO] 保存迭代 102 的模型
2025-04-25 21:57:26,979 [INFO] Model saved to ./models/best.pt
2025-04-25 21:57:27,250 [INFO] Model saved to ./models/iteration_102.pt
2025-04-25 21:57:27,250 [INFO] 所有训练迭代完成
2025-04-25 21:57:27,250 [INFO] 开始迭代 103/300
2025-04-25 21:57:27,251 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 22:03:59,067 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 22:03:59,067 [INFO] 保存训练样本
2025-04-25 22:04:02,449 [INFO] 使用 118496 个样本训练神经网络
2025-04-25 22:04:02,449 [INFO] Training with 118496 examples
2025-04-25 22:04:02,450 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-25 22:04:02,493 [INFO] 循环学习率周期大小: 171 步
2025-04-25 22:04:24,747 [INFO] Epoch 1/15 - Policy Loss: 1.0773, Value Loss: 0.1948, Total Loss: 1.2721, LR: 0.001671
2025-04-25 22:04:46,930 [INFO] Epoch 2/15 - Policy Loss: 1.0688, Value Loss: 0.1913, Total Loss: 1.2602, LR: 0.003321
2025-04-25 22:05:09,340 [INFO] Epoch 3/15 - Policy Loss: 1.0648, Value Loss: 0.1897, Total Loss: 1.2544, LR: 0.004971
2025-04-25 22:05:31,438 [INFO] Epoch 4/15 - Policy Loss: 1.0645, Value Loss: 0.1891, Total Loss: 1.2536, LR: 0.003379
2025-04-25 22:05:53,568 [INFO] Epoch 5/15 - Policy Loss: 1.0598, Value Loss: 0.1879, Total Loss: 1.2477, LR: 0.001729
2025-04-25 22:06:15,766 [INFO] Epoch 6/15 - Policy Loss: 1.0568, Value Loss: 0.1867, Total Loss: 1.2435, LR: 0.000079
2025-04-25 22:06:37,916 [INFO] Epoch 7/15 - Policy Loss: 1.0546, Value Loss: 0.1863, Total Loss: 1.2408, LR: 0.001671
2025-04-25 22:07:00,129 [INFO] Epoch 8/15 - Policy Loss: 1.0527, Value Loss: 0.1859, Total Loss: 1.2386, LR: 0.003321
2025-04-25 22:07:22,246 [INFO] Epoch 9/15 - Policy Loss: 1.0512, Value Loss: 0.1855, Total Loss: 1.2367, LR: 0.004971
2025-04-25 22:07:44,384 [INFO] Epoch 10/15 - Policy Loss: 1.0503, Value Loss: 0.1856, Total Loss: 1.2358, LR: 0.003379
2025-04-25 22:08:06,508 [INFO] Epoch 11/15 - Policy Loss: 1.0491, Value Loss: 0.1856, Total Loss: 1.2347, LR: 0.001729
2025-04-25 22:08:28,650 [INFO] Epoch 12/15 - Policy Loss: 1.0481, Value Loss: 0.1852, Total Loss: 1.2333, LR: 0.000079
2025-04-25 22:08:50,762 [INFO] Epoch 13/15 - Policy Loss: 1.0473, Value Loss: 0.1849, Total Loss: 1.2322, LR: 0.001671
2025-04-25 22:09:12,877 [INFO] Epoch 14/15 - Policy Loss: 1.0465, Value Loss: 0.1846, Total Loss: 1.2311, LR: 0.003321
2025-04-25 22:09:35,178 [INFO] Epoch 15/15 - Policy Loss: 1.0466, Value Loss: 0.1846, Total Loss: 1.2312, LR: 0.004971
2025-04-25 22:09:35,193 [INFO] 训练完成，总损失: 1.2312
2025-04-25 22:09:35,193 [INFO] 保存迭代 103 的模型
2025-04-25 22:09:35,581 [INFO] Model saved to ./models/best.pt
2025-04-25 22:09:35,852 [INFO] Model saved to ./models/iteration_103.pt
2025-04-25 22:09:35,853 [INFO] 所有训练迭代完成
2025-04-25 22:09:35,853 [INFO] 开始迭代 104/300
2025-04-25 22:09:35,853 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 22:15:43,792 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 22:15:43,792 [INFO] 保存训练样本
2025-04-25 22:15:46,815 [INFO] 使用 116264 个样本训练神经网络
2025-04-25 22:15:46,816 [INFO] Training with 116264 examples
2025-04-25 22:15:46,816 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 22:15:46,853 [INFO] 循环学习率周期大小: 168 步
2025-04-25 22:16:08,924 [INFO] Epoch 1/15 - Policy Loss: 1.0771, Value Loss: 0.1906, Total Loss: 1.2677, LR: 0.001671
2025-04-25 22:16:30,631 [INFO] Epoch 2/15 - Policy Loss: 1.0702, Value Loss: 0.1873, Total Loss: 1.2575, LR: 0.003321
2025-04-25 22:16:52,300 [INFO] Epoch 3/15 - Policy Loss: 1.0671, Value Loss: 0.1844, Total Loss: 1.2515, LR: 0.004971
2025-04-25 22:17:14,101 [INFO] Epoch 4/15 - Policy Loss: 1.0651, Value Loss: 0.1829, Total Loss: 1.2480, LR: 0.003379
2025-04-25 22:17:35,839 [INFO] Epoch 5/15 - Policy Loss: 1.0623, Value Loss: 0.1811, Total Loss: 1.2434, LR: 0.001729
2025-04-25 22:17:57,550 [INFO] Epoch 6/15 - Policy Loss: 1.0605, Value Loss: 0.1791, Total Loss: 1.2397, LR: 0.000079
2025-04-25 22:18:19,290 [INFO] Epoch 7/15 - Policy Loss: 1.0580, Value Loss: 0.1782, Total Loss: 1.2362, LR: 0.001671
2025-04-25 22:18:41,038 [INFO] Epoch 8/15 - Policy Loss: 1.0561, Value Loss: 0.1768, Total Loss: 1.2329, LR: 0.003321
2025-04-25 22:19:02,764 [INFO] Epoch 9/15 - Policy Loss: 1.0555, Value Loss: 0.1758, Total Loss: 1.2313, LR: 0.004971
2025-04-25 22:19:24,563 [INFO] Epoch 10/15 - Policy Loss: 1.0555, Value Loss: 0.1746, Total Loss: 1.2301, LR: 0.003379
2025-04-25 22:19:46,321 [INFO] Epoch 11/15 - Policy Loss: 1.0548, Value Loss: 0.1740, Total Loss: 1.2289, LR: 0.001729
2025-04-25 22:20:08,054 [INFO] Epoch 12/15 - Policy Loss: 1.0538, Value Loss: 0.1732, Total Loss: 1.2270, LR: 0.000079
2025-04-25 22:20:29,874 [INFO] Epoch 13/15 - Policy Loss: 1.0524, Value Loss: 0.1726, Total Loss: 1.2251, LR: 0.001671
2025-04-25 22:20:51,634 [INFO] Epoch 14/15 - Policy Loss: 1.0510, Value Loss: 0.1721, Total Loss: 1.2231, LR: 0.003321
2025-04-25 22:21:13,380 [INFO] Epoch 15/15 - Policy Loss: 1.0506, Value Loss: 0.1717, Total Loss: 1.2223, LR: 0.004971
2025-04-25 22:21:13,397 [INFO] 训练完成，总损失: 1.2223
2025-04-25 22:21:13,397 [INFO] 保存迭代 104 的模型
2025-04-25 22:21:13,898 [INFO] Model saved to ./models/best.pt
2025-04-25 22:21:14,256 [INFO] Model saved to ./models/iteration_104.pt
2025-04-25 22:21:14,257 [INFO] 所有训练迭代完成
2025-04-25 22:21:14,257 [INFO] 开始迭代 105/300
2025-04-25 22:21:14,257 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 22:28:06,381 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 22:28:06,382 [INFO] 保存训练样本
2025-04-25 22:28:09,145 [INFO] 使用 116304 个样本训练神经网络
2025-04-25 22:28:09,145 [INFO] Training with 116304 examples
2025-04-25 22:28:09,145 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 22:28:09,441 [INFO] 循环学习率周期大小: 168 步
2025-04-25 22:28:31,076 [INFO] Epoch 1/15 - Policy Loss: 1.0842, Value Loss: 0.1938, Total Loss: 1.2780, LR: 0.001671
2025-04-25 22:28:52,733 [INFO] Epoch 2/15 - Policy Loss: 1.0812, Value Loss: 0.1877, Total Loss: 1.2689, LR: 0.003321
2025-04-25 22:29:14,350 [INFO] Epoch 3/15 - Policy Loss: 1.0766, Value Loss: 0.1846, Total Loss: 1.2613, LR: 0.004971
2025-04-25 22:29:35,976 [INFO] Epoch 4/15 - Policy Loss: 1.0731, Value Loss: 0.1813, Total Loss: 1.2544, LR: 0.003379
2025-04-25 22:29:57,604 [INFO] Epoch 5/15 - Policy Loss: 1.0708, Value Loss: 0.1799, Total Loss: 1.2508, LR: 0.001729
2025-04-25 22:30:19,238 [INFO] Epoch 6/15 - Policy Loss: 1.0678, Value Loss: 0.1789, Total Loss: 1.2467, LR: 0.000079
2025-04-25 22:30:40,889 [INFO] Epoch 7/15 - Policy Loss: 1.0653, Value Loss: 0.1776, Total Loss: 1.2429, LR: 0.001671
2025-04-25 22:31:02,547 [INFO] Epoch 8/15 - Policy Loss: 1.0634, Value Loss: 0.1765, Total Loss: 1.2399, LR: 0.003321
2025-04-25 22:31:24,221 [INFO] Epoch 9/15 - Policy Loss: 1.0619, Value Loss: 0.1758, Total Loss: 1.2377, LR: 0.004971
2025-04-25 22:31:45,899 [INFO] Epoch 10/15 - Policy Loss: 1.0615, Value Loss: 0.1751, Total Loss: 1.2366, LR: 0.003379
2025-04-25 22:32:07,556 [INFO] Epoch 11/15 - Policy Loss: 1.0602, Value Loss: 0.1744, Total Loss: 1.2346, LR: 0.001729
2025-04-25 22:32:29,236 [INFO] Epoch 12/15 - Policy Loss: 1.0583, Value Loss: 0.1735, Total Loss: 1.2318, LR: 0.000079
2025-04-25 22:32:50,906 [INFO] Epoch 13/15 - Policy Loss: 1.0575, Value Loss: 0.1729, Total Loss: 1.2304, LR: 0.001671
2025-04-25 22:33:12,589 [INFO] Epoch 14/15 - Policy Loss: 1.0564, Value Loss: 0.1726, Total Loss: 1.2290, LR: 0.003321
2025-04-25 22:33:34,254 [INFO] Epoch 15/15 - Policy Loss: 1.0556, Value Loss: 0.1723, Total Loss: 1.2279, LR: 0.004971
2025-04-25 22:33:34,268 [INFO] 训练完成，总损失: 1.2279
2025-04-25 22:33:34,269 [INFO] 保存迭代 105 的模型
2025-04-25 22:33:34,696 [INFO] Model saved to ./models/best.pt
2025-04-25 22:33:34,966 [INFO] Model saved to ./models/iteration_105.pt
2025-04-25 22:33:34,967 [INFO] 所有训练迭代完成
2025-04-25 22:33:34,967 [INFO] 开始迭代 106/300
2025-04-25 22:33:34,967 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 22:40:03,005 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 22:40:03,006 [INFO] 保存训练样本
2025-04-25 22:40:06,257 [INFO] 使用 116328 个样本训练神经网络
2025-04-25 22:40:06,257 [INFO] Training with 116328 examples
2025-04-25 22:40:06,257 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 22:40:06,593 [INFO] 循环学习率周期大小: 168 步
2025-04-25 22:40:28,288 [INFO] Epoch 1/15 - Policy Loss: 1.0812, Value Loss: 0.1970, Total Loss: 1.2781, LR: 0.001671
2025-04-25 22:40:49,993 [INFO] Epoch 2/15 - Policy Loss: 1.0766, Value Loss: 0.1910, Total Loss: 1.2676, LR: 0.003321
2025-04-25 22:41:11,699 [INFO] Epoch 3/15 - Policy Loss: 1.0709, Value Loss: 0.1880, Total Loss: 1.2588, LR: 0.004971
2025-04-25 22:41:33,377 [INFO] Epoch 4/15 - Policy Loss: 1.0700, Value Loss: 0.1852, Total Loss: 1.2552, LR: 0.003379
2025-04-25 22:41:55,067 [INFO] Epoch 5/15 - Policy Loss: 1.0672, Value Loss: 0.1830, Total Loss: 1.2502, LR: 0.001729
2025-04-25 22:42:16,731 [INFO] Epoch 6/15 - Policy Loss: 1.0649, Value Loss: 0.1815, Total Loss: 1.2465, LR: 0.000079
2025-04-25 22:42:38,393 [INFO] Epoch 7/15 - Policy Loss: 1.0622, Value Loss: 0.1803, Total Loss: 1.2425, LR: 0.001671
2025-04-25 22:43:00,057 [INFO] Epoch 8/15 - Policy Loss: 1.0610, Value Loss: 0.1798, Total Loss: 1.2407, LR: 0.003321
2025-04-25 22:43:21,795 [INFO] Epoch 9/15 - Policy Loss: 1.0598, Value Loss: 0.1793, Total Loss: 1.2391, LR: 0.004971
2025-04-25 22:43:43,459 [INFO] Epoch 10/15 - Policy Loss: 1.0592, Value Loss: 0.1790, Total Loss: 1.2382, LR: 0.003379
2025-04-25 22:44:05,089 [INFO] Epoch 11/15 - Policy Loss: 1.0581, Value Loss: 0.1784, Total Loss: 1.2365, LR: 0.001729
2025-04-25 22:44:26,753 [INFO] Epoch 12/15 - Policy Loss: 1.0565, Value Loss: 0.1779, Total Loss: 1.2344, LR: 0.000079
2025-04-25 22:44:48,446 [INFO] Epoch 13/15 - Policy Loss: 1.0554, Value Loss: 0.1774, Total Loss: 1.2328, LR: 0.001671
2025-04-25 22:45:10,118 [INFO] Epoch 14/15 - Policy Loss: 1.0544, Value Loss: 0.1772, Total Loss: 1.2316, LR: 0.003321
2025-04-25 22:45:32,038 [INFO] Epoch 15/15 - Policy Loss: 1.0533, Value Loss: 0.1771, Total Loss: 1.2304, LR: 0.004971
2025-04-25 22:45:32,055 [INFO] 训练完成，总损失: 1.2304
2025-04-25 22:45:32,055 [INFO] 保存迭代 106 的模型
2025-04-25 22:45:32,560 [INFO] Model saved to ./models/best.pt
2025-04-25 22:45:32,926 [INFO] Model saved to ./models/iteration_106.pt
2025-04-25 22:45:32,926 [INFO] 所有训练迭代完成
2025-04-25 22:45:32,926 [INFO] 开始迭代 107/300
2025-04-25 22:45:32,926 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 22:51:58,319 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 22:51:58,320 [INFO] 保存训练样本
2025-04-25 22:52:01,173 [INFO] 使用 115808 个样本训练神经网络
2025-04-25 22:52:01,174 [INFO] Training with 115808 examples
2025-04-25 22:52:01,174 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 22:52:01,480 [INFO] 循环学习率周期大小: 168 步
2025-04-25 22:52:23,321 [INFO] Epoch 1/15 - Policy Loss: 1.0770, Value Loss: 0.2051, Total Loss: 1.2821, LR: 0.001671
2025-04-25 22:52:45,060 [INFO] Epoch 2/15 - Policy Loss: 1.0725, Value Loss: 0.2005, Total Loss: 1.2730, LR: 0.003321
2025-04-25 22:53:06,768 [INFO] Epoch 3/15 - Policy Loss: 1.0679, Value Loss: 0.1962, Total Loss: 1.2641, LR: 0.004971
2025-04-25 22:53:28,500 [INFO] Epoch 4/15 - Policy Loss: 1.0649, Value Loss: 0.1940, Total Loss: 1.2589, LR: 0.003379
2025-04-25 22:53:50,223 [INFO] Epoch 5/15 - Policy Loss: 1.0609, Value Loss: 0.1919, Total Loss: 1.2528, LR: 0.001729
2025-04-25 22:54:11,910 [INFO] Epoch 6/15 - Policy Loss: 1.0594, Value Loss: 0.1910, Total Loss: 1.2504, LR: 0.000079
2025-04-25 22:54:33,631 [INFO] Epoch 7/15 - Policy Loss: 1.0569, Value Loss: 0.1896, Total Loss: 1.2464, LR: 0.001671
2025-04-25 22:54:55,314 [INFO] Epoch 8/15 - Policy Loss: 1.0553, Value Loss: 0.1882, Total Loss: 1.2435, LR: 0.003321
2025-04-25 22:55:16,977 [INFO] Epoch 9/15 - Policy Loss: 1.0543, Value Loss: 0.1877, Total Loss: 1.2419, LR: 0.004971
2025-04-25 22:55:38,701 [INFO] Epoch 10/15 - Policy Loss: 1.0537, Value Loss: 0.1872, Total Loss: 1.2409, LR: 0.003379
2025-04-25 22:56:00,544 [INFO] Epoch 11/15 - Policy Loss: 1.0531, Value Loss: 0.1866, Total Loss: 1.2398, LR: 0.001729
2025-04-25 22:56:22,458 [INFO] Epoch 12/15 - Policy Loss: 1.0522, Value Loss: 0.1859, Total Loss: 1.2381, LR: 0.000079
2025-04-25 22:56:44,314 [INFO] Epoch 13/15 - Policy Loss: 1.0516, Value Loss: 0.1853, Total Loss: 1.2370, LR: 0.001671
2025-04-25 22:57:06,187 [INFO] Epoch 14/15 - Policy Loss: 1.0507, Value Loss: 0.1847, Total Loss: 1.2354, LR: 0.003321
2025-04-25 22:57:28,346 [INFO] Epoch 15/15 - Policy Loss: 1.0501, Value Loss: 0.1843, Total Loss: 1.2344, LR: 0.004971
2025-04-25 22:57:28,363 [INFO] 训练完成，总损失: 1.2344
2025-04-25 22:57:28,363 [INFO] 保存迭代 107 的模型
2025-04-25 22:57:28,828 [INFO] Model saved to ./models/best.pt
2025-04-25 22:57:29,218 [INFO] Model saved to ./models/iteration_107.pt
2025-04-25 22:57:29,219 [INFO] 所有训练迭代完成
2025-04-25 22:57:29,219 [INFO] 开始迭代 108/300
2025-04-25 22:57:29,219 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 23:04:49,734 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 23:04:49,735 [INFO] 保存训练样本
2025-04-25 23:04:52,836 [INFO] 使用 116624 个样本训练神经网络
2025-04-25 23:04:52,837 [INFO] Training with 116624 examples
2025-04-25 23:04:52,837 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 23:04:53,197 [INFO] 循环学习率周期大小: 168 步
2025-04-25 23:05:15,112 [INFO] Epoch 1/15 - Policy Loss: 1.0858, Value Loss: 0.2043, Total Loss: 1.2901, LR: 0.001671
2025-04-25 23:05:37,001 [INFO] Epoch 2/15 - Policy Loss: 1.0796, Value Loss: 0.1995, Total Loss: 1.2791, LR: 0.003321
2025-04-25 23:05:58,803 [INFO] Epoch 3/15 - Policy Loss: 1.0744, Value Loss: 0.1977, Total Loss: 1.2721, LR: 0.004971
2025-04-25 23:06:20,532 [INFO] Epoch 4/15 - Policy Loss: 1.0702, Value Loss: 0.1943, Total Loss: 1.2645, LR: 0.003379
2025-04-25 23:06:42,293 [INFO] Epoch 5/15 - Policy Loss: 1.0669, Value Loss: 0.1928, Total Loss: 1.2598, LR: 0.001729
2025-04-25 23:07:04,059 [INFO] Epoch 6/15 - Policy Loss: 1.0641, Value Loss: 0.1915, Total Loss: 1.2556, LR: 0.000079
2025-04-25 23:07:26,021 [INFO] Epoch 7/15 - Policy Loss: 1.0611, Value Loss: 0.1900, Total Loss: 1.2511, LR: 0.001671
2025-04-25 23:07:47,999 [INFO] Epoch 8/15 - Policy Loss: 1.0593, Value Loss: 0.1891, Total Loss: 1.2483, LR: 0.003321
2025-04-25 23:08:10,022 [INFO] Epoch 9/15 - Policy Loss: 1.0571, Value Loss: 0.1879, Total Loss: 1.2450, LR: 0.004971
2025-04-25 23:08:32,055 [INFO] Epoch 10/15 - Policy Loss: 1.0559, Value Loss: 0.1872, Total Loss: 1.2431, LR: 0.003379
2025-04-25 23:08:54,021 [INFO] Epoch 11/15 - Policy Loss: 1.0553, Value Loss: 0.1866, Total Loss: 1.2419, LR: 0.001729
2025-04-25 23:09:15,971 [INFO] Epoch 12/15 - Policy Loss: 1.0531, Value Loss: 0.1861, Total Loss: 1.2392, LR: 0.000079
2025-04-25 23:09:37,959 [INFO] Epoch 13/15 - Policy Loss: 1.0517, Value Loss: 0.1859, Total Loss: 1.2377, LR: 0.001671
2025-04-25 23:10:00,246 [INFO] Epoch 14/15 - Policy Loss: 1.0510, Value Loss: 0.1854, Total Loss: 1.2364, LR: 0.003321
2025-04-25 23:10:22,222 [INFO] Epoch 15/15 - Policy Loss: 1.0502, Value Loss: 0.1850, Total Loss: 1.2352, LR: 0.004971
2025-04-25 23:10:22,239 [INFO] 训练完成，总损失: 1.2352
2025-04-25 23:10:22,239 [INFO] 保存迭代 108 的模型
2025-04-25 23:10:22,651 [INFO] Model saved to ./models/best.pt
2025-04-25 23:10:22,941 [INFO] Model saved to ./models/iteration_108.pt
2025-04-25 23:10:22,941 [INFO] 所有训练迭代完成
2025-04-25 23:10:22,941 [INFO] 开始迭代 109/300
2025-04-25 23:10:22,941 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 23:16:51,141 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 23:16:51,142 [INFO] 保存训练样本
2025-04-25 23:16:53,997 [INFO] 使用 116224 个样本训练神经网络
2025-04-25 23:16:53,997 [INFO] Training with 116224 examples
2025-04-25 23:16:53,998 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 23:16:54,327 [INFO] 循环学习率周期大小: 168 步
2025-04-25 23:17:16,261 [INFO] Epoch 1/15 - Policy Loss: 1.0758, Value Loss: 0.1988, Total Loss: 1.2745, LR: 0.001671
2025-04-25 23:17:38,076 [INFO] Epoch 2/15 - Policy Loss: 1.0676, Value Loss: 0.1964, Total Loss: 1.2640, LR: 0.003321
2025-04-25 23:17:59,855 [INFO] Epoch 3/15 - Policy Loss: 1.0643, Value Loss: 0.1952, Total Loss: 1.2595, LR: 0.004971
2025-04-25 23:18:21,652 [INFO] Epoch 4/15 - Policy Loss: 1.0619, Value Loss: 0.1944, Total Loss: 1.2563, LR: 0.003379
2025-04-25 23:18:43,395 [INFO] Epoch 5/15 - Policy Loss: 1.0603, Value Loss: 0.1929, Total Loss: 1.2532, LR: 0.001729
2025-04-25 23:19:05,154 [INFO] Epoch 6/15 - Policy Loss: 1.0564, Value Loss: 0.1921, Total Loss: 1.2485, LR: 0.000079
2025-04-25 23:19:26,888 [INFO] Epoch 7/15 - Policy Loss: 1.0553, Value Loss: 0.1913, Total Loss: 1.2466, LR: 0.001671
2025-04-25 23:19:48,837 [INFO] Epoch 8/15 - Policy Loss: 1.0531, Value Loss: 0.1904, Total Loss: 1.2435, LR: 0.003321
2025-04-25 23:20:10,621 [INFO] Epoch 9/15 - Policy Loss: 1.0523, Value Loss: 0.1902, Total Loss: 1.2424, LR: 0.004971
2025-04-25 23:20:32,417 [INFO] Epoch 10/15 - Policy Loss: 1.0516, Value Loss: 0.1898, Total Loss: 1.2414, LR: 0.003379
2025-04-25 23:20:54,151 [INFO] Epoch 11/15 - Policy Loss: 1.0507, Value Loss: 0.1896, Total Loss: 1.2403, LR: 0.001729
2025-04-25 23:21:16,197 [INFO] Epoch 12/15 - Policy Loss: 1.0492, Value Loss: 0.1891, Total Loss: 1.2383, LR: 0.000079
2025-04-25 23:21:37,955 [INFO] Epoch 13/15 - Policy Loss: 1.0481, Value Loss: 0.1885, Total Loss: 1.2366, LR: 0.001671
2025-04-25 23:21:59,704 [INFO] Epoch 14/15 - Policy Loss: 1.0469, Value Loss: 0.1882, Total Loss: 1.2351, LR: 0.003321
2025-04-25 23:22:21,468 [INFO] Epoch 15/15 - Policy Loss: 1.0463, Value Loss: 0.1880, Total Loss: 1.2343, LR: 0.004971
2025-04-25 23:22:21,483 [INFO] 训练完成，总损失: 1.2343
2025-04-25 23:22:21,484 [INFO] 保存迭代 109 的模型
2025-04-25 23:22:21,929 [INFO] Model saved to ./models/best.pt
2025-04-25 23:22:22,241 [INFO] Model saved to ./models/iteration_109.pt
2025-04-25 23:22:22,242 [INFO] 所有训练迭代完成
2025-04-25 23:22:22,242 [INFO] 开始迭代 110/300
2025-04-25 23:22:22,242 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 23:28:34,182 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 23:28:34,182 [INFO] 保存训练样本
2025-04-25 23:28:37,127 [INFO] 使用 116392 个样本训练神经网络
2025-04-25 23:28:37,128 [INFO] Training with 116392 examples
2025-04-25 23:28:37,128 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 23:28:37,480 [INFO] 循环学习率周期大小: 168 步
2025-04-25 23:28:59,224 [INFO] Epoch 1/15 - Policy Loss: 1.0669, Value Loss: 0.2036, Total Loss: 1.2706, LR: 0.001671
2025-04-25 23:29:20,967 [INFO] Epoch 2/15 - Policy Loss: 1.0606, Value Loss: 0.2010, Total Loss: 1.2616, LR: 0.003321
2025-04-25 23:29:42,778 [INFO] Epoch 3/15 - Policy Loss: 1.0575, Value Loss: 0.1987, Total Loss: 1.2562, LR: 0.004971
2025-04-25 23:30:04,528 [INFO] Epoch 4/15 - Policy Loss: 1.0561, Value Loss: 0.1974, Total Loss: 1.2534, LR: 0.003379
2025-04-25 23:30:26,252 [INFO] Epoch 5/15 - Policy Loss: 1.0541, Value Loss: 0.1955, Total Loss: 1.2496, LR: 0.001729
2025-04-25 23:30:48,010 [INFO] Epoch 6/15 - Policy Loss: 1.0509, Value Loss: 0.1943, Total Loss: 1.2452, LR: 0.000079
2025-04-25 23:31:09,744 [INFO] Epoch 7/15 - Policy Loss: 1.0488, Value Loss: 0.1932, Total Loss: 1.2420, LR: 0.001671
2025-04-25 23:31:31,464 [INFO] Epoch 8/15 - Policy Loss: 1.0475, Value Loss: 0.1927, Total Loss: 1.2401, LR: 0.003321
2025-04-25 23:31:53,211 [INFO] Epoch 9/15 - Policy Loss: 1.0467, Value Loss: 0.1922, Total Loss: 1.2389, LR: 0.004971
2025-04-25 23:32:15,070 [INFO] Epoch 10/15 - Policy Loss: 1.0467, Value Loss: 0.1917, Total Loss: 1.2384, LR: 0.003379
2025-04-25 23:32:37,047 [INFO] Epoch 11/15 - Policy Loss: 1.0460, Value Loss: 0.1911, Total Loss: 1.2371, LR: 0.001729
2025-04-25 23:32:58,878 [INFO] Epoch 12/15 - Policy Loss: 1.0452, Value Loss: 0.1907, Total Loss: 1.2359, LR: 0.000079
2025-04-25 23:33:20,634 [INFO] Epoch 13/15 - Policy Loss: 1.0441, Value Loss: 0.1902, Total Loss: 1.2343, LR: 0.001671
2025-04-25 23:33:42,524 [INFO] Epoch 14/15 - Policy Loss: 1.0433, Value Loss: 0.1898, Total Loss: 1.2331, LR: 0.003321
2025-04-25 23:34:04,266 [INFO] Epoch 15/15 - Policy Loss: 1.0426, Value Loss: 0.1895, Total Loss: 1.2321, LR: 0.004971
2025-04-25 23:34:04,283 [INFO] 训练完成，总损失: 1.2321
2025-04-25 23:34:04,283 [INFO] 保存迭代 110 的模型
2025-04-25 23:34:04,722 [INFO] Model saved to ./models/best.pt
2025-04-25 23:34:05,009 [INFO] Model saved to ./models/iteration_110.pt
2025-04-25 23:34:05,010 [INFO] 所有训练迭代完成
2025-04-25 23:34:05,010 [INFO] 开始迭代 111/300
2025-04-25 23:34:05,010 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 23:40:26,462 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 23:40:26,463 [INFO] 保存训练样本
2025-04-25 23:40:29,912 [INFO] 使用 116264 个样本训练神经网络
2025-04-25 23:40:29,912 [INFO] Training with 116264 examples
2025-04-25 23:40:29,913 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 23:40:29,957 [INFO] 循环学习率周期大小: 168 步
2025-04-25 23:40:51,877 [INFO] Epoch 1/15 - Policy Loss: 1.0726, Value Loss: 0.1977, Total Loss: 1.2702, LR: 0.001671
2025-04-25 23:41:13,793 [INFO] Epoch 2/15 - Policy Loss: 1.0643, Value Loss: 0.1941, Total Loss: 1.2584, LR: 0.003321
2025-04-25 23:41:35,710 [INFO] Epoch 3/15 - Policy Loss: 1.0592, Value Loss: 0.1919, Total Loss: 1.2511, LR: 0.004971
2025-04-25 23:41:57,608 [INFO] Epoch 4/15 - Policy Loss: 1.0560, Value Loss: 0.1911, Total Loss: 1.2471, LR: 0.003379
2025-04-25 23:42:19,540 [INFO] Epoch 5/15 - Policy Loss: 1.0526, Value Loss: 0.1903, Total Loss: 1.2429, LR: 0.001729
2025-04-25 23:42:41,480 [INFO] Epoch 6/15 - Policy Loss: 1.0495, Value Loss: 0.1898, Total Loss: 1.2394, LR: 0.000079
2025-04-25 23:43:03,404 [INFO] Epoch 7/15 - Policy Loss: 1.0472, Value Loss: 0.1890, Total Loss: 1.2361, LR: 0.001671
2025-04-25 23:43:25,725 [INFO] Epoch 8/15 - Policy Loss: 1.0454, Value Loss: 0.1884, Total Loss: 1.2338, LR: 0.003321
2025-04-25 23:43:47,700 [INFO] Epoch 9/15 - Policy Loss: 1.0433, Value Loss: 0.1876, Total Loss: 1.2309, LR: 0.004971
2025-04-25 23:44:09,619 [INFO] Epoch 10/15 - Policy Loss: 1.0425, Value Loss: 0.1874, Total Loss: 1.2300, LR: 0.003379
2025-04-25 23:44:31,518 [INFO] Epoch 11/15 - Policy Loss: 1.0417, Value Loss: 0.1870, Total Loss: 1.2286, LR: 0.001729
2025-04-25 23:44:53,437 [INFO] Epoch 12/15 - Policy Loss: 1.0401, Value Loss: 0.1862, Total Loss: 1.2263, LR: 0.000079
2025-04-25 23:45:15,324 [INFO] Epoch 13/15 - Policy Loss: 1.0395, Value Loss: 0.1859, Total Loss: 1.2254, LR: 0.001671
2025-04-25 23:45:37,290 [INFO] Epoch 14/15 - Policy Loss: 1.0392, Value Loss: 0.1858, Total Loss: 1.2250, LR: 0.003321
2025-04-25 23:45:59,248 [INFO] Epoch 15/15 - Policy Loss: 1.0384, Value Loss: 0.1856, Total Loss: 1.2240, LR: 0.004971
2025-04-25 23:45:59,271 [INFO] 训练完成，总损失: 1.2240
2025-04-25 23:45:59,271 [INFO] 保存迭代 111 的模型
2025-04-25 23:45:59,741 [INFO] Model saved to ./models/best.pt
2025-04-25 23:46:00,058 [INFO] Model saved to ./models/iteration_111.pt
2025-04-25 23:46:00,059 [INFO] 所有训练迭代完成
2025-04-25 23:46:00,059 [INFO] 开始迭代 112/300
2025-04-25 23:46:00,059 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-25 23:52:58,766 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-25 23:52:58,767 [INFO] 保存训练样本
2025-04-25 23:53:02,213 [INFO] 使用 116648 个样本训练神经网络
2025-04-25 23:53:02,213 [INFO] Training with 116648 examples
2025-04-25 23:53:02,213 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-25 23:53:02,275 [INFO] 循环学习率周期大小: 168 步
2025-04-25 23:53:23,987 [INFO] Epoch 1/15 - Policy Loss: 1.0685, Value Loss: 0.2041, Total Loss: 1.2726, LR: 0.001671
2025-04-25 23:53:45,690 [INFO] Epoch 2/15 - Policy Loss: 1.0625, Value Loss: 0.2012, Total Loss: 1.2637, LR: 0.003321
2025-04-25 23:54:07,380 [INFO] Epoch 3/15 - Policy Loss: 1.0600, Value Loss: 0.2009, Total Loss: 1.2609, LR: 0.004971
2025-04-25 23:54:29,057 [INFO] Epoch 4/15 - Policy Loss: 1.0583, Value Loss: 0.2007, Total Loss: 1.2590, LR: 0.003379
2025-04-25 23:54:50,712 [INFO] Epoch 5/15 - Policy Loss: 1.0552, Value Loss: 0.1994, Total Loss: 1.2546, LR: 0.001729
2025-04-25 23:55:12,677 [INFO] Epoch 6/15 - Policy Loss: 1.0523, Value Loss: 0.1983, Total Loss: 1.2505, LR: 0.000079
2025-04-25 23:55:34,328 [INFO] Epoch 7/15 - Policy Loss: 1.0502, Value Loss: 0.1972, Total Loss: 1.2474, LR: 0.001671
2025-04-25 23:55:55,982 [INFO] Epoch 8/15 - Policy Loss: 1.0480, Value Loss: 0.1961, Total Loss: 1.2442, LR: 0.003321
2025-04-25 23:56:17,645 [INFO] Epoch 9/15 - Policy Loss: 1.0461, Value Loss: 0.1956, Total Loss: 1.2418, LR: 0.004971
2025-04-25 23:56:39,301 [INFO] Epoch 10/15 - Policy Loss: 1.0454, Value Loss: 0.1952, Total Loss: 1.2407, LR: 0.003379
2025-04-25 23:57:00,991 [INFO] Epoch 11/15 - Policy Loss: 1.0443, Value Loss: 0.1946, Total Loss: 1.2389, LR: 0.001729
2025-04-25 23:57:22,681 [INFO] Epoch 12/15 - Policy Loss: 1.0434, Value Loss: 0.1941, Total Loss: 1.2375, LR: 0.000079
2025-04-25 23:57:44,352 [INFO] Epoch 13/15 - Policy Loss: 1.0415, Value Loss: 0.1936, Total Loss: 1.2351, LR: 0.001671
2025-04-25 23:58:06,007 [INFO] Epoch 14/15 - Policy Loss: 1.0403, Value Loss: 0.1934, Total Loss: 1.2337, LR: 0.003321
2025-04-25 23:58:27,683 [INFO] Epoch 15/15 - Policy Loss: 1.0397, Value Loss: 0.1930, Total Loss: 1.2327, LR: 0.004971
2025-04-25 23:58:27,697 [INFO] 训练完成，总损失: 1.2327
2025-04-25 23:58:27,697 [INFO] 保存迭代 112 的模型
2025-04-25 23:58:28,128 [INFO] Model saved to ./models/best.pt
2025-04-25 23:58:28,404 [INFO] Model saved to ./models/iteration_112.pt
2025-04-25 23:58:28,405 [INFO] 所有训练迭代完成
2025-04-25 23:58:28,405 [INFO] 开始迭代 113/300
2025-04-25 23:58:28,405 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 00:04:24,865 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 00:04:24,866 [INFO] 保存训练样本
2025-04-26 00:04:28,295 [INFO] 使用 116512 个样本训练神经网络
2025-04-26 00:04:28,295 [INFO] Training with 116512 examples
2025-04-26 00:04:28,296 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-26 00:04:28,331 [INFO] 循环学习率周期大小: 168 步
2025-04-26 00:04:50,277 [INFO] Epoch 1/15 - Policy Loss: 1.0668, Value Loss: 0.2107, Total Loss: 1.2775, LR: 0.001671
2025-04-26 00:05:12,251 [INFO] Epoch 2/15 - Policy Loss: 1.0587, Value Loss: 0.2075, Total Loss: 1.2662, LR: 0.003321
2025-04-26 00:05:34,382 [INFO] Epoch 3/15 - Policy Loss: 1.0567, Value Loss: 0.2056, Total Loss: 1.2623, LR: 0.004971
2025-04-26 00:05:56,092 [INFO] Epoch 4/15 - Policy Loss: 1.0558, Value Loss: 0.2041, Total Loss: 1.2599, LR: 0.003379
2025-04-26 00:06:17,750 [INFO] Epoch 5/15 - Policy Loss: 1.0520, Value Loss: 0.2025, Total Loss: 1.2545, LR: 0.001729
2025-04-26 00:06:39,403 [INFO] Epoch 6/15 - Policy Loss: 1.0496, Value Loss: 0.2012, Total Loss: 1.2507, LR: 0.000079
2025-04-26 00:07:01,080 [INFO] Epoch 7/15 - Policy Loss: 1.0467, Value Loss: 0.2002, Total Loss: 1.2469, LR: 0.001671
2025-04-26 00:07:22,727 [INFO] Epoch 8/15 - Policy Loss: 1.0450, Value Loss: 0.1994, Total Loss: 1.2444, LR: 0.003321
2025-04-26 00:07:44,396 [INFO] Epoch 9/15 - Policy Loss: 1.0436, Value Loss: 0.1989, Total Loss: 1.2425, LR: 0.004971
2025-04-26 00:08:06,064 [INFO] Epoch 10/15 - Policy Loss: 1.0436, Value Loss: 0.1987, Total Loss: 1.2423, LR: 0.003379
2025-04-26 00:08:27,714 [INFO] Epoch 11/15 - Policy Loss: 1.0427, Value Loss: 0.1986, Total Loss: 1.2413, LR: 0.001729
2025-04-26 00:08:49,360 [INFO] Epoch 12/15 - Policy Loss: 1.0414, Value Loss: 0.1980, Total Loss: 1.2394, LR: 0.000079
2025-04-26 00:09:11,017 [INFO] Epoch 13/15 - Policy Loss: 1.0400, Value Loss: 0.1977, Total Loss: 1.2377, LR: 0.001671
2025-04-26 00:09:32,667 [INFO] Epoch 14/15 - Policy Loss: 1.0387, Value Loss: 0.1974, Total Loss: 1.2361, LR: 0.003321
2025-04-26 00:09:54,356 [INFO] Epoch 15/15 - Policy Loss: 1.0378, Value Loss: 0.1972, Total Loss: 1.2350, LR: 0.004971
2025-04-26 00:09:54,371 [INFO] 训练完成，总损失: 1.2350
2025-04-26 00:09:54,371 [INFO] 保存迭代 113 的模型
2025-04-26 00:09:54,818 [INFO] Model saved to ./models/best.pt
2025-04-26 00:09:55,119 [INFO] Model saved to ./models/iteration_113.pt
2025-04-26 00:09:55,119 [INFO] 所有训练迭代完成
2025-04-26 00:09:55,119 [INFO] 开始迭代 114/300
2025-04-26 00:09:55,119 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 00:16:47,483 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 00:16:47,483 [INFO] 保存训练样本
2025-04-26 00:16:50,014 [INFO] 使用 115888 个样本训练神经网络
2025-04-26 00:16:50,014 [INFO] Training with 115888 examples
2025-04-26 00:16:50,014 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-26 00:16:50,336 [INFO] 循环学习率周期大小: 168 步
2025-04-26 00:17:12,228 [INFO] Epoch 1/15 - Policy Loss: 1.0865, Value Loss: 0.2158, Total Loss: 1.3022, LR: 0.001671
2025-04-26 00:17:34,210 [INFO] Epoch 2/15 - Policy Loss: 1.0735, Value Loss: 0.2114, Total Loss: 1.2849, LR: 0.003321
2025-04-26 00:17:55,982 [INFO] Epoch 3/15 - Policy Loss: 1.0686, Value Loss: 0.2098, Total Loss: 1.2784, LR: 0.004971
2025-04-26 00:18:17,735 [INFO] Epoch 4/15 - Policy Loss: 1.0649, Value Loss: 0.2082, Total Loss: 1.2731, LR: 0.003379
2025-04-26 00:18:39,477 [INFO] Epoch 5/15 - Policy Loss: 1.0613, Value Loss: 0.2071, Total Loss: 1.2684, LR: 0.001729
2025-04-26 00:19:01,254 [INFO] Epoch 6/15 - Policy Loss: 1.0570, Value Loss: 0.2066, Total Loss: 1.2636, LR: 0.000079
2025-04-26 00:19:23,028 [INFO] Epoch 7/15 - Policy Loss: 1.0544, Value Loss: 0.2056, Total Loss: 1.2600, LR: 0.001671
2025-04-26 00:19:44,914 [INFO] Epoch 8/15 - Policy Loss: 1.0520, Value Loss: 0.2048, Total Loss: 1.2569, LR: 0.003321
2025-04-26 00:20:06,900 [INFO] Epoch 9/15 - Policy Loss: 1.0507, Value Loss: 0.2044, Total Loss: 1.2551, LR: 0.004971
2025-04-26 00:20:28,896 [INFO] Epoch 10/15 - Policy Loss: 1.0496, Value Loss: 0.2037, Total Loss: 1.2533, LR: 0.003379
2025-04-26 00:20:50,905 [INFO] Epoch 11/15 - Policy Loss: 1.0488, Value Loss: 0.2034, Total Loss: 1.2522, LR: 0.001729
2025-04-26 00:21:12,720 [INFO] Epoch 12/15 - Policy Loss: 1.0471, Value Loss: 0.2029, Total Loss: 1.2499, LR: 0.000079
2025-04-26 00:21:34,456 [INFO] Epoch 13/15 - Policy Loss: 1.0459, Value Loss: 0.2025, Total Loss: 1.2484, LR: 0.001671
2025-04-26 00:21:56,173 [INFO] Epoch 14/15 - Policy Loss: 1.0447, Value Loss: 0.2023, Total Loss: 1.2470, LR: 0.003321
2025-04-26 00:22:17,873 [INFO] Epoch 15/15 - Policy Loss: 1.0440, Value Loss: 0.2021, Total Loss: 1.2461, LR: 0.004971
2025-04-26 00:22:17,887 [INFO] 训练完成，总损失: 1.2461
2025-04-26 00:22:17,887 [INFO] 保存迭代 114 的模型
2025-04-26 00:22:18,334 [INFO] Model saved to ./models/best.pt
2025-04-26 00:22:18,641 [INFO] Model saved to ./models/iteration_114.pt
2025-04-26 00:22:18,641 [INFO] 所有训练迭代完成
2025-04-26 00:22:18,641 [INFO] 开始迭代 115/300
2025-04-26 00:22:18,641 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 00:29:36,368 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 00:29:36,369 [INFO] 保存训练样本
2025-04-26 00:29:39,849 [INFO] 使用 116656 个样本训练神经网络
2025-04-26 00:29:39,850 [INFO] Training with 116656 examples
2025-04-26 00:29:39,850 [INFO] 总训练步数: 840, 每轮次批次数: 56
2025-04-26 00:29:40,253 [INFO] 循环学习率周期大小: 168 步
2025-04-26 00:30:02,199 [INFO] Epoch 1/15 - Policy Loss: 1.0790, Value Loss: 0.2225, Total Loss: 1.3015, LR: 0.001671
2025-04-26 00:30:23,946 [INFO] Epoch 2/15 - Policy Loss: 1.0725, Value Loss: 0.2178, Total Loss: 1.2902, LR: 0.003321
2025-04-26 00:30:45,745 [INFO] Epoch 3/15 - Policy Loss: 1.0673, Value Loss: 0.2163, Total Loss: 1.2835, LR: 0.004971
2025-04-26 00:31:07,541 [INFO] Epoch 4/15 - Policy Loss: 1.0635, Value Loss: 0.2149, Total Loss: 1.2784, LR: 0.003379
2025-04-26 00:31:29,277 [INFO] Epoch 5/15 - Policy Loss: 1.0600, Value Loss: 0.2140, Total Loss: 1.2739, LR: 0.001729
2025-04-26 00:31:51,010 [INFO] Epoch 6/15 - Policy Loss: 1.0569, Value Loss: 0.2123, Total Loss: 1.2692, LR: 0.000079
2025-04-26 00:32:12,737 [INFO] Epoch 7/15 - Policy Loss: 1.0541, Value Loss: 0.2111, Total Loss: 1.2652, LR: 0.001671
2025-04-26 00:32:34,482 [INFO] Epoch 8/15 - Policy Loss: 1.0524, Value Loss: 0.2106, Total Loss: 1.2629, LR: 0.003321
2025-04-26 00:32:56,236 [INFO] Epoch 9/15 - Policy Loss: 1.0506, Value Loss: 0.2095, Total Loss: 1.2601, LR: 0.004971
2025-04-26 00:33:17,948 [INFO] Epoch 10/15 - Policy Loss: 1.0496, Value Loss: 0.2090, Total Loss: 1.2586, LR: 0.003379
2025-04-26 00:33:39,690 [INFO] Epoch 11/15 - Policy Loss: 1.0484, Value Loss: 0.2083, Total Loss: 1.2568, LR: 0.001729
2025-04-26 00:34:01,433 [INFO] Epoch 12/15 - Policy Loss: 1.0467, Value Loss: 0.2078, Total Loss: 1.2545, LR: 0.000079
2025-04-26 00:34:23,164 [INFO] Epoch 13/15 - Policy Loss: 1.0454, Value Loss: 0.2072, Total Loss: 1.2526, LR: 0.001671
2025-04-26 00:34:44,996 [INFO] Epoch 14/15 - Policy Loss: 1.0441, Value Loss: 0.2067, Total Loss: 1.2508, LR: 0.003321
2025-04-26 00:35:06,825 [INFO] Epoch 15/15 - Policy Loss: 1.0436, Value Loss: 0.2065, Total Loss: 1.2500, LR: 0.004971
2025-04-26 00:35:06,850 [INFO] 训练完成，总损失: 1.2500
2025-04-26 00:35:06,851 [INFO] 保存迭代 115 的模型
2025-04-26 00:35:07,367 [INFO] Model saved to ./models/best.pt
2025-04-26 00:35:07,738 [INFO] Model saved to ./models/iteration_115.pt
2025-04-26 00:35:07,739 [INFO] 所有训练迭代完成
2025-04-26 00:35:07,739 [INFO] 开始迭代 116/300
2025-04-26 00:35:07,739 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 00:42:25,094 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 00:42:25,094 [INFO] 保存训练样本
2025-04-26 00:42:28,079 [INFO] 使用 117168 个样本训练神经网络
2025-04-26 00:42:28,079 [INFO] Training with 117168 examples
2025-04-26 00:42:28,079 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-26 00:42:28,445 [INFO] 循环学习率周期大小: 171 步
2025-04-26 00:42:50,623 [INFO] Epoch 1/15 - Policy Loss: 1.0718, Value Loss: 0.2193, Total Loss: 1.2910, LR: 0.001671
2025-04-26 00:43:12,743 [INFO] Epoch 2/15 - Policy Loss: 1.0692, Value Loss: 0.2154, Total Loss: 1.2846, LR: 0.003321
2025-04-26 00:43:34,867 [INFO] Epoch 3/15 - Policy Loss: 1.0637, Value Loss: 0.2144, Total Loss: 1.2781, LR: 0.004971
2025-04-26 00:43:56,993 [INFO] Epoch 4/15 - Policy Loss: 1.0599, Value Loss: 0.2122, Total Loss: 1.2721, LR: 0.003379
2025-04-26 00:44:19,122 [INFO] Epoch 5/15 - Policy Loss: 1.0568, Value Loss: 0.2107, Total Loss: 1.2675, LR: 0.001729
2025-04-26 00:44:41,248 [INFO] Epoch 6/15 - Policy Loss: 1.0539, Value Loss: 0.2091, Total Loss: 1.2630, LR: 0.000079
2025-04-26 00:45:03,481 [INFO] Epoch 7/15 - Policy Loss: 1.0503, Value Loss: 0.2077, Total Loss: 1.2580, LR: 0.001671
2025-04-26 00:45:25,721 [INFO] Epoch 8/15 - Policy Loss: 1.0490, Value Loss: 0.2066, Total Loss: 1.2555, LR: 0.003321
2025-04-26 00:45:47,862 [INFO] Epoch 9/15 - Policy Loss: 1.0475, Value Loss: 0.2060, Total Loss: 1.2535, LR: 0.004971
2025-04-26 00:46:10,002 [INFO] Epoch 10/15 - Policy Loss: 1.0470, Value Loss: 0.2056, Total Loss: 1.2527, LR: 0.003379
2025-04-26 00:46:32,157 [INFO] Epoch 11/15 - Policy Loss: 1.0457, Value Loss: 0.2052, Total Loss: 1.2509, LR: 0.001729
2025-04-26 00:46:54,325 [INFO] Epoch 12/15 - Policy Loss: 1.0444, Value Loss: 0.2046, Total Loss: 1.2490, LR: 0.000079
2025-04-26 00:47:16,562 [INFO] Epoch 13/15 - Policy Loss: 1.0428, Value Loss: 0.2041, Total Loss: 1.2469, LR: 0.001671
2025-04-26 00:47:39,024 [INFO] Epoch 14/15 - Policy Loss: 1.0415, Value Loss: 0.2037, Total Loss: 1.2452, LR: 0.003321
2025-04-26 00:48:01,257 [INFO] Epoch 15/15 - Policy Loss: 1.0408, Value Loss: 0.2033, Total Loss: 1.2441, LR: 0.004971
2025-04-26 00:48:01,278 [INFO] 训练完成，总损失: 1.2441
2025-04-26 00:48:01,279 [INFO] 保存迭代 116 的模型
2025-04-26 00:48:01,734 [INFO] Model saved to ./models/best.pt
2025-04-26 00:48:02,045 [INFO] Model saved to ./models/iteration_116.pt
2025-04-26 00:48:02,045 [INFO] 所有训练迭代完成
2025-04-26 00:48:02,045 [INFO] 开始迭代 117/300
2025-04-26 00:48:02,045 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 00:55:26,706 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 00:55:26,706 [INFO] 保存训练样本
2025-04-26 00:55:29,701 [INFO] 使用 118360 个样本训练神经网络
2025-04-26 00:55:29,702 [INFO] Training with 118360 examples
2025-04-26 00:55:29,702 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-26 00:55:30,022 [INFO] 循环学习率周期大小: 171 步
2025-04-26 00:55:52,122 [INFO] Epoch 1/15 - Policy Loss: 1.0728, Value Loss: 0.2168, Total Loss: 1.2896, LR: 0.001671
2025-04-26 00:56:14,170 [INFO] Epoch 2/15 - Policy Loss: 1.0669, Value Loss: 0.2133, Total Loss: 1.2802, LR: 0.003321
2025-04-26 00:56:36,252 [INFO] Epoch 3/15 - Policy Loss: 1.0611, Value Loss: 0.2110, Total Loss: 1.2721, LR: 0.004971
2025-04-26 00:56:58,344 [INFO] Epoch 4/15 - Policy Loss: 1.0586, Value Loss: 0.2105, Total Loss: 1.2691, LR: 0.003379
2025-04-26 00:57:20,407 [INFO] Epoch 5/15 - Policy Loss: 1.0552, Value Loss: 0.2094, Total Loss: 1.2645, LR: 0.001729
2025-04-26 00:57:42,506 [INFO] Epoch 6/15 - Policy Loss: 1.0517, Value Loss: 0.2077, Total Loss: 1.2594, LR: 0.000079
2025-04-26 00:58:04,570 [INFO] Epoch 7/15 - Policy Loss: 1.0499, Value Loss: 0.2066, Total Loss: 1.2565, LR: 0.001671
2025-04-26 00:58:26,638 [INFO] Epoch 8/15 - Policy Loss: 1.0475, Value Loss: 0.2056, Total Loss: 1.2532, LR: 0.003321
2025-04-26 00:58:48,704 [INFO] Epoch 9/15 - Policy Loss: 1.0460, Value Loss: 0.2054, Total Loss: 1.2514, LR: 0.004971
2025-04-26 00:59:10,764 [INFO] Epoch 10/15 - Policy Loss: 1.0451, Value Loss: 0.2049, Total Loss: 1.2500, LR: 0.003379
2025-04-26 00:59:32,835 [INFO] Epoch 11/15 - Policy Loss: 1.0435, Value Loss: 0.2044, Total Loss: 1.2479, LR: 0.001729
2025-04-26 00:59:54,950 [INFO] Epoch 12/15 - Policy Loss: 1.0420, Value Loss: 0.2044, Total Loss: 1.2464, LR: 0.000079
2025-04-26 01:00:17,370 [INFO] Epoch 13/15 - Policy Loss: 1.0410, Value Loss: 0.2040, Total Loss: 1.2449, LR: 0.001671
2025-04-26 01:00:39,475 [INFO] Epoch 14/15 - Policy Loss: 1.0395, Value Loss: 0.2035, Total Loss: 1.2430, LR: 0.003321
2025-04-26 01:01:01,581 [INFO] Epoch 15/15 - Policy Loss: 1.0385, Value Loss: 0.2033, Total Loss: 1.2418, LR: 0.004971
2025-04-26 01:01:01,597 [INFO] 训练完成，总损失: 1.2418
2025-04-26 01:01:01,597 [INFO] 保存迭代 117 的模型
2025-04-26 01:01:01,991 [INFO] Model saved to ./models/best.pt
2025-04-26 01:01:02,308 [INFO] Model saved to ./models/iteration_117.pt
2025-04-26 01:01:02,308 [INFO] 所有训练迭代完成
2025-04-26 01:01:02,308 [INFO] 开始迭代 118/300
2025-04-26 01:01:02,308 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 01:06:27,983 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 01:06:27,984 [INFO] 保存训练样本
2025-04-26 01:06:30,830 [INFO] 使用 117808 个样本训练神经网络
2025-04-26 01:06:30,830 [INFO] Training with 117808 examples
2025-04-26 01:06:30,831 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-26 01:06:31,156 [INFO] 循环学习率周期大小: 171 步
2025-04-26 01:06:53,318 [INFO] Epoch 1/15 - Policy Loss: 1.0495, Value Loss: 0.2044, Total Loss: 1.2539, LR: 0.001671
2025-04-26 01:07:15,427 [INFO] Epoch 2/15 - Policy Loss: 1.0455, Value Loss: 0.2035, Total Loss: 1.2490, LR: 0.003321
2025-04-26 01:07:37,631 [INFO] Epoch 3/15 - Policy Loss: 1.0441, Value Loss: 0.2030, Total Loss: 1.2470, LR: 0.004971
2025-04-26 01:07:59,967 [INFO] Epoch 4/15 - Policy Loss: 1.0432, Value Loss: 0.2022, Total Loss: 1.2454, LR: 0.003379
2025-04-26 01:08:22,320 [INFO] Epoch 5/15 - Policy Loss: 1.0402, Value Loss: 0.2020, Total Loss: 1.2422, LR: 0.001729
2025-04-26 01:08:44,444 [INFO] Epoch 6/15 - Policy Loss: 1.0379, Value Loss: 0.2013, Total Loss: 1.2392, LR: 0.000079
2025-04-26 01:09:06,742 [INFO] Epoch 7/15 - Policy Loss: 1.0363, Value Loss: 0.2008, Total Loss: 1.2371, LR: 0.001671
2025-04-26 01:09:28,993 [INFO] Epoch 8/15 - Policy Loss: 1.0344, Value Loss: 0.2006, Total Loss: 1.2350, LR: 0.003321
2025-04-26 01:09:51,306 [INFO] Epoch 9/15 - Policy Loss: 1.0341, Value Loss: 0.2004, Total Loss: 1.2345, LR: 0.004971
2025-04-26 01:10:13,583 [INFO] Epoch 10/15 - Policy Loss: 1.0335, Value Loss: 0.2002, Total Loss: 1.2337, LR: 0.003379
2025-04-26 01:10:35,841 [INFO] Epoch 11/15 - Policy Loss: 1.0327, Value Loss: 0.1998, Total Loss: 1.2325, LR: 0.001729
2025-04-26 01:10:58,501 [INFO] Epoch 12/15 - Policy Loss: 1.0316, Value Loss: 0.1993, Total Loss: 1.2309, LR: 0.000079
2025-04-26 01:11:20,714 [INFO] Epoch 13/15 - Policy Loss: 1.0304, Value Loss: 0.1991, Total Loss: 1.2295, LR: 0.001671
2025-04-26 01:11:42,994 [INFO] Epoch 14/15 - Policy Loss: 1.0297, Value Loss: 0.1990, Total Loss: 1.2287, LR: 0.003321
2025-04-26 01:12:05,249 [INFO] Epoch 15/15 - Policy Loss: 1.0297, Value Loss: 0.1988, Total Loss: 1.2285, LR: 0.004971
2025-04-26 01:12:05,267 [INFO] 训练完成，总损失: 1.2285
2025-04-26 01:12:05,267 [INFO] 保存迭代 118 的模型
2025-04-26 01:12:05,695 [INFO] Model saved to ./models/best.pt
2025-04-26 01:12:05,996 [INFO] Model saved to ./models/iteration_118.pt
2025-04-26 01:12:05,996 [INFO] 所有训练迭代完成
2025-04-26 01:12:05,996 [INFO] 开始迭代 119/300
2025-04-26 01:12:05,996 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 01:18:44,455 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 01:18:44,455 [INFO] 保存训练样本
2025-04-26 01:18:47,531 [INFO] 使用 118240 个样本训练神经网络
2025-04-26 01:18:47,532 [INFO] Training with 118240 examples
2025-04-26 01:18:47,532 [INFO] 总训练步数: 855, 每轮次批次数: 57
2025-04-26 01:18:47,888 [INFO] 循环学习率周期大小: 171 步
2025-04-26 01:19:10,062 [INFO] Epoch 1/15 - Policy Loss: 1.0500, Value Loss: 0.2268, Total Loss: 1.2768, LR: 0.001671
2025-04-26 01:19:32,159 [INFO] Epoch 2/15 - Policy Loss: 1.0500, Value Loss: 0.2239, Total Loss: 1.2739, LR: 0.003321
2025-04-26 01:19:54,257 [INFO] Epoch 3/15 - Policy Loss: 1.0478, Value Loss: 0.2216, Total Loss: 1.2694, LR: 0.004971
2025-04-26 01:20:16,282 [INFO] Epoch 4/15 - Policy Loss: 1.0453, Value Loss: 0.2189, Total Loss: 1.2641, LR: 0.003379
2025-04-26 01:20:38,306 [INFO] Epoch 5/15 - Policy Loss: 1.0419, Value Loss: 0.2168, Total Loss: 1.2586, LR: 0.001729
2025-04-26 01:21:00,343 [INFO] Epoch 6/15 - Policy Loss: 1.0398, Value Loss: 0.2156, Total Loss: 1.2554, LR: 0.000079
2025-04-26 01:21:22,365 [INFO] Epoch 7/15 - Policy Loss: 1.0375, Value Loss: 0.2141, Total Loss: 1.2516, LR: 0.001671
2025-04-26 01:21:44,434 [INFO] Epoch 8/15 - Policy Loss: 1.0362, Value Loss: 0.2131, Total Loss: 1.2493, LR: 0.003321
2025-04-26 01:22:06,506 [INFO] Epoch 9/15 - Policy Loss: 1.0351, Value Loss: 0.2123, Total Loss: 1.2475, LR: 0.004971
2025-04-26 01:22:28,831 [INFO] Epoch 10/15 - Policy Loss: 1.0349, Value Loss: 0.2118, Total Loss: 1.2466, LR: 0.003379
2025-04-26 01:22:50,893 [INFO] Epoch 11/15 - Policy Loss: 1.0343, Value Loss: 0.2112, Total Loss: 1.2455, LR: 0.001729
2025-04-26 01:23:12,954 [INFO] Epoch 12/15 - Policy Loss: 1.0328, Value Loss: 0.2105, Total Loss: 1.2432, LR: 0.000079
2025-04-26 01:23:35,008 [INFO] Epoch 13/15 - Policy Loss: 1.0314, Value Loss: 0.2097, Total Loss: 1.2411, LR: 0.001671
2025-04-26 01:23:57,087 [INFO] Epoch 14/15 - Policy Loss: 1.0306, Value Loss: 0.2092, Total Loss: 1.2398, LR: 0.003321
2025-04-26 01:24:19,140 [INFO] Epoch 15/15 - Policy Loss: 1.0301, Value Loss: 0.2086, Total Loss: 1.2388, LR: 0.004971
2025-04-26 01:24:19,156 [INFO] 训练完成，总损失: 1.2388
2025-04-26 01:24:19,156 [INFO] 保存迭代 119 的模型
2025-04-26 01:24:19,610 [INFO] Model saved to ./models/best.pt
2025-04-26 01:24:19,883 [INFO] Model saved to ./models/iteration_119.pt
2025-04-26 01:24:19,883 [INFO] 所有训练迭代完成
2025-04-26 01:24:19,883 [INFO] 开始迭代 120/300
2025-04-26 01:24:19,883 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 01:30:52,191 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 01:30:52,192 [INFO] 保存训练样本
2025-04-26 01:30:54,794 [INFO] 使用 118944 个样本训练神经网络
2025-04-26 01:30:54,795 [INFO] Training with 118944 examples
2025-04-26 01:30:54,795 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 01:30:54,828 [INFO] 循环学习率周期大小: 174 步
2025-04-26 01:31:17,362 [INFO] Epoch 1/15 - Policy Loss: 1.0586, Value Loss: 0.2340, Total Loss: 1.2926, LR: 0.001672
2025-04-26 01:31:39,836 [INFO] Epoch 2/15 - Policy Loss: 1.0526, Value Loss: 0.2297, Total Loss: 1.2823, LR: 0.003322
2025-04-26 01:32:02,281 [INFO] Epoch 3/15 - Policy Loss: 1.0487, Value Loss: 0.2262, Total Loss: 1.2749, LR: 0.004972
2025-04-26 01:32:24,683 [INFO] Epoch 4/15 - Policy Loss: 1.0480, Value Loss: 0.2247, Total Loss: 1.2726, LR: 0.003378
2025-04-26 01:32:47,112 [INFO] Epoch 5/15 - Policy Loss: 1.0464, Value Loss: 0.2227, Total Loss: 1.2691, LR: 0.001728
2025-04-26 01:33:09,516 [INFO] Epoch 6/15 - Policy Loss: 1.0445, Value Loss: 0.2214, Total Loss: 1.2659, LR: 0.000078
2025-04-26 01:33:31,936 [INFO] Epoch 7/15 - Policy Loss: 1.0410, Value Loss: 0.2205, Total Loss: 1.2616, LR: 0.001672
2025-04-26 01:33:54,727 [INFO] Epoch 8/15 - Policy Loss: 1.0391, Value Loss: 0.2195, Total Loss: 1.2586, LR: 0.003322
2025-04-26 01:34:17,235 [INFO] Epoch 9/15 - Policy Loss: 1.0381, Value Loss: 0.2187, Total Loss: 1.2569, LR: 0.004972
2025-04-26 01:34:39,800 [INFO] Epoch 10/15 - Policy Loss: 1.0374, Value Loss: 0.2179, Total Loss: 1.2553, LR: 0.003378
2025-04-26 01:35:02,321 [INFO] Epoch 11/15 - Policy Loss: 1.0368, Value Loss: 0.2172, Total Loss: 1.2540, LR: 0.001728
2025-04-26 01:35:24,846 [INFO] Epoch 12/15 - Policy Loss: 1.0351, Value Loss: 0.2166, Total Loss: 1.2517, LR: 0.000078
2025-04-26 01:35:47,371 [INFO] Epoch 13/15 - Policy Loss: 1.0337, Value Loss: 0.2160, Total Loss: 1.2497, LR: 0.001672
2025-04-26 01:36:09,937 [INFO] Epoch 14/15 - Policy Loss: 1.0325, Value Loss: 0.2153, Total Loss: 1.2479, LR: 0.003322
2025-04-26 01:36:32,543 [INFO] Epoch 15/15 - Policy Loss: 1.0319, Value Loss: 0.2149, Total Loss: 1.2468, LR: 0.004972
2025-04-26 01:36:32,559 [INFO] 训练完成，总损失: 1.2468
2025-04-26 01:36:32,559 [INFO] 保存迭代 120 的模型
2025-04-26 01:36:32,943 [INFO] Model saved to ./models/best.pt
2025-04-26 01:36:33,230 [INFO] Model saved to ./models/iteration_120.pt
2025-04-26 01:36:33,231 [INFO] 所有训练迭代完成
2025-04-26 01:36:33,231 [INFO] 开始迭代 121/300
2025-04-26 01:36:33,231 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 01:43:15,844 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 01:43:15,844 [INFO] 保存训练样本
2025-04-26 01:43:19,202 [INFO] 使用 119352 个样本训练神经网络
2025-04-26 01:43:19,202 [INFO] Training with 119352 examples
2025-04-26 01:43:19,203 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 01:43:19,243 [INFO] 循环学习率周期大小: 174 步
2025-04-26 01:43:41,822 [INFO] Epoch 1/15 - Policy Loss: 1.0565, Value Loss: 0.2301, Total Loss: 1.2865, LR: 0.001672
2025-04-26 01:44:04,360 [INFO] Epoch 2/15 - Policy Loss: 1.0497, Value Loss: 0.2262, Total Loss: 1.2760, LR: 0.003322
2025-04-26 01:44:26,860 [INFO] Epoch 3/15 - Policy Loss: 1.0469, Value Loss: 0.2247, Total Loss: 1.2716, LR: 0.004972
2025-04-26 01:44:49,426 [INFO] Epoch 4/15 - Policy Loss: 1.0428, Value Loss: 0.2229, Total Loss: 1.2657, LR: 0.003378
2025-04-26 01:45:12,224 [INFO] Epoch 5/15 - Policy Loss: 1.0402, Value Loss: 0.2220, Total Loss: 1.2622, LR: 0.001728
2025-04-26 01:45:34,707 [INFO] Epoch 6/15 - Policy Loss: 1.0374, Value Loss: 0.2209, Total Loss: 1.2583, LR: 0.000078
2025-04-26 01:45:57,392 [INFO] Epoch 7/15 - Policy Loss: 1.0343, Value Loss: 0.2196, Total Loss: 1.2539, LR: 0.001672
2025-04-26 01:46:20,101 [INFO] Epoch 8/15 - Policy Loss: 1.0325, Value Loss: 0.2190, Total Loss: 1.2514, LR: 0.003322
2025-04-26 01:46:42,824 [INFO] Epoch 9/15 - Policy Loss: 1.0317, Value Loss: 0.2180, Total Loss: 1.2497, LR: 0.004972
2025-04-26 01:47:05,598 [INFO] Epoch 10/15 - Policy Loss: 1.0310, Value Loss: 0.2175, Total Loss: 1.2484, LR: 0.003378
2025-04-26 01:47:28,239 [INFO] Epoch 11/15 - Policy Loss: 1.0301, Value Loss: 0.2172, Total Loss: 1.2473, LR: 0.001728
2025-04-26 01:47:50,974 [INFO] Epoch 12/15 - Policy Loss: 1.0286, Value Loss: 0.2167, Total Loss: 1.2453, LR: 0.000078
2025-04-26 01:48:13,742 [INFO] Epoch 13/15 - Policy Loss: 1.0270, Value Loss: 0.2163, Total Loss: 1.2434, LR: 0.001672
2025-04-26 01:48:36,387 [INFO] Epoch 14/15 - Policy Loss: 1.0267, Value Loss: 0.2159, Total Loss: 1.2426, LR: 0.003322
2025-04-26 01:48:59,104 [INFO] Epoch 15/15 - Policy Loss: 1.0260, Value Loss: 0.2156, Total Loss: 1.2416, LR: 0.004972
2025-04-26 01:48:59,121 [INFO] 训练完成，总损失: 1.2416
2025-04-26 01:48:59,121 [INFO] 保存迭代 121 的模型
2025-04-26 01:48:59,510 [INFO] Model saved to ./models/best.pt
2025-04-26 01:48:59,795 [INFO] Model saved to ./models/iteration_121.pt
2025-04-26 01:48:59,795 [INFO] 所有训练迭代完成
2025-04-26 01:48:59,795 [INFO] 开始迭代 122/300
2025-04-26 01:48:59,795 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 01:55:17,020 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 01:55:17,021 [INFO] 保存训练样本
2025-04-26 01:55:20,607 [INFO] 使用 119656 个样本训练神经网络
2025-04-26 01:55:20,608 [INFO] Training with 119656 examples
2025-04-26 01:55:20,608 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 01:55:20,674 [INFO] 循环学习率周期大小: 174 步
2025-04-26 01:55:43,502 [INFO] Epoch 1/15 - Policy Loss: 1.0462, Value Loss: 0.2345, Total Loss: 1.2807, LR: 0.001672
2025-04-26 01:56:06,436 [INFO] Epoch 2/15 - Policy Loss: 1.0423, Value Loss: 0.2318, Total Loss: 1.2741, LR: 0.003322
2025-04-26 01:56:29,220 [INFO] Epoch 3/15 - Policy Loss: 1.0397, Value Loss: 0.2292, Total Loss: 1.2689, LR: 0.004972
2025-04-26 01:56:51,928 [INFO] Epoch 4/15 - Policy Loss: 1.0375, Value Loss: 0.2281, Total Loss: 1.2655, LR: 0.003378
2025-04-26 01:57:14,587 [INFO] Epoch 5/15 - Policy Loss: 1.0357, Value Loss: 0.2263, Total Loss: 1.2620, LR: 0.001728
2025-04-26 01:57:37,348 [INFO] Epoch 6/15 - Policy Loss: 1.0325, Value Loss: 0.2255, Total Loss: 1.2581, LR: 0.000078
2025-04-26 01:58:00,024 [INFO] Epoch 7/15 - Policy Loss: 1.0307, Value Loss: 0.2247, Total Loss: 1.2554, LR: 0.001672
2025-04-26 01:58:22,696 [INFO] Epoch 8/15 - Policy Loss: 1.0284, Value Loss: 0.2238, Total Loss: 1.2522, LR: 0.003322
2025-04-26 01:58:45,402 [INFO] Epoch 9/15 - Policy Loss: 1.0269, Value Loss: 0.2229, Total Loss: 1.2499, LR: 0.004972
2025-04-26 01:59:08,138 [INFO] Epoch 10/15 - Policy Loss: 1.0263, Value Loss: 0.2229, Total Loss: 1.2492, LR: 0.003378
2025-04-26 01:59:30,820 [INFO] Epoch 11/15 - Policy Loss: 1.0253, Value Loss: 0.2224, Total Loss: 1.2477, LR: 0.001728
2025-04-26 01:59:53,465 [INFO] Epoch 12/15 - Policy Loss: 1.0246, Value Loss: 0.2220, Total Loss: 1.2466, LR: 0.000078
2025-04-26 02:00:16,184 [INFO] Epoch 13/15 - Policy Loss: 1.0239, Value Loss: 0.2213, Total Loss: 1.2452, LR: 0.001672
2025-04-26 02:00:38,908 [INFO] Epoch 14/15 - Policy Loss: 1.0235, Value Loss: 0.2210, Total Loss: 1.2444, LR: 0.003322
2025-04-26 02:01:01,565 [INFO] Epoch 15/15 - Policy Loss: 1.0231, Value Loss: 0.2206, Total Loss: 1.2438, LR: 0.004972
2025-04-26 02:01:01,583 [INFO] 训练完成，总损失: 1.2438
2025-04-26 02:01:01,583 [INFO] 保存迭代 122 的模型
2025-04-26 02:01:01,977 [INFO] Model saved to ./models/best.pt
2025-04-26 02:01:02,251 [INFO] Model saved to ./models/iteration_122.pt
2025-04-26 02:01:02,252 [INFO] 所有训练迭代完成
2025-04-26 02:01:02,252 [INFO] 开始迭代 123/300
2025-04-26 02:01:02,252 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 02:07:09,144 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 02:07:09,144 [INFO] 保存训练样本
2025-04-26 02:07:12,547 [INFO] 使用 119664 个样本训练神经网络
2025-04-26 02:07:12,547 [INFO] Training with 119664 examples
2025-04-26 02:07:12,548 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 02:07:12,890 [INFO] 循环学习率周期大小: 174 步
2025-04-26 02:07:35,580 [INFO] Epoch 1/15 - Policy Loss: 1.0412, Value Loss: 0.2194, Total Loss: 1.2606, LR: 0.001672
2025-04-26 02:07:58,294 [INFO] Epoch 2/15 - Policy Loss: 1.0372, Value Loss: 0.2158, Total Loss: 1.2529, LR: 0.003322
2025-04-26 02:08:21,051 [INFO] Epoch 3/15 - Policy Loss: 1.0343, Value Loss: 0.2159, Total Loss: 1.2503, LR: 0.004972
2025-04-26 02:08:43,814 [INFO] Epoch 4/15 - Policy Loss: 1.0317, Value Loss: 0.2152, Total Loss: 1.2470, LR: 0.003378
2025-04-26 02:09:06,519 [INFO] Epoch 5/15 - Policy Loss: 1.0292, Value Loss: 0.2156, Total Loss: 1.2447, LR: 0.001728
2025-04-26 02:09:29,215 [INFO] Epoch 6/15 - Policy Loss: 1.0275, Value Loss: 0.2154, Total Loss: 1.2430, LR: 0.000078
2025-04-26 02:09:51,834 [INFO] Epoch 7/15 - Policy Loss: 1.0255, Value Loss: 0.2151, Total Loss: 1.2405, LR: 0.001672
2025-04-26 02:10:14,462 [INFO] Epoch 8/15 - Policy Loss: 1.0243, Value Loss: 0.2143, Total Loss: 1.2386, LR: 0.003322
2025-04-26 02:10:37,068 [INFO] Epoch 9/15 - Policy Loss: 1.0234, Value Loss: 0.2141, Total Loss: 1.2375, LR: 0.004972
2025-04-26 02:10:59,658 [INFO] Epoch 10/15 - Policy Loss: 1.0228, Value Loss: 0.2140, Total Loss: 1.2368, LR: 0.003378
2025-04-26 02:11:22,260 [INFO] Epoch 11/15 - Policy Loss: 1.0222, Value Loss: 0.2138, Total Loss: 1.2359, LR: 0.001728
2025-04-26 02:11:44,890 [INFO] Epoch 12/15 - Policy Loss: 1.0212, Value Loss: 0.2134, Total Loss: 1.2346, LR: 0.000078
2025-04-26 02:12:07,657 [INFO] Epoch 13/15 - Policy Loss: 1.0200, Value Loss: 0.2131, Total Loss: 1.2331, LR: 0.001672
2025-04-26 02:12:30,358 [INFO] Epoch 14/15 - Policy Loss: 1.0189, Value Loss: 0.2128, Total Loss: 1.2317, LR: 0.003322
2025-04-26 02:12:53,056 [INFO] Epoch 15/15 - Policy Loss: 1.0183, Value Loss: 0.2128, Total Loss: 1.2311, LR: 0.004972
2025-04-26 02:12:53,073 [INFO] 训练完成，总损失: 1.2311
2025-04-26 02:12:53,073 [INFO] 保存迭代 123 的模型
2025-04-26 02:12:53,519 [INFO] Model saved to ./models/best.pt
2025-04-26 02:12:53,813 [INFO] Model saved to ./models/iteration_123.pt
2025-04-26 02:12:53,813 [INFO] 所有训练迭代完成
2025-04-26 02:12:53,813 [INFO] 开始迭代 124/300
2025-04-26 02:12:53,813 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 02:19:21,797 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 02:19:21,798 [INFO] 保存训练样本
2025-04-26 02:19:25,061 [INFO] 使用 119976 个样本训练神经网络
2025-04-26 02:19:25,062 [INFO] Training with 119976 examples
2025-04-26 02:19:25,062 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 02:19:25,494 [INFO] 循环学习率周期大小: 174 步
2025-04-26 02:19:48,190 [INFO] Epoch 1/15 - Policy Loss: 1.0428, Value Loss: 0.2292, Total Loss: 1.2720, LR: 0.001672
2025-04-26 02:20:10,862 [INFO] Epoch 2/15 - Policy Loss: 1.0379, Value Loss: 0.2267, Total Loss: 1.2646, LR: 0.003322
2025-04-26 02:20:33,538 [INFO] Epoch 3/15 - Policy Loss: 1.0351, Value Loss: 0.2246, Total Loss: 1.2597, LR: 0.004972
2025-04-26 02:20:56,170 [INFO] Epoch 4/15 - Policy Loss: 1.0334, Value Loss: 0.2231, Total Loss: 1.2565, LR: 0.003378
2025-04-26 02:21:18,867 [INFO] Epoch 5/15 - Policy Loss: 1.0306, Value Loss: 0.2216, Total Loss: 1.2521, LR: 0.001728
2025-04-26 02:21:41,565 [INFO] Epoch 6/15 - Policy Loss: 1.0278, Value Loss: 0.2202, Total Loss: 1.2480, LR: 0.000078
2025-04-26 02:22:04,262 [INFO] Epoch 7/15 - Policy Loss: 1.0258, Value Loss: 0.2191, Total Loss: 1.2450, LR: 0.001672
2025-04-26 02:22:26,903 [INFO] Epoch 8/15 - Policy Loss: 1.0239, Value Loss: 0.2181, Total Loss: 1.2420, LR: 0.003322
2025-04-26 02:22:49,527 [INFO] Epoch 9/15 - Policy Loss: 1.0225, Value Loss: 0.2174, Total Loss: 1.2399, LR: 0.004972
2025-04-26 02:23:12,147 [INFO] Epoch 10/15 - Policy Loss: 1.0223, Value Loss: 0.2172, Total Loss: 1.2395, LR: 0.003378
2025-04-26 02:23:34,800 [INFO] Epoch 11/15 - Policy Loss: 1.0217, Value Loss: 0.2166, Total Loss: 1.2383, LR: 0.001728
2025-04-26 02:23:57,426 [INFO] Epoch 12/15 - Policy Loss: 1.0205, Value Loss: 0.2162, Total Loss: 1.2367, LR: 0.000078
2025-04-26 02:24:20,062 [INFO] Epoch 13/15 - Policy Loss: 1.0193, Value Loss: 0.2157, Total Loss: 1.2350, LR: 0.001672
2025-04-26 02:24:42,663 [INFO] Epoch 14/15 - Policy Loss: 1.0185, Value Loss: 0.2154, Total Loss: 1.2340, LR: 0.003322
2025-04-26 02:25:05,262 [INFO] Epoch 15/15 - Policy Loss: 1.0184, Value Loss: 0.2151, Total Loss: 1.2335, LR: 0.004972
2025-04-26 02:25:05,280 [INFO] 训练完成，总损失: 1.2335
2025-04-26 02:25:05,280 [INFO] 保存迭代 124 的模型
2025-04-26 02:25:05,692 [INFO] Model saved to ./models/best.pt
2025-04-26 02:25:05,976 [INFO] Model saved to ./models/iteration_124.pt
2025-04-26 02:25:05,976 [INFO] 所有训练迭代完成
2025-04-26 02:25:05,976 [INFO] 开始迭代 125/300
2025-04-26 02:25:05,977 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 02:32:11,567 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 02:32:11,568 [INFO] 保存训练样本
2025-04-26 02:32:14,823 [INFO] 使用 120296 个样本训练神经网络
2025-04-26 02:32:14,823 [INFO] Training with 120296 examples
2025-04-26 02:32:14,824 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 02:32:15,196 [INFO] 循环学习率周期大小: 174 步
2025-04-26 02:32:37,868 [INFO] Epoch 1/15 - Policy Loss: 1.0524, Value Loss: 0.2210, Total Loss: 1.2734, LR: 0.001672
2025-04-26 02:33:00,538 [INFO] Epoch 2/15 - Policy Loss: 1.0461, Value Loss: 0.2182, Total Loss: 1.2642, LR: 0.003322
2025-04-26 02:33:23,189 [INFO] Epoch 3/15 - Policy Loss: 1.0415, Value Loss: 0.2168, Total Loss: 1.2584, LR: 0.004972
2025-04-26 02:33:45,871 [INFO] Epoch 4/15 - Policy Loss: 1.0387, Value Loss: 0.2161, Total Loss: 1.2548, LR: 0.003378
2025-04-26 02:34:08,553 [INFO] Epoch 5/15 - Policy Loss: 1.0346, Value Loss: 0.2150, Total Loss: 1.2496, LR: 0.001728
2025-04-26 02:34:31,235 [INFO] Epoch 6/15 - Policy Loss: 1.0314, Value Loss: 0.2137, Total Loss: 1.2451, LR: 0.000078
2025-04-26 02:34:53,895 [INFO] Epoch 7/15 - Policy Loss: 1.0291, Value Loss: 0.2130, Total Loss: 1.2421, LR: 0.001672
2025-04-26 02:35:16,543 [INFO] Epoch 8/15 - Policy Loss: 1.0266, Value Loss: 0.2126, Total Loss: 1.2392, LR: 0.003322
2025-04-26 02:35:39,247 [INFO] Epoch 9/15 - Policy Loss: 1.0252, Value Loss: 0.2124, Total Loss: 1.2375, LR: 0.004972
2025-04-26 02:36:01,945 [INFO] Epoch 10/15 - Policy Loss: 1.0248, Value Loss: 0.2117, Total Loss: 1.2366, LR: 0.003378
2025-04-26 02:36:24,997 [INFO] Epoch 11/15 - Policy Loss: 1.0236, Value Loss: 0.2114, Total Loss: 1.2350, LR: 0.001728
2025-04-26 02:36:47,682 [INFO] Epoch 12/15 - Policy Loss: 1.0220, Value Loss: 0.2109, Total Loss: 1.2329, LR: 0.000078
2025-04-26 02:37:10,394 [INFO] Epoch 13/15 - Policy Loss: 1.0211, Value Loss: 0.2106, Total Loss: 1.2316, LR: 0.001672
2025-04-26 02:37:33,088 [INFO] Epoch 14/15 - Policy Loss: 1.0199, Value Loss: 0.2100, Total Loss: 1.2299, LR: 0.003322
2025-04-26 02:37:55,824 [INFO] Epoch 15/15 - Policy Loss: 1.0194, Value Loss: 0.2095, Total Loss: 1.2289, LR: 0.004972
2025-04-26 02:37:55,842 [INFO] 训练完成，总损失: 1.2289
2025-04-26 02:37:55,843 [INFO] 保存迭代 125 的模型
2025-04-26 02:37:56,261 [INFO] Model saved to ./models/best.pt
2025-04-26 02:37:56,560 [INFO] Model saved to ./models/iteration_125.pt
2025-04-26 02:37:56,560 [INFO] 所有训练迭代完成
2025-04-26 02:37:56,560 [INFO] 开始迭代 126/300
2025-04-26 02:37:56,560 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 02:44:41,344 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 02:44:41,345 [INFO] 保存训练样本
2025-04-26 02:44:44,842 [INFO] 使用 120496 个样本训练神经网络
2025-04-26 02:44:44,843 [INFO] Training with 120496 examples
2025-04-26 02:44:44,843 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 02:44:44,888 [INFO] 循环学习率周期大小: 174 步
2025-04-26 02:45:07,652 [INFO] Epoch 1/15 - Policy Loss: 1.0415, Value Loss: 0.2314, Total Loss: 1.2729, LR: 0.001672
2025-04-26 02:45:30,331 [INFO] Epoch 2/15 - Policy Loss: 1.0351, Value Loss: 0.2258, Total Loss: 1.2609, LR: 0.003322
2025-04-26 02:45:53,016 [INFO] Epoch 3/15 - Policy Loss: 1.0347, Value Loss: 0.2237, Total Loss: 1.2584, LR: 0.004972
2025-04-26 02:46:15,722 [INFO] Epoch 4/15 - Policy Loss: 1.0352, Value Loss: 0.2218, Total Loss: 1.2570, LR: 0.003378
2025-04-26 02:46:38,427 [INFO] Epoch 5/15 - Policy Loss: 1.0318, Value Loss: 0.2198, Total Loss: 1.2515, LR: 0.001728
2025-04-26 02:47:01,132 [INFO] Epoch 6/15 - Policy Loss: 1.0289, Value Loss: 0.2180, Total Loss: 1.2468, LR: 0.000078
2025-04-26 02:47:23,795 [INFO] Epoch 7/15 - Policy Loss: 1.0271, Value Loss: 0.2172, Total Loss: 1.2443, LR: 0.001672
2025-04-26 02:47:46,803 [INFO] Epoch 8/15 - Policy Loss: 1.0252, Value Loss: 0.2160, Total Loss: 1.2412, LR: 0.003322
2025-04-26 02:48:09,506 [INFO] Epoch 9/15 - Policy Loss: 1.0237, Value Loss: 0.2149, Total Loss: 1.2386, LR: 0.004972
2025-04-26 02:48:32,198 [INFO] Epoch 10/15 - Policy Loss: 1.0225, Value Loss: 0.2141, Total Loss: 1.2367, LR: 0.003378
2025-04-26 02:48:54,955 [INFO] Epoch 11/15 - Policy Loss: 1.0209, Value Loss: 0.2134, Total Loss: 1.2343, LR: 0.001728
2025-04-26 02:49:17,646 [INFO] Epoch 12/15 - Policy Loss: 1.0200, Value Loss: 0.2127, Total Loss: 1.2327, LR: 0.000078
2025-04-26 02:49:40,396 [INFO] Epoch 13/15 - Policy Loss: 1.0186, Value Loss: 0.2119, Total Loss: 1.2305, LR: 0.001672
2025-04-26 02:50:03,126 [INFO] Epoch 14/15 - Policy Loss: 1.0177, Value Loss: 0.2113, Total Loss: 1.2289, LR: 0.003322
2025-04-26 02:50:25,822 [INFO] Epoch 15/15 - Policy Loss: 1.0166, Value Loss: 0.2109, Total Loss: 1.2275, LR: 0.004972
2025-04-26 02:50:25,839 [INFO] 训练完成，总损失: 1.2275
2025-04-26 02:50:25,839 [INFO] 保存迭代 126 的模型
2025-04-26 02:50:26,231 [INFO] Model saved to ./models/best.pt
2025-04-26 02:50:26,515 [INFO] Model saved to ./models/iteration_126.pt
2025-04-26 02:50:26,515 [INFO] 所有训练迭代完成
2025-04-26 02:50:26,515 [INFO] 开始迭代 127/300
2025-04-26 02:50:26,515 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 02:56:26,835 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 02:56:26,836 [INFO] 保存训练样本
2025-04-26 02:56:30,360 [INFO] 使用 120248 个样本训练神经网络
2025-04-26 02:56:30,360 [INFO] Training with 120248 examples
2025-04-26 02:56:30,361 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 02:56:30,407 [INFO] 循环学习率周期大小: 174 步
2025-04-26 02:56:53,128 [INFO] Epoch 1/15 - Policy Loss: 1.0331, Value Loss: 0.2159, Total Loss: 1.2489, LR: 0.001672
2025-04-26 02:57:15,896 [INFO] Epoch 2/15 - Policy Loss: 1.0285, Value Loss: 0.2131, Total Loss: 1.2416, LR: 0.003322
2025-04-26 02:57:38,635 [INFO] Epoch 3/15 - Policy Loss: 1.0248, Value Loss: 0.2101, Total Loss: 1.2349, LR: 0.004972
2025-04-26 02:58:01,352 [INFO] Epoch 4/15 - Policy Loss: 1.0238, Value Loss: 0.2091, Total Loss: 1.2329, LR: 0.003378
2025-04-26 02:58:24,076 [INFO] Epoch 5/15 - Policy Loss: 1.0235, Value Loss: 0.2072, Total Loss: 1.2307, LR: 0.001728
2025-04-26 02:58:47,176 [INFO] Epoch 6/15 - Policy Loss: 1.0197, Value Loss: 0.2061, Total Loss: 1.2258, LR: 0.000078
2025-04-26 02:59:09,882 [INFO] Epoch 7/15 - Policy Loss: 1.0170, Value Loss: 0.2047, Total Loss: 1.2217, LR: 0.001672
2025-04-26 02:59:32,659 [INFO] Epoch 8/15 - Policy Loss: 1.0152, Value Loss: 0.2040, Total Loss: 1.2191, LR: 0.003322
2025-04-26 02:59:55,388 [INFO] Epoch 9/15 - Policy Loss: 1.0143, Value Loss: 0.2034, Total Loss: 1.2177, LR: 0.004972
2025-04-26 03:00:18,078 [INFO] Epoch 10/15 - Policy Loss: 1.0141, Value Loss: 0.2031, Total Loss: 1.2171, LR: 0.003378
2025-04-26 03:00:40,801 [INFO] Epoch 11/15 - Policy Loss: 1.0132, Value Loss: 0.2024, Total Loss: 1.2157, LR: 0.001728
2025-04-26 03:01:03,531 [INFO] Epoch 12/15 - Policy Loss: 1.0124, Value Loss: 0.2018, Total Loss: 1.2142, LR: 0.000078
2025-04-26 03:01:26,300 [INFO] Epoch 13/15 - Policy Loss: 1.0116, Value Loss: 0.2017, Total Loss: 1.2133, LR: 0.001672
2025-04-26 03:01:48,963 [INFO] Epoch 14/15 - Policy Loss: 1.0107, Value Loss: 0.2012, Total Loss: 1.2120, LR: 0.003322
2025-04-26 03:02:11,704 [INFO] Epoch 15/15 - Policy Loss: 1.0103, Value Loss: 0.2010, Total Loss: 1.2114, LR: 0.004972
2025-04-26 03:02:11,721 [INFO] 训练完成，总损失: 1.2114
2025-04-26 03:02:11,721 [INFO] 保存迭代 127 的模型
2025-04-26 03:02:12,096 [INFO] Model saved to ./models/best.pt
2025-04-26 03:02:12,368 [INFO] Model saved to ./models/iteration_127.pt
2025-04-26 03:02:12,368 [INFO] 所有训练迭代完成
2025-04-26 03:02:12,368 [INFO] 开始迭代 128/300
2025-04-26 03:02:12,368 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 03:07:52,291 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 03:07:52,291 [INFO] 保存训练样本
2025-04-26 03:07:55,254 [INFO] 使用 119312 个样本训练神经网络
2025-04-26 03:07:55,255 [INFO] Training with 119312 examples
2025-04-26 03:07:55,255 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 03:07:55,294 [INFO] 循环学习率周期大小: 174 步
2025-04-26 03:08:18,038 [INFO] Epoch 1/15 - Policy Loss: 1.0291, Value Loss: 0.2061, Total Loss: 1.2352, LR: 0.001672
2025-04-26 03:08:40,773 [INFO] Epoch 2/15 - Policy Loss: 1.0226, Value Loss: 0.2038, Total Loss: 1.2264, LR: 0.003322
2025-04-26 03:09:03,804 [INFO] Epoch 3/15 - Policy Loss: 1.0206, Value Loss: 0.2027, Total Loss: 1.2233, LR: 0.004972
2025-04-26 03:09:26,479 [INFO] Epoch 4/15 - Policy Loss: 1.0208, Value Loss: 0.2024, Total Loss: 1.2232, LR: 0.003378
2025-04-26 03:09:49,173 [INFO] Epoch 5/15 - Policy Loss: 1.0193, Value Loss: 0.2013, Total Loss: 1.2206, LR: 0.001728
2025-04-26 03:10:11,998 [INFO] Epoch 6/15 - Policy Loss: 1.0171, Value Loss: 0.2002, Total Loss: 1.2172, LR: 0.000078
2025-04-26 03:10:34,769 [INFO] Epoch 7/15 - Policy Loss: 1.0156, Value Loss: 0.1990, Total Loss: 1.2146, LR: 0.001672
2025-04-26 03:10:57,527 [INFO] Epoch 8/15 - Policy Loss: 1.0140, Value Loss: 0.1985, Total Loss: 1.2125, LR: 0.003322
2025-04-26 03:11:20,358 [INFO] Epoch 9/15 - Policy Loss: 1.0136, Value Loss: 0.1981, Total Loss: 1.2117, LR: 0.004972
2025-04-26 03:11:43,178 [INFO] Epoch 10/15 - Policy Loss: 1.0129, Value Loss: 0.1980, Total Loss: 1.2109, LR: 0.003378
2025-04-26 03:12:05,940 [INFO] Epoch 11/15 - Policy Loss: 1.0122, Value Loss: 0.1976, Total Loss: 1.2098, LR: 0.001728
2025-04-26 03:12:28,535 [INFO] Epoch 12/15 - Policy Loss: 1.0112, Value Loss: 0.1972, Total Loss: 1.2084, LR: 0.000078
2025-04-26 03:12:51,174 [INFO] Epoch 13/15 - Policy Loss: 1.0104, Value Loss: 0.1967, Total Loss: 1.2071, LR: 0.001672
2025-04-26 03:13:14,040 [INFO] Epoch 14/15 - Policy Loss: 1.0099, Value Loss: 0.1964, Total Loss: 1.2063, LR: 0.003322
2025-04-26 03:13:36,907 [INFO] Epoch 15/15 - Policy Loss: 1.0091, Value Loss: 0.1961, Total Loss: 1.2052, LR: 0.004972
2025-04-26 03:13:36,925 [INFO] 训练完成，总损失: 1.2052
2025-04-26 03:13:36,925 [INFO] 保存迭代 128 的模型
2025-04-26 03:13:37,463 [INFO] Model saved to ./models/best.pt
2025-04-26 03:13:37,839 [INFO] Model saved to ./models/iteration_128.pt
2025-04-26 03:13:37,840 [INFO] 所有训练迭代完成
2025-04-26 03:13:37,840 [INFO] 开始迭代 129/300
2025-04-26 03:13:37,840 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 03:19:56,158 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 03:19:56,159 [INFO] 保存训练样本
2025-04-26 03:19:58,991 [INFO] 使用 119336 个样本训练神经网络
2025-04-26 03:19:58,991 [INFO] Training with 119336 examples
2025-04-26 03:19:58,992 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 03:19:59,376 [INFO] 循环学习率周期大小: 174 步
2025-04-26 03:20:22,100 [INFO] Epoch 1/15 - Policy Loss: 1.0415, Value Loss: 0.2011, Total Loss: 1.2426, LR: 0.001672
2025-04-26 03:20:44,903 [INFO] Epoch 2/15 - Policy Loss: 1.0344, Value Loss: 0.1984, Total Loss: 1.2328, LR: 0.003322
2025-04-26 03:21:07,710 [INFO] Epoch 3/15 - Policy Loss: 1.0312, Value Loss: 0.1982, Total Loss: 1.2294, LR: 0.004972
2025-04-26 03:21:30,466 [INFO] Epoch 4/15 - Policy Loss: 1.0286, Value Loss: 0.1976, Total Loss: 1.2262, LR: 0.003378
2025-04-26 03:21:53,198 [INFO] Epoch 5/15 - Policy Loss: 1.0260, Value Loss: 0.1963, Total Loss: 1.2223, LR: 0.001728
2025-04-26 03:22:16,032 [INFO] Epoch 6/15 - Policy Loss: 1.0218, Value Loss: 0.1955, Total Loss: 1.2173, LR: 0.000078
2025-04-26 03:22:38,844 [INFO] Epoch 7/15 - Policy Loss: 1.0195, Value Loss: 0.1951, Total Loss: 1.2146, LR: 0.001672
2025-04-26 03:23:01,651 [INFO] Epoch 8/15 - Policy Loss: 1.0177, Value Loss: 0.1948, Total Loss: 1.2125, LR: 0.003322
2025-04-26 03:23:24,425 [INFO] Epoch 9/15 - Policy Loss: 1.0166, Value Loss: 0.1945, Total Loss: 1.2111, LR: 0.004972
2025-04-26 03:23:47,261 [INFO] Epoch 10/15 - Policy Loss: 1.0159, Value Loss: 0.1945, Total Loss: 1.2104, LR: 0.003378
2025-04-26 03:24:10,079 [INFO] Epoch 11/15 - Policy Loss: 1.0151, Value Loss: 0.1943, Total Loss: 1.2094, LR: 0.001728
2025-04-26 03:24:32,850 [INFO] Epoch 12/15 - Policy Loss: 1.0135, Value Loss: 0.1940, Total Loss: 1.2075, LR: 0.000078
2025-04-26 03:24:55,649 [INFO] Epoch 13/15 - Policy Loss: 1.0122, Value Loss: 0.1936, Total Loss: 1.2059, LR: 0.001672
2025-04-26 03:25:18,436 [INFO] Epoch 14/15 - Policy Loss: 1.0114, Value Loss: 0.1933, Total Loss: 1.2047, LR: 0.003322
2025-04-26 03:25:41,207 [INFO] Epoch 15/15 - Policy Loss: 1.0101, Value Loss: 0.1934, Total Loss: 1.2035, LR: 0.004972
2025-04-26 03:25:41,232 [INFO] 训练完成，总损失: 1.2035
2025-04-26 03:25:41,232 [INFO] 保存迭代 129 的模型
2025-04-26 03:25:41,770 [INFO] Model saved to ./models/best.pt
2025-04-26 03:25:42,145 [INFO] Model saved to ./models/iteration_129.pt
2025-04-26 03:25:42,146 [INFO] 所有训练迭代完成
2025-04-26 03:25:42,146 [INFO] 开始迭代 130/300
2025-04-26 03:25:42,146 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 03:32:39,614 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 03:32:39,615 [INFO] 保存训练样本
2025-04-26 03:32:42,961 [INFO] 使用 120088 个样本训练神经网络
2025-04-26 03:32:42,961 [INFO] Training with 120088 examples
2025-04-26 03:32:42,962 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 03:32:43,271 [INFO] 循环学习率周期大小: 174 步
2025-04-26 03:33:05,720 [INFO] Epoch 1/15 - Policy Loss: 1.0405, Value Loss: 0.2001, Total Loss: 1.2406, LR: 0.001672
2025-04-26 03:33:28,155 [INFO] Epoch 2/15 - Policy Loss: 1.0342, Value Loss: 0.1996, Total Loss: 1.2339, LR: 0.003322
2025-04-26 03:33:50,581 [INFO] Epoch 3/15 - Policy Loss: 1.0313, Value Loss: 0.1984, Total Loss: 1.2297, LR: 0.004972
2025-04-26 03:34:12,997 [INFO] Epoch 4/15 - Policy Loss: 1.0299, Value Loss: 0.1974, Total Loss: 1.2274, LR: 0.003378
2025-04-26 03:34:35,457 [INFO] Epoch 5/15 - Policy Loss: 1.0270, Value Loss: 0.1967, Total Loss: 1.2237, LR: 0.001728
2025-04-26 03:34:57,890 [INFO] Epoch 6/15 - Policy Loss: 1.0232, Value Loss: 0.1951, Total Loss: 1.2182, LR: 0.000078
2025-04-26 03:35:20,308 [INFO] Epoch 7/15 - Policy Loss: 1.0201, Value Loss: 0.1939, Total Loss: 1.2140, LR: 0.001672
2025-04-26 03:35:42,726 [INFO] Epoch 8/15 - Policy Loss: 1.0180, Value Loss: 0.1931, Total Loss: 1.2111, LR: 0.003322
2025-04-26 03:36:05,146 [INFO] Epoch 9/15 - Policy Loss: 1.0163, Value Loss: 0.1926, Total Loss: 1.2089, LR: 0.004972
2025-04-26 03:36:27,578 [INFO] Epoch 10/15 - Policy Loss: 1.0152, Value Loss: 0.1922, Total Loss: 1.2074, LR: 0.003378
2025-04-26 03:36:50,034 [INFO] Epoch 11/15 - Policy Loss: 1.0139, Value Loss: 0.1920, Total Loss: 1.2058, LR: 0.001728
2025-04-26 03:37:12,606 [INFO] Epoch 12/15 - Policy Loss: 1.0124, Value Loss: 0.1916, Total Loss: 1.2040, LR: 0.000078
2025-04-26 03:37:35,072 [INFO] Epoch 13/15 - Policy Loss: 1.0111, Value Loss: 0.1910, Total Loss: 1.2022, LR: 0.001672
2025-04-26 03:37:57,537 [INFO] Epoch 14/15 - Policy Loss: 1.0103, Value Loss: 0.1908, Total Loss: 1.2011, LR: 0.003322
2025-04-26 03:38:20,103 [INFO] Epoch 15/15 - Policy Loss: 1.0098, Value Loss: 0.1907, Total Loss: 1.2005, LR: 0.004972
2025-04-26 03:38:20,119 [INFO] 训练完成，总损失: 1.2005
2025-04-26 03:38:20,119 [INFO] 保存迭代 130 的模型
2025-04-26 03:38:20,521 [INFO] Model saved to ./models/best.pt
2025-04-26 03:38:20,802 [INFO] Model saved to ./models/iteration_130.pt
2025-04-26 03:38:20,802 [INFO] 所有训练迭代完成
2025-04-26 03:38:20,802 [INFO] 开始迭代 131/300
2025-04-26 03:38:20,802 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 03:45:44,690 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 03:45:44,691 [INFO] 保存训练样本
2025-04-26 03:45:47,615 [INFO] 使用 120784 个样本训练神经网络
2025-04-26 03:45:47,615 [INFO] Training with 120784 examples
2025-04-26 03:45:47,616 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 03:45:47,928 [INFO] 循环学习率周期大小: 174 步
2025-04-26 03:46:10,454 [INFO] Epoch 1/15 - Policy Loss: 1.0486, Value Loss: 0.2155, Total Loss: 1.2641, LR: 0.001672
2025-04-26 03:46:32,965 [INFO] Epoch 2/15 - Policy Loss: 1.0395, Value Loss: 0.2093, Total Loss: 1.2488, LR: 0.003322
2025-04-26 03:46:55,587 [INFO] Epoch 3/15 - Policy Loss: 1.0339, Value Loss: 0.2070, Total Loss: 1.2408, LR: 0.004972
2025-04-26 03:47:18,060 [INFO] Epoch 4/15 - Policy Loss: 1.0307, Value Loss: 0.2047, Total Loss: 1.2354, LR: 0.003378
2025-04-26 03:47:40,593 [INFO] Epoch 5/15 - Policy Loss: 1.0278, Value Loss: 0.2027, Total Loss: 1.2306, LR: 0.001728
2025-04-26 03:48:03,120 [INFO] Epoch 6/15 - Policy Loss: 1.0253, Value Loss: 0.2015, Total Loss: 1.2268, LR: 0.000078
2025-04-26 03:48:25,539 [INFO] Epoch 7/15 - Policy Loss: 1.0219, Value Loss: 0.1997, Total Loss: 1.2217, LR: 0.001672
2025-04-26 03:48:48,069 [INFO] Epoch 8/15 - Policy Loss: 1.0197, Value Loss: 0.1989, Total Loss: 1.2187, LR: 0.003322
2025-04-26 03:49:10,727 [INFO] Epoch 9/15 - Policy Loss: 1.0184, Value Loss: 0.1979, Total Loss: 1.2163, LR: 0.004972
2025-04-26 03:49:33,382 [INFO] Epoch 10/15 - Policy Loss: 1.0173, Value Loss: 0.1976, Total Loss: 1.2148, LR: 0.003378
2025-04-26 03:49:56,045 [INFO] Epoch 11/15 - Policy Loss: 1.0157, Value Loss: 0.1969, Total Loss: 1.2125, LR: 0.001728
2025-04-26 03:50:18,703 [INFO] Epoch 12/15 - Policy Loss: 1.0140, Value Loss: 0.1961, Total Loss: 1.2101, LR: 0.000078
2025-04-26 03:50:41,168 [INFO] Epoch 13/15 - Policy Loss: 1.0128, Value Loss: 0.1956, Total Loss: 1.2085, LR: 0.001672
2025-04-26 03:51:03,632 [INFO] Epoch 14/15 - Policy Loss: 1.0119, Value Loss: 0.1952, Total Loss: 1.2070, LR: 0.003322
2025-04-26 03:51:26,405 [INFO] Epoch 15/15 - Policy Loss: 1.0111, Value Loss: 0.1947, Total Loss: 1.2058, LR: 0.004972
2025-04-26 03:51:26,420 [INFO] 训练完成，总损失: 1.2058
2025-04-26 03:51:26,420 [INFO] 保存迭代 131 的模型
2025-04-26 03:51:26,830 [INFO] Model saved to ./models/best.pt
2025-04-26 03:51:27,084 [INFO] Model saved to ./models/iteration_131.pt
2025-04-26 03:51:27,085 [INFO] 所有训练迭代完成
2025-04-26 03:51:27,085 [INFO] 开始迭代 132/300
2025-04-26 03:51:27,085 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 03:58:24,404 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 03:58:24,404 [INFO] 保存训练样本
2025-04-26 03:58:27,288 [INFO] 使用 120800 个样本训练神经网络
2025-04-26 03:58:27,288 [INFO] Training with 120800 examples
2025-04-26 03:58:27,289 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 03:58:27,639 [INFO] 循环学习率周期大小: 174 步
2025-04-26 03:58:50,137 [INFO] Epoch 1/15 - Policy Loss: 1.0194, Value Loss: 0.1934, Total Loss: 1.2128, LR: 0.001672
2025-04-26 03:59:12,619 [INFO] Epoch 2/15 - Policy Loss: 1.0176, Value Loss: 0.1924, Total Loss: 1.2100, LR: 0.003322
2025-04-26 03:59:35,091 [INFO] Epoch 3/15 - Policy Loss: 1.0150, Value Loss: 0.1914, Total Loss: 1.2064, LR: 0.004972
2025-04-26 03:59:57,561 [INFO] Epoch 4/15 - Policy Loss: 1.0141, Value Loss: 0.1895, Total Loss: 1.2036, LR: 0.003378
2025-04-26 04:00:20,007 [INFO] Epoch 5/15 - Policy Loss: 1.0118, Value Loss: 0.1886, Total Loss: 1.2003, LR: 0.001728
2025-04-26 04:00:42,451 [INFO] Epoch 6/15 - Policy Loss: 1.0106, Value Loss: 0.1875, Total Loss: 1.1981, LR: 0.000078
2025-04-26 04:01:04,941 [INFO] Epoch 7/15 - Policy Loss: 1.0091, Value Loss: 0.1869, Total Loss: 1.1960, LR: 0.001672
2025-04-26 04:01:27,367 [INFO] Epoch 8/15 - Policy Loss: 1.0077, Value Loss: 0.1854, Total Loss: 1.1931, LR: 0.003322
2025-04-26 04:01:49,771 [INFO] Epoch 9/15 - Policy Loss: 1.0073, Value Loss: 0.1849, Total Loss: 1.1922, LR: 0.004972
2025-04-26 04:02:12,210 [INFO] Epoch 10/15 - Policy Loss: 1.0071, Value Loss: 0.1848, Total Loss: 1.1919, LR: 0.003378
2025-04-26 04:02:34,676 [INFO] Epoch 11/15 - Policy Loss: 1.0067, Value Loss: 0.1846, Total Loss: 1.1913, LR: 0.001728
2025-04-26 04:02:57,120 [INFO] Epoch 12/15 - Policy Loss: 1.0056, Value Loss: 0.1844, Total Loss: 1.1899, LR: 0.000078
2025-04-26 04:03:19,562 [INFO] Epoch 13/15 - Policy Loss: 1.0043, Value Loss: 0.1841, Total Loss: 1.1884, LR: 0.001672
2025-04-26 04:03:42,292 [INFO] Epoch 14/15 - Policy Loss: 1.0035, Value Loss: 0.1837, Total Loss: 1.1872, LR: 0.003322
2025-04-26 04:04:04,740 [INFO] Epoch 15/15 - Policy Loss: 1.0025, Value Loss: 0.1835, Total Loss: 1.1860, LR: 0.004972
2025-04-26 04:04:04,756 [INFO] 训练完成，总损失: 1.1860
2025-04-26 04:04:04,756 [INFO] 保存迭代 132 的模型
2025-04-26 04:04:05,449 [INFO] Model saved to ./models/best.pt
2025-04-26 04:04:05,764 [INFO] Model saved to ./models/iteration_132.pt
2025-04-26 04:04:05,764 [INFO] 所有训练迭代完成
2025-04-26 04:04:05,764 [INFO] 开始迭代 133/300
2025-04-26 04:04:05,764 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 04:10:46,950 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 04:10:46,951 [INFO] 保存训练样本
2025-04-26 04:10:49,974 [INFO] 使用 121544 个样本训练神经网络
2025-04-26 04:10:49,974 [INFO] Training with 121544 examples
2025-04-26 04:10:49,975 [INFO] 总训练步数: 885, 每轮次批次数: 59
2025-04-26 04:10:50,267 [INFO] 循环学习率周期大小: 177 步
2025-04-26 04:11:13,157 [INFO] Epoch 1/15 - Policy Loss: 1.0306, Value Loss: 0.2083, Total Loss: 1.2390, LR: 0.001672
2025-04-26 04:11:36,249 [INFO] Epoch 2/15 - Policy Loss: 1.0246, Value Loss: 0.2046, Total Loss: 1.2292, LR: 0.003322
2025-04-26 04:11:59,315 [INFO] Epoch 3/15 - Policy Loss: 1.0210, Value Loss: 0.2024, Total Loss: 1.2234, LR: 0.004972
2025-04-26 04:12:22,446 [INFO] Epoch 4/15 - Policy Loss: 1.0166, Value Loss: 0.2014, Total Loss: 1.2180, LR: 0.003378
2025-04-26 04:12:45,563 [INFO] Epoch 5/15 - Policy Loss: 1.0150, Value Loss: 0.2001, Total Loss: 1.2151, LR: 0.001728
2025-04-26 04:13:08,744 [INFO] Epoch 6/15 - Policy Loss: 1.0119, Value Loss: 0.1983, Total Loss: 1.2102, LR: 0.000078
2025-04-26 04:13:31,996 [INFO] Epoch 7/15 - Policy Loss: 1.0098, Value Loss: 0.1975, Total Loss: 1.2073, LR: 0.001672
2025-04-26 04:13:55,122 [INFO] Epoch 8/15 - Policy Loss: 1.0080, Value Loss: 0.1966, Total Loss: 1.2046, LR: 0.003322
2025-04-26 04:14:18,261 [INFO] Epoch 9/15 - Policy Loss: 1.0066, Value Loss: 0.1961, Total Loss: 1.2027, LR: 0.004972
2025-04-26 04:14:41,382 [INFO] Epoch 10/15 - Policy Loss: 1.0055, Value Loss: 0.1955, Total Loss: 1.2011, LR: 0.003378
2025-04-26 04:15:04,566 [INFO] Epoch 11/15 - Policy Loss: 1.0043, Value Loss: 0.1951, Total Loss: 1.1994, LR: 0.001728
2025-04-26 04:15:28,142 [INFO] Epoch 12/15 - Policy Loss: 1.0032, Value Loss: 0.1946, Total Loss: 1.1978, LR: 0.000078
2025-04-26 04:15:51,314 [INFO] Epoch 13/15 - Policy Loss: 1.0023, Value Loss: 0.1942, Total Loss: 1.1965, LR: 0.001672
2025-04-26 04:16:14,488 [INFO] Epoch 14/15 - Policy Loss: 1.0007, Value Loss: 0.1938, Total Loss: 1.1945, LR: 0.003322
2025-04-26 04:16:37,602 [INFO] Epoch 15/15 - Policy Loss: 1.0003, Value Loss: 0.1937, Total Loss: 1.1940, LR: 0.004972
2025-04-26 04:16:37,620 [INFO] 训练完成，总损失: 1.1940
2025-04-26 04:16:37,620 [INFO] 保存迭代 133 的模型
2025-04-26 04:16:38,043 [INFO] Model saved to ./models/best.pt
2025-04-26 04:16:38,342 [INFO] Model saved to ./models/iteration_133.pt
2025-04-26 04:16:38,342 [INFO] 所有训练迭代完成
2025-04-26 04:16:38,342 [INFO] 开始迭代 134/300
2025-04-26 04:16:38,342 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 04:22:32,656 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 04:22:32,657 [INFO] 保存训练样本
2025-04-26 04:22:35,691 [INFO] 使用 120984 个样本训练神经网络
2025-04-26 04:22:35,691 [INFO] Training with 120984 examples
2025-04-26 04:22:35,692 [INFO] 总训练步数: 885, 每轮次批次数: 59
2025-04-26 04:22:35,992 [INFO] 循环学习率周期大小: 177 步
2025-04-26 04:22:58,916 [INFO] Epoch 1/15 - Policy Loss: 1.0061, Value Loss: 0.1996, Total Loss: 1.2056, LR: 0.001672
2025-04-26 04:23:21,801 [INFO] Epoch 2/15 - Policy Loss: 1.0045, Value Loss: 0.1979, Total Loss: 1.2024, LR: 0.003322
2025-04-26 04:23:44,796 [INFO] Epoch 3/15 - Policy Loss: 1.0051, Value Loss: 0.1964, Total Loss: 1.2015, LR: 0.004972
2025-04-26 04:24:07,735 [INFO] Epoch 4/15 - Policy Loss: 1.0040, Value Loss: 0.1955, Total Loss: 1.1995, LR: 0.003378
2025-04-26 04:24:30,659 [INFO] Epoch 5/15 - Policy Loss: 1.0031, Value Loss: 0.1945, Total Loss: 1.1976, LR: 0.001728
2025-04-26 04:24:53,569 [INFO] Epoch 6/15 - Policy Loss: 1.0011, Value Loss: 0.1938, Total Loss: 1.1949, LR: 0.000078
2025-04-26 04:25:16,546 [INFO] Epoch 7/15 - Policy Loss: 0.9996, Value Loss: 0.1932, Total Loss: 1.1928, LR: 0.001672
2025-04-26 04:25:39,585 [INFO] Epoch 8/15 - Policy Loss: 0.9980, Value Loss: 0.1925, Total Loss: 1.1905, LR: 0.003322
2025-04-26 04:26:02,594 [INFO] Epoch 9/15 - Policy Loss: 0.9977, Value Loss: 0.1923, Total Loss: 1.1900, LR: 0.004972
2025-04-26 04:26:26,216 [INFO] Epoch 10/15 - Policy Loss: 0.9971, Value Loss: 0.1919, Total Loss: 1.1891, LR: 0.003378
2025-04-26 04:26:49,324 [INFO] Epoch 11/15 - Policy Loss: 0.9964, Value Loss: 0.1917, Total Loss: 1.1881, LR: 0.001728
2025-04-26 04:27:12,505 [INFO] Epoch 12/15 - Policy Loss: 0.9953, Value Loss: 0.1914, Total Loss: 1.1867, LR: 0.000078
2025-04-26 04:27:35,626 [INFO] Epoch 13/15 - Policy Loss: 0.9947, Value Loss: 0.1911, Total Loss: 1.1857, LR: 0.001672
2025-04-26 04:27:58,695 [INFO] Epoch 14/15 - Policy Loss: 0.9937, Value Loss: 0.1906, Total Loss: 1.1844, LR: 0.003322
2025-04-26 04:28:21,656 [INFO] Epoch 15/15 - Policy Loss: 0.9936, Value Loss: 0.1905, Total Loss: 1.1841, LR: 0.004972
2025-04-26 04:28:21,672 [INFO] 训练完成，总损失: 1.1841
2025-04-26 04:28:21,672 [INFO] 保存迭代 134 的模型
2025-04-26 04:28:22,051 [INFO] Model saved to ./models/best.pt
2025-04-26 04:28:22,312 [INFO] Model saved to ./models/iteration_134.pt
2025-04-26 04:28:22,312 [INFO] 所有训练迭代完成
2025-04-26 04:28:22,312 [INFO] 开始迭代 135/300
2025-04-26 04:28:22,312 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 04:34:51,271 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 04:34:51,272 [INFO] 保存训练样本
2025-04-26 04:34:54,679 [INFO] 使用 120648 个样本训练神经网络
2025-04-26 04:34:54,679 [INFO] Training with 120648 examples
2025-04-26 04:34:54,680 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 04:34:54,725 [INFO] 循环学习率周期大小: 174 步
2025-04-26 04:35:17,382 [INFO] Epoch 1/15 - Policy Loss: 1.0210, Value Loss: 0.2143, Total Loss: 1.2353, LR: 0.001672
2025-04-26 04:35:40,138 [INFO] Epoch 2/15 - Policy Loss: 1.0143, Value Loss: 0.2117, Total Loss: 1.2260, LR: 0.003322
2025-04-26 04:36:02,820 [INFO] Epoch 3/15 - Policy Loss: 1.0126, Value Loss: 0.2084, Total Loss: 1.2210, LR: 0.004972
2025-04-26 04:36:25,548 [INFO] Epoch 4/15 - Policy Loss: 1.0109, Value Loss: 0.2072, Total Loss: 1.2181, LR: 0.003378
2025-04-26 04:36:48,356 [INFO] Epoch 5/15 - Policy Loss: 1.0089, Value Loss: 0.2051, Total Loss: 1.2140, LR: 0.001728
2025-04-26 04:37:11,067 [INFO] Epoch 6/15 - Policy Loss: 1.0063, Value Loss: 0.2038, Total Loss: 1.2102, LR: 0.000078
2025-04-26 04:37:34,174 [INFO] Epoch 7/15 - Policy Loss: 1.0034, Value Loss: 0.2027, Total Loss: 1.2060, LR: 0.001672
2025-04-26 04:37:56,842 [INFO] Epoch 8/15 - Policy Loss: 1.0016, Value Loss: 0.2019, Total Loss: 1.2035, LR: 0.003322
2025-04-26 04:38:19,470 [INFO] Epoch 9/15 - Policy Loss: 1.0006, Value Loss: 0.2014, Total Loss: 1.2019, LR: 0.004972
2025-04-26 04:38:42,091 [INFO] Epoch 10/15 - Policy Loss: 0.9999, Value Loss: 0.2006, Total Loss: 1.2005, LR: 0.003378
2025-04-26 04:39:04,684 [INFO] Epoch 11/15 - Policy Loss: 0.9992, Value Loss: 0.2000, Total Loss: 1.1991, LR: 0.001728
2025-04-26 04:39:27,199 [INFO] Epoch 12/15 - Policy Loss: 0.9981, Value Loss: 0.1994, Total Loss: 1.1975, LR: 0.000078
2025-04-26 04:39:49,729 [INFO] Epoch 13/15 - Policy Loss: 0.9970, Value Loss: 0.1990, Total Loss: 1.1960, LR: 0.001672
2025-04-26 04:40:12,225 [INFO] Epoch 14/15 - Policy Loss: 0.9959, Value Loss: 0.1985, Total Loss: 1.1944, LR: 0.003322
2025-04-26 04:40:34,812 [INFO] Epoch 15/15 - Policy Loss: 0.9954, Value Loss: 0.1982, Total Loss: 1.1936, LR: 0.004972
2025-04-26 04:40:34,828 [INFO] 训练完成，总损失: 1.1936
2025-04-26 04:40:34,828 [INFO] 保存迭代 135 的模型
2025-04-26 04:40:35,231 [INFO] Model saved to ./models/best.pt
2025-04-26 04:40:35,497 [INFO] Model saved to ./models/iteration_135.pt
2025-04-26 04:40:35,497 [INFO] 所有训练迭代完成
2025-04-26 04:40:35,498 [INFO] 开始迭代 136/300
2025-04-26 04:40:35,498 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 04:46:59,411 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 04:46:59,411 [INFO] 保存训练样本
2025-04-26 04:47:02,846 [INFO] 使用 120256 个样本训练神经网络
2025-04-26 04:47:02,846 [INFO] Training with 120256 examples
2025-04-26 04:47:02,847 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 04:47:02,889 [INFO] 循环学习率周期大小: 174 步
2025-04-26 04:47:25,521 [INFO] Epoch 1/15 - Policy Loss: 1.0161, Value Loss: 0.2131, Total Loss: 1.2292, LR: 0.001672
2025-04-26 04:47:48,165 [INFO] Epoch 2/15 - Policy Loss: 1.0094, Value Loss: 0.2086, Total Loss: 1.2180, LR: 0.003322
2025-04-26 04:48:10,714 [INFO] Epoch 3/15 - Policy Loss: 1.0090, Value Loss: 0.2067, Total Loss: 1.2157, LR: 0.004972
2025-04-26 04:48:33,690 [INFO] Epoch 4/15 - Policy Loss: 1.0081, Value Loss: 0.2070, Total Loss: 1.2151, LR: 0.003378
2025-04-26 04:48:56,207 [INFO] Epoch 5/15 - Policy Loss: 1.0056, Value Loss: 0.2051, Total Loss: 1.2107, LR: 0.001728
2025-04-26 04:49:18,706 [INFO] Epoch 6/15 - Policy Loss: 1.0029, Value Loss: 0.2040, Total Loss: 1.2069, LR: 0.000078
2025-04-26 04:49:41,179 [INFO] Epoch 7/15 - Policy Loss: 1.0013, Value Loss: 0.2030, Total Loss: 1.2043, LR: 0.001672
2025-04-26 04:50:03,711 [INFO] Epoch 8/15 - Policy Loss: 0.9999, Value Loss: 0.2023, Total Loss: 1.2023, LR: 0.003322
2025-04-26 04:50:26,248 [INFO] Epoch 9/15 - Policy Loss: 1.0001, Value Loss: 0.2020, Total Loss: 1.2022, LR: 0.004972
2025-04-26 04:50:48,770 [INFO] Epoch 10/15 - Policy Loss: 1.0002, Value Loss: 0.2019, Total Loss: 1.2021, LR: 0.003378
2025-04-26 04:51:11,328 [INFO] Epoch 11/15 - Policy Loss: 0.9989, Value Loss: 0.2014, Total Loss: 1.2003, LR: 0.001728
2025-04-26 04:51:33,871 [INFO] Epoch 12/15 - Policy Loss: 0.9982, Value Loss: 0.2009, Total Loss: 1.1991, LR: 0.000078
2025-04-26 04:51:56,422 [INFO] Epoch 13/15 - Policy Loss: 0.9968, Value Loss: 0.2005, Total Loss: 1.1973, LR: 0.001672
2025-04-26 04:52:19,012 [INFO] Epoch 14/15 - Policy Loss: 0.9959, Value Loss: 0.2000, Total Loss: 1.1959, LR: 0.003322
2025-04-26 04:52:41,508 [INFO] Epoch 15/15 - Policy Loss: 0.9952, Value Loss: 0.1999, Total Loss: 1.1950, LR: 0.004972
2025-04-26 04:52:41,523 [INFO] 训练完成，总损失: 1.1950
2025-04-26 04:52:41,523 [INFO] 保存迭代 136 的模型
2025-04-26 04:52:41,922 [INFO] Model saved to ./models/best.pt
2025-04-26 04:52:42,199 [INFO] Model saved to ./models/iteration_136.pt
2025-04-26 04:52:42,199 [INFO] 所有训练迭代完成
2025-04-26 04:52:42,199 [INFO] 开始迭代 137/300
2025-04-26 04:52:42,199 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 04:58:55,782 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 04:58:55,782 [INFO] 保存训练样本
2025-04-26 04:58:59,225 [INFO] 使用 120024 个样本训练神经网络
2025-04-26 04:58:59,225 [INFO] Training with 120024 examples
2025-04-26 04:58:59,226 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 04:58:59,585 [INFO] 循环学习率周期大小: 174 步
2025-04-26 04:59:22,316 [INFO] Epoch 1/15 - Policy Loss: 0.9953, Value Loss: 0.1974, Total Loss: 1.1926, LR: 0.001672
2025-04-26 04:59:45,029 [INFO] Epoch 2/15 - Policy Loss: 0.9911, Value Loss: 0.1962, Total Loss: 1.1874, LR: 0.003322
2025-04-26 05:00:07,688 [INFO] Epoch 3/15 - Policy Loss: 0.9913, Value Loss: 0.1967, Total Loss: 1.1880, LR: 0.004972
2025-04-26 05:00:30,368 [INFO] Epoch 4/15 - Policy Loss: 0.9920, Value Loss: 0.1962, Total Loss: 1.1882, LR: 0.003378
2025-04-26 05:00:53,057 [INFO] Epoch 5/15 - Policy Loss: 0.9915, Value Loss: 0.1961, Total Loss: 1.1876, LR: 0.001728
2025-04-26 05:01:15,777 [INFO] Epoch 6/15 - Policy Loss: 0.9891, Value Loss: 0.1956, Total Loss: 1.1848, LR: 0.000078
2025-04-26 05:01:38,486 [INFO] Epoch 7/15 - Policy Loss: 0.9875, Value Loss: 0.1947, Total Loss: 1.1822, LR: 0.001672
2025-04-26 05:02:01,159 [INFO] Epoch 8/15 - Policy Loss: 0.9870, Value Loss: 0.1942, Total Loss: 1.1812, LR: 0.003322
2025-04-26 05:02:23,912 [INFO] Epoch 9/15 - Policy Loss: 0.9870, Value Loss: 0.1942, Total Loss: 1.1811, LR: 0.004972
2025-04-26 05:02:46,658 [INFO] Epoch 10/15 - Policy Loss: 0.9863, Value Loss: 0.1941, Total Loss: 1.1804, LR: 0.003378
2025-04-26 05:03:09,360 [INFO] Epoch 11/15 - Policy Loss: 0.9858, Value Loss: 0.1941, Total Loss: 1.1799, LR: 0.001728
2025-04-26 05:03:32,030 [INFO] Epoch 12/15 - Policy Loss: 0.9854, Value Loss: 0.1939, Total Loss: 1.1793, LR: 0.000078
2025-04-26 05:03:54,769 [INFO] Epoch 13/15 - Policy Loss: 0.9846, Value Loss: 0.1935, Total Loss: 1.1781, LR: 0.001672
2025-04-26 05:04:17,505 [INFO] Epoch 14/15 - Policy Loss: 0.9844, Value Loss: 0.1934, Total Loss: 1.1778, LR: 0.003322
2025-04-26 05:04:40,212 [INFO] Epoch 15/15 - Policy Loss: 0.9840, Value Loss: 0.1932, Total Loss: 1.1772, LR: 0.004972
2025-04-26 05:04:40,231 [INFO] 训练完成，总损失: 1.1772
2025-04-26 05:04:40,232 [INFO] 保存迭代 137 的模型
2025-04-26 05:04:40,758 [INFO] Model saved to ./models/best.pt
2025-04-26 05:04:41,138 [INFO] Model saved to ./models/iteration_137.pt
2025-04-26 05:04:41,138 [INFO] 所有训练迭代完成
2025-04-26 05:04:41,138 [INFO] 开始迭代 138/300
2025-04-26 05:04:41,138 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 05:10:43,631 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 05:10:43,635 [INFO] 保存训练样本
2025-04-26 05:10:47,324 [INFO] 使用 120536 个样本训练神经网络
2025-04-26 05:10:47,324 [INFO] Training with 120536 examples
2025-04-26 05:10:47,325 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 05:10:47,760 [INFO] 循环学习率周期大小: 174 步
2025-04-26 05:11:10,482 [INFO] Epoch 1/15 - Policy Loss: 1.0008, Value Loss: 0.2078, Total Loss: 1.2087, LR: 0.001672
2025-04-26 05:11:33,153 [INFO] Epoch 2/15 - Policy Loss: 0.9954, Value Loss: 0.2044, Total Loss: 1.1998, LR: 0.003322
2025-04-26 05:11:55,842 [INFO] Epoch 3/15 - Policy Loss: 0.9940, Value Loss: 0.2031, Total Loss: 1.1971, LR: 0.004972
2025-04-26 05:12:18,540 [INFO] Epoch 4/15 - Policy Loss: 0.9921, Value Loss: 0.2024, Total Loss: 1.1946, LR: 0.003378
2025-04-26 05:12:41,261 [INFO] Epoch 5/15 - Policy Loss: 0.9900, Value Loss: 0.2021, Total Loss: 1.1921, LR: 0.001728
2025-04-26 05:13:03,948 [INFO] Epoch 6/15 - Policy Loss: 0.9882, Value Loss: 0.2014, Total Loss: 1.1897, LR: 0.000078
2025-04-26 05:13:26,647 [INFO] Epoch 7/15 - Policy Loss: 0.9866, Value Loss: 0.2012, Total Loss: 1.1878, LR: 0.001672
2025-04-26 05:13:49,324 [INFO] Epoch 8/15 - Policy Loss: 0.9856, Value Loss: 0.2007, Total Loss: 1.1863, LR: 0.003322
2025-04-26 05:14:12,007 [INFO] Epoch 9/15 - Policy Loss: 0.9850, Value Loss: 0.2003, Total Loss: 1.1853, LR: 0.004972
2025-04-26 05:14:34,664 [INFO] Epoch 10/15 - Policy Loss: 0.9841, Value Loss: 0.2000, Total Loss: 1.1842, LR: 0.003378
2025-04-26 05:14:57,399 [INFO] Epoch 11/15 - Policy Loss: 0.9836, Value Loss: 0.1998, Total Loss: 1.1834, LR: 0.001728
2025-04-26 05:15:20,084 [INFO] Epoch 12/15 - Policy Loss: 0.9829, Value Loss: 0.1996, Total Loss: 1.1825, LR: 0.000078
2025-04-26 05:15:42,779 [INFO] Epoch 13/15 - Policy Loss: 0.9821, Value Loss: 0.1990, Total Loss: 1.1812, LR: 0.001672
2025-04-26 05:16:05,471 [INFO] Epoch 14/15 - Policy Loss: 0.9812, Value Loss: 0.1986, Total Loss: 1.1798, LR: 0.003322
2025-04-26 05:16:28,163 [INFO] Epoch 15/15 - Policy Loss: 0.9808, Value Loss: 0.1984, Total Loss: 1.1793, LR: 0.004972
2025-04-26 05:16:28,181 [INFO] 训练完成，总损失: 1.1793
2025-04-26 05:16:28,181 [INFO] 保存迭代 138 的模型
2025-04-26 05:16:28,610 [INFO] Model saved to ./models/best.pt
2025-04-26 05:16:28,904 [INFO] Model saved to ./models/iteration_138.pt
2025-04-26 05:16:28,904 [INFO] 所有训练迭代完成
2025-04-26 05:16:28,904 [INFO] 开始迭代 139/300
2025-04-26 05:16:28,904 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 05:22:43,401 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 05:22:43,402 [INFO] 保存训练样本
2025-04-26 05:22:46,391 [INFO] 使用 120600 个样本训练神经网络
2025-04-26 05:22:46,391 [INFO] Training with 120600 examples
2025-04-26 05:22:46,392 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 05:22:46,720 [INFO] 循环学习率周期大小: 174 步
2025-04-26 05:23:09,210 [INFO] Epoch 1/15 - Policy Loss: 0.9974, Value Loss: 0.2041, Total Loss: 1.2015, LR: 0.001672
2025-04-26 05:23:31,704 [INFO] Epoch 2/15 - Policy Loss: 0.9901, Value Loss: 0.2027, Total Loss: 1.1928, LR: 0.003322
2025-04-26 05:23:54,147 [INFO] Epoch 3/15 - Policy Loss: 0.9869, Value Loss: 0.2019, Total Loss: 1.1887, LR: 0.004972
2025-04-26 05:24:16,827 [INFO] Epoch 4/15 - Policy Loss: 0.9852, Value Loss: 0.2013, Total Loss: 1.1865, LR: 0.003378
2025-04-26 05:24:39,550 [INFO] Epoch 5/15 - Policy Loss: 0.9837, Value Loss: 0.2008, Total Loss: 1.1846, LR: 0.001728
2025-04-26 05:25:02,151 [INFO] Epoch 6/15 - Policy Loss: 0.9812, Value Loss: 0.2003, Total Loss: 1.1814, LR: 0.000078
2025-04-26 05:25:24,770 [INFO] Epoch 7/15 - Policy Loss: 0.9787, Value Loss: 0.1991, Total Loss: 1.1779, LR: 0.001672
2025-04-26 05:25:47,416 [INFO] Epoch 8/15 - Policy Loss: 0.9774, Value Loss: 0.1986, Total Loss: 1.1760, LR: 0.003322
2025-04-26 05:26:10,060 [INFO] Epoch 9/15 - Policy Loss: 0.9774, Value Loss: 0.1983, Total Loss: 1.1757, LR: 0.004972
2025-04-26 05:26:32,708 [INFO] Epoch 10/15 - Policy Loss: 0.9769, Value Loss: 0.1980, Total Loss: 1.1749, LR: 0.003378
2025-04-26 05:26:55,402 [INFO] Epoch 11/15 - Policy Loss: 0.9756, Value Loss: 0.1977, Total Loss: 1.1733, LR: 0.001728
2025-04-26 05:27:18,074 [INFO] Epoch 12/15 - Policy Loss: 0.9750, Value Loss: 0.1974, Total Loss: 1.1724, LR: 0.000078
2025-04-26 05:27:40,692 [INFO] Epoch 13/15 - Policy Loss: 0.9745, Value Loss: 0.1972, Total Loss: 1.1717, LR: 0.001672
2025-04-26 05:28:03,375 [INFO] Epoch 14/15 - Policy Loss: 0.9739, Value Loss: 0.1969, Total Loss: 1.1708, LR: 0.003322
2025-04-26 05:28:26,078 [INFO] Epoch 15/15 - Policy Loss: 0.9739, Value Loss: 0.1966, Total Loss: 1.1706, LR: 0.004972
2025-04-26 05:28:26,096 [INFO] 训练完成，总损失: 1.1706
2025-04-26 05:28:26,096 [INFO] 保存迭代 139 的模型
2025-04-26 05:28:26,505 [INFO] Model saved to ./models/best.pt
2025-04-26 05:28:26,773 [INFO] Model saved to ./models/iteration_139.pt
2025-04-26 05:28:26,773 [INFO] 所有训练迭代完成
2025-04-26 05:28:26,773 [INFO] 开始迭代 140/300
2025-04-26 05:28:26,773 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 05:34:49,969 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 05:34:49,969 [INFO] 保存训练样本
2025-04-26 05:34:53,005 [INFO] 使用 120736 个样本训练神经网络
2025-04-26 05:34:53,005 [INFO] Training with 120736 examples
2025-04-26 05:34:53,006 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 05:34:53,323 [INFO] 循环学习率周期大小: 174 步
2025-04-26 05:35:15,882 [INFO] Epoch 1/15 - Policy Loss: 0.9824, Value Loss: 0.2051, Total Loss: 1.1876, LR: 0.001672
2025-04-26 05:35:38,480 [INFO] Epoch 2/15 - Policy Loss: 0.9792, Value Loss: 0.2046, Total Loss: 1.1838, LR: 0.003322
2025-04-26 05:36:01,248 [INFO] Epoch 3/15 - Policy Loss: 0.9777, Value Loss: 0.2025, Total Loss: 1.1802, LR: 0.004972
2025-04-26 05:36:23,966 [INFO] Epoch 4/15 - Policy Loss: 0.9773, Value Loss: 0.2018, Total Loss: 1.1791, LR: 0.003378
2025-04-26 05:36:46,703 [INFO] Epoch 5/15 - Policy Loss: 0.9763, Value Loss: 0.2021, Total Loss: 1.1784, LR: 0.001728
2025-04-26 05:37:09,491 [INFO] Epoch 6/15 - Policy Loss: 0.9732, Value Loss: 0.2014, Total Loss: 1.1746, LR: 0.000078
2025-04-26 05:37:32,203 [INFO] Epoch 7/15 - Policy Loss: 0.9714, Value Loss: 0.2004, Total Loss: 1.1718, LR: 0.001672
2025-04-26 05:37:54,889 [INFO] Epoch 8/15 - Policy Loss: 0.9701, Value Loss: 0.2000, Total Loss: 1.1700, LR: 0.003322
2025-04-26 05:38:17,373 [INFO] Epoch 9/15 - Policy Loss: 0.9696, Value Loss: 0.2000, Total Loss: 1.1696, LR: 0.004972
2025-04-26 05:38:40,073 [INFO] Epoch 10/15 - Policy Loss: 0.9693, Value Loss: 0.1996, Total Loss: 1.1689, LR: 0.003378
2025-04-26 05:39:02,915 [INFO] Epoch 11/15 - Policy Loss: 0.9690, Value Loss: 0.1993, Total Loss: 1.1683, LR: 0.001728
2025-04-26 05:39:25,624 [INFO] Epoch 12/15 - Policy Loss: 0.9679, Value Loss: 0.1990, Total Loss: 1.1669, LR: 0.000078
2025-04-26 05:39:48,563 [INFO] Epoch 13/15 - Policy Loss: 0.9669, Value Loss: 0.1985, Total Loss: 1.1654, LR: 0.001672
2025-04-26 05:40:11,280 [INFO] Epoch 14/15 - Policy Loss: 0.9662, Value Loss: 0.1982, Total Loss: 1.1644, LR: 0.003322
2025-04-26 05:40:33,817 [INFO] Epoch 15/15 - Policy Loss: 0.9657, Value Loss: 0.1979, Total Loss: 1.1636, LR: 0.004972
2025-04-26 05:40:33,833 [INFO] 训练完成，总损失: 1.1636
2025-04-26 05:40:33,833 [INFO] 保存迭代 140 的模型
2025-04-26 05:40:34,203 [INFO] Model saved to ./models/best.pt
2025-04-26 05:40:34,495 [INFO] Model saved to ./models/iteration_140.pt
2025-04-26 05:40:34,496 [INFO] 所有训练迭代完成
2025-04-26 05:40:34,496 [INFO] 开始迭代 141/300
2025-04-26 05:40:34,496 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 05:47:36,927 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 05:47:36,927 [INFO] 保存训练样本
2025-04-26 05:47:40,288 [INFO] 使用 121256 个样本训练神经网络
2025-04-26 05:47:40,288 [INFO] Training with 121256 examples
2025-04-26 05:47:40,288 [INFO] 总训练步数: 885, 每轮次批次数: 59
2025-04-26 05:47:40,657 [INFO] 循环学习率周期大小: 177 步
2025-04-26 05:48:03,741 [INFO] Epoch 1/15 - Policy Loss: 0.9899, Value Loss: 0.2118, Total Loss: 1.2017, LR: 0.001672
2025-04-26 05:48:26,887 [INFO] Epoch 2/15 - Policy Loss: 0.9826, Value Loss: 0.2080, Total Loss: 1.1906, LR: 0.003322
2025-04-26 05:48:50,112 [INFO] Epoch 3/15 - Policy Loss: 0.9797, Value Loss: 0.2051, Total Loss: 1.1848, LR: 0.004972
2025-04-26 05:49:13,298 [INFO] Epoch 4/15 - Policy Loss: 0.9787, Value Loss: 0.2050, Total Loss: 1.1836, LR: 0.003378
2025-04-26 05:49:36,492 [INFO] Epoch 5/15 - Policy Loss: 0.9760, Value Loss: 0.2037, Total Loss: 1.1796, LR: 0.001728
2025-04-26 05:49:59,759 [INFO] Epoch 6/15 - Policy Loss: 0.9722, Value Loss: 0.2017, Total Loss: 1.1738, LR: 0.000078
2025-04-26 05:50:22,925 [INFO] Epoch 7/15 - Policy Loss: 0.9699, Value Loss: 0.2008, Total Loss: 1.1707, LR: 0.001672
2025-04-26 05:50:46,106 [INFO] Epoch 8/15 - Policy Loss: 0.9684, Value Loss: 0.2003, Total Loss: 1.1687, LR: 0.003322
2025-04-26 05:51:09,295 [INFO] Epoch 9/15 - Policy Loss: 0.9675, Value Loss: 0.2001, Total Loss: 1.1676, LR: 0.004972
2025-04-26 05:51:32,529 [INFO] Epoch 10/15 - Policy Loss: 0.9667, Value Loss: 0.1998, Total Loss: 1.1665, LR: 0.003378
2025-04-26 05:51:56,191 [INFO] Epoch 11/15 - Policy Loss: 0.9661, Value Loss: 0.1996, Total Loss: 1.1657, LR: 0.001728
2025-04-26 05:52:19,170 [INFO] Epoch 12/15 - Policy Loss: 0.9650, Value Loss: 0.1992, Total Loss: 1.1642, LR: 0.000078
2025-04-26 05:52:42,068 [INFO] Epoch 13/15 - Policy Loss: 0.9638, Value Loss: 0.1989, Total Loss: 1.1626, LR: 0.001672
2025-04-26 05:53:04,938 [INFO] Epoch 14/15 - Policy Loss: 0.9626, Value Loss: 0.1983, Total Loss: 1.1610, LR: 0.003322
2025-04-26 05:53:27,809 [INFO] Epoch 15/15 - Policy Loss: 0.9621, Value Loss: 0.1981, Total Loss: 1.1602, LR: 0.004972
2025-04-26 05:53:27,826 [INFO] 训练完成，总损失: 1.1602
2025-04-26 05:53:27,826 [INFO] 保存迭代 141 的模型
2025-04-26 05:53:28,174 [INFO] Model saved to ./models/best.pt
2025-04-26 05:53:28,430 [INFO] Model saved to ./models/iteration_141.pt
2025-04-26 05:53:28,430 [INFO] 所有训练迭代完成
2025-04-26 05:53:28,431 [INFO] 开始迭代 142/300
2025-04-26 05:53:28,431 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 05:59:51,900 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 05:59:51,901 [INFO] 保存训练样本
2025-04-26 05:59:55,560 [INFO] 使用 121504 个样本训练神经网络
2025-04-26 05:59:55,560 [INFO] Training with 121504 examples
2025-04-26 05:59:55,561 [INFO] 总训练步数: 885, 每轮次批次数: 59
2025-04-26 05:59:55,607 [INFO] 循环学习率周期大小: 177 步
2025-04-26 06:00:18,852 [INFO] Epoch 1/15 - Policy Loss: 0.9934, Value Loss: 0.2235, Total Loss: 1.2169, LR: 0.001672
2025-04-26 06:00:42,006 [INFO] Epoch 2/15 - Policy Loss: 0.9832, Value Loss: 0.2171, Total Loss: 1.2003, LR: 0.003322
2025-04-26 06:01:05,002 [INFO] Epoch 3/15 - Policy Loss: 0.9784, Value Loss: 0.2140, Total Loss: 1.1924, LR: 0.004972
2025-04-26 06:01:28,009 [INFO] Epoch 4/15 - Policy Loss: 0.9760, Value Loss: 0.2126, Total Loss: 1.1887, LR: 0.003378
2025-04-26 06:01:51,062 [INFO] Epoch 5/15 - Policy Loss: 0.9723, Value Loss: 0.2106, Total Loss: 1.1829, LR: 0.001728
2025-04-26 06:02:13,970 [INFO] Epoch 6/15 - Policy Loss: 0.9696, Value Loss: 0.2087, Total Loss: 1.1783, LR: 0.000078
2025-04-26 06:02:36,872 [INFO] Epoch 7/15 - Policy Loss: 0.9670, Value Loss: 0.2074, Total Loss: 1.1744, LR: 0.001672
2025-04-26 06:03:00,115 [INFO] Epoch 8/15 - Policy Loss: 0.9647, Value Loss: 0.2063, Total Loss: 1.1709, LR: 0.003322
2025-04-26 06:03:23,082 [INFO] Epoch 9/15 - Policy Loss: 0.9635, Value Loss: 0.2057, Total Loss: 1.1692, LR: 0.004972
2025-04-26 06:03:46,062 [INFO] Epoch 10/15 - Policy Loss: 0.9632, Value Loss: 0.2053, Total Loss: 1.1685, LR: 0.003378
2025-04-26 06:04:08,965 [INFO] Epoch 11/15 - Policy Loss: 0.9622, Value Loss: 0.2047, Total Loss: 1.1668, LR: 0.001728
2025-04-26 06:04:31,959 [INFO] Epoch 12/15 - Policy Loss: 0.9611, Value Loss: 0.2042, Total Loss: 1.1653, LR: 0.000078
2025-04-26 06:04:54,998 [INFO] Epoch 13/15 - Policy Loss: 0.9602, Value Loss: 0.2037, Total Loss: 1.1639, LR: 0.001672
2025-04-26 06:05:18,123 [INFO] Epoch 14/15 - Policy Loss: 0.9596, Value Loss: 0.2033, Total Loss: 1.1629, LR: 0.003322
2025-04-26 06:05:41,189 [INFO] Epoch 15/15 - Policy Loss: 0.9591, Value Loss: 0.2028, Total Loss: 1.1618, LR: 0.004972
2025-04-26 06:05:41,205 [INFO] 训练完成，总损失: 1.1618
2025-04-26 06:05:41,205 [INFO] 保存迭代 142 的模型
2025-04-26 06:05:41,581 [INFO] Model saved to ./models/best.pt
2025-04-26 06:05:41,853 [INFO] Model saved to ./models/iteration_142.pt
2025-04-26 06:05:41,854 [INFO] 所有训练迭代完成
2025-04-26 06:05:41,854 [INFO] 开始迭代 143/300
2025-04-26 06:05:41,854 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 06:10:46,940 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 06:10:46,940 [INFO] 保存训练样本
2025-04-26 06:10:49,563 [INFO] 使用 121112 个样本训练神经网络
2025-04-26 06:10:49,563 [INFO] Training with 121112 examples
2025-04-26 06:10:49,563 [INFO] 总训练步数: 885, 每轮次批次数: 59
2025-04-26 06:10:49,597 [INFO] 循环学习率周期大小: 177 步
2025-04-26 06:11:12,441 [INFO] Epoch 1/15 - Policy Loss: 0.9885, Value Loss: 0.2179, Total Loss: 1.2064, LR: 0.001672
2025-04-26 06:11:35,286 [INFO] Epoch 2/15 - Policy Loss: 0.9809, Value Loss: 0.2149, Total Loss: 1.1958, LR: 0.003322
2025-04-26 06:11:58,121 [INFO] Epoch 3/15 - Policy Loss: 0.9774, Value Loss: 0.2123, Total Loss: 1.1897, LR: 0.004972
2025-04-26 06:12:20,937 [INFO] Epoch 4/15 - Policy Loss: 0.9755, Value Loss: 0.2116, Total Loss: 1.1871, LR: 0.003378
2025-04-26 06:12:44,107 [INFO] Epoch 5/15 - Policy Loss: 0.9729, Value Loss: 0.2104, Total Loss: 1.1833, LR: 0.001728
2025-04-26 06:13:06,959 [INFO] Epoch 6/15 - Policy Loss: 0.9697, Value Loss: 0.2093, Total Loss: 1.1790, LR: 0.000078
2025-04-26 06:13:29,827 [INFO] Epoch 7/15 - Policy Loss: 0.9673, Value Loss: 0.2084, Total Loss: 1.1757, LR: 0.001672
2025-04-26 06:13:52,674 [INFO] Epoch 8/15 - Policy Loss: 0.9653, Value Loss: 0.2078, Total Loss: 1.1731, LR: 0.003322
2025-04-26 06:14:15,535 [INFO] Epoch 9/15 - Policy Loss: 0.9644, Value Loss: 0.2074, Total Loss: 1.1718, LR: 0.004972
2025-04-26 06:14:38,543 [INFO] Epoch 10/15 - Policy Loss: 0.9639, Value Loss: 0.2072, Total Loss: 1.1712, LR: 0.003378
2025-04-26 06:15:01,558 [INFO] Epoch 11/15 - Policy Loss: 0.9631, Value Loss: 0.2069, Total Loss: 1.1700, LR: 0.001728
2025-04-26 06:15:24,379 [INFO] Epoch 12/15 - Policy Loss: 0.9617, Value Loss: 0.2063, Total Loss: 1.1680, LR: 0.000078
2025-04-26 06:15:47,186 [INFO] Epoch 13/15 - Policy Loss: 0.9611, Value Loss: 0.2060, Total Loss: 1.1671, LR: 0.001672
2025-04-26 06:16:10,005 [INFO] Epoch 14/15 - Policy Loss: 0.9601, Value Loss: 0.2056, Total Loss: 1.1657, LR: 0.003322
2025-04-26 06:16:32,823 [INFO] Epoch 15/15 - Policy Loss: 0.9595, Value Loss: 0.2052, Total Loss: 1.1647, LR: 0.004972
2025-04-26 06:16:32,839 [INFO] 训练完成，总损失: 1.1647
2025-04-26 06:16:32,839 [INFO] 保存迭代 143 的模型
2025-04-26 06:16:33,275 [INFO] Model saved to ./models/best.pt
2025-04-26 06:16:33,597 [INFO] Model saved to ./models/iteration_143.pt
2025-04-26 06:16:33,597 [INFO] 所有训练迭代完成
2025-04-26 06:16:33,597 [INFO] 开始迭代 144/300
2025-04-26 06:16:33,597 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 06:22:34,856 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 06:22:34,857 [INFO] 保存训练样本
2025-04-26 06:22:38,264 [INFO] 使用 120848 个样本训练神经网络
2025-04-26 06:22:38,265 [INFO] Training with 120848 examples
2025-04-26 06:22:38,265 [INFO] 总训练步数: 885, 每轮次批次数: 59
2025-04-26 06:22:38,316 [INFO] 循环学习率周期大小: 177 步
2025-04-26 06:23:01,198 [INFO] Epoch 1/15 - Policy Loss: 0.9794, Value Loss: 0.2118, Total Loss: 1.1912, LR: 0.001672
2025-04-26 06:23:24,354 [INFO] Epoch 2/15 - Policy Loss: 0.9725, Value Loss: 0.2101, Total Loss: 1.1826, LR: 0.003322
2025-04-26 06:23:47,266 [INFO] Epoch 3/15 - Policy Loss: 0.9713, Value Loss: 0.2100, Total Loss: 1.1813, LR: 0.004972
2025-04-26 06:24:10,112 [INFO] Epoch 4/15 - Policy Loss: 0.9701, Value Loss: 0.2086, Total Loss: 1.1787, LR: 0.003378
2025-04-26 06:24:32,985 [INFO] Epoch 5/15 - Policy Loss: 0.9686, Value Loss: 0.2073, Total Loss: 1.1759, LR: 0.001728
2025-04-26 06:24:55,893 [INFO] Epoch 6/15 - Policy Loss: 0.9667, Value Loss: 0.2064, Total Loss: 1.1731, LR: 0.000078
2025-04-26 06:25:18,745 [INFO] Epoch 7/15 - Policy Loss: 0.9641, Value Loss: 0.2058, Total Loss: 1.1700, LR: 0.001672
2025-04-26 06:25:41,579 [INFO] Epoch 8/15 - Policy Loss: 0.9621, Value Loss: 0.2044, Total Loss: 1.1665, LR: 0.003322
2025-04-26 06:26:04,406 [INFO] Epoch 9/15 - Policy Loss: 0.9620, Value Loss: 0.2041, Total Loss: 1.1661, LR: 0.004972
2025-04-26 06:26:27,245 [INFO] Epoch 10/15 - Policy Loss: 0.9609, Value Loss: 0.2039, Total Loss: 1.1648, LR: 0.003378
2025-04-26 06:26:50,094 [INFO] Epoch 11/15 - Policy Loss: 0.9603, Value Loss: 0.2037, Total Loss: 1.1640, LR: 0.001728
2025-04-26 06:27:12,921 [INFO] Epoch 12/15 - Policy Loss: 0.9592, Value Loss: 0.2033, Total Loss: 1.1625, LR: 0.000078
2025-04-26 06:27:35,780 [INFO] Epoch 13/15 - Policy Loss: 0.9582, Value Loss: 0.2029, Total Loss: 1.1612, LR: 0.001672
2025-04-26 06:27:58,657 [INFO] Epoch 14/15 - Policy Loss: 0.9574, Value Loss: 0.2026, Total Loss: 1.1599, LR: 0.003322
2025-04-26 06:28:21,511 [INFO] Epoch 15/15 - Policy Loss: 0.9570, Value Loss: 0.2023, Total Loss: 1.1592, LR: 0.004972
2025-04-26 06:28:21,526 [INFO] 训练完成，总损失: 1.1592
2025-04-26 06:28:21,526 [INFO] 保存迭代 144 的模型
2025-04-26 06:28:21,974 [INFO] Model saved to ./models/best.pt
2025-04-26 06:28:22,269 [INFO] Model saved to ./models/iteration_144.pt
2025-04-26 06:28:22,270 [INFO] 所有训练迭代完成
2025-04-26 06:28:22,270 [INFO] 开始迭代 145/300
2025-04-26 06:28:22,270 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 06:35:05,313 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 06:35:05,314 [INFO] 保存训练样本
2025-04-26 06:35:08,169 [INFO] 使用 120536 个样本训练神经网络
2025-04-26 06:35:08,169 [INFO] Training with 120536 examples
2025-04-26 06:35:08,169 [INFO] 总训练步数: 870, 每轮次批次数: 58
2025-04-26 06:35:08,545 [INFO] 循环学习率周期大小: 174 步
2025-04-26 06:35:31,093 [INFO] Epoch 1/15 - Policy Loss: 0.9747, Value Loss: 0.2317, Total Loss: 1.2064, LR: 0.001672
2025-04-26 06:35:53,558 [INFO] Epoch 2/15 - Policy Loss: 0.9705, Value Loss: 0.2277, Total Loss: 1.1982, LR: 0.003322
2025-04-26 06:36:16,018 [INFO] Epoch 3/15 - Policy Loss: 0.9672, Value Loss: 0.2235, Total Loss: 1.1908, LR: 0.004972
2025-04-26 06:36:38,491 [INFO] Epoch 4/15 - Policy Loss: 0.9658, Value Loss: 0.2218, Total Loss: 1.1875, LR: 0.003378
2025-04-26 06:37:00,953 [INFO] Epoch 5/15 - Policy Loss: 0.9623, Value Loss: 0.2196, Total Loss: 1.1819, LR: 0.001728
2025-04-26 06:37:23,409 [INFO] Epoch 6/15 - Policy Loss: 0.9601, Value Loss: 0.2172, Total Loss: 1.1773, LR: 0.000078
2025-04-26 06:37:45,885 [INFO] Epoch 7/15 - Policy Loss: 0.9576, Value Loss: 0.2154, Total Loss: 1.1730, LR: 0.001672
2025-04-26 06:38:08,359 [INFO] Epoch 8/15 - Policy Loss: 0.9563, Value Loss: 0.2142, Total Loss: 1.1705, LR: 0.003322
2025-04-26 06:38:30,829 [INFO] Epoch 9/15 - Policy Loss: 0.9554, Value Loss: 0.2135, Total Loss: 1.1689, LR: 0.004972
2025-04-26 06:38:53,301 [INFO] Epoch 10/15 - Policy Loss: 0.9551, Value Loss: 0.2129, Total Loss: 1.1679, LR: 0.003378
2025-04-26 06:39:15,774 [INFO] Epoch 11/15 - Policy Loss: 0.9541, Value Loss: 0.2122, Total Loss: 1.1662, LR: 0.001728
2025-04-26 06:39:38,234 [INFO] Epoch 12/15 - Policy Loss: 0.9533, Value Loss: 0.2118, Total Loss: 1.1651, LR: 0.000078
2025-04-26 06:40:00,699 [INFO] Epoch 13/15 - Policy Loss: 0.9517, Value Loss: 0.2113, Total Loss: 1.1631, LR: 0.001672
2025-04-26 06:40:23,178 [INFO] Epoch 14/15 - Policy Loss: 0.9514, Value Loss: 0.2109, Total Loss: 1.1623, LR: 0.003322
2025-04-26 06:40:45,642 [INFO] Epoch 15/15 - Policy Loss: 0.9507, Value Loss: 0.2107, Total Loss: 1.1614, LR: 0.004972
2025-04-26 06:40:45,658 [INFO] 训练完成，总损失: 1.1614
2025-04-26 06:40:45,658 [INFO] 保存迭代 145 的模型
2025-04-26 06:40:46,093 [INFO] Model saved to ./models/best.pt
2025-04-26 06:40:46,384 [INFO] Model saved to ./models/iteration_145.pt
2025-04-26 06:40:46,384 [INFO] 所有训练迭代完成
2025-04-26 06:40:46,384 [INFO] 开始迭代 146/300
2025-04-26 06:40:46,384 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 06:47:49,883 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 06:47:49,884 [INFO] 保存训练样本
2025-04-26 06:47:52,816 [INFO] 使用 120928 个样本训练神经网络
2025-04-26 06:47:52,816 [INFO] Training with 120928 examples
2025-04-26 06:47:52,817 [INFO] 总训练步数: 885, 每轮次批次数: 59
2025-04-26 06:47:53,140 [INFO] 循环学习率周期大小: 177 步
2025-04-26 06:48:15,974 [INFO] Epoch 1/15 - Policy Loss: 0.9685, Value Loss: 0.2101, Total Loss: 1.1786, LR: 0.001672
2025-04-26 06:48:38,801 [INFO] Epoch 2/15 - Policy Loss: 0.9632, Value Loss: 0.2088, Total Loss: 1.1720, LR: 0.003322
2025-04-26 06:49:01,632 [INFO] Epoch 3/15 - Policy Loss: 0.9624, Value Loss: 0.2064, Total Loss: 1.1688, LR: 0.004972
2025-04-26 06:49:24,465 [INFO] Epoch 4/15 - Policy Loss: 0.9593, Value Loss: 0.2057, Total Loss: 1.1649, LR: 0.003378
2025-04-26 06:49:47,304 [INFO] Epoch 5/15 - Policy Loss: 0.9578, Value Loss: 0.2050, Total Loss: 1.1629, LR: 0.001728
2025-04-26 06:50:10,132 [INFO] Epoch 6/15 - Policy Loss: 0.9552, Value Loss: 0.2036, Total Loss: 1.1588, LR: 0.000078
2025-04-26 06:50:33,014 [INFO] Epoch 7/15 - Policy Loss: 0.9529, Value Loss: 0.2027, Total Loss: 1.1556, LR: 0.001672
2025-04-26 06:50:55,875 [INFO] Epoch 8/15 - Policy Loss: 0.9515, Value Loss: 0.2021, Total Loss: 1.1536, LR: 0.003322
2025-04-26 06:51:18,755 [INFO] Epoch 9/15 - Policy Loss: 0.9506, Value Loss: 0.2015, Total Loss: 1.1521, LR: 0.004972
2025-04-26 06:51:41,811 [INFO] Epoch 10/15 - Policy Loss: 0.9493, Value Loss: 0.2008, Total Loss: 1.1500, LR: 0.003378
2025-04-26 06:52:04,804 [INFO] Epoch 11/15 - Policy Loss: 0.9490, Value Loss: 0.2001, Total Loss: 1.1492, LR: 0.001728
2025-04-26 06:52:27,737 [INFO] Epoch 12/15 - Policy Loss: 0.9479, Value Loss: 0.1996, Total Loss: 1.1475, LR: 0.000078
2025-04-26 06:52:50,716 [INFO] Epoch 13/15 - Policy Loss: 0.9467, Value Loss: 0.1991, Total Loss: 1.1457, LR: 0.001672
2025-04-26 06:53:13,697 [INFO] Epoch 14/15 - Policy Loss: 0.9461, Value Loss: 0.1988, Total Loss: 1.1449, LR: 0.003322
2025-04-26 06:53:36,928 [INFO] Epoch 15/15 - Policy Loss: 0.9459, Value Loss: 0.1986, Total Loss: 1.1445, LR: 0.004972
2025-04-26 06:53:36,949 [INFO] 训练完成，总损失: 1.1445
2025-04-26 06:53:36,949 [INFO] 保存迭代 146 的模型
2025-04-26 06:53:37,361 [INFO] Model saved to ./models/best.pt
2025-04-26 06:53:37,729 [INFO] Model saved to ./models/iteration_146.pt
2025-04-26 06:53:37,729 [INFO] 所有训练迭代完成
2025-04-26 06:53:37,729 [INFO] 开始迭代 147/300
2025-04-26 06:53:37,729 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 07:00:19,103 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 07:00:19,103 [INFO] 保存训练样本
2025-04-26 07:00:22,208 [INFO] 使用 121664 个样本训练神经网络
2025-04-26 07:00:22,208 [INFO] Training with 121664 examples
2025-04-26 07:00:22,209 [INFO] 总训练步数: 885, 每轮次批次数: 59
2025-04-26 07:00:22,595 [INFO] 循环学习率周期大小: 177 步
2025-04-26 07:00:45,532 [INFO] Epoch 1/15 - Policy Loss: 0.9655, Value Loss: 0.2078, Total Loss: 1.1733, LR: 0.001672
2025-04-26 07:01:08,461 [INFO] Epoch 2/15 - Policy Loss: 0.9576, Value Loss: 0.2063, Total Loss: 1.1638, LR: 0.003322
2025-04-26 07:01:31,375 [INFO] Epoch 3/15 - Policy Loss: 0.9555, Value Loss: 0.2043, Total Loss: 1.1597, LR: 0.004972
2025-04-26 07:01:54,336 [INFO] Epoch 4/15 - Policy Loss: 0.9524, Value Loss: 0.2031, Total Loss: 1.1555, LR: 0.003378
2025-04-26 07:02:17,298 [INFO] Epoch 5/15 - Policy Loss: 0.9506, Value Loss: 0.2028, Total Loss: 1.1534, LR: 0.001728
2025-04-26 07:02:40,236 [INFO] Epoch 6/15 - Policy Loss: 0.9478, Value Loss: 0.2021, Total Loss: 1.1499, LR: 0.000078
2025-04-26 07:03:03,117 [INFO] Epoch 7/15 - Policy Loss: 0.9456, Value Loss: 0.2014, Total Loss: 1.1470, LR: 0.001672
2025-04-26 07:03:26,077 [INFO] Epoch 8/15 - Policy Loss: 0.9444, Value Loss: 0.2011, Total Loss: 1.1454, LR: 0.003322
2025-04-26 07:03:49,059 [INFO] Epoch 9/15 - Policy Loss: 0.9440, Value Loss: 0.2006, Total Loss: 1.1446, LR: 0.004972
2025-04-26 07:04:11,935 [INFO] Epoch 10/15 - Policy Loss: 0.9431, Value Loss: 0.2004, Total Loss: 1.1436, LR: 0.003378
2025-04-26 07:04:34,826 [INFO] Epoch 11/15 - Policy Loss: 0.9424, Value Loss: 0.2002, Total Loss: 1.1426, LR: 0.001728
2025-04-26 07:04:57,793 [INFO] Epoch 12/15 - Policy Loss: 0.9410, Value Loss: 0.1998, Total Loss: 1.1409, LR: 0.000078
2025-04-26 07:05:21,138 [INFO] Epoch 13/15 - Policy Loss: 0.9398, Value Loss: 0.1992, Total Loss: 1.1390, LR: 0.001672
2025-04-26 07:05:44,214 [INFO] Epoch 14/15 - Policy Loss: 0.9392, Value Loss: 0.1990, Total Loss: 1.1383, LR: 0.003322
2025-04-26 07:06:07,278 [INFO] Epoch 15/15 - Policy Loss: 0.9389, Value Loss: 0.1985, Total Loss: 1.1375, LR: 0.004972
2025-04-26 07:06:07,296 [INFO] 训练完成，总损失: 1.1375
2025-04-26 07:06:07,296 [INFO] 保存迭代 147 的模型
2025-04-26 07:06:07,697 [INFO] Model saved to ./models/best.pt
2025-04-26 07:06:07,993 [INFO] Model saved to ./models/iteration_147.pt
2025-04-26 07:06:07,993 [INFO] 所有训练迭代完成
2025-04-26 07:06:07,993 [INFO] 开始迭代 148/300
2025-04-26 07:06:07,993 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 07:13:38,366 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 07:13:38,366 [INFO] 保存训练样本
2025-04-26 07:13:41,569 [INFO] 使用 123120 个样本训练神经网络
2025-04-26 07:13:41,569 [INFO] Training with 123120 examples
2025-04-26 07:13:41,569 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 07:13:41,906 [INFO] 循环学习率周期大小: 180 步
2025-04-26 07:14:05,326 [INFO] Epoch 1/15 - Policy Loss: 0.9656, Value Loss: 0.2119, Total Loss: 1.1775, LR: 0.001673
2025-04-26 07:14:28,634 [INFO] Epoch 2/15 - Policy Loss: 0.9611, Value Loss: 0.2093, Total Loss: 1.1704, LR: 0.003323
2025-04-26 07:14:52,041 [INFO] Epoch 3/15 - Policy Loss: 0.9571, Value Loss: 0.2075, Total Loss: 1.1646, LR: 0.004973
2025-04-26 07:15:15,340 [INFO] Epoch 4/15 - Policy Loss: 0.9557, Value Loss: 0.2064, Total Loss: 1.1621, LR: 0.003377
2025-04-26 07:15:38,893 [INFO] Epoch 5/15 - Policy Loss: 0.9530, Value Loss: 0.2057, Total Loss: 1.1588, LR: 0.001727
2025-04-26 07:16:02,449 [INFO] Epoch 6/15 - Policy Loss: 0.9510, Value Loss: 0.2050, Total Loss: 1.1560, LR: 0.000077
2025-04-26 07:16:25,921 [INFO] Epoch 7/15 - Policy Loss: 0.9483, Value Loss: 0.2038, Total Loss: 1.1521, LR: 0.001673
2025-04-26 07:16:49,239 [INFO] Epoch 8/15 - Policy Loss: 0.9466, Value Loss: 0.2030, Total Loss: 1.1496, LR: 0.003323
2025-04-26 07:17:12,544 [INFO] Epoch 9/15 - Policy Loss: 0.9450, Value Loss: 0.2025, Total Loss: 1.1475, LR: 0.004973
2025-04-26 07:17:35,805 [INFO] Epoch 10/15 - Policy Loss: 0.9439, Value Loss: 0.2020, Total Loss: 1.1459, LR: 0.003377
2025-04-26 07:17:59,268 [INFO] Epoch 11/15 - Policy Loss: 0.9427, Value Loss: 0.2014, Total Loss: 1.1441, LR: 0.001727
2025-04-26 07:18:22,493 [INFO] Epoch 12/15 - Policy Loss: 0.9419, Value Loss: 0.2008, Total Loss: 1.1427, LR: 0.000077
2025-04-26 07:18:45,785 [INFO] Epoch 13/15 - Policy Loss: 0.9408, Value Loss: 0.2003, Total Loss: 1.1411, LR: 0.001673
2025-04-26 07:19:09,072 [INFO] Epoch 14/15 - Policy Loss: 0.9399, Value Loss: 0.1999, Total Loss: 1.1399, LR: 0.003323
2025-04-26 07:19:32,421 [INFO] Epoch 15/15 - Policy Loss: 0.9393, Value Loss: 0.1996, Total Loss: 1.1389, LR: 0.004973
2025-04-26 07:19:32,437 [INFO] 训练完成，总损失: 1.1389
2025-04-26 07:19:32,437 [INFO] 保存迭代 148 的模型
2025-04-26 07:19:32,815 [INFO] Model saved to ./models/best.pt
2025-04-26 07:19:33,069 [INFO] Model saved to ./models/iteration_148.pt
2025-04-26 07:19:33,069 [INFO] 所有训练迭代完成
2025-04-26 07:19:33,069 [INFO] 开始迭代 149/300
2025-04-26 07:19:33,069 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 07:26:36,867 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 07:26:36,867 [INFO] 保存训练样本
2025-04-26 07:26:40,369 [INFO] 使用 123616 个样本训练神经网络
2025-04-26 07:26:40,370 [INFO] Training with 123616 examples
2025-04-26 07:26:40,370 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 07:26:40,445 [INFO] 循环学习率周期大小: 180 步
2025-04-26 07:27:03,914 [INFO] Epoch 1/15 - Policy Loss: 0.9549, Value Loss: 0.2075, Total Loss: 1.1624, LR: 0.001673
2025-04-26 07:27:27,230 [INFO] Epoch 2/15 - Policy Loss: 0.9543, Value Loss: 0.2069, Total Loss: 1.1612, LR: 0.003323
2025-04-26 07:27:50,513 [INFO] Epoch 3/15 - Policy Loss: 0.9499, Value Loss: 0.2054, Total Loss: 1.1554, LR: 0.004973
2025-04-26 07:28:13,922 [INFO] Epoch 4/15 - Policy Loss: 0.9481, Value Loss: 0.2042, Total Loss: 1.1523, LR: 0.003377
2025-04-26 07:28:37,389 [INFO] Epoch 5/15 - Policy Loss: 0.9458, Value Loss: 0.2043, Total Loss: 1.1501, LR: 0.001727
2025-04-26 07:29:00,823 [INFO] Epoch 6/15 - Policy Loss: 0.9435, Value Loss: 0.2033, Total Loss: 1.1468, LR: 0.000077
2025-04-26 07:29:24,224 [INFO] Epoch 7/15 - Policy Loss: 0.9408, Value Loss: 0.2026, Total Loss: 1.1434, LR: 0.001673
2025-04-26 07:29:47,735 [INFO] Epoch 8/15 - Policy Loss: 0.9394, Value Loss: 0.2019, Total Loss: 1.1413, LR: 0.003323
2025-04-26 07:30:11,600 [INFO] Epoch 9/15 - Policy Loss: 0.9381, Value Loss: 0.2012, Total Loss: 1.1394, LR: 0.004973
2025-04-26 07:30:35,148 [INFO] Epoch 10/15 - Policy Loss: 0.9374, Value Loss: 0.2008, Total Loss: 1.1382, LR: 0.003377
2025-04-26 07:30:58,592 [INFO] Epoch 11/15 - Policy Loss: 0.9368, Value Loss: 0.2004, Total Loss: 1.1373, LR: 0.001727
2025-04-26 07:31:22,024 [INFO] Epoch 12/15 - Policy Loss: 0.9357, Value Loss: 0.2002, Total Loss: 1.1358, LR: 0.000077
2025-04-26 07:31:45,482 [INFO] Epoch 13/15 - Policy Loss: 0.9350, Value Loss: 0.2001, Total Loss: 1.1350, LR: 0.001673
2025-04-26 07:32:08,923 [INFO] Epoch 14/15 - Policy Loss: 0.9338, Value Loss: 0.1998, Total Loss: 1.1336, LR: 0.003323
2025-04-26 07:32:32,382 [INFO] Epoch 15/15 - Policy Loss: 0.9335, Value Loss: 0.1996, Total Loss: 1.1331, LR: 0.004973
2025-04-26 07:32:32,400 [INFO] 训练完成，总损失: 1.1331
2025-04-26 07:32:32,400 [INFO] 保存迭代 149 的模型
2025-04-26 07:32:32,814 [INFO] Model saved to ./models/best.pt
2025-04-26 07:32:33,098 [INFO] Model saved to ./models/iteration_149.pt
2025-04-26 07:32:33,098 [INFO] 所有训练迭代完成
2025-04-26 07:32:33,098 [INFO] 开始迭代 150/300
2025-04-26 07:32:33,098 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 07:39:35,126 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 07:39:35,127 [INFO] 保存训练样本
2025-04-26 07:39:38,463 [INFO] 使用 123648 个样本训练神经网络
2025-04-26 07:39:38,463 [INFO] Training with 123648 examples
2025-04-26 07:39:38,463 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 07:39:38,504 [INFO] 循环学习率周期大小: 180 步
2025-04-26 07:40:01,758 [INFO] Epoch 1/15 - Policy Loss: 0.9572, Value Loss: 0.2169, Total Loss: 1.1741, LR: 0.001673
2025-04-26 07:40:24,936 [INFO] Epoch 2/15 - Policy Loss: 0.9527, Value Loss: 0.2163, Total Loss: 1.1690, LR: 0.003323
2025-04-26 07:40:48,111 [INFO] Epoch 3/15 - Policy Loss: 0.9503, Value Loss: 0.2153, Total Loss: 1.1657, LR: 0.004973
2025-04-26 07:41:11,607 [INFO] Epoch 4/15 - Policy Loss: 0.9478, Value Loss: 0.2151, Total Loss: 1.1629, LR: 0.003377
2025-04-26 07:41:34,825 [INFO] Epoch 5/15 - Policy Loss: 0.9451, Value Loss: 0.2144, Total Loss: 1.1595, LR: 0.001727
2025-04-26 07:41:58,035 [INFO] Epoch 6/15 - Policy Loss: 0.9425, Value Loss: 0.2132, Total Loss: 1.1558, LR: 0.000077
2025-04-26 07:42:21,292 [INFO] Epoch 7/15 - Policy Loss: 0.9401, Value Loss: 0.2123, Total Loss: 1.1524, LR: 0.001673
2025-04-26 07:42:44,600 [INFO] Epoch 8/15 - Policy Loss: 0.9378, Value Loss: 0.2114, Total Loss: 1.1492, LR: 0.003323
2025-04-26 07:43:08,071 [INFO] Epoch 9/15 - Policy Loss: 0.9368, Value Loss: 0.2106, Total Loss: 1.1475, LR: 0.004973
2025-04-26 07:43:31,549 [INFO] Epoch 10/15 - Policy Loss: 0.9359, Value Loss: 0.2102, Total Loss: 1.1461, LR: 0.003377
2025-04-26 07:43:55,016 [INFO] Epoch 11/15 - Policy Loss: 0.9351, Value Loss: 0.2099, Total Loss: 1.1450, LR: 0.001727
2025-04-26 07:44:18,459 [INFO] Epoch 12/15 - Policy Loss: 0.9337, Value Loss: 0.2094, Total Loss: 1.1432, LR: 0.000077
2025-04-26 07:44:41,942 [INFO] Epoch 13/15 - Policy Loss: 0.9322, Value Loss: 0.2091, Total Loss: 1.1412, LR: 0.001673
2025-04-26 07:45:05,413 [INFO] Epoch 14/15 - Policy Loss: 0.9312, Value Loss: 0.2083, Total Loss: 1.1395, LR: 0.003323
2025-04-26 07:45:28,897 [INFO] Epoch 15/15 - Policy Loss: 0.9304, Value Loss: 0.2081, Total Loss: 1.1385, LR: 0.004973
2025-04-26 07:45:28,915 [INFO] 训练完成，总损失: 1.1385
2025-04-26 07:45:28,915 [INFO] 保存迭代 150 的模型
2025-04-26 07:45:29,336 [INFO] Model saved to ./models/best.pt
2025-04-26 07:45:29,613 [INFO] Model saved to ./models/iteration_150.pt
2025-04-26 07:45:29,613 [INFO] 所有训练迭代完成
2025-04-26 07:45:29,613 [INFO] 开始迭代 151/300
2025-04-26 07:45:29,613 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 07:51:52,878 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 07:51:52,878 [INFO] 保存训练样本
2025-04-26 07:51:56,235 [INFO] 使用 123096 个样本训练神经网络
2025-04-26 07:51:56,235 [INFO] Training with 123096 examples
2025-04-26 07:51:56,236 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 07:51:56,278 [INFO] 循环学习率周期大小: 180 步
2025-04-26 07:52:19,820 [INFO] Epoch 1/15 - Policy Loss: 0.9488, Value Loss: 0.2242, Total Loss: 1.1730, LR: 0.001673
2025-04-26 07:52:43,135 [INFO] Epoch 2/15 - Policy Loss: 0.9449, Value Loss: 0.2194, Total Loss: 1.1643, LR: 0.003323
2025-04-26 07:53:06,580 [INFO] Epoch 3/15 - Policy Loss: 0.9427, Value Loss: 0.2158, Total Loss: 1.1585, LR: 0.004973
2025-04-26 07:53:30,115 [INFO] Epoch 4/15 - Policy Loss: 0.9397, Value Loss: 0.2142, Total Loss: 1.1540, LR: 0.003377
2025-04-26 07:53:53,650 [INFO] Epoch 5/15 - Policy Loss: 0.9378, Value Loss: 0.2129, Total Loss: 1.1507, LR: 0.001727
2025-04-26 07:54:17,272 [INFO] Epoch 6/15 - Policy Loss: 0.9346, Value Loss: 0.2120, Total Loss: 1.1466, LR: 0.000077
2025-04-26 07:54:40,814 [INFO] Epoch 7/15 - Policy Loss: 0.9323, Value Loss: 0.2109, Total Loss: 1.1432, LR: 0.001673
2025-04-26 07:55:04,286 [INFO] Epoch 8/15 - Policy Loss: 0.9302, Value Loss: 0.2100, Total Loss: 1.1402, LR: 0.003323
2025-04-26 07:55:27,825 [INFO] Epoch 9/15 - Policy Loss: 0.9294, Value Loss: 0.2096, Total Loss: 1.1389, LR: 0.004973
2025-04-26 07:55:51,288 [INFO] Epoch 10/15 - Policy Loss: 0.9291, Value Loss: 0.2094, Total Loss: 1.1385, LR: 0.003377
2025-04-26 07:56:14,716 [INFO] Epoch 11/15 - Policy Loss: 0.9282, Value Loss: 0.2090, Total Loss: 1.1372, LR: 0.001727
2025-04-26 07:56:38,227 [INFO] Epoch 12/15 - Policy Loss: 0.9269, Value Loss: 0.2087, Total Loss: 1.1355, LR: 0.000077
2025-04-26 07:57:01,728 [INFO] Epoch 13/15 - Policy Loss: 0.9259, Value Loss: 0.2084, Total Loss: 1.1343, LR: 0.001673
2025-04-26 07:57:25,261 [INFO] Epoch 14/15 - Policy Loss: 0.9247, Value Loss: 0.2080, Total Loss: 1.1327, LR: 0.003323
2025-04-26 07:57:48,726 [INFO] Epoch 15/15 - Policy Loss: 0.9246, Value Loss: 0.2077, Total Loss: 1.1322, LR: 0.004973
2025-04-26 07:57:48,742 [INFO] 训练完成，总损失: 1.1322
2025-04-26 07:57:48,743 [INFO] 保存迭代 151 的模型
2025-04-26 07:57:49,155 [INFO] Model saved to ./models/best.pt
2025-04-26 07:57:49,433 [INFO] Model saved to ./models/iteration_151.pt
2025-04-26 07:57:49,433 [INFO] 所有训练迭代完成
2025-04-26 07:57:49,433 [INFO] 开始迭代 152/300
2025-04-26 07:57:49,433 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 08:04:44,180 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 08:04:44,181 [INFO] 保存训练样本
2025-04-26 08:04:47,735 [INFO] 使用 123208 个样本训练神经网络
2025-04-26 08:04:47,735 [INFO] Training with 123208 examples
2025-04-26 08:04:47,735 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 08:04:48,061 [INFO] 循环学习率周期大小: 180 步
2025-04-26 08:05:11,508 [INFO] Epoch 1/15 - Policy Loss: 0.9569, Value Loss: 0.2127, Total Loss: 1.1696, LR: 0.001673
2025-04-26 08:05:34,957 [INFO] Epoch 2/15 - Policy Loss: 0.9522, Value Loss: 0.2126, Total Loss: 1.1648, LR: 0.003323
2025-04-26 08:05:58,406 [INFO] Epoch 3/15 - Policy Loss: 0.9488, Value Loss: 0.2126, Total Loss: 1.1614, LR: 0.004973
2025-04-26 08:06:21,855 [INFO] Epoch 4/15 - Policy Loss: 0.9442, Value Loss: 0.2121, Total Loss: 1.1563, LR: 0.003377
2025-04-26 08:06:45,282 [INFO] Epoch 5/15 - Policy Loss: 0.9398, Value Loss: 0.2111, Total Loss: 1.1509, LR: 0.001727
2025-04-26 08:07:08,709 [INFO] Epoch 6/15 - Policy Loss: 0.9359, Value Loss: 0.2104, Total Loss: 1.1464, LR: 0.000077
2025-04-26 08:07:32,142 [INFO] Epoch 7/15 - Policy Loss: 0.9337, Value Loss: 0.2098, Total Loss: 1.1435, LR: 0.001673
2025-04-26 08:07:55,563 [INFO] Epoch 8/15 - Policy Loss: 0.9314, Value Loss: 0.2094, Total Loss: 1.1408, LR: 0.003323
2025-04-26 08:08:19,014 [INFO] Epoch 9/15 - Policy Loss: 0.9301, Value Loss: 0.2093, Total Loss: 1.1394, LR: 0.004973
2025-04-26 08:08:42,489 [INFO] Epoch 10/15 - Policy Loss: 0.9292, Value Loss: 0.2091, Total Loss: 1.1383, LR: 0.003377
2025-04-26 08:09:05,965 [INFO] Epoch 11/15 - Policy Loss: 0.9287, Value Loss: 0.2091, Total Loss: 1.1378, LR: 0.001727
2025-04-26 08:09:29,436 [INFO] Epoch 12/15 - Policy Loss: 0.9275, Value Loss: 0.2088, Total Loss: 1.1363, LR: 0.000077
2025-04-26 08:09:52,914 [INFO] Epoch 13/15 - Policy Loss: 0.9262, Value Loss: 0.2083, Total Loss: 1.1345, LR: 0.001673
2025-04-26 08:10:16,381 [INFO] Epoch 14/15 - Policy Loss: 0.9255, Value Loss: 0.2079, Total Loss: 1.1334, LR: 0.003323
2025-04-26 08:10:39,884 [INFO] Epoch 15/15 - Policy Loss: 0.9249, Value Loss: 0.2075, Total Loss: 1.1324, LR: 0.004973
2025-04-26 08:10:39,902 [INFO] 训练完成，总损失: 1.1324
2025-04-26 08:10:39,902 [INFO] 保存迭代 152 的模型
2025-04-26 08:10:40,329 [INFO] Model saved to ./models/best.pt
2025-04-26 08:10:40,620 [INFO] Model saved to ./models/iteration_152.pt
2025-04-26 08:10:40,620 [INFO] 所有训练迭代完成
2025-04-26 08:10:40,621 [INFO] 开始迭代 153/300
2025-04-26 08:10:40,621 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 08:17:35,799 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 08:17:35,799 [INFO] 保存训练样本
2025-04-26 08:17:38,977 [INFO] 使用 123584 个样本训练神经网络
2025-04-26 08:17:38,977 [INFO] Training with 123584 examples
2025-04-26 08:17:38,978 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 08:17:39,333 [INFO] 循环学习率周期大小: 180 步
2025-04-26 08:18:02,797 [INFO] Epoch 1/15 - Policy Loss: 0.9390, Value Loss: 0.2184, Total Loss: 1.1574, LR: 0.001673
2025-04-26 08:18:26,236 [INFO] Epoch 2/15 - Policy Loss: 0.9384, Value Loss: 0.2152, Total Loss: 1.1536, LR: 0.003323
2025-04-26 08:18:49,650 [INFO] Epoch 3/15 - Policy Loss: 0.9366, Value Loss: 0.2139, Total Loss: 1.1504, LR: 0.004973
2025-04-26 08:19:13,087 [INFO] Epoch 4/15 - Policy Loss: 0.9335, Value Loss: 0.2138, Total Loss: 1.1473, LR: 0.003377
2025-04-26 08:19:36,529 [INFO] Epoch 5/15 - Policy Loss: 0.9303, Value Loss: 0.2119, Total Loss: 1.1421, LR: 0.001727
2025-04-26 08:19:59,992 [INFO] Epoch 6/15 - Policy Loss: 0.9276, Value Loss: 0.2106, Total Loss: 1.1382, LR: 0.000077
2025-04-26 08:20:23,468 [INFO] Epoch 7/15 - Policy Loss: 0.9257, Value Loss: 0.2092, Total Loss: 1.1349, LR: 0.001673
2025-04-26 08:20:46,946 [INFO] Epoch 8/15 - Policy Loss: 0.9236, Value Loss: 0.2085, Total Loss: 1.1321, LR: 0.003323
2025-04-26 08:21:10,408 [INFO] Epoch 9/15 - Policy Loss: 0.9227, Value Loss: 0.2080, Total Loss: 1.1306, LR: 0.004973
2025-04-26 08:21:33,880 [INFO] Epoch 10/15 - Policy Loss: 0.9227, Value Loss: 0.2079, Total Loss: 1.1306, LR: 0.003377
2025-04-26 08:21:57,337 [INFO] Epoch 11/15 - Policy Loss: 0.9217, Value Loss: 0.2075, Total Loss: 1.1292, LR: 0.001727
2025-04-26 08:22:20,790 [INFO] Epoch 12/15 - Policy Loss: 0.9205, Value Loss: 0.2069, Total Loss: 1.1274, LR: 0.000077
2025-04-26 08:22:44,240 [INFO] Epoch 13/15 - Policy Loss: 0.9191, Value Loss: 0.2064, Total Loss: 1.1255, LR: 0.001673
2025-04-26 08:23:07,670 [INFO] Epoch 14/15 - Policy Loss: 0.9180, Value Loss: 0.2059, Total Loss: 1.1239, LR: 0.003323
2025-04-26 08:23:30,917 [INFO] Epoch 15/15 - Policy Loss: 0.9171, Value Loss: 0.2055, Total Loss: 1.1227, LR: 0.004973
2025-04-26 08:23:30,933 [INFO] 训练完成，总损失: 1.1227
2025-04-26 08:23:30,934 [INFO] 保存迭代 153 的模型
2025-04-26 08:23:31,308 [INFO] Model saved to ./models/best.pt
2025-04-26 08:23:31,580 [INFO] Model saved to ./models/iteration_153.pt
2025-04-26 08:23:31,580 [INFO] 所有训练迭代完成
2025-04-26 08:23:31,580 [INFO] 开始迭代 154/300
2025-04-26 08:23:31,580 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 08:30:08,808 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 08:30:08,808 [INFO] 保存训练样本
2025-04-26 08:30:12,122 [INFO] 使用 124176 个样本训练神经网络
2025-04-26 08:30:12,123 [INFO] Training with 124176 examples
2025-04-26 08:30:12,123 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 08:30:12,474 [INFO] 循环学习率周期大小: 180 步
2025-04-26 08:30:35,805 [INFO] Epoch 1/15 - Policy Loss: 0.9360, Value Loss: 0.2273, Total Loss: 1.1633, LR: 0.001673
2025-04-26 08:30:59,080 [INFO] Epoch 2/15 - Policy Loss: 0.9264, Value Loss: 0.2217, Total Loss: 1.1481, LR: 0.003323
2025-04-26 08:31:22,360 [INFO] Epoch 3/15 - Policy Loss: 0.9245, Value Loss: 0.2198, Total Loss: 1.1443, LR: 0.004973
2025-04-26 08:31:45,636 [INFO] Epoch 4/15 - Policy Loss: 0.9218, Value Loss: 0.2178, Total Loss: 1.1397, LR: 0.003377
2025-04-26 08:32:08,918 [INFO] Epoch 5/15 - Policy Loss: 0.9190, Value Loss: 0.2162, Total Loss: 1.1352, LR: 0.001727
2025-04-26 08:32:32,239 [INFO] Epoch 6/15 - Policy Loss: 0.9181, Value Loss: 0.2152, Total Loss: 1.1333, LR: 0.000077
2025-04-26 08:32:55,734 [INFO] Epoch 7/15 - Policy Loss: 0.9165, Value Loss: 0.2142, Total Loss: 1.1307, LR: 0.001673
2025-04-26 08:33:19,250 [INFO] Epoch 8/15 - Policy Loss: 0.9151, Value Loss: 0.2138, Total Loss: 1.1288, LR: 0.003323
2025-04-26 08:33:42,764 [INFO] Epoch 9/15 - Policy Loss: 0.9143, Value Loss: 0.2130, Total Loss: 1.1272, LR: 0.004973
2025-04-26 08:34:06,292 [INFO] Epoch 10/15 - Policy Loss: 0.9132, Value Loss: 0.2129, Total Loss: 1.1262, LR: 0.003377
2025-04-26 08:34:29,865 [INFO] Epoch 11/15 - Policy Loss: 0.9126, Value Loss: 0.2126, Total Loss: 1.1252, LR: 0.001727
2025-04-26 08:34:53,767 [INFO] Epoch 12/15 - Policy Loss: 0.9115, Value Loss: 0.2122, Total Loss: 1.1237, LR: 0.000077
2025-04-26 08:35:17,280 [INFO] Epoch 13/15 - Policy Loss: 0.9110, Value Loss: 0.2119, Total Loss: 1.1228, LR: 0.001673
2025-04-26 08:35:40,822 [INFO] Epoch 14/15 - Policy Loss: 0.9101, Value Loss: 0.2114, Total Loss: 1.1216, LR: 0.003323
2025-04-26 08:36:04,239 [INFO] Epoch 15/15 - Policy Loss: 0.9098, Value Loss: 0.2112, Total Loss: 1.1211, LR: 0.004973
2025-04-26 08:36:04,255 [INFO] 训练完成，总损失: 1.1211
2025-04-26 08:36:04,256 [INFO] 保存迭代 154 的模型
2025-04-26 08:36:04,651 [INFO] Model saved to ./models/best.pt
2025-04-26 08:36:04,935 [INFO] Model saved to ./models/iteration_154.pt
2025-04-26 08:36:04,936 [INFO] 所有训练迭代完成
2025-04-26 08:36:04,936 [INFO] 开始迭代 155/300
2025-04-26 08:36:04,936 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 08:41:50,707 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 08:41:50,707 [INFO] 保存训练样本
2025-04-26 08:41:54,019 [INFO] 使用 123592 个样本训练神经网络
2025-04-26 08:41:54,020 [INFO] Training with 123592 examples
2025-04-26 08:41:54,020 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 08:41:54,418 [INFO] 循环学习率周期大小: 180 步
2025-04-26 08:42:17,950 [INFO] Epoch 1/15 - Policy Loss: 0.9243, Value Loss: 0.2214, Total Loss: 1.1457, LR: 0.001673
2025-04-26 08:42:41,432 [INFO] Epoch 2/15 - Policy Loss: 0.9208, Value Loss: 0.2190, Total Loss: 1.1398, LR: 0.003323
2025-04-26 08:43:04,956 [INFO] Epoch 3/15 - Policy Loss: 0.9196, Value Loss: 0.2191, Total Loss: 1.1388, LR: 0.004973
2025-04-26 08:43:28,462 [INFO] Epoch 4/15 - Policy Loss: 0.9175, Value Loss: 0.2184, Total Loss: 1.1360, LR: 0.003377
2025-04-26 08:43:51,981 [INFO] Epoch 5/15 - Policy Loss: 0.9162, Value Loss: 0.2181, Total Loss: 1.1343, LR: 0.001727
2025-04-26 08:44:15,443 [INFO] Epoch 6/15 - Policy Loss: 0.9145, Value Loss: 0.2178, Total Loss: 1.1323, LR: 0.000077
2025-04-26 08:44:38,995 [INFO] Epoch 7/15 - Policy Loss: 0.9126, Value Loss: 0.2170, Total Loss: 1.1296, LR: 0.001673
2025-04-26 08:45:02,522 [INFO] Epoch 8/15 - Policy Loss: 0.9112, Value Loss: 0.2160, Total Loss: 1.1272, LR: 0.003323
2025-04-26 08:45:26,028 [INFO] Epoch 9/15 - Policy Loss: 0.9104, Value Loss: 0.2159, Total Loss: 1.1263, LR: 0.004973
2025-04-26 08:45:49,848 [INFO] Epoch 10/15 - Policy Loss: 0.9097, Value Loss: 0.2161, Total Loss: 1.1258, LR: 0.003377
2025-04-26 08:46:13,335 [INFO] Epoch 11/15 - Policy Loss: 0.9087, Value Loss: 0.2160, Total Loss: 1.1247, LR: 0.001727
2025-04-26 08:46:36,840 [INFO] Epoch 12/15 - Policy Loss: 0.9080, Value Loss: 0.2157, Total Loss: 1.1238, LR: 0.000077
2025-04-26 08:47:00,392 [INFO] Epoch 13/15 - Policy Loss: 0.9072, Value Loss: 0.2154, Total Loss: 1.1225, LR: 0.001673
2025-04-26 08:47:23,933 [INFO] Epoch 14/15 - Policy Loss: 0.9067, Value Loss: 0.2152, Total Loss: 1.1219, LR: 0.003323
2025-04-26 08:47:47,438 [INFO] Epoch 15/15 - Policy Loss: 0.9063, Value Loss: 0.2151, Total Loss: 1.1214, LR: 0.004973
2025-04-26 08:47:47,486 [INFO] 训练完成，总损失: 1.1214
2025-04-26 08:47:47,486 [INFO] 保存迭代 155 的模型
2025-04-26 08:47:48,045 [INFO] Model saved to ./models/best.pt
2025-04-26 08:47:48,489 [INFO] Model saved to ./models/iteration_155.pt
2025-04-26 08:47:48,489 [INFO] 所有训练迭代完成
2025-04-26 08:47:48,490 [INFO] 开始迭代 156/300
2025-04-26 08:47:48,490 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 08:54:45,752 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 08:54:45,753 [INFO] 保存训练样本
2025-04-26 08:54:49,138 [INFO] 使用 124184 个样本训练神经网络
2025-04-26 08:54:49,138 [INFO] Training with 124184 examples
2025-04-26 08:54:49,138 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 08:54:49,181 [INFO] 循环学习率周期大小: 180 步
2025-04-26 08:55:12,461 [INFO] Epoch 1/15 - Policy Loss: 0.9276, Value Loss: 0.2273, Total Loss: 1.1549, LR: 0.001673
2025-04-26 08:55:35,754 [INFO] Epoch 2/15 - Policy Loss: 0.9220, Value Loss: 0.2255, Total Loss: 1.1476, LR: 0.003323
2025-04-26 08:55:59,049 [INFO] Epoch 3/15 - Policy Loss: 0.9207, Value Loss: 0.2242, Total Loss: 1.1449, LR: 0.004973
2025-04-26 08:56:22,438 [INFO] Epoch 4/15 - Policy Loss: 0.9181, Value Loss: 0.2236, Total Loss: 1.1417, LR: 0.003377
2025-04-26 08:56:45,707 [INFO] Epoch 5/15 - Policy Loss: 0.9158, Value Loss: 0.2221, Total Loss: 1.1380, LR: 0.001727
2025-04-26 08:57:09,269 [INFO] Epoch 6/15 - Policy Loss: 0.9133, Value Loss: 0.2214, Total Loss: 1.1347, LR: 0.000077
2025-04-26 08:57:32,579 [INFO] Epoch 7/15 - Policy Loss: 0.9119, Value Loss: 0.2203, Total Loss: 1.1322, LR: 0.001673
2025-04-26 08:57:56,133 [INFO] Epoch 8/15 - Policy Loss: 0.9105, Value Loss: 0.2197, Total Loss: 1.1302, LR: 0.003323
2025-04-26 08:58:19,659 [INFO] Epoch 9/15 - Policy Loss: 0.9095, Value Loss: 0.2195, Total Loss: 1.1289, LR: 0.004973
2025-04-26 08:58:43,285 [INFO] Epoch 10/15 - Policy Loss: 0.9089, Value Loss: 0.2190, Total Loss: 1.1279, LR: 0.003377
2025-04-26 08:59:06,883 [INFO] Epoch 11/15 - Policy Loss: 0.9083, Value Loss: 0.2187, Total Loss: 1.1269, LR: 0.001727
2025-04-26 08:59:30,514 [INFO] Epoch 12/15 - Policy Loss: 0.9073, Value Loss: 0.2185, Total Loss: 1.1257, LR: 0.000077
2025-04-26 08:59:54,096 [INFO] Epoch 13/15 - Policy Loss: 0.9063, Value Loss: 0.2181, Total Loss: 1.1243, LR: 0.001673
2025-04-26 09:00:17,698 [INFO] Epoch 14/15 - Policy Loss: 0.9051, Value Loss: 0.2177, Total Loss: 1.1227, LR: 0.003323
2025-04-26 09:00:41,330 [INFO] Epoch 15/15 - Policy Loss: 0.9048, Value Loss: 0.2176, Total Loss: 1.1224, LR: 0.004973
2025-04-26 09:00:41,347 [INFO] 训练完成，总损失: 1.1224
2025-04-26 09:00:41,348 [INFO] 保存迭代 156 的模型
2025-04-26 09:00:41,705 [INFO] Model saved to ./models/best.pt
2025-04-26 09:00:41,969 [INFO] Model saved to ./models/iteration_156.pt
2025-04-26 09:00:41,969 [INFO] 所有训练迭代完成
2025-04-26 09:00:41,969 [INFO] 开始迭代 157/300
2025-04-26 09:00:41,969 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 09:08:02,994 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 09:08:02,994 [INFO] 保存训练样本
2025-04-26 09:08:06,314 [INFO] 使用 124496 个样本训练神经网络
2025-04-26 09:08:06,314 [INFO] Training with 124496 examples
2025-04-26 09:08:06,314 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 09:08:06,354 [INFO] 循环学习率周期大小: 180 步
2025-04-26 09:08:29,887 [INFO] Epoch 1/15 - Policy Loss: 0.9336, Value Loss: 0.2318, Total Loss: 1.1653, LR: 0.001673
2025-04-26 09:08:53,143 [INFO] Epoch 2/15 - Policy Loss: 0.9273, Value Loss: 0.2273, Total Loss: 1.1546, LR: 0.003323
2025-04-26 09:09:16,377 [INFO] Epoch 3/15 - Policy Loss: 0.9239, Value Loss: 0.2257, Total Loss: 1.1496, LR: 0.004973
2025-04-26 09:09:39,656 [INFO] Epoch 4/15 - Policy Loss: 0.9214, Value Loss: 0.2259, Total Loss: 1.1473, LR: 0.003377
2025-04-26 09:10:02,893 [INFO] Epoch 5/15 - Policy Loss: 0.9182, Value Loss: 0.2244, Total Loss: 1.1426, LR: 0.001727
2025-04-26 09:10:26,164 [INFO] Epoch 6/15 - Policy Loss: 0.9160, Value Loss: 0.2233, Total Loss: 1.1393, LR: 0.000077
2025-04-26 09:10:49,449 [INFO] Epoch 7/15 - Policy Loss: 0.9145, Value Loss: 0.2226, Total Loss: 1.1371, LR: 0.001673
2025-04-26 09:11:12,710 [INFO] Epoch 8/15 - Policy Loss: 0.9124, Value Loss: 0.2215, Total Loss: 1.1339, LR: 0.003323
2025-04-26 09:11:35,985 [INFO] Epoch 9/15 - Policy Loss: 0.9115, Value Loss: 0.2213, Total Loss: 1.1328, LR: 0.004973
2025-04-26 09:11:59,333 [INFO] Epoch 10/15 - Policy Loss: 0.9109, Value Loss: 0.2210, Total Loss: 1.1319, LR: 0.003377
2025-04-26 09:12:22,549 [INFO] Epoch 11/15 - Policy Loss: 0.9101, Value Loss: 0.2206, Total Loss: 1.1307, LR: 0.001727
2025-04-26 09:12:45,778 [INFO] Epoch 12/15 - Policy Loss: 0.9089, Value Loss: 0.2206, Total Loss: 1.1295, LR: 0.000077
2025-04-26 09:13:09,048 [INFO] Epoch 13/15 - Policy Loss: 0.9078, Value Loss: 0.2202, Total Loss: 1.1280, LR: 0.001673
2025-04-26 09:13:32,283 [INFO] Epoch 14/15 - Policy Loss: 0.9070, Value Loss: 0.2199, Total Loss: 1.1269, LR: 0.003323
2025-04-26 09:13:55,503 [INFO] Epoch 15/15 - Policy Loss: 0.9067, Value Loss: 0.2199, Total Loss: 1.1266, LR: 0.004973
2025-04-26 09:13:55,519 [INFO] 训练完成，总损失: 1.1266
2025-04-26 09:13:55,519 [INFO] 保存迭代 157 的模型
2025-04-26 09:13:55,950 [INFO] Model saved to ./models/best.pt
2025-04-26 09:13:56,244 [INFO] Model saved to ./models/iteration_157.pt
2025-04-26 09:13:56,244 [INFO] 所有训练迭代完成
2025-04-26 09:13:56,244 [INFO] 开始迭代 158/300
2025-04-26 09:13:56,244 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 09:20:11,069 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 09:20:11,069 [INFO] 保存训练样本
2025-04-26 09:20:14,355 [INFO] 使用 124664 个样本训练神经网络
2025-04-26 09:20:14,355 [INFO] Training with 124664 examples
2025-04-26 09:20:14,355 [INFO] 总训练步数: 900, 每轮次批次数: 60
2025-04-26 09:20:14,690 [INFO] 循环学习率周期大小: 180 步
2025-04-26 09:20:38,068 [INFO] Epoch 1/15 - Policy Loss: 0.9118, Value Loss: 0.2219, Total Loss: 1.1337, LR: 0.001673
2025-04-26 09:21:01,476 [INFO] Epoch 2/15 - Policy Loss: 0.9113, Value Loss: 0.2194, Total Loss: 1.1307, LR: 0.003323
2025-04-26 09:21:24,987 [INFO] Epoch 3/15 - Policy Loss: 0.9101, Value Loss: 0.2186, Total Loss: 1.1287, LR: 0.004973
2025-04-26 09:21:48,414 [INFO] Epoch 4/15 - Policy Loss: 0.9093, Value Loss: 0.2189, Total Loss: 1.1282, LR: 0.003377
2025-04-26 09:22:11,669 [INFO] Epoch 5/15 - Policy Loss: 0.9086, Value Loss: 0.2196, Total Loss: 1.1283, LR: 0.001727
2025-04-26 09:22:34,916 [INFO] Epoch 6/15 - Policy Loss: 0.9085, Value Loss: 0.2187, Total Loss: 1.1271, LR: 0.000077
2025-04-26 09:22:58,175 [INFO] Epoch 7/15 - Policy Loss: 0.9066, Value Loss: 0.2177, Total Loss: 1.1244, LR: 0.001673
2025-04-26 09:23:21,419 [INFO] Epoch 8/15 - Policy Loss: 0.9054, Value Loss: 0.2175, Total Loss: 1.1228, LR: 0.003323
2025-04-26 09:23:44,667 [INFO] Epoch 9/15 - Policy Loss: 0.9049, Value Loss: 0.2172, Total Loss: 1.1221, LR: 0.004973
2025-04-26 09:24:07,927 [INFO] Epoch 10/15 - Policy Loss: 0.9053, Value Loss: 0.2169, Total Loss: 1.1222, LR: 0.003377
2025-04-26 09:24:31,189 [INFO] Epoch 11/15 - Policy Loss: 0.9051, Value Loss: 0.2167, Total Loss: 1.1218, LR: 0.001727
2025-04-26 09:24:54,448 [INFO] Epoch 12/15 - Policy Loss: 0.9041, Value Loss: 0.2167, Total Loss: 1.1209, LR: 0.000077
2025-04-26 09:25:17,700 [INFO] Epoch 13/15 - Policy Loss: 0.9038, Value Loss: 0.2165, Total Loss: 1.1203, LR: 0.001673
2025-04-26 09:25:40,988 [INFO] Epoch 14/15 - Policy Loss: 0.9032, Value Loss: 0.2161, Total Loss: 1.1193, LR: 0.003323
2025-04-26 09:26:04,236 [INFO] Epoch 15/15 - Policy Loss: 0.9024, Value Loss: 0.2158, Total Loss: 1.1182, LR: 0.004973
2025-04-26 09:26:04,258 [INFO] 训练完成，总损失: 1.1182
2025-04-26 09:26:04,258 [INFO] 保存迭代 158 的模型
2025-04-26 09:26:04,782 [INFO] Model saved to ./models/best.pt
2025-04-26 09:26:05,115 [INFO] Model saved to ./models/iteration_158.pt
2025-04-26 09:26:05,115 [INFO] 所有训练迭代完成
2025-04-26 09:26:05,115 [INFO] 开始迭代 159/300
2025-04-26 09:26:05,115 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 09:34:28,589 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 09:34:28,589 [INFO] 保存训练样本
2025-04-26 09:34:31,805 [INFO] 使用 125712 个样本训练神经网络
2025-04-26 09:34:31,805 [INFO] Training with 125712 examples
2025-04-26 09:34:31,806 [INFO] 总训练步数: 915, 每轮次批次数: 61
2025-04-26 09:34:32,134 [INFO] 循环学习率周期大小: 183 步
2025-04-26 09:34:56,047 [INFO] Epoch 1/15 - Policy Loss: 0.9510, Value Loss: 0.2353, Total Loss: 1.1863, LR: 0.001673
2025-04-26 09:35:20,007 [INFO] Epoch 2/15 - Policy Loss: 0.9416, Value Loss: 0.2326, Total Loss: 1.1743, LR: 0.003323
2025-04-26 09:35:43,906 [INFO] Epoch 3/15 - Policy Loss: 0.9366, Value Loss: 0.2307, Total Loss: 1.1672, LR: 0.004973
2025-04-26 09:36:07,850 [INFO] Epoch 4/15 - Policy Loss: 0.9315, Value Loss: 0.2287, Total Loss: 1.1601, LR: 0.003377
2025-04-26 09:36:31,624 [INFO] Epoch 5/15 - Policy Loss: 0.9274, Value Loss: 0.2269, Total Loss: 1.1543, LR: 0.001727
2025-04-26 09:36:55,451 [INFO] Epoch 6/15 - Policy Loss: 0.9241, Value Loss: 0.2256, Total Loss: 1.1498, LR: 0.000077
2025-04-26 09:37:19,405 [INFO] Epoch 7/15 - Policy Loss: 0.9209, Value Loss: 0.2246, Total Loss: 1.1455, LR: 0.001673
2025-04-26 09:37:43,585 [INFO] Epoch 8/15 - Policy Loss: 0.9174, Value Loss: 0.2239, Total Loss: 1.1413, LR: 0.003323
2025-04-26 09:38:07,652 [INFO] Epoch 9/15 - Policy Loss: 0.9161, Value Loss: 0.2231, Total Loss: 1.1392, LR: 0.004973
2025-04-26 09:38:31,511 [INFO] Epoch 10/15 - Policy Loss: 0.9150, Value Loss: 0.2228, Total Loss: 1.1378, LR: 0.003377
2025-04-26 09:38:55,576 [INFO] Epoch 11/15 - Policy Loss: 0.9135, Value Loss: 0.2220, Total Loss: 1.1355, LR: 0.001727
2025-04-26 09:39:19,537 [INFO] Epoch 12/15 - Policy Loss: 0.9123, Value Loss: 0.2213, Total Loss: 1.1336, LR: 0.000077
2025-04-26 09:39:43,559 [INFO] Epoch 13/15 - Policy Loss: 0.9110, Value Loss: 0.2206, Total Loss: 1.1317, LR: 0.001673
2025-04-26 09:40:07,998 [INFO] Epoch 14/15 - Policy Loss: 0.9095, Value Loss: 0.2201, Total Loss: 1.1296, LR: 0.003323
2025-04-26 09:40:32,090 [INFO] Epoch 15/15 - Policy Loss: 0.9087, Value Loss: 0.2198, Total Loss: 1.1285, LR: 0.004973
2025-04-26 09:40:32,112 [INFO] 训练完成，总损失: 1.1285
2025-04-26 09:40:32,112 [INFO] 保存迭代 159 的模型
2025-04-26 09:40:32,762 [INFO] Model saved to ./models/best.pt
2025-04-26 09:40:33,173 [INFO] Model saved to ./models/iteration_159.pt
2025-04-26 09:40:33,173 [INFO] 所有训练迭代完成
2025-04-26 09:40:33,173 [INFO] 开始迭代 160/300
2025-04-26 09:40:33,174 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 09:47:23,513 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 09:47:23,513 [INFO] 保存训练样本
2025-04-26 09:47:27,197 [INFO] 使用 125976 个样本训练神经网络
2025-04-26 09:47:27,197 [INFO] Training with 125976 examples
2025-04-26 09:47:27,198 [INFO] 总训练步数: 915, 每轮次批次数: 61
2025-04-26 09:47:27,672 [INFO] 循环学习率周期大小: 183 步
2025-04-26 09:47:51,934 [INFO] Epoch 1/15 - Policy Loss: 0.9296, Value Loss: 0.2337, Total Loss: 1.1633, LR: 0.001673
2025-04-26 09:48:16,138 [INFO] Epoch 2/15 - Policy Loss: 0.9234, Value Loss: 0.2308, Total Loss: 1.1543, LR: 0.003323
2025-04-26 09:48:40,206 [INFO] Epoch 3/15 - Policy Loss: 0.9202, Value Loss: 0.2300, Total Loss: 1.1502, LR: 0.004973
2025-04-26 09:49:04,227 [INFO] Epoch 4/15 - Policy Loss: 0.9195, Value Loss: 0.2292, Total Loss: 1.1488, LR: 0.003377
2025-04-26 09:49:28,199 [INFO] Epoch 5/15 - Policy Loss: 0.9174, Value Loss: 0.2280, Total Loss: 1.1454, LR: 0.001727
2025-04-26 09:49:52,118 [INFO] Epoch 6/15 - Policy Loss: 0.9155, Value Loss: 0.2272, Total Loss: 1.1428, LR: 0.000077
2025-04-26 09:50:16,122 [INFO] Epoch 7/15 - Policy Loss: 0.9124, Value Loss: 0.2269, Total Loss: 1.1394, LR: 0.001673
2025-04-26 09:50:40,173 [INFO] Epoch 8/15 - Policy Loss: 0.9114, Value Loss: 0.2264, Total Loss: 1.1378, LR: 0.003323
2025-04-26 09:51:04,239 [INFO] Epoch 9/15 - Policy Loss: 0.9092, Value Loss: 0.2257, Total Loss: 1.1349, LR: 0.004973
2025-04-26 09:51:28,473 [INFO] Epoch 10/15 - Policy Loss: 0.9085, Value Loss: 0.2255, Total Loss: 1.1340, LR: 0.003377
2025-04-26 09:51:52,732 [INFO] Epoch 11/15 - Policy Loss: 0.9076, Value Loss: 0.2250, Total Loss: 1.1326, LR: 0.001727
2025-04-26 09:52:17,463 [INFO] Epoch 12/15 - Policy Loss: 0.9065, Value Loss: 0.2243, Total Loss: 1.1308, LR: 0.000077
2025-04-26 09:52:41,849 [INFO] Epoch 13/15 - Policy Loss: 0.9052, Value Loss: 0.2235, Total Loss: 1.1287, LR: 0.001673
2025-04-26 09:53:06,280 [INFO] Epoch 14/15 - Policy Loss: 0.9044, Value Loss: 0.2231, Total Loss: 1.1276, LR: 0.003323
2025-04-26 09:53:30,644 [INFO] Epoch 15/15 - Policy Loss: 0.9040, Value Loss: 0.2230, Total Loss: 1.1270, LR: 0.004973
2025-04-26 09:53:30,667 [INFO] 训练完成，总损失: 1.1270
2025-04-26 09:53:30,667 [INFO] 保存迭代 160 的模型
2025-04-26 09:53:31,186 [INFO] Model saved to ./models/best.pt
2025-04-26 09:53:31,565 [INFO] Model saved to ./models/iteration_160.pt
2025-04-26 09:53:31,565 [INFO] 所有训练迭代完成
2025-04-26 09:53:31,565 [INFO] 开始迭代 161/300
2025-04-26 09:53:31,565 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 10:00:55,561 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 10:00:55,562 [INFO] 保存训练样本
2025-04-26 10:00:59,212 [INFO] 使用 125912 个样本训练神经网络
2025-04-26 10:00:59,212 [INFO] Training with 125912 examples
2025-04-26 10:00:59,213 [INFO] 总训练步数: 915, 每轮次批次数: 61
2025-04-26 10:00:59,585 [INFO] 循环学习率周期大小: 183 步
2025-04-26 10:01:23,785 [INFO] Epoch 1/15 - Policy Loss: 0.9356, Value Loss: 0.2299, Total Loss: 1.1656, LR: 0.001673
2025-04-26 10:01:47,998 [INFO] Epoch 2/15 - Policy Loss: 0.9321, Value Loss: 0.2296, Total Loss: 1.1617, LR: 0.003323
2025-04-26 10:02:12,141 [INFO] Epoch 3/15 - Policy Loss: 0.9279, Value Loss: 0.2281, Total Loss: 1.1560, LR: 0.004973
2025-04-26 10:02:36,303 [INFO] Epoch 4/15 - Policy Loss: 0.9255, Value Loss: 0.2273, Total Loss: 1.1528, LR: 0.003377
2025-04-26 10:03:00,519 [INFO] Epoch 5/15 - Policy Loss: 0.9234, Value Loss: 0.2265, Total Loss: 1.1498, LR: 0.001727
2025-04-26 10:03:24,777 [INFO] Epoch 6/15 - Policy Loss: 0.9208, Value Loss: 0.2261, Total Loss: 1.1468, LR: 0.000077
2025-04-26 10:03:49,099 [INFO] Epoch 7/15 - Policy Loss: 0.9181, Value Loss: 0.2254, Total Loss: 1.1435, LR: 0.001673
2025-04-26 10:04:13,482 [INFO] Epoch 8/15 - Policy Loss: 0.9163, Value Loss: 0.2249, Total Loss: 1.1412, LR: 0.003323
2025-04-26 10:04:37,848 [INFO] Epoch 9/15 - Policy Loss: 0.9153, Value Loss: 0.2246, Total Loss: 1.1399, LR: 0.004973
2025-04-26 10:05:02,613 [INFO] Epoch 10/15 - Policy Loss: 0.9143, Value Loss: 0.2244, Total Loss: 1.1387, LR: 0.003377
2025-04-26 10:05:27,049 [INFO] Epoch 11/15 - Policy Loss: 0.9134, Value Loss: 0.2239, Total Loss: 1.1374, LR: 0.001727
2025-04-26 10:05:51,248 [INFO] Epoch 12/15 - Policy Loss: 0.9121, Value Loss: 0.2235, Total Loss: 1.1356, LR: 0.000077
2025-04-26 10:06:15,343 [INFO] Epoch 13/15 - Policy Loss: 0.9108, Value Loss: 0.2231, Total Loss: 1.1338, LR: 0.001673
2025-04-26 10:06:39,468 [INFO] Epoch 14/15 - Policy Loss: 0.9095, Value Loss: 0.2229, Total Loss: 1.1325, LR: 0.003323
2025-04-26 10:07:03,752 [INFO] Epoch 15/15 - Policy Loss: 0.9090, Value Loss: 0.2226, Total Loss: 1.1316, LR: 0.004973
2025-04-26 10:07:03,772 [INFO] 训练完成，总损失: 1.1316
2025-04-26 10:07:03,772 [INFO] 保存迭代 161 的模型
2025-04-26 10:07:04,490 [INFO] Model saved to ./models/best.pt
2025-04-26 10:07:04,953 [INFO] Model saved to ./models/iteration_161.pt
2025-04-26 10:07:04,954 [INFO] 所有训练迭代完成
2025-04-26 10:07:04,954 [INFO] 开始迭代 162/300
2025-04-26 10:07:04,954 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 10:14:04,747 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 10:14:04,748 [INFO] 保存训练样本
2025-04-26 10:14:08,526 [INFO] 使用 126128 个样本训练神经网络
2025-04-26 10:14:08,526 [INFO] Training with 126128 examples
2025-04-26 10:14:08,527 [INFO] 总训练步数: 915, 每轮次批次数: 61
2025-04-26 10:14:08,566 [INFO] 循环学习率周期大小: 183 步
2025-04-26 10:14:32,593 [INFO] Epoch 1/15 - Policy Loss: 0.9473, Value Loss: 0.2369, Total Loss: 1.1843, LR: 0.001673
2025-04-26 10:14:56,493 [INFO] Epoch 2/15 - Policy Loss: 0.9400, Value Loss: 0.2357, Total Loss: 1.1757, LR: 0.003323
2025-04-26 10:15:20,517 [INFO] Epoch 3/15 - Policy Loss: 0.9357, Value Loss: 0.2347, Total Loss: 1.1703, LR: 0.004973
2025-04-26 10:15:44,535 [INFO] Epoch 4/15 - Policy Loss: 0.9319, Value Loss: 0.2330, Total Loss: 1.1649, LR: 0.003377
2025-04-26 10:16:08,536 [INFO] Epoch 5/15 - Policy Loss: 0.9290, Value Loss: 0.2321, Total Loss: 1.1611, LR: 0.001727
2025-04-26 10:16:32,390 [INFO] Epoch 6/15 - Policy Loss: 0.9261, Value Loss: 0.2308, Total Loss: 1.1569, LR: 0.000077
2025-04-26 10:16:56,918 [INFO] Epoch 7/15 - Policy Loss: 0.9233, Value Loss: 0.2298, Total Loss: 1.1531, LR: 0.001673
2025-04-26 10:17:21,199 [INFO] Epoch 8/15 - Policy Loss: 0.9215, Value Loss: 0.2290, Total Loss: 1.1505, LR: 0.003323
2025-04-26 10:17:45,492 [INFO] Epoch 9/15 - Policy Loss: 0.9195, Value Loss: 0.2281, Total Loss: 1.1477, LR: 0.004973
2025-04-26 10:18:09,639 [INFO] Epoch 10/15 - Policy Loss: 0.9187, Value Loss: 0.2279, Total Loss: 1.1466, LR: 0.003377
2025-04-26 10:18:33,792 [INFO] Epoch 11/15 - Policy Loss: 0.9176, Value Loss: 0.2274, Total Loss: 1.1450, LR: 0.001727
2025-04-26 10:18:58,175 [INFO] Epoch 12/15 - Policy Loss: 0.9163, Value Loss: 0.2266, Total Loss: 1.1429, LR: 0.000077
2025-04-26 10:19:22,494 [INFO] Epoch 13/15 - Policy Loss: 0.9150, Value Loss: 0.2262, Total Loss: 1.1412, LR: 0.001673
2025-04-26 10:19:46,861 [INFO] Epoch 14/15 - Policy Loss: 0.9137, Value Loss: 0.2259, Total Loss: 1.1396, LR: 0.003323
2025-04-26 10:20:11,222 [INFO] Epoch 15/15 - Policy Loss: 0.9130, Value Loss: 0.2257, Total Loss: 1.1386, LR: 0.004973
2025-04-26 10:20:11,243 [INFO] 训练完成，总损失: 1.1386
2025-04-26 10:20:11,244 [INFO] 保存迭代 162 的模型
2025-04-26 10:20:12,009 [INFO] Model saved to ./models/best.pt
2025-04-26 10:20:12,516 [INFO] Model saved to ./models/iteration_162.pt
2025-04-26 10:20:12,517 [INFO] 所有训练迭代完成
2025-04-26 10:20:12,517 [INFO] 开始迭代 163/300
2025-04-26 10:20:12,517 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 10:27:26,154 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 10:27:26,155 [INFO] 保存训练样本
2025-04-26 10:27:30,320 [INFO] 使用 127440 个样本训练神经网络
2025-04-26 10:27:30,320 [INFO] Training with 127440 examples
2025-04-26 10:27:30,321 [INFO] 总训练步数: 930, 每轮次批次数: 62
2025-04-26 10:27:30,371 [INFO] 循环学习率周期大小: 186 步
2025-04-26 10:27:54,934 [INFO] Epoch 1/15 - Policy Loss: 0.9355, Value Loss: 0.2336, Total Loss: 1.1691, LR: 0.001673
2025-04-26 10:28:19,264 [INFO] Epoch 2/15 - Policy Loss: 0.9295, Value Loss: 0.2304, Total Loss: 1.1599, LR: 0.003323
2025-04-26 10:28:43,851 [INFO] Epoch 3/15 - Policy Loss: 0.9267, Value Loss: 0.2269, Total Loss: 1.1536, LR: 0.004973
2025-04-26 10:29:08,785 [INFO] Epoch 4/15 - Policy Loss: 0.9241, Value Loss: 0.2247, Total Loss: 1.1488, LR: 0.003377
2025-04-26 10:29:33,236 [INFO] Epoch 5/15 - Policy Loss: 0.9201, Value Loss: 0.2236, Total Loss: 1.1437, LR: 0.001727
2025-04-26 10:29:57,849 [INFO] Epoch 6/15 - Policy Loss: 0.9173, Value Loss: 0.2216, Total Loss: 1.1389, LR: 0.000077
2025-04-26 10:30:22,613 [INFO] Epoch 7/15 - Policy Loss: 0.9155, Value Loss: 0.2208, Total Loss: 1.1363, LR: 0.001673
2025-04-26 10:30:47,419 [INFO] Epoch 8/15 - Policy Loss: 0.9129, Value Loss: 0.2201, Total Loss: 1.1330, LR: 0.003323
2025-04-26 10:31:12,269 [INFO] Epoch 9/15 - Policy Loss: 0.9117, Value Loss: 0.2197, Total Loss: 1.1314, LR: 0.004973
2025-04-26 10:31:37,009 [INFO] Epoch 10/15 - Policy Loss: 0.9103, Value Loss: 0.2194, Total Loss: 1.1297, LR: 0.003377
2025-04-26 10:32:02,018 [INFO] Epoch 11/15 - Policy Loss: 0.9096, Value Loss: 0.2190, Total Loss: 1.1286, LR: 0.001727
2025-04-26 10:32:27,152 [INFO] Epoch 12/15 - Policy Loss: 0.9088, Value Loss: 0.2185, Total Loss: 1.1273, LR: 0.000077
2025-04-26 10:32:51,961 [INFO] Epoch 13/15 - Policy Loss: 0.9078, Value Loss: 0.2179, Total Loss: 1.1258, LR: 0.001673
2025-04-26 10:33:16,697 [INFO] Epoch 14/15 - Policy Loss: 0.9071, Value Loss: 0.2176, Total Loss: 1.1247, LR: 0.003323
2025-04-26 10:33:41,309 [INFO] Epoch 15/15 - Policy Loss: 0.9065, Value Loss: 0.2175, Total Loss: 1.1240, LR: 0.004973
2025-04-26 10:33:41,331 [INFO] 训练完成，总损失: 1.1240
2025-04-26 10:33:41,331 [INFO] 保存迭代 163 的模型
2025-04-26 10:33:41,888 [INFO] Model saved to ./models/best.pt
2025-04-26 10:33:42,272 [INFO] Model saved to ./models/iteration_163.pt
2025-04-26 10:33:42,273 [INFO] 所有训练迭代完成
2025-04-26 10:33:42,273 [INFO] 开始迭代 164/300
2025-04-26 10:33:42,273 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 10:40:21,160 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 10:40:21,160 [INFO] 保存训练样本
2025-04-26 10:40:25,384 [INFO] 使用 127816 个样本训练神经网络
2025-04-26 10:40:25,384 [INFO] Training with 127816 examples
2025-04-26 10:40:25,385 [INFO] 总训练步数: 930, 每轮次批次数: 62
2025-04-26 10:40:25,838 [INFO] 循环学习率周期大小: 186 步
2025-04-26 10:40:50,536 [INFO] Epoch 1/15 - Policy Loss: 0.9269, Value Loss: 0.2234, Total Loss: 1.1503, LR: 0.001673
2025-04-26 10:41:15,074 [INFO] Epoch 2/15 - Policy Loss: 0.9258, Value Loss: 0.2213, Total Loss: 1.1471, LR: 0.003323
2025-04-26 10:41:39,676 [INFO] Epoch 3/15 - Policy Loss: 0.9231, Value Loss: 0.2203, Total Loss: 1.1434, LR: 0.004973
2025-04-26 10:42:04,188 [INFO] Epoch 4/15 - Policy Loss: 0.9189, Value Loss: 0.2187, Total Loss: 1.1376, LR: 0.003377
2025-04-26 10:42:28,780 [INFO] Epoch 5/15 - Policy Loss: 0.9172, Value Loss: 0.2180, Total Loss: 1.1352, LR: 0.001727
2025-04-26 10:42:53,471 [INFO] Epoch 6/15 - Policy Loss: 0.9147, Value Loss: 0.2162, Total Loss: 1.1309, LR: 0.000077
2025-04-26 10:43:17,868 [INFO] Epoch 7/15 - Policy Loss: 0.9117, Value Loss: 0.2160, Total Loss: 1.1277, LR: 0.001673
2025-04-26 10:43:42,160 [INFO] Epoch 8/15 - Policy Loss: 0.9097, Value Loss: 0.2152, Total Loss: 1.1249, LR: 0.003323
2025-04-26 10:44:06,646 [INFO] Epoch 9/15 - Policy Loss: 0.9090, Value Loss: 0.2144, Total Loss: 1.1235, LR: 0.004973
2025-04-26 10:44:31,096 [INFO] Epoch 10/15 - Policy Loss: 0.9081, Value Loss: 0.2139, Total Loss: 1.1220, LR: 0.003377
2025-04-26 10:44:55,992 [INFO] Epoch 11/15 - Policy Loss: 0.9072, Value Loss: 0.2138, Total Loss: 1.1211, LR: 0.001727
2025-04-26 10:45:20,457 [INFO] Epoch 12/15 - Policy Loss: 0.9063, Value Loss: 0.2133, Total Loss: 1.1197, LR: 0.000077
2025-04-26 10:45:44,918 [INFO] Epoch 13/15 - Policy Loss: 0.9052, Value Loss: 0.2128, Total Loss: 1.1180, LR: 0.001673
2025-04-26 10:46:09,573 [INFO] Epoch 14/15 - Policy Loss: 0.9044, Value Loss: 0.2124, Total Loss: 1.1168, LR: 0.003323
2025-04-26 10:46:34,150 [INFO] Epoch 15/15 - Policy Loss: 0.9038, Value Loss: 0.2120, Total Loss: 1.1158, LR: 0.004973
2025-04-26 10:46:34,171 [INFO] 训练完成，总损失: 1.1158
2025-04-26 10:46:34,171 [INFO] 保存迭代 164 的模型
2025-04-26 10:46:35,132 [INFO] Model saved to ./models/best.pt
2025-04-26 10:46:35,652 [INFO] Model saved to ./models/iteration_164.pt
2025-04-26 10:46:35,652 [INFO] 所有训练迭代完成
2025-04-26 10:46:35,652 [INFO] 开始迭代 165/300
2025-04-26 10:46:35,652 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 10:54:36,240 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 10:54:36,241 [INFO] 保存训练样本
2025-04-26 10:54:40,099 [INFO] 使用 128296 个样本训练神经网络
2025-04-26 10:54:40,099 [INFO] Training with 128296 examples
2025-04-26 10:54:40,100 [INFO] 总训练步数: 930, 每轮次批次数: 62
2025-04-26 10:54:40,489 [INFO] 循环学习率周期大小: 186 步
2025-04-26 10:55:05,020 [INFO] Epoch 1/15 - Policy Loss: 0.9310, Value Loss: 0.2194, Total Loss: 1.1503, LR: 0.001673
2025-04-26 10:55:29,562 [INFO] Epoch 2/15 - Policy Loss: 0.9278, Value Loss: 0.2166, Total Loss: 1.1444, LR: 0.003323
2025-04-26 10:55:54,090 [INFO] Epoch 3/15 - Policy Loss: 0.9234, Value Loss: 0.2145, Total Loss: 1.1379, LR: 0.004973
2025-04-26 10:56:18,704 [INFO] Epoch 4/15 - Policy Loss: 0.9230, Value Loss: 0.2140, Total Loss: 1.1369, LR: 0.003377
2025-04-26 10:56:43,282 [INFO] Epoch 5/15 - Policy Loss: 0.9206, Value Loss: 0.2134, Total Loss: 1.1340, LR: 0.001727
2025-04-26 10:57:07,810 [INFO] Epoch 6/15 - Policy Loss: 0.9173, Value Loss: 0.2120, Total Loss: 1.1293, LR: 0.000077
2025-04-26 10:57:32,347 [INFO] Epoch 7/15 - Policy Loss: 0.9145, Value Loss: 0.2114, Total Loss: 1.1260, LR: 0.001673
2025-04-26 10:57:56,577 [INFO] Epoch 8/15 - Policy Loss: 0.9129, Value Loss: 0.2106, Total Loss: 1.1235, LR: 0.003323
2025-04-26 10:58:20,933 [INFO] Epoch 9/15 - Policy Loss: 0.9115, Value Loss: 0.2098, Total Loss: 1.1213, LR: 0.004973
2025-04-26 10:58:45,228 [INFO] Epoch 10/15 - Policy Loss: 0.9107, Value Loss: 0.2096, Total Loss: 1.1203, LR: 0.003377
2025-04-26 10:59:09,517 [INFO] Epoch 11/15 - Policy Loss: 0.9098, Value Loss: 0.2091, Total Loss: 1.1189, LR: 0.001727
2025-04-26 10:59:33,681 [INFO] Epoch 12/15 - Policy Loss: 0.9093, Value Loss: 0.2088, Total Loss: 1.1181, LR: 0.000077
2025-04-26 10:59:57,967 [INFO] Epoch 13/15 - Policy Loss: 0.9081, Value Loss: 0.2083, Total Loss: 1.1165, LR: 0.001673
2025-04-26 11:00:22,423 [INFO] Epoch 14/15 - Policy Loss: 0.9073, Value Loss: 0.2079, Total Loss: 1.1152, LR: 0.003323
2025-04-26 11:00:46,817 [INFO] Epoch 15/15 - Policy Loss: 0.9072, Value Loss: 0.2076, Total Loss: 1.1148, LR: 0.004973
2025-04-26 11:00:46,837 [INFO] 训练完成，总损失: 1.1148
2025-04-26 11:00:46,837 [INFO] 保存迭代 165 的模型
2025-04-26 11:00:47,517 [INFO] Model saved to ./models/best.pt
2025-04-26 11:00:47,950 [INFO] Model saved to ./models/iteration_165.pt
2025-04-26 11:00:47,951 [INFO] 所有训练迭代完成
2025-04-26 11:00:47,951 [INFO] 开始迭代 166/300
2025-04-26 11:00:47,951 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 11:07:56,883 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 11:07:56,883 [INFO] 保存训练样本
2025-04-26 11:08:00,729 [INFO] 使用 128040 个样本训练神经网络
2025-04-26 11:08:00,729 [INFO] Training with 128040 examples
2025-04-26 11:08:00,730 [INFO] 总训练步数: 930, 每轮次批次数: 62
2025-04-26 11:08:01,193 [INFO] 循环学习率周期大小: 186 步
2025-04-26 11:08:25,752 [INFO] Epoch 1/15 - Policy Loss: 0.9233, Value Loss: 0.2054, Total Loss: 1.1287, LR: 0.001673
2025-04-26 11:08:50,204 [INFO] Epoch 2/15 - Policy Loss: 0.9187, Value Loss: 0.2056, Total Loss: 1.1243, LR: 0.003323
2025-04-26 11:09:14,634 [INFO] Epoch 3/15 - Policy Loss: 0.9208, Value Loss: 0.2051, Total Loss: 1.1258, LR: 0.004973
2025-04-26 11:09:38,996 [INFO] Epoch 4/15 - Policy Loss: 0.9178, Value Loss: 0.2051, Total Loss: 1.1228, LR: 0.003377
2025-04-26 11:10:03,465 [INFO] Epoch 5/15 - Policy Loss: 0.9159, Value Loss: 0.2043, Total Loss: 1.1202, LR: 0.001727
2025-04-26 11:10:27,975 [INFO] Epoch 6/15 - Policy Loss: 0.9135, Value Loss: 0.2033, Total Loss: 1.1168, LR: 0.000077
2025-04-26 11:10:52,496 [INFO] Epoch 7/15 - Policy Loss: 0.9124, Value Loss: 0.2022, Total Loss: 1.1145, LR: 0.001673
2025-04-26 11:11:17,031 [INFO] Epoch 8/15 - Policy Loss: 0.9104, Value Loss: 0.2015, Total Loss: 1.1119, LR: 0.003323
2025-04-26 11:11:41,573 [INFO] Epoch 9/15 - Policy Loss: 0.9097, Value Loss: 0.2010, Total Loss: 1.1107, LR: 0.004973
2025-04-26 11:12:06,048 [INFO] Epoch 10/15 - Policy Loss: 0.9093, Value Loss: 0.2007, Total Loss: 1.1100, LR: 0.003377
2025-04-26 11:12:30,579 [INFO] Epoch 11/15 - Policy Loss: 0.9085, Value Loss: 0.2002, Total Loss: 1.1087, LR: 0.001727
2025-04-26 11:12:55,064 [INFO] Epoch 12/15 - Policy Loss: 0.9075, Value Loss: 0.2001, Total Loss: 1.1076, LR: 0.000077
2025-04-26 11:13:19,509 [INFO] Epoch 13/15 - Policy Loss: 0.9066, Value Loss: 0.2000, Total Loss: 1.1066, LR: 0.001673
2025-04-26 11:13:43,923 [INFO] Epoch 14/15 - Policy Loss: 0.9060, Value Loss: 0.1997, Total Loss: 1.1057, LR: 0.003323
2025-04-26 11:14:08,409 [INFO] Epoch 15/15 - Policy Loss: 0.9054, Value Loss: 0.1996, Total Loss: 1.1050, LR: 0.004973
2025-04-26 11:14:08,428 [INFO] 训练完成，总损失: 1.1050
2025-04-26 11:14:08,428 [INFO] 保存迭代 166 的模型
2025-04-26 11:14:08,973 [INFO] Model saved to ./models/best.pt
2025-04-26 11:14:09,332 [INFO] Model saved to ./models/iteration_166.pt
2025-04-26 11:14:09,333 [INFO] 所有训练迭代完成
2025-04-26 11:14:09,333 [INFO] 开始迭代 167/300
2025-04-26 11:14:09,333 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 11:21:52,337 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 11:21:52,337 [INFO] 保存训练样本
2025-04-26 11:21:56,190 [INFO] 使用 128496 个样本训练神经网络
2025-04-26 11:21:56,191 [INFO] Training with 128496 examples
2025-04-26 11:21:56,191 [INFO] 总训练步数: 930, 每轮次批次数: 62
2025-04-26 11:21:56,616 [INFO] 循环学习率周期大小: 186 步
2025-04-26 11:22:21,348 [INFO] Epoch 1/15 - Policy Loss: 0.9366, Value Loss: 0.2232, Total Loss: 1.1597, LR: 0.001673
2025-04-26 11:22:45,699 [INFO] Epoch 2/15 - Policy Loss: 0.9291, Value Loss: 0.2192, Total Loss: 1.1483, LR: 0.003323
2025-04-26 11:23:10,041 [INFO] Epoch 3/15 - Policy Loss: 0.9271, Value Loss: 0.2162, Total Loss: 1.1433, LR: 0.004973
2025-04-26 11:23:34,305 [INFO] Epoch 4/15 - Policy Loss: 0.9233, Value Loss: 0.2142, Total Loss: 1.1374, LR: 0.003377
2025-04-26 11:23:58,508 [INFO] Epoch 5/15 - Policy Loss: 0.9211, Value Loss: 0.2119, Total Loss: 1.1330, LR: 0.001727
2025-04-26 11:24:22,821 [INFO] Epoch 6/15 - Policy Loss: 0.9189, Value Loss: 0.2097, Total Loss: 1.1286, LR: 0.000077
2025-04-26 11:24:47,125 [INFO] Epoch 7/15 - Policy Loss: 0.9169, Value Loss: 0.2089, Total Loss: 1.1258, LR: 0.001673
2025-04-26 11:25:11,422 [INFO] Epoch 8/15 - Policy Loss: 0.9152, Value Loss: 0.2083, Total Loss: 1.1235, LR: 0.003323
2025-04-26 11:25:35,716 [INFO] Epoch 9/15 - Policy Loss: 0.9143, Value Loss: 0.2073, Total Loss: 1.1215, LR: 0.004973
2025-04-26 11:26:00,030 [INFO] Epoch 10/15 - Policy Loss: 0.9136, Value Loss: 0.2071, Total Loss: 1.1207, LR: 0.003377
2025-04-26 11:26:24,691 [INFO] Epoch 11/15 - Policy Loss: 0.9125, Value Loss: 0.2066, Total Loss: 1.1191, LR: 0.001727
2025-04-26 11:26:48,889 [INFO] Epoch 12/15 - Policy Loss: 0.9112, Value Loss: 0.2059, Total Loss: 1.1172, LR: 0.000077
2025-04-26 11:27:13,129 [INFO] Epoch 13/15 - Policy Loss: 0.9093, Value Loss: 0.2055, Total Loss: 1.1148, LR: 0.001673
2025-04-26 11:27:37,374 [INFO] Epoch 14/15 - Policy Loss: 0.9087, Value Loss: 0.2052, Total Loss: 1.1139, LR: 0.003323
2025-04-26 11:28:01,458 [INFO] Epoch 15/15 - Policy Loss: 0.9076, Value Loss: 0.2048, Total Loss: 1.1125, LR: 0.004973
2025-04-26 11:28:01,475 [INFO] 训练完成，总损失: 1.1125
2025-04-26 11:28:01,475 [INFO] 保存迭代 167 的模型
2025-04-26 11:28:01,936 [INFO] Model saved to ./models/best.pt
2025-04-26 11:28:02,240 [INFO] Model saved to ./models/iteration_167.pt
2025-04-26 11:28:02,241 [INFO] 所有训练迭代完成
2025-04-26 11:28:02,241 [INFO] 开始迭代 168/300
2025-04-26 11:28:02,241 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 11:35:25,126 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 11:35:25,126 [INFO] 保存训练样本
2025-04-26 11:35:29,700 [INFO] 使用 128320 个样本训练神经网络
2025-04-26 11:35:29,700 [INFO] Training with 128320 examples
2025-04-26 11:35:29,700 [INFO] 总训练步数: 930, 每轮次批次数: 62
2025-04-26 11:35:29,757 [INFO] 循环学习率周期大小: 186 步
2025-04-26 11:35:54,308 [INFO] Epoch 1/15 - Policy Loss: 0.9375, Value Loss: 0.2204, Total Loss: 1.1579, LR: 0.001673
2025-04-26 11:36:18,790 [INFO] Epoch 2/15 - Policy Loss: 0.9338, Value Loss: 0.2170, Total Loss: 1.1508, LR: 0.003323
2025-04-26 11:36:43,282 [INFO] Epoch 3/15 - Policy Loss: 0.9304, Value Loss: 0.2138, Total Loss: 1.1442, LR: 0.004973
2025-04-26 11:37:07,684 [INFO] Epoch 4/15 - Policy Loss: 0.9271, Value Loss: 0.2136, Total Loss: 1.1407, LR: 0.003377
2025-04-26 11:37:32,162 [INFO] Epoch 5/15 - Policy Loss: 0.9230, Value Loss: 0.2121, Total Loss: 1.1350, LR: 0.001727
2025-04-26 11:37:56,716 [INFO] Epoch 6/15 - Policy Loss: 0.9204, Value Loss: 0.2113, Total Loss: 1.1317, LR: 0.000077
2025-04-26 11:38:21,284 [INFO] Epoch 7/15 - Policy Loss: 0.9182, Value Loss: 0.2101, Total Loss: 1.1284, LR: 0.001673
2025-04-26 11:38:45,958 [INFO] Epoch 8/15 - Policy Loss: 0.9156, Value Loss: 0.2091, Total Loss: 1.1247, LR: 0.003323
2025-04-26 11:39:10,381 [INFO] Epoch 9/15 - Policy Loss: 0.9139, Value Loss: 0.2089, Total Loss: 1.1228, LR: 0.004973
2025-04-26 11:39:34,909 [INFO] Epoch 10/15 - Policy Loss: 0.9135, Value Loss: 0.2086, Total Loss: 1.1222, LR: 0.003377
2025-04-26 11:39:59,434 [INFO] Epoch 11/15 - Policy Loss: 0.9123, Value Loss: 0.2083, Total Loss: 1.1206, LR: 0.001727
2025-04-26 11:40:24,046 [INFO] Epoch 12/15 - Policy Loss: 0.9108, Value Loss: 0.2074, Total Loss: 1.1182, LR: 0.000077
2025-04-26 11:40:48,838 [INFO] Epoch 13/15 - Policy Loss: 0.9101, Value Loss: 0.2072, Total Loss: 1.1173, LR: 0.001673
2025-04-26 11:41:13,721 [INFO] Epoch 14/15 - Policy Loss: 0.9092, Value Loss: 0.2069, Total Loss: 1.1161, LR: 0.003323
2025-04-26 11:41:37,938 [INFO] Epoch 15/15 - Policy Loss: 0.9087, Value Loss: 0.2065, Total Loss: 1.1152, LR: 0.004973
2025-04-26 11:41:37,958 [INFO] 训练完成，总损失: 1.1152
2025-04-26 11:41:37,958 [INFO] 保存迭代 168 的模型
2025-04-26 11:41:38,503 [INFO] Model saved to ./models/best.pt
2025-04-26 11:41:38,900 [INFO] Model saved to ./models/iteration_168.pt
2025-04-26 11:41:38,901 [INFO] 所有训练迭代完成
2025-04-26 11:41:38,901 [INFO] 开始迭代 169/300
2025-04-26 11:41:38,901 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 11:48:55,731 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 11:48:55,731 [INFO] 保存训练样本
2025-04-26 11:48:59,525 [INFO] 使用 128480 个样本训练神经网络
2025-04-26 11:48:59,525 [INFO] Training with 128480 examples
2025-04-26 11:48:59,525 [INFO] 总训练步数: 930, 每轮次批次数: 62
2025-04-26 11:48:59,571 [INFO] 循环学习率周期大小: 186 步
2025-04-26 11:49:23,866 [INFO] Epoch 1/15 - Policy Loss: 0.9226, Value Loss: 0.2079, Total Loss: 1.1305, LR: 0.001673
2025-04-26 11:49:48,249 [INFO] Epoch 2/15 - Policy Loss: 0.9173, Value Loss: 0.2077, Total Loss: 1.1250, LR: 0.003323
2025-04-26 11:50:12,616 [INFO] Epoch 3/15 - Policy Loss: 0.9161, Value Loss: 0.2078, Total Loss: 1.1238, LR: 0.004973
2025-04-26 11:50:37,529 [INFO] Epoch 4/15 - Policy Loss: 0.9151, Value Loss: 0.2082, Total Loss: 1.1233, LR: 0.003377
2025-04-26 11:51:01,900 [INFO] Epoch 5/15 - Policy Loss: 0.9123, Value Loss: 0.2069, Total Loss: 1.1192, LR: 0.001727
2025-04-26 11:51:26,360 [INFO] Epoch 6/15 - Policy Loss: 0.9098, Value Loss: 0.2063, Total Loss: 1.1161, LR: 0.000077
2025-04-26 11:51:50,926 [INFO] Epoch 7/15 - Policy Loss: 0.9075, Value Loss: 0.2053, Total Loss: 1.1128, LR: 0.001673
2025-04-26 11:52:15,385 [INFO] Epoch 8/15 - Policy Loss: 0.9064, Value Loss: 0.2049, Total Loss: 1.1112, LR: 0.003323
2025-04-26 11:52:39,885 [INFO] Epoch 9/15 - Policy Loss: 0.9054, Value Loss: 0.2046, Total Loss: 1.1100, LR: 0.004973
2025-04-26 11:53:04,344 [INFO] Epoch 10/15 - Policy Loss: 0.9052, Value Loss: 0.2044, Total Loss: 1.1096, LR: 0.003377
2025-04-26 11:53:28,772 [INFO] Epoch 11/15 - Policy Loss: 0.9047, Value Loss: 0.2042, Total Loss: 1.1089, LR: 0.001727
2025-04-26 11:53:53,378 [INFO] Epoch 12/15 - Policy Loss: 0.9040, Value Loss: 0.2041, Total Loss: 1.1081, LR: 0.000077
2025-04-26 11:54:17,982 [INFO] Epoch 13/15 - Policy Loss: 0.9032, Value Loss: 0.2039, Total Loss: 1.1072, LR: 0.001673
2025-04-26 11:54:42,691 [INFO] Epoch 14/15 - Policy Loss: 0.9024, Value Loss: 0.2037, Total Loss: 1.1061, LR: 0.003323
2025-04-26 11:55:07,522 [INFO] Epoch 15/15 - Policy Loss: 0.9022, Value Loss: 0.2036, Total Loss: 1.1058, LR: 0.004973
2025-04-26 11:55:07,543 [INFO] 训练完成，总损失: 1.1058
2025-04-26 11:55:07,543 [INFO] 保存迭代 169 的模型
2025-04-26 11:55:08,230 [INFO] Model saved to ./models/best.pt
2025-04-26 11:55:08,694 [INFO] Model saved to ./models/iteration_169.pt
2025-04-26 11:55:08,694 [INFO] 所有训练迭代完成
2025-04-26 11:55:08,694 [INFO] 开始迭代 170/300
2025-04-26 11:55:08,695 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 12:02:50,091 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 12:02:50,092 [INFO] 保存训练样本
2025-04-26 12:02:54,357 [INFO] 使用 128824 个样本训练神经网络
2025-04-26 12:02:54,358 [INFO] Training with 128824 examples
2025-04-26 12:02:54,358 [INFO] 总训练步数: 930, 每轮次批次数: 62
2025-04-26 12:02:54,805 [INFO] 循环学习率周期大小: 186 步
2025-04-26 12:03:19,251 [INFO] Epoch 1/15 - Policy Loss: 0.9360, Value Loss: 0.2132, Total Loss: 1.1492, LR: 0.001673
2025-04-26 12:03:43,847 [INFO] Epoch 2/15 - Policy Loss: 0.9290, Value Loss: 0.2106, Total Loss: 1.1395, LR: 0.003323
2025-04-26 12:04:08,406 [INFO] Epoch 3/15 - Policy Loss: 0.9254, Value Loss: 0.2085, Total Loss: 1.1339, LR: 0.004973
2025-04-26 12:04:32,815 [INFO] Epoch 4/15 - Policy Loss: 0.9225, Value Loss: 0.2069, Total Loss: 1.1294, LR: 0.003377
2025-04-26 12:04:57,502 [INFO] Epoch 5/15 - Policy Loss: 0.9183, Value Loss: 0.2057, Total Loss: 1.1240, LR: 0.001727
2025-04-26 12:05:22,303 [INFO] Epoch 6/15 - Policy Loss: 0.9162, Value Loss: 0.2046, Total Loss: 1.1208, LR: 0.000077
2025-04-26 12:05:47,070 [INFO] Epoch 7/15 - Policy Loss: 0.9139, Value Loss: 0.2035, Total Loss: 1.1174, LR: 0.001673
2025-04-26 12:06:11,963 [INFO] Epoch 8/15 - Policy Loss: 0.9117, Value Loss: 0.2027, Total Loss: 1.1145, LR: 0.003323
2025-04-26 12:06:36,851 [INFO] Epoch 9/15 - Policy Loss: 0.9105, Value Loss: 0.2026, Total Loss: 1.1131, LR: 0.004973
2025-04-26 12:07:01,676 [INFO] Epoch 10/15 - Policy Loss: 0.9095, Value Loss: 0.2023, Total Loss: 1.1118, LR: 0.003377
2025-04-26 12:07:26,440 [INFO] Epoch 11/15 - Policy Loss: 0.9088, Value Loss: 0.2017, Total Loss: 1.1105, LR: 0.001727
2025-04-26 12:07:51,197 [INFO] Epoch 12/15 - Policy Loss: 0.9073, Value Loss: 0.2011, Total Loss: 1.1084, LR: 0.000077
2025-04-26 12:08:16,008 [INFO] Epoch 13/15 - Policy Loss: 0.9059, Value Loss: 0.2005, Total Loss: 1.1064, LR: 0.001673
2025-04-26 12:08:40,884 [INFO] Epoch 14/15 - Policy Loss: 0.9048, Value Loss: 0.2000, Total Loss: 1.1047, LR: 0.003323
2025-04-26 12:09:05,530 [INFO] Epoch 15/15 - Policy Loss: 0.9042, Value Loss: 0.1996, Total Loss: 1.1037, LR: 0.004973
2025-04-26 12:09:05,552 [INFO] 训练完成，总损失: 1.1037
2025-04-26 12:09:05,552 [INFO] 保存迭代 170 的模型
2025-04-26 12:09:06,190 [INFO] Model saved to ./models/best.pt
2025-04-26 12:09:06,609 [INFO] Model saved to ./models/iteration_170.pt
2025-04-26 12:09:06,609 [INFO] 所有训练迭代完成
2025-04-26 12:09:06,610 [INFO] 开始迭代 171/300
2025-04-26 12:09:06,610 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 12:17:07,922 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 12:17:07,923 [INFO] 保存训练样本
2025-04-26 12:17:12,376 [INFO] 使用 129472 个样本训练神经网络
2025-04-26 12:17:12,376 [INFO] Training with 129472 examples
2025-04-26 12:17:12,377 [INFO] 总训练步数: 945, 每轮次批次数: 63
2025-04-26 12:17:12,754 [INFO] 循环学习率周期大小: 189 步
2025-04-26 12:17:37,565 [INFO] Epoch 1/15 - Policy Loss: 0.9296, Value Loss: 0.2056, Total Loss: 1.1352, LR: 0.001674
2025-04-26 12:18:02,346 [INFO] Epoch 2/15 - Policy Loss: 0.9238, Value Loss: 0.2024, Total Loss: 1.1262, LR: 0.003324
2025-04-26 12:18:27,242 [INFO] Epoch 3/15 - Policy Loss: 0.9224, Value Loss: 0.2021, Total Loss: 1.1244, LR: 0.004974
2025-04-26 12:18:52,191 [INFO] Epoch 4/15 - Policy Loss: 0.9201, Value Loss: 0.2008, Total Loss: 1.1210, LR: 0.003376
2025-04-26 12:19:17,017 [INFO] Epoch 5/15 - Policy Loss: 0.9172, Value Loss: 0.2001, Total Loss: 1.1173, LR: 0.001726
2025-04-26 12:19:41,968 [INFO] Epoch 6/15 - Policy Loss: 0.9148, Value Loss: 0.1995, Total Loss: 1.1142, LR: 0.000076
2025-04-26 12:20:06,979 [INFO] Epoch 7/15 - Policy Loss: 0.9131, Value Loss: 0.1990, Total Loss: 1.1121, LR: 0.001674
2025-04-26 12:20:32,125 [INFO] Epoch 8/15 - Policy Loss: 0.9112, Value Loss: 0.1981, Total Loss: 1.1093, LR: 0.003324
2025-04-26 12:20:57,196 [INFO] Epoch 9/15 - Policy Loss: 0.9103, Value Loss: 0.1975, Total Loss: 1.1078, LR: 0.004974
2025-04-26 12:21:22,385 [INFO] Epoch 10/15 - Policy Loss: 0.9094, Value Loss: 0.1970, Total Loss: 1.1064, LR: 0.003376
2025-04-26 12:21:47,738 [INFO] Epoch 11/15 - Policy Loss: 0.9077, Value Loss: 0.1963, Total Loss: 1.1040, LR: 0.001726
2025-04-26 12:22:12,756 [INFO] Epoch 12/15 - Policy Loss: 0.9065, Value Loss: 0.1959, Total Loss: 1.1024, LR: 0.000076
2025-04-26 12:22:37,670 [INFO] Epoch 13/15 - Policy Loss: 0.9052, Value Loss: 0.1956, Total Loss: 1.1008, LR: 0.001674
2025-04-26 12:23:02,615 [INFO] Epoch 14/15 - Policy Loss: 0.9044, Value Loss: 0.1954, Total Loss: 1.0998, LR: 0.003324
2025-04-26 12:23:27,653 [INFO] Epoch 15/15 - Policy Loss: 0.9038, Value Loss: 0.1952, Total Loss: 1.0991, LR: 0.004974
2025-04-26 12:23:27,679 [INFO] 训练完成，总损失: 1.0991
2025-04-26 12:23:27,679 [INFO] 保存迭代 171 的模型
2025-04-26 12:23:28,371 [INFO] Model saved to ./models/best.pt
2025-04-26 12:23:28,823 [INFO] Model saved to ./models/iteration_171.pt
2025-04-26 12:23:28,824 [INFO] 所有训练迭代完成
2025-04-26 12:23:28,824 [INFO] 开始迭代 172/300
2025-04-26 12:23:28,824 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 12:30:05,291 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 12:30:05,291 [INFO] 保存训练样本
2025-04-26 12:30:09,603 [INFO] 使用 129104 个样本训练神经网络
2025-04-26 12:30:09,603 [INFO] Training with 129104 examples
2025-04-26 12:30:09,604 [INFO] 总训练步数: 945, 每轮次批次数: 63
2025-04-26 12:30:10,058 [INFO] 循环学习率周期大小: 189 步
2025-04-26 12:30:35,157 [INFO] Epoch 1/15 - Policy Loss: 0.9227, Value Loss: 0.2075, Total Loss: 1.1301, LR: 0.001674
2025-04-26 12:31:00,309 [INFO] Epoch 2/15 - Policy Loss: 0.9169, Value Loss: 0.2044, Total Loss: 1.1213, LR: 0.003324
2025-04-26 12:31:25,479 [INFO] Epoch 3/15 - Policy Loss: 0.9122, Value Loss: 0.2029, Total Loss: 1.1151, LR: 0.004974
2025-04-26 12:31:50,708 [INFO] Epoch 4/15 - Policy Loss: 0.9106, Value Loss: 0.2023, Total Loss: 1.1129, LR: 0.003376
2025-04-26 12:32:15,836 [INFO] Epoch 5/15 - Policy Loss: 0.9094, Value Loss: 0.2012, Total Loss: 1.1106, LR: 0.001726
2025-04-26 12:32:40,924 [INFO] Epoch 6/15 - Policy Loss: 0.9072, Value Loss: 0.2008, Total Loss: 1.1080, LR: 0.000076
2025-04-26 12:33:05,895 [INFO] Epoch 7/15 - Policy Loss: 0.9051, Value Loss: 0.2000, Total Loss: 1.1051, LR: 0.001674
2025-04-26 12:33:30,601 [INFO] Epoch 8/15 - Policy Loss: 0.9038, Value Loss: 0.1998, Total Loss: 1.1036, LR: 0.003324
2025-04-26 12:33:55,423 [INFO] Epoch 9/15 - Policy Loss: 0.9031, Value Loss: 0.1996, Total Loss: 1.1027, LR: 0.004974
2025-04-26 12:34:20,231 [INFO] Epoch 10/15 - Policy Loss: 0.9023, Value Loss: 0.1994, Total Loss: 1.1016, LR: 0.003376
2025-04-26 12:34:45,051 [INFO] Epoch 11/15 - Policy Loss: 0.9015, Value Loss: 0.1986, Total Loss: 1.1001, LR: 0.001726
2025-04-26 12:35:09,935 [INFO] Epoch 12/15 - Policy Loss: 0.9007, Value Loss: 0.1981, Total Loss: 1.0988, LR: 0.000076
2025-04-26 12:35:35,188 [INFO] Epoch 13/15 - Policy Loss: 0.9000, Value Loss: 0.1979, Total Loss: 1.0980, LR: 0.001674
2025-04-26 12:36:00,058 [INFO] Epoch 14/15 - Policy Loss: 0.8998, Value Loss: 0.1977, Total Loss: 1.0974, LR: 0.003324
2025-04-26 12:36:24,919 [INFO] Epoch 15/15 - Policy Loss: 0.8993, Value Loss: 0.1975, Total Loss: 1.0969, LR: 0.004974
2025-04-26 12:36:24,936 [INFO] 训练完成，总损失: 1.0969
2025-04-26 12:36:24,937 [INFO] 保存迭代 172 的模型
2025-04-26 12:36:25,581 [INFO] Model saved to ./models/best.pt
2025-04-26 12:36:25,992 [INFO] Model saved to ./models/iteration_172.pt
2025-04-26 12:36:25,993 [INFO] 所有训练迭代完成
2025-04-26 12:36:25,993 [INFO] 开始迭代 173/300
2025-04-26 12:36:25,993 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 12:43:19,127 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 12:43:19,127 [INFO] 保存训练样本
2025-04-26 12:43:22,931 [INFO] 使用 128824 个样本训练神经网络
2025-04-26 12:43:22,931 [INFO] Training with 128824 examples
2025-04-26 12:43:22,931 [INFO] 总训练步数: 930, 每轮次批次数: 62
2025-04-26 12:43:23,314 [INFO] 循环学习率周期大小: 186 步
2025-04-26 12:43:47,797 [INFO] Epoch 1/15 - Policy Loss: 0.9313, Value Loss: 0.2115, Total Loss: 1.1427, LR: 0.001673
2025-04-26 12:44:12,325 [INFO] Epoch 2/15 - Policy Loss: 0.9257, Value Loss: 0.2083, Total Loss: 1.1340, LR: 0.003323
2025-04-26 12:44:36,889 [INFO] Epoch 3/15 - Policy Loss: 0.9215, Value Loss: 0.2064, Total Loss: 1.1279, LR: 0.004973
2025-04-26 12:45:01,408 [INFO] Epoch 4/15 - Policy Loss: 0.9180, Value Loss: 0.2045, Total Loss: 1.1226, LR: 0.003377
2025-04-26 12:45:25,960 [INFO] Epoch 5/15 - Policy Loss: 0.9158, Value Loss: 0.2032, Total Loss: 1.1191, LR: 0.001727
2025-04-26 12:45:50,330 [INFO] Epoch 6/15 - Policy Loss: 0.9137, Value Loss: 0.2022, Total Loss: 1.1158, LR: 0.000077
2025-04-26 12:46:14,803 [INFO] Epoch 7/15 - Policy Loss: 0.9117, Value Loss: 0.2018, Total Loss: 1.1135, LR: 0.001673
2025-04-26 12:46:39,262 [INFO] Epoch 8/15 - Policy Loss: 0.9096, Value Loss: 0.2008, Total Loss: 1.1104, LR: 0.003323
2025-04-26 12:47:03,801 [INFO] Epoch 9/15 - Policy Loss: 0.9081, Value Loss: 0.2002, Total Loss: 1.1084, LR: 0.004973
2025-04-26 12:47:28,400 [INFO] Epoch 10/15 - Policy Loss: 0.9069, Value Loss: 0.1999, Total Loss: 1.1068, LR: 0.003377
2025-04-26 12:47:53,258 [INFO] Epoch 11/15 - Policy Loss: 0.9059, Value Loss: 0.1992, Total Loss: 1.1051, LR: 0.001727
2025-04-26 12:48:17,782 [INFO] Epoch 12/15 - Policy Loss: 0.9050, Value Loss: 0.1989, Total Loss: 1.1039, LR: 0.000077
2025-04-26 12:48:42,164 [INFO] Epoch 13/15 - Policy Loss: 0.9035, Value Loss: 0.1983, Total Loss: 1.1018, LR: 0.001673
2025-04-26 12:49:06,527 [INFO] Epoch 14/15 - Policy Loss: 0.9027, Value Loss: 0.1980, Total Loss: 1.1007, LR: 0.003323
2025-04-26 12:49:31,030 [INFO] Epoch 15/15 - Policy Loss: 0.9022, Value Loss: 0.1977, Total Loss: 1.0999, LR: 0.004973
2025-04-26 12:49:31,052 [INFO] 训练完成，总损失: 1.0999
2025-04-26 12:49:31,052 [INFO] 保存迭代 173 的模型
2025-04-26 12:49:31,705 [INFO] Model saved to ./models/best.pt
2025-04-26 12:49:32,163 [INFO] Model saved to ./models/iteration_173.pt
2025-04-26 12:49:32,163 [INFO] 所有训练迭代完成
2025-04-26 12:49:32,163 [INFO] 开始迭代 174/300
2025-04-26 12:49:32,164 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 12:57:17,122 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 12:57:17,123 [INFO] 保存训练样本
2025-04-26 12:57:21,326 [INFO] 使用 129360 个样本训练神经网络
2025-04-26 12:57:21,326 [INFO] Training with 129360 examples
2025-04-26 12:57:21,327 [INFO] 总训练步数: 945, 每轮次批次数: 63
2025-04-26 12:57:21,393 [INFO] 循环学习率周期大小: 189 步
2025-04-26 12:57:46,290 [INFO] Epoch 1/15 - Policy Loss: 0.9292, Value Loss: 0.2079, Total Loss: 1.1371, LR: 0.001674
2025-04-26 12:58:11,170 [INFO] Epoch 2/15 - Policy Loss: 0.9259, Value Loss: 0.2032, Total Loss: 1.1292, LR: 0.003324
2025-04-26 12:58:36,080 [INFO] Epoch 3/15 - Policy Loss: 0.9229, Value Loss: 0.2008, Total Loss: 1.1237, LR: 0.004974
2025-04-26 12:59:00,824 [INFO] Epoch 4/15 - Policy Loss: 0.9197, Value Loss: 0.1994, Total Loss: 1.1191, LR: 0.003376
2025-04-26 12:59:25,640 [INFO] Epoch 5/15 - Policy Loss: 0.9160, Value Loss: 0.1978, Total Loss: 1.1138, LR: 0.001726
2025-04-26 12:59:50,395 [INFO] Epoch 6/15 - Policy Loss: 0.9126, Value Loss: 0.1962, Total Loss: 1.1087, LR: 0.000076
2025-04-26 13:00:15,742 [INFO] Epoch 7/15 - Policy Loss: 0.9105, Value Loss: 0.1947, Total Loss: 1.1052, LR: 0.001674
2025-04-26 13:00:40,619 [INFO] Epoch 8/15 - Policy Loss: 0.9083, Value Loss: 0.1936, Total Loss: 1.1020, LR: 0.003324
2025-04-26 13:01:05,449 [INFO] Epoch 9/15 - Policy Loss: 0.9073, Value Loss: 0.1931, Total Loss: 1.1003, LR: 0.004974
2025-04-26 13:01:30,369 [INFO] Epoch 10/15 - Policy Loss: 0.9067, Value Loss: 0.1926, Total Loss: 1.0992, LR: 0.003376
2025-04-26 13:01:55,375 [INFO] Epoch 11/15 - Policy Loss: 0.9052, Value Loss: 0.1922, Total Loss: 1.0973, LR: 0.001726
2025-04-26 13:02:20,431 [INFO] Epoch 12/15 - Policy Loss: 0.9043, Value Loss: 0.1917, Total Loss: 1.0960, LR: 0.000076
2025-04-26 13:02:45,453 [INFO] Epoch 13/15 - Policy Loss: 0.9030, Value Loss: 0.1912, Total Loss: 1.0943, LR: 0.001674
2025-04-26 13:03:10,567 [INFO] Epoch 14/15 - Policy Loss: 0.9020, Value Loss: 0.1907, Total Loss: 1.0927, LR: 0.003324
2025-04-26 13:03:35,544 [INFO] Epoch 15/15 - Policy Loss: 0.9013, Value Loss: 0.1902, Total Loss: 1.0915, LR: 0.004974
2025-04-26 13:03:35,567 [INFO] 训练完成，总损失: 1.0915
2025-04-26 13:03:35,567 [INFO] 保存迭代 174 的模型
2025-04-26 13:03:36,210 [INFO] Model saved to ./models/best.pt
2025-04-26 13:03:36,648 [INFO] Model saved to ./models/iteration_174.pt
2025-04-26 13:03:36,648 [INFO] 所有训练迭代完成
2025-04-26 13:03:36,648 [INFO] 开始迭代 175/300
2025-04-26 13:03:36,648 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 13:11:50,029 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 13:11:50,030 [INFO] 保存训练样本
2025-04-26 13:11:53,977 [INFO] 使用 130936 个样本训练神经网络
2025-04-26 13:11:53,977 [INFO] Training with 130936 examples
2025-04-26 13:11:53,978 [INFO] 总训练步数: 945, 每轮次批次数: 63
2025-04-26 13:11:54,039 [INFO] 循环学习率周期大小: 189 步
2025-04-26 13:12:18,809 [INFO] Epoch 1/15 - Policy Loss: 0.9325, Value Loss: 0.2007, Total Loss: 1.1332, LR: 0.001674
2025-04-26 13:12:43,920 [INFO] Epoch 2/15 - Policy Loss: 0.9253, Value Loss: 0.1988, Total Loss: 1.1241, LR: 0.003324
2025-04-26 13:13:08,659 [INFO] Epoch 3/15 - Policy Loss: 0.9207, Value Loss: 0.1963, Total Loss: 1.1170, LR: 0.004974
2025-04-26 13:13:33,266 [INFO] Epoch 4/15 - Policy Loss: 0.9157, Value Loss: 0.1952, Total Loss: 1.1110, LR: 0.003376
2025-04-26 13:13:57,759 [INFO] Epoch 5/15 - Policy Loss: 0.9122, Value Loss: 0.1935, Total Loss: 1.1057, LR: 0.001726
2025-04-26 13:14:22,436 [INFO] Epoch 6/15 - Policy Loss: 0.9089, Value Loss: 0.1921, Total Loss: 1.1010, LR: 0.000076
2025-04-26 13:14:47,400 [INFO] Epoch 7/15 - Policy Loss: 0.9076, Value Loss: 0.1909, Total Loss: 1.0985, LR: 0.001674
2025-04-26 13:15:12,210 [INFO] Epoch 8/15 - Policy Loss: 0.9053, Value Loss: 0.1900, Total Loss: 1.0953, LR: 0.003324
2025-04-26 13:15:37,022 [INFO] Epoch 9/15 - Policy Loss: 0.9039, Value Loss: 0.1894, Total Loss: 1.0932, LR: 0.004974
2025-04-26 13:16:01,999 [INFO] Epoch 10/15 - Policy Loss: 0.9033, Value Loss: 0.1888, Total Loss: 1.0921, LR: 0.003376
2025-04-26 13:16:26,969 [INFO] Epoch 11/15 - Policy Loss: 0.9021, Value Loss: 0.1884, Total Loss: 1.0905, LR: 0.001726
2025-04-26 13:16:51,980 [INFO] Epoch 12/15 - Policy Loss: 0.9011, Value Loss: 0.1879, Total Loss: 1.0890, LR: 0.000076
2025-04-26 13:17:16,931 [INFO] Epoch 13/15 - Policy Loss: 0.9000, Value Loss: 0.1875, Total Loss: 1.0876, LR: 0.001674
2025-04-26 13:17:41,977 [INFO] Epoch 14/15 - Policy Loss: 0.8987, Value Loss: 0.1873, Total Loss: 1.0860, LR: 0.003324
2025-04-26 13:18:06,943 [INFO] Epoch 15/15 - Policy Loss: 0.8980, Value Loss: 0.1872, Total Loss: 1.0852, LR: 0.004974
2025-04-26 13:18:06,967 [INFO] 训练完成，总损失: 1.0852
2025-04-26 13:18:06,967 [INFO] 保存迭代 175 的模型
2025-04-26 13:18:07,516 [INFO] Model saved to ./models/best.pt
2025-04-26 13:18:07,920 [INFO] Model saved to ./models/iteration_175.pt
2025-04-26 13:18:07,921 [INFO] 所有训练迭代完成
2025-04-26 13:18:07,921 [INFO] 开始迭代 176/300
2025-04-26 13:18:07,921 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 13:26:35,328 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 13:26:35,328 [INFO] 保存训练样本
2025-04-26 13:26:40,481 [INFO] 使用 131176 个样本训练神经网络
2025-04-26 13:26:40,481 [INFO] Training with 131176 examples
2025-04-26 13:26:40,482 [INFO] 总训练步数: 960, 每轮次批次数: 64
2025-04-26 13:26:41,062 [INFO] 循环学习率周期大小: 192 步
2025-04-26 13:27:07,924 [INFO] Epoch 1/15 - Policy Loss: 0.9179, Value Loss: 0.2071, Total Loss: 1.1250, LR: 0.001674
2025-04-26 13:27:33,436 [INFO] Epoch 2/15 - Policy Loss: 0.9140, Value Loss: 0.2027, Total Loss: 1.1167, LR: 0.003324
2025-04-26 13:27:58,998 [INFO] Epoch 3/15 - Policy Loss: 0.9112, Value Loss: 0.2010, Total Loss: 1.1122, LR: 0.004974
2025-04-26 13:28:24,372 [INFO] Epoch 4/15 - Policy Loss: 0.9094, Value Loss: 0.1995, Total Loss: 1.1088, LR: 0.003376
2025-04-26 13:28:49,688 [INFO] Epoch 5/15 - Policy Loss: 0.9076, Value Loss: 0.1979, Total Loss: 1.1055, LR: 0.001726
2025-04-26 13:29:15,189 [INFO] Epoch 6/15 - Policy Loss: 0.9052, Value Loss: 0.1966, Total Loss: 1.1018, LR: 0.000076
2025-04-26 13:29:40,633 [INFO] Epoch 7/15 - Policy Loss: 0.9024, Value Loss: 0.1960, Total Loss: 1.0984, LR: 0.001674
2025-04-26 13:30:06,465 [INFO] Epoch 8/15 - Policy Loss: 0.9006, Value Loss: 0.1949, Total Loss: 1.0955, LR: 0.003324
2025-04-26 13:30:31,703 [INFO] Epoch 9/15 - Policy Loss: 0.8996, Value Loss: 0.1943, Total Loss: 1.0938, LR: 0.004974
2025-04-26 13:30:57,087 [INFO] Epoch 10/15 - Policy Loss: 0.8986, Value Loss: 0.1939, Total Loss: 1.0924, LR: 0.003376
2025-04-26 13:31:22,417 [INFO] Epoch 11/15 - Policy Loss: 0.8972, Value Loss: 0.1933, Total Loss: 1.0905, LR: 0.001726
2025-04-26 13:31:47,675 [INFO] Epoch 12/15 - Policy Loss: 0.8958, Value Loss: 0.1927, Total Loss: 1.0885, LR: 0.000076
2025-04-26 13:32:12,953 [INFO] Epoch 13/15 - Policy Loss: 0.8945, Value Loss: 0.1923, Total Loss: 1.0869, LR: 0.001674
2025-04-26 13:32:38,135 [INFO] Epoch 14/15 - Policy Loss: 0.8938, Value Loss: 0.1919, Total Loss: 1.0857, LR: 0.003324
2025-04-26 13:33:03,136 [INFO] Epoch 15/15 - Policy Loss: 0.8931, Value Loss: 0.1918, Total Loss: 1.0849, LR: 0.004974
2025-04-26 13:33:03,153 [INFO] 训练完成，总损失: 1.0849
2025-04-26 13:33:03,153 [INFO] 保存迭代 176 的模型
2025-04-26 13:33:03,567 [INFO] Model saved to ./models/best.pt
2025-04-26 13:33:03,856 [INFO] Model saved to ./models/iteration_176.pt
2025-04-26 13:33:03,856 [INFO] 所有训练迭代完成
2025-04-26 13:33:03,856 [INFO] 开始迭代 177/300
2025-04-26 13:33:03,856 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 13:39:41,688 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 13:39:41,688 [INFO] 保存训练样本
2025-04-26 13:39:45,263 [INFO] 使用 130896 个样本训练神经网络
2025-04-26 13:39:45,264 [INFO] Training with 130896 examples
2025-04-26 13:39:45,264 [INFO] 总训练步数: 945, 每轮次批次数: 63
2025-04-26 13:39:45,609 [INFO] 循环学习率周期大小: 189 步
2025-04-26 13:40:10,580 [INFO] Epoch 1/15 - Policy Loss: 0.9015, Value Loss: 0.1964, Total Loss: 1.0979, LR: 0.001674
2025-04-26 13:40:35,535 [INFO] Epoch 2/15 - Policy Loss: 0.8970, Value Loss: 0.1944, Total Loss: 1.0914, LR: 0.003324
2025-04-26 13:41:00,692 [INFO] Epoch 3/15 - Policy Loss: 0.8956, Value Loss: 0.1938, Total Loss: 1.0895, LR: 0.004974
2025-04-26 13:41:25,873 [INFO] Epoch 4/15 - Policy Loss: 0.8948, Value Loss: 0.1938, Total Loss: 1.0886, LR: 0.003376
2025-04-26 13:41:51,150 [INFO] Epoch 5/15 - Policy Loss: 0.8931, Value Loss: 0.1931, Total Loss: 1.0862, LR: 0.001726
2025-04-26 13:42:16,811 [INFO] Epoch 6/15 - Policy Loss: 0.8914, Value Loss: 0.1924, Total Loss: 1.0839, LR: 0.000076
2025-04-26 13:42:41,806 [INFO] Epoch 7/15 - Policy Loss: 0.8895, Value Loss: 0.1920, Total Loss: 1.0815, LR: 0.001674
2025-04-26 13:43:06,514 [INFO] Epoch 8/15 - Policy Loss: 0.8881, Value Loss: 0.1918, Total Loss: 1.0799, LR: 0.003324
2025-04-26 13:43:31,266 [INFO] Epoch 9/15 - Policy Loss: 0.8884, Value Loss: 0.1918, Total Loss: 1.0802, LR: 0.004974
2025-04-26 13:43:56,129 [INFO] Epoch 10/15 - Policy Loss: 0.8880, Value Loss: 0.1916, Total Loss: 1.0796, LR: 0.003376
2025-04-26 13:44:20,804 [INFO] Epoch 11/15 - Policy Loss: 0.8884, Value Loss: 0.1914, Total Loss: 1.0797, LR: 0.001726
2025-04-26 13:44:45,376 [INFO] Epoch 12/15 - Policy Loss: 0.8877, Value Loss: 0.1912, Total Loss: 1.0790, LR: 0.000076
2025-04-26 13:45:10,067 [INFO] Epoch 13/15 - Policy Loss: 0.8871, Value Loss: 0.1909, Total Loss: 1.0779, LR: 0.001674
2025-04-26 13:45:34,918 [INFO] Epoch 14/15 - Policy Loss: 0.8863, Value Loss: 0.1906, Total Loss: 1.0770, LR: 0.003324
2025-04-26 13:46:00,090 [INFO] Epoch 15/15 - Policy Loss: 0.8864, Value Loss: 0.1907, Total Loss: 1.0771, LR: 0.004974
2025-04-26 13:46:00,110 [INFO] 训练完成，总损失: 1.0771
2025-04-26 13:46:00,110 [INFO] 保存迭代 177 的模型
2025-04-26 13:46:00,683 [INFO] Model saved to ./models/best.pt
2025-04-26 13:46:01,128 [INFO] Model saved to ./models/iteration_177.pt
2025-04-26 13:46:01,128 [INFO] 所有训练迭代完成
2025-04-26 13:46:01,128 [INFO] 开始迭代 178/300
2025-04-26 13:46:01,128 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 13:54:12,585 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 13:54:12,587 [INFO] 保存训练样本
2025-04-26 13:54:16,939 [INFO] 使用 132176 个样本训练神经网络
2025-04-26 13:54:16,940 [INFO] Training with 132176 examples
2025-04-26 13:54:16,940 [INFO] 总训练步数: 960, 每轮次批次数: 64
2025-04-26 13:54:17,413 [INFO] 循环学习率周期大小: 192 步
2025-04-26 13:54:42,852 [INFO] Epoch 1/15 - Policy Loss: 0.9063, Value Loss: 0.1927, Total Loss: 1.0989, LR: 0.001674
2025-04-26 13:55:08,517 [INFO] Epoch 2/15 - Policy Loss: 0.9000, Value Loss: 0.1914, Total Loss: 1.0914, LR: 0.003324
2025-04-26 13:55:34,224 [INFO] Epoch 3/15 - Policy Loss: 0.8996, Value Loss: 0.1908, Total Loss: 1.0904, LR: 0.004974
2025-04-26 13:55:59,431 [INFO] Epoch 4/15 - Policy Loss: 0.8972, Value Loss: 0.1901, Total Loss: 1.0874, LR: 0.003376
2025-04-26 13:56:24,604 [INFO] Epoch 5/15 - Policy Loss: 0.8943, Value Loss: 0.1885, Total Loss: 1.0829, LR: 0.001726
2025-04-26 13:56:49,779 [INFO] Epoch 6/15 - Policy Loss: 0.8931, Value Loss: 0.1873, Total Loss: 1.0804, LR: 0.000076
2025-04-26 13:57:15,112 [INFO] Epoch 7/15 - Policy Loss: 0.8908, Value Loss: 0.1867, Total Loss: 1.0775, LR: 0.001674
2025-04-26 13:57:40,412 [INFO] Epoch 8/15 - Policy Loss: 0.8886, Value Loss: 0.1861, Total Loss: 1.0747, LR: 0.003324
2025-04-26 13:58:05,759 [INFO] Epoch 9/15 - Policy Loss: 0.8869, Value Loss: 0.1854, Total Loss: 1.0724, LR: 0.004974
2025-04-26 13:58:31,052 [INFO] Epoch 10/15 - Policy Loss: 0.8859, Value Loss: 0.1850, Total Loss: 1.0709, LR: 0.003376
2025-04-26 13:58:56,355 [INFO] Epoch 11/15 - Policy Loss: 0.8843, Value Loss: 0.1842, Total Loss: 1.0685, LR: 0.001726
2025-04-26 13:59:22,158 [INFO] Epoch 12/15 - Policy Loss: 0.8834, Value Loss: 0.1840, Total Loss: 1.0673, LR: 0.000076
2025-04-26 13:59:47,413 [INFO] Epoch 13/15 - Policy Loss: 0.8827, Value Loss: 0.1834, Total Loss: 1.0661, LR: 0.001674
2025-04-26 14:00:12,864 [INFO] Epoch 14/15 - Policy Loss: 0.8818, Value Loss: 0.1830, Total Loss: 1.0647, LR: 0.003324
2025-04-26 14:00:38,280 [INFO] Epoch 15/15 - Policy Loss: 0.8815, Value Loss: 0.1826, Total Loss: 1.0641, LR: 0.004974
2025-04-26 14:00:38,303 [INFO] 训练完成，总损失: 1.0641
2025-04-26 14:00:38,304 [INFO] 保存迭代 178 的模型
2025-04-26 14:00:38,868 [INFO] Model saved to ./models/best.pt
2025-04-26 14:00:39,212 [INFO] Model saved to ./models/iteration_178.pt
2025-04-26 14:00:39,213 [INFO] 所有训练迭代完成
2025-04-26 14:00:39,213 [INFO] 开始迭代 179/300
2025-04-26 14:00:39,213 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 14:09:32,759 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 14:09:32,760 [INFO] 保存训练样本
2025-04-26 14:09:36,791 [INFO] 使用 132584 个样本训练神经网络
2025-04-26 14:09:36,791 [INFO] Training with 132584 examples
2025-04-26 14:09:36,792 [INFO] 总训练步数: 960, 每轮次批次数: 64
2025-04-26 14:09:37,216 [INFO] 循环学习率周期大小: 192 步
2025-04-26 14:10:02,463 [INFO] Epoch 1/15 - Policy Loss: 0.9146, Value Loss: 0.2075, Total Loss: 1.1220, LR: 0.001674
2025-04-26 14:10:27,710 [INFO] Epoch 2/15 - Policy Loss: 0.9108, Value Loss: 0.2036, Total Loss: 1.1143, LR: 0.003324
2025-04-26 14:10:52,922 [INFO] Epoch 3/15 - Policy Loss: 0.9070, Value Loss: 0.1995, Total Loss: 1.1065, LR: 0.004974
2025-04-26 14:11:18,059 [INFO] Epoch 4/15 - Policy Loss: 0.9033, Value Loss: 0.1975, Total Loss: 1.1009, LR: 0.003376
2025-04-26 14:11:43,330 [INFO] Epoch 5/15 - Policy Loss: 0.9004, Value Loss: 0.1951, Total Loss: 1.0956, LR: 0.001726
2025-04-26 14:12:08,601 [INFO] Epoch 6/15 - Policy Loss: 0.8976, Value Loss: 0.1927, Total Loss: 1.0903, LR: 0.000076
2025-04-26 14:12:33,693 [INFO] Epoch 7/15 - Policy Loss: 0.8946, Value Loss: 0.1913, Total Loss: 1.0859, LR: 0.001674
2025-04-26 14:12:58,817 [INFO] Epoch 8/15 - Policy Loss: 0.8922, Value Loss: 0.1902, Total Loss: 1.0825, LR: 0.003324
2025-04-26 14:13:24,295 [INFO] Epoch 9/15 - Policy Loss: 0.8907, Value Loss: 0.1893, Total Loss: 1.0800, LR: 0.004974
2025-04-26 14:13:49,665 [INFO] Epoch 10/15 - Policy Loss: 0.8895, Value Loss: 0.1888, Total Loss: 1.0783, LR: 0.003376
2025-04-26 14:14:15,055 [INFO] Epoch 11/15 - Policy Loss: 0.8886, Value Loss: 0.1883, Total Loss: 1.0769, LR: 0.001726
2025-04-26 14:14:40,302 [INFO] Epoch 12/15 - Policy Loss: 0.8874, Value Loss: 0.1875, Total Loss: 1.0749, LR: 0.000076
2025-04-26 14:15:05,561 [INFO] Epoch 13/15 - Policy Loss: 0.8866, Value Loss: 0.1867, Total Loss: 1.0733, LR: 0.001674
2025-04-26 14:15:30,720 [INFO] Epoch 14/15 - Policy Loss: 0.8859, Value Loss: 0.1862, Total Loss: 1.0721, LR: 0.003324
2025-04-26 14:15:55,909 [INFO] Epoch 15/15 - Policy Loss: 0.8854, Value Loss: 0.1859, Total Loss: 1.0714, LR: 0.004974
2025-04-26 14:15:55,930 [INFO] 训练完成，总损失: 1.0714
2025-04-26 14:15:55,931 [INFO] 保存迭代 179 的模型
2025-04-26 14:15:56,675 [INFO] Model saved to ./models/best.pt
2025-04-26 14:15:57,140 [INFO] Model saved to ./models/iteration_179.pt
2025-04-26 14:15:57,140 [INFO] 所有训练迭代完成
2025-04-26 14:15:57,140 [INFO] 开始迭代 180/300
2025-04-26 14:15:57,140 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 14:23:36,680 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 14:23:36,680 [INFO] 保存训练样本
2025-04-26 14:23:41,162 [INFO] 使用 133024 个样本训练神经网络
2025-04-26 14:23:41,163 [INFO] Training with 133024 examples
2025-04-26 14:23:41,163 [INFO] 总训练步数: 960, 每轮次批次数: 64
2025-04-26 14:23:41,215 [INFO] 循环学习率周期大小: 192 步
2025-04-26 14:24:06,760 [INFO] Epoch 1/15 - Policy Loss: 0.9131, Value Loss: 0.1987, Total Loss: 1.1119, LR: 0.001674
2025-04-26 14:24:32,354 [INFO] Epoch 2/15 - Policy Loss: 0.9076, Value Loss: 0.1948, Total Loss: 1.1023, LR: 0.003324
2025-04-26 14:24:57,900 [INFO] Epoch 3/15 - Policy Loss: 0.9039, Value Loss: 0.1944, Total Loss: 1.0983, LR: 0.004974
2025-04-26 14:25:23,547 [INFO] Epoch 4/15 - Policy Loss: 0.9013, Value Loss: 0.1931, Total Loss: 1.0944, LR: 0.003376
2025-04-26 14:25:49,600 [INFO] Epoch 5/15 - Policy Loss: 0.8981, Value Loss: 0.1916, Total Loss: 1.0897, LR: 0.001726
2025-04-26 14:26:15,054 [INFO] Epoch 6/15 - Policy Loss: 0.8951, Value Loss: 0.1897, Total Loss: 1.0849, LR: 0.000076
2025-04-26 14:26:40,672 [INFO] Epoch 7/15 - Policy Loss: 0.8921, Value Loss: 0.1884, Total Loss: 1.0805, LR: 0.001674
2025-04-26 14:27:06,237 [INFO] Epoch 8/15 - Policy Loss: 0.8900, Value Loss: 0.1876, Total Loss: 1.0776, LR: 0.003324
2025-04-26 14:27:31,795 [INFO] Epoch 9/15 - Policy Loss: 0.8885, Value Loss: 0.1871, Total Loss: 1.0755, LR: 0.004974
2025-04-26 14:27:57,284 [INFO] Epoch 10/15 - Policy Loss: 0.8879, Value Loss: 0.1867, Total Loss: 1.0746, LR: 0.003376
2025-04-26 14:28:22,476 [INFO] Epoch 11/15 - Policy Loss: 0.8871, Value Loss: 0.1859, Total Loss: 1.0730, LR: 0.001726
2025-04-26 14:28:47,883 [INFO] Epoch 12/15 - Policy Loss: 0.8859, Value Loss: 0.1854, Total Loss: 1.0713, LR: 0.000076
2025-04-26 14:29:13,662 [INFO] Epoch 13/15 - Policy Loss: 0.8849, Value Loss: 0.1848, Total Loss: 1.0697, LR: 0.001674
2025-04-26 14:29:39,340 [INFO] Epoch 14/15 - Policy Loss: 0.8837, Value Loss: 0.1844, Total Loss: 1.0680, LR: 0.003324
2025-04-26 14:30:05,133 [INFO] Epoch 15/15 - Policy Loss: 0.8829, Value Loss: 0.1841, Total Loss: 1.0671, LR: 0.004974
2025-04-26 14:30:05,164 [INFO] 训练完成，总损失: 1.0671
2025-04-26 14:30:05,164 [INFO] 保存迭代 180 的模型
2025-04-26 14:30:06,049 [INFO] Model saved to ./models/best.pt
2025-04-26 14:30:06,461 [INFO] Model saved to ./models/iteration_180.pt
2025-04-26 14:30:06,462 [INFO] 所有训练迭代完成
2025-04-26 14:30:06,462 [INFO] 开始迭代 181/300
2025-04-26 14:30:06,462 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 14:37:05,435 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 14:37:05,435 [INFO] 保存训练样本
2025-04-26 14:37:09,759 [INFO] 使用 132712 个样本训练神经网络
2025-04-26 14:37:09,760 [INFO] Training with 132712 examples
2025-04-26 14:37:09,760 [INFO] 总训练步数: 960, 每轮次批次数: 64
2025-04-26 14:37:09,852 [INFO] 循环学习率周期大小: 192 步
2025-04-26 14:37:35,833 [INFO] Epoch 1/15 - Policy Loss: 0.8938, Value Loss: 0.1983, Total Loss: 1.0921, LR: 0.001674
2025-04-26 14:38:01,334 [INFO] Epoch 2/15 - Policy Loss: 0.8897, Value Loss: 0.1932, Total Loss: 1.0829, LR: 0.003324
2025-04-26 14:38:26,677 [INFO] Epoch 3/15 - Policy Loss: 0.8876, Value Loss: 0.1908, Total Loss: 1.0784, LR: 0.004974
2025-04-26 14:38:52,068 [INFO] Epoch 4/15 - Policy Loss: 0.8869, Value Loss: 0.1894, Total Loss: 1.0763, LR: 0.003376
2025-04-26 14:39:17,468 [INFO] Epoch 5/15 - Policy Loss: 0.8845, Value Loss: 0.1880, Total Loss: 1.0724, LR: 0.001726
2025-04-26 14:39:42,729 [INFO] Epoch 6/15 - Policy Loss: 0.8814, Value Loss: 0.1862, Total Loss: 1.0676, LR: 0.000076
2025-04-26 14:40:08,182 [INFO] Epoch 7/15 - Policy Loss: 0.8811, Value Loss: 0.1848, Total Loss: 1.0659, LR: 0.001674
2025-04-26 14:40:33,597 [INFO] Epoch 8/15 - Policy Loss: 0.8796, Value Loss: 0.1840, Total Loss: 1.0635, LR: 0.003324
2025-04-26 14:40:59,125 [INFO] Epoch 9/15 - Policy Loss: 0.8789, Value Loss: 0.1830, Total Loss: 1.0619, LR: 0.004974
2025-04-26 14:41:24,556 [INFO] Epoch 10/15 - Policy Loss: 0.8786, Value Loss: 0.1826, Total Loss: 1.0612, LR: 0.003376
2025-04-26 14:41:50,168 [INFO] Epoch 11/15 - Policy Loss: 0.8780, Value Loss: 0.1818, Total Loss: 1.0598, LR: 0.001726
2025-04-26 14:42:15,670 [INFO] Epoch 12/15 - Policy Loss: 0.8768, Value Loss: 0.1811, Total Loss: 1.0579, LR: 0.000076
2025-04-26 14:42:41,112 [INFO] Epoch 13/15 - Policy Loss: 0.8760, Value Loss: 0.1809, Total Loss: 1.0569, LR: 0.001674
2025-04-26 14:43:06,403 [INFO] Epoch 14/15 - Policy Loss: 0.8752, Value Loss: 0.1805, Total Loss: 1.0557, LR: 0.003324
2025-04-26 14:43:31,813 [INFO] Epoch 15/15 - Policy Loss: 0.8747, Value Loss: 0.1801, Total Loss: 1.0547, LR: 0.004974
2025-04-26 14:43:31,834 [INFO] 训练完成，总损失: 1.0547
2025-04-26 14:43:31,834 [INFO] 保存迭代 181 的模型
2025-04-26 14:43:32,489 [INFO] Model saved to ./models/best.pt
2025-04-26 14:43:32,879 [INFO] Model saved to ./models/iteration_181.pt
2025-04-26 14:43:32,880 [INFO] 所有训练迭代完成
2025-04-26 14:43:32,880 [INFO] 开始迭代 182/300
2025-04-26 14:43:32,880 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 14:50:55,135 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 14:50:55,136 [INFO] 保存训练样本
2025-04-26 14:50:59,907 [INFO] 使用 133424 个样本训练神经网络
2025-04-26 14:50:59,907 [INFO] Training with 133424 examples
2025-04-26 14:50:59,908 [INFO] 总训练步数: 975, 每轮次批次数: 65
2025-04-26 14:51:00,336 [INFO] 循环学习率周期大小: 195 步
2025-04-26 14:51:25,823 [INFO] Epoch 1/15 - Policy Loss: 0.9026, Value Loss: 0.1905, Total Loss: 1.0931, LR: 0.001675
2025-04-26 14:51:51,306 [INFO] Epoch 2/15 - Policy Loss: 0.8937, Value Loss: 0.1870, Total Loss: 1.0807, LR: 0.003325
2025-04-26 14:52:16,746 [INFO] Epoch 3/15 - Policy Loss: 0.8882, Value Loss: 0.1842, Total Loss: 1.0725, LR: 0.004975
2025-04-26 14:52:42,231 [INFO] Epoch 4/15 - Policy Loss: 0.8842, Value Loss: 0.1820, Total Loss: 1.0662, LR: 0.003375
2025-04-26 14:53:07,707 [INFO] Epoch 5/15 - Policy Loss: 0.8825, Value Loss: 0.1803, Total Loss: 1.0627, LR: 0.001725
2025-04-26 14:53:33,030 [INFO] Epoch 6/15 - Policy Loss: 0.8800, Value Loss: 0.1787, Total Loss: 1.0587, LR: 0.000075
2025-04-26 14:53:58,455 [INFO] Epoch 7/15 - Policy Loss: 0.8783, Value Loss: 0.1782, Total Loss: 1.0565, LR: 0.001675
2025-04-26 14:54:23,838 [INFO] Epoch 8/15 - Policy Loss: 0.8772, Value Loss: 0.1777, Total Loss: 1.0549, LR: 0.003325
2025-04-26 14:54:49,346 [INFO] Epoch 9/15 - Policy Loss: 0.8764, Value Loss: 0.1774, Total Loss: 1.0538, LR: 0.004975
2025-04-26 14:55:14,929 [INFO] Epoch 10/15 - Policy Loss: 0.8760, Value Loss: 0.1771, Total Loss: 1.0531, LR: 0.003375
2025-04-26 14:55:40,375 [INFO] Epoch 11/15 - Policy Loss: 0.8750, Value Loss: 0.1767, Total Loss: 1.0517, LR: 0.001725
2025-04-26 14:56:05,886 [INFO] Epoch 12/15 - Policy Loss: 0.8738, Value Loss: 0.1762, Total Loss: 1.0500, LR: 0.000075
2025-04-26 14:56:31,320 [INFO] Epoch 13/15 - Policy Loss: 0.8729, Value Loss: 0.1757, Total Loss: 1.0486, LR: 0.001675
2025-04-26 14:56:56,908 [INFO] Epoch 14/15 - Policy Loss: 0.8719, Value Loss: 0.1753, Total Loss: 1.0473, LR: 0.003325
2025-04-26 14:57:22,559 [INFO] Epoch 15/15 - Policy Loss: 0.8714, Value Loss: 0.1753, Total Loss: 1.0467, LR: 0.004975
2025-04-26 14:57:22,577 [INFO] 训练完成，总损失: 1.0467
2025-04-26 14:57:22,577 [INFO] 保存迭代 182 的模型
2025-04-26 14:57:23,148 [INFO] Model saved to ./models/best.pt
2025-04-26 14:57:23,526 [INFO] Model saved to ./models/iteration_182.pt
2025-04-26 14:57:23,526 [INFO] 所有训练迭代完成
2025-04-26 14:57:23,526 [INFO] 开始迭代 183/300
2025-04-26 14:57:23,526 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 15:05:11,974 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 15:05:11,974 [INFO] 保存训练样本
2025-04-26 15:05:16,025 [INFO] 使用 133648 个样本训练神经网络
2025-04-26 15:05:16,025 [INFO] Training with 133648 examples
2025-04-26 15:05:16,026 [INFO] 总训练步数: 975, 每轮次批次数: 65
2025-04-26 15:05:16,594 [INFO] 循环学习率周期大小: 195 步
2025-04-26 15:05:42,221 [INFO] Epoch 1/15 - Policy Loss: 0.8965, Value Loss: 0.1884, Total Loss: 1.0849, LR: 0.001675
2025-04-26 15:06:07,904 [INFO] Epoch 2/15 - Policy Loss: 0.8912, Value Loss: 0.1859, Total Loss: 1.0770, LR: 0.003325
2025-04-26 15:06:33,583 [INFO] Epoch 3/15 - Policy Loss: 0.8892, Value Loss: 0.1843, Total Loss: 1.0735, LR: 0.004975
2025-04-26 15:06:59,157 [INFO] Epoch 4/15 - Policy Loss: 0.8873, Value Loss: 0.1821, Total Loss: 1.0694, LR: 0.003375
2025-04-26 15:07:24,725 [INFO] Epoch 5/15 - Policy Loss: 0.8847, Value Loss: 0.1811, Total Loss: 1.0658, LR: 0.001725
2025-04-26 15:07:50,255 [INFO] Epoch 6/15 - Policy Loss: 0.8831, Value Loss: 0.1807, Total Loss: 1.0638, LR: 0.000075
2025-04-26 15:08:15,820 [INFO] Epoch 7/15 - Policy Loss: 0.8808, Value Loss: 0.1796, Total Loss: 1.0604, LR: 0.001675
2025-04-26 15:08:41,258 [INFO] Epoch 8/15 - Policy Loss: 0.8799, Value Loss: 0.1791, Total Loss: 1.0591, LR: 0.003325
2025-04-26 15:09:06,750 [INFO] Epoch 9/15 - Policy Loss: 0.8789, Value Loss: 0.1785, Total Loss: 1.0575, LR: 0.004975
2025-04-26 15:09:32,227 [INFO] Epoch 10/15 - Policy Loss: 0.8776, Value Loss: 0.1783, Total Loss: 1.0560, LR: 0.003375
2025-04-26 15:09:57,776 [INFO] Epoch 11/15 - Policy Loss: 0.8766, Value Loss: 0.1777, Total Loss: 1.0543, LR: 0.001725
2025-04-26 15:10:23,343 [INFO] Epoch 12/15 - Policy Loss: 0.8753, Value Loss: 0.1773, Total Loss: 1.0526, LR: 0.000075
2025-04-26 15:10:48,822 [INFO] Epoch 13/15 - Policy Loss: 0.8743, Value Loss: 0.1770, Total Loss: 1.0513, LR: 0.001675
2025-04-26 15:11:14,293 [INFO] Epoch 14/15 - Policy Loss: 0.8731, Value Loss: 0.1767, Total Loss: 1.0498, LR: 0.003325
2025-04-26 15:11:39,915 [INFO] Epoch 15/15 - Policy Loss: 0.8726, Value Loss: 0.1762, Total Loss: 1.0487, LR: 0.004975
2025-04-26 15:11:39,933 [INFO] 训练完成，总损失: 1.0487
2025-04-26 15:11:39,933 [INFO] 保存迭代 183 的模型
2025-04-26 15:11:40,437 [INFO] Model saved to ./models/best.pt
2025-04-26 15:11:40,763 [INFO] Model saved to ./models/iteration_183.pt
2025-04-26 15:11:40,763 [INFO] 所有训练迭代完成
2025-04-26 15:11:40,763 [INFO] 开始迭代 184/300
2025-04-26 15:11:40,764 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 15:19:18,399 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 15:19:18,400 [INFO] 保存训练样本
2025-04-26 15:19:22,427 [INFO] 使用 134448 个样本训练神经网络
2025-04-26 15:19:22,427 [INFO] Training with 134448 examples
2025-04-26 15:19:22,428 [INFO] 总训练步数: 975, 每轮次批次数: 65
2025-04-26 15:19:22,942 [INFO] 循环学习率周期大小: 195 步
2025-04-26 15:19:48,674 [INFO] Epoch 1/15 - Policy Loss: 0.9050, Value Loss: 0.1981, Total Loss: 1.1031, LR: 0.001675
2025-04-26 15:20:14,197 [INFO] Epoch 2/15 - Policy Loss: 0.9002, Value Loss: 0.1965, Total Loss: 1.0966, LR: 0.003325
2025-04-26 15:20:39,891 [INFO] Epoch 3/15 - Policy Loss: 0.8950, Value Loss: 0.1946, Total Loss: 1.0896, LR: 0.004975
2025-04-26 15:21:05,658 [INFO] Epoch 4/15 - Policy Loss: 0.8907, Value Loss: 0.1933, Total Loss: 1.0840, LR: 0.003375
2025-04-26 15:21:31,320 [INFO] Epoch 5/15 - Policy Loss: 0.8869, Value Loss: 0.1921, Total Loss: 1.0790, LR: 0.001725
2025-04-26 15:21:57,108 [INFO] Epoch 6/15 - Policy Loss: 0.8841, Value Loss: 0.1907, Total Loss: 1.0748, LR: 0.000075
2025-04-26 15:22:22,775 [INFO] Epoch 7/15 - Policy Loss: 0.8806, Value Loss: 0.1898, Total Loss: 1.0704, LR: 0.001675
2025-04-26 15:22:48,702 [INFO] Epoch 8/15 - Policy Loss: 0.8787, Value Loss: 0.1887, Total Loss: 1.0674, LR: 0.003325
2025-04-26 15:23:14,451 [INFO] Epoch 9/15 - Policy Loss: 0.8771, Value Loss: 0.1881, Total Loss: 1.0652, LR: 0.004975
2025-04-26 15:23:40,099 [INFO] Epoch 10/15 - Policy Loss: 0.8760, Value Loss: 0.1876, Total Loss: 1.0636, LR: 0.003375
2025-04-26 15:24:05,848 [INFO] Epoch 11/15 - Policy Loss: 0.8741, Value Loss: 0.1872, Total Loss: 1.0613, LR: 0.001725
2025-04-26 15:24:32,078 [INFO] Epoch 12/15 - Policy Loss: 0.8730, Value Loss: 0.1865, Total Loss: 1.0595, LR: 0.000075
2025-04-26 15:24:57,855 [INFO] Epoch 13/15 - Policy Loss: 0.8716, Value Loss: 0.1859, Total Loss: 1.0575, LR: 0.001675
2025-04-26 15:25:23,495 [INFO] Epoch 14/15 - Policy Loss: 0.8707, Value Loss: 0.1856, Total Loss: 1.0563, LR: 0.003325
2025-04-26 15:25:49,225 [INFO] Epoch 15/15 - Policy Loss: 0.8697, Value Loss: 0.1852, Total Loss: 1.0549, LR: 0.004975
2025-04-26 15:25:49,253 [INFO] 训练完成，总损失: 1.0549
2025-04-26 15:25:49,253 [INFO] 保存迭代 184 的模型
2025-04-26 15:25:49,862 [INFO] Model saved to ./models/best.pt
2025-04-26 15:25:50,296 [INFO] Model saved to ./models/iteration_184.pt
2025-04-26 15:25:50,297 [INFO] 所有训练迭代完成
2025-04-26 15:25:50,297 [INFO] 开始迭代 185/300
2025-04-26 15:25:50,297 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 15:34:47,944 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 15:34:47,945 [INFO] 保存训练样本
2025-04-26 15:34:52,303 [INFO] 使用 135520 个样本训练神经网络
2025-04-26 15:34:52,303 [INFO] Training with 135520 examples
2025-04-26 15:34:52,303 [INFO] 总训练步数: 990, 每轮次批次数: 66
2025-04-26 15:34:52,715 [INFO] 循环学习率周期大小: 198 步
2025-04-26 15:35:18,875 [INFO] Epoch 1/15 - Policy Loss: 0.9156, Value Loss: 0.2213, Total Loss: 1.1369, LR: 0.001675
2025-04-26 15:36:07,685 [INFO] Epoch 2/15 - Policy Loss: 0.9045, Value Loss: 0.2152, Total Loss: 1.1197, LR: 0.003325
2025-04-26 15:36:34,917 [INFO] Epoch 3/15 - Policy Loss: 0.8987, Value Loss: 0.2127, Total Loss: 1.1114, LR: 0.004975
2025-04-26 15:37:01,048 [INFO] Epoch 4/15 - Policy Loss: 0.8932, Value Loss: 0.2101, Total Loss: 1.1033, LR: 0.003375
2025-04-26 15:37:27,329 [INFO] Epoch 5/15 - Policy Loss: 0.8885, Value Loss: 0.2074, Total Loss: 1.0960, LR: 0.001725
2025-04-26 15:38:14,577 [INFO] Epoch 6/15 - Policy Loss: 0.8848, Value Loss: 0.2058, Total Loss: 1.0907, LR: 0.000075
2025-04-26 15:38:40,835 [INFO] Epoch 7/15 - Policy Loss: 0.8818, Value Loss: 0.2041, Total Loss: 1.0859, LR: 0.001675
2025-04-26 15:39:07,092 [INFO] Epoch 8/15 - Policy Loss: 0.8801, Value Loss: 0.2027, Total Loss: 1.0828, LR: 0.003325
2025-04-26 15:39:33,729 [INFO] Epoch 9/15 - Policy Loss: 0.8783, Value Loss: 0.2017, Total Loss: 1.0800, LR: 0.004975
2025-04-26 15:40:16,620 [INFO] Epoch 10/15 - Policy Loss: 0.8770, Value Loss: 0.2009, Total Loss: 1.0780, LR: 0.003375
2025-04-26 15:40:46,504 [INFO] Epoch 11/15 - Policy Loss: 0.8754, Value Loss: 0.2001, Total Loss: 1.0754, LR: 0.001725
2025-04-26 15:41:12,655 [INFO] Epoch 12/15 - Policy Loss: 0.8740, Value Loss: 0.1993, Total Loss: 1.0733, LR: 0.000075
2025-04-26 15:41:39,048 [INFO] Epoch 13/15 - Policy Loss: 0.8722, Value Loss: 0.1984, Total Loss: 1.0706, LR: 0.001675
2025-04-26 15:42:05,283 [INFO] Epoch 14/15 - Policy Loss: 0.8707, Value Loss: 0.1978, Total Loss: 1.0685, LR: 0.003325
2025-04-26 15:42:31,433 [INFO] Epoch 15/15 - Policy Loss: 0.8699, Value Loss: 0.1972, Total Loss: 1.0671, LR: 0.004975
2025-04-26 15:42:31,455 [INFO] 训练完成，总损失: 1.0671
2025-04-26 15:42:31,456 [INFO] 保存迭代 185 的模型
2025-04-26 15:42:32,207 [INFO] Model saved to ./models/best.pt
2025-04-26 15:42:32,719 [INFO] Model saved to ./models/iteration_185.pt
2025-04-26 15:42:32,720 [INFO] 所有训练迭代完成
2025-04-26 15:42:32,720 [INFO] 开始迭代 186/300
2025-04-26 15:42:32,720 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 15:51:41,337 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 15:51:41,338 [INFO] 保存训练样本
2025-04-26 15:51:45,531 [INFO] 使用 136768 个样本训练神经网络
2025-04-26 15:51:45,531 [INFO] Training with 136768 examples
2025-04-26 15:51:45,531 [INFO] 总训练步数: 990, 每轮次批次数: 66
2025-04-26 15:51:45,582 [INFO] 循环学习率周期大小: 198 步
2025-04-26 15:52:38,662 [INFO] Epoch 1/15 - Policy Loss: 0.8954, Value Loss: 0.2151, Total Loss: 1.1105, LR: 0.001675
2025-04-26 15:53:08,345 [INFO] Epoch 2/15 - Policy Loss: 0.8905, Value Loss: 0.2113, Total Loss: 1.1018, LR: 0.003325
2025-04-26 15:53:34,736 [INFO] Epoch 3/15 - Policy Loss: 0.8847, Value Loss: 0.2083, Total Loss: 1.0930, LR: 0.004975
2025-04-26 15:54:01,503 [INFO] Epoch 4/15 - Policy Loss: 0.8822, Value Loss: 0.2071, Total Loss: 1.0894, LR: 0.003375
2025-04-26 15:54:29,916 [INFO] Epoch 5/15 - Policy Loss: 0.8798, Value Loss: 0.2058, Total Loss: 1.0856, LR: 0.001725
2025-04-26 15:55:19,865 [INFO] Epoch 6/15 - Policy Loss: 0.8765, Value Loss: 0.2041, Total Loss: 1.0806, LR: 0.000075
2025-04-26 15:55:45,836 [INFO] Epoch 7/15 - Policy Loss: 0.8746, Value Loss: 0.2028, Total Loss: 1.0775, LR: 0.001675
2025-04-26 15:56:11,830 [INFO] Epoch 8/15 - Policy Loss: 0.8727, Value Loss: 0.2018, Total Loss: 1.0745, LR: 0.003325
2025-04-26 15:56:38,018 [INFO] Epoch 9/15 - Policy Loss: 0.8713, Value Loss: 0.2013, Total Loss: 1.0726, LR: 0.004975
2025-04-26 15:57:04,286 [INFO] Epoch 10/15 - Policy Loss: 0.8701, Value Loss: 0.2005, Total Loss: 1.0706, LR: 0.003375
2025-04-26 15:57:30,623 [INFO] Epoch 11/15 - Policy Loss: 0.8685, Value Loss: 0.1999, Total Loss: 1.0684, LR: 0.001725
2025-04-26 15:57:58,284 [INFO] Epoch 12/15 - Policy Loss: 0.8669, Value Loss: 0.1995, Total Loss: 1.0663, LR: 0.000075
2025-04-26 15:58:25,414 [INFO] Epoch 13/15 - Policy Loss: 0.8658, Value Loss: 0.1987, Total Loss: 1.0645, LR: 0.001675
2025-04-26 15:58:52,859 [INFO] Epoch 14/15 - Policy Loss: 0.8647, Value Loss: 0.1984, Total Loss: 1.0631, LR: 0.003325
2025-04-26 15:59:21,270 [INFO] Epoch 15/15 - Policy Loss: 0.8643, Value Loss: 0.1982, Total Loss: 1.0625, LR: 0.004975
2025-04-26 15:59:21,292 [INFO] 训练完成，总损失: 1.0625
2025-04-26 15:59:21,292 [INFO] 保存迭代 186 的模型
2025-04-26 15:59:22,045 [INFO] Model saved to ./models/best.pt
2025-04-26 15:59:22,579 [INFO] Model saved to ./models/iteration_186.pt
2025-04-26 15:59:22,580 [INFO] 所有训练迭代完成
2025-04-26 15:59:22,580 [INFO] 开始迭代 187/300
2025-04-26 15:59:22,580 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 16:08:50,375 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 16:08:50,376 [INFO] 保存训练样本
2025-04-26 16:08:55,442 [INFO] 使用 137520 个样本训练神经网络
2025-04-26 16:08:55,443 [INFO] Training with 137520 examples
2025-04-26 16:08:55,444 [INFO] 总训练步数: 1005, 每轮次批次数: 67
2025-04-26 16:08:55,899 [INFO] 循环学习率周期大小: 201 步
2025-04-26 16:09:22,580 [INFO] Epoch 1/15 - Policy Loss: 0.8936, Value Loss: 0.2190, Total Loss: 1.1126, LR: 0.001675
2025-04-26 16:09:49,212 [INFO] Epoch 2/15 - Policy Loss: 0.8891, Value Loss: 0.2159, Total Loss: 1.1050, LR: 0.003325
2025-04-26 16:10:15,748 [INFO] Epoch 3/15 - Policy Loss: 0.8818, Value Loss: 0.2129, Total Loss: 1.0947, LR: 0.004975
2025-04-26 16:10:42,215 [INFO] Epoch 4/15 - Policy Loss: 0.8796, Value Loss: 0.2107, Total Loss: 1.0904, LR: 0.003375
2025-04-26 16:11:08,765 [INFO] Epoch 5/15 - Policy Loss: 0.8764, Value Loss: 0.2090, Total Loss: 1.0853, LR: 0.001725
2025-04-26 16:11:35,339 [INFO] Epoch 6/15 - Policy Loss: 0.8741, Value Loss: 0.2077, Total Loss: 1.0818, LR: 0.000075
2025-04-26 16:12:02,034 [INFO] Epoch 7/15 - Policy Loss: 0.8719, Value Loss: 0.2066, Total Loss: 1.0785, LR: 0.001675
2025-04-26 16:12:28,984 [INFO] Epoch 8/15 - Policy Loss: 0.8699, Value Loss: 0.2060, Total Loss: 1.0759, LR: 0.003325
2025-04-26 16:12:55,965 [INFO] Epoch 9/15 - Policy Loss: 0.8683, Value Loss: 0.2054, Total Loss: 1.0737, LR: 0.004975
2025-04-26 16:13:23,286 [INFO] Epoch 10/15 - Policy Loss: 0.8671, Value Loss: 0.2050, Total Loss: 1.0721, LR: 0.003375
2025-04-26 16:13:50,218 [INFO] Epoch 11/15 - Policy Loss: 0.8656, Value Loss: 0.2045, Total Loss: 1.0701, LR: 0.001725
2025-04-26 16:14:16,908 [INFO] Epoch 12/15 - Policy Loss: 0.8642, Value Loss: 0.2038, Total Loss: 1.0680, LR: 0.000075
2025-04-26 16:14:44,070 [INFO] Epoch 13/15 - Policy Loss: 0.8633, Value Loss: 0.2035, Total Loss: 1.0668, LR: 0.001675
2025-04-26 16:15:10,394 [INFO] Epoch 14/15 - Policy Loss: 0.8621, Value Loss: 0.2029, Total Loss: 1.0651, LR: 0.003325
2025-04-26 16:15:36,898 [INFO] Epoch 15/15 - Policy Loss: 0.8616, Value Loss: 0.2027, Total Loss: 1.0642, LR: 0.004975
2025-04-26 16:15:36,932 [INFO] 训练完成，总损失: 1.0642
2025-04-26 16:15:36,933 [INFO] 保存迭代 187 的模型
2025-04-26 16:15:37,773 [INFO] Model saved to ./models/best.pt
2025-04-26 16:15:38,263 [INFO] Model saved to ./models/iteration_187.pt
2025-04-26 16:15:38,263 [INFO] 所有训练迭代完成
2025-04-26 16:15:38,263 [INFO] 开始迭代 188/300
2025-04-26 16:15:38,263 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 16:24:32,429 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 16:24:32,429 [INFO] 保存训练样本
2025-04-26 16:24:37,187 [INFO] 使用 138088 个样本训练神经网络
2025-04-26 16:24:37,188 [INFO] Training with 138088 examples
2025-04-26 16:24:37,188 [INFO] 总训练步数: 1005, 每轮次批次数: 67
2025-04-26 16:24:37,683 [INFO] 循环学习率周期大小: 201 步
2025-04-26 16:25:04,429 [INFO] Epoch 1/15 - Policy Loss: 0.8939, Value Loss: 0.2151, Total Loss: 1.1090, LR: 0.001675
2025-04-26 16:25:31,114 [INFO] Epoch 2/15 - Policy Loss: 0.8896, Value Loss: 0.2130, Total Loss: 1.1026, LR: 0.003325
2025-04-26 16:25:57,482 [INFO] Epoch 3/15 - Policy Loss: 0.8851, Value Loss: 0.2114, Total Loss: 1.0965, LR: 0.004975
2025-04-26 16:26:23,654 [INFO] Epoch 4/15 - Policy Loss: 0.8814, Value Loss: 0.2101, Total Loss: 1.0915, LR: 0.003375
2025-04-26 16:26:50,020 [INFO] Epoch 5/15 - Policy Loss: 0.8784, Value Loss: 0.2087, Total Loss: 1.0871, LR: 0.001725
2025-04-26 16:27:16,611 [INFO] Epoch 6/15 - Policy Loss: 0.8760, Value Loss: 0.2079, Total Loss: 1.0839, LR: 0.000075
2025-04-26 16:27:43,076 [INFO] Epoch 7/15 - Policy Loss: 0.8737, Value Loss: 0.2072, Total Loss: 1.0808, LR: 0.001675
2025-04-26 16:28:09,400 [INFO] Epoch 8/15 - Policy Loss: 0.8712, Value Loss: 0.2065, Total Loss: 1.0776, LR: 0.003325
2025-04-26 16:28:35,569 [INFO] Epoch 9/15 - Policy Loss: 0.8698, Value Loss: 0.2058, Total Loss: 1.0755, LR: 0.004975
2025-04-26 16:29:01,731 [INFO] Epoch 10/15 - Policy Loss: 0.8688, Value Loss: 0.2052, Total Loss: 1.0739, LR: 0.003375
2025-04-26 16:29:28,030 [INFO] Epoch 11/15 - Policy Loss: 0.8678, Value Loss: 0.2047, Total Loss: 1.0725, LR: 0.001725
2025-04-26 16:29:54,232 [INFO] Epoch 12/15 - Policy Loss: 0.8665, Value Loss: 0.2042, Total Loss: 1.0707, LR: 0.000075
2025-04-26 16:30:20,298 [INFO] Epoch 13/15 - Policy Loss: 0.8652, Value Loss: 0.2038, Total Loss: 1.0690, LR: 0.001675
2025-04-26 16:30:47,269 [INFO] Epoch 14/15 - Policy Loss: 0.8637, Value Loss: 0.2034, Total Loss: 1.0671, LR: 0.003325
2025-04-26 16:31:13,675 [INFO] Epoch 15/15 - Policy Loss: 0.8629, Value Loss: 0.2031, Total Loss: 1.0660, LR: 0.004975
2025-04-26 16:31:13,695 [INFO] 训练完成，总损失: 1.0660
2025-04-26 16:31:13,695 [INFO] 保存迭代 188 的模型
2025-04-26 16:31:14,404 [INFO] Model saved to ./models/best.pt
2025-04-26 16:31:14,875 [INFO] Model saved to ./models/iteration_188.pt
2025-04-26 16:31:14,875 [INFO] 所有训练迭代完成
2025-04-26 16:31:14,876 [INFO] 开始迭代 189/300
2025-04-26 16:31:14,876 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 16:41:34,077 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 16:41:34,078 [INFO] 保存训练样本
2025-04-26 16:41:38,383 [INFO] 使用 139584 个样本训练神经网络
2025-04-26 16:41:38,384 [INFO] Training with 139584 examples
2025-04-26 16:41:38,384 [INFO] 总训练步数: 1020, 每轮次批次数: 68
2025-04-26 16:41:39,069 [INFO] 循环学习率周期大小: 204 步
2025-04-26 16:42:09,075 [INFO] Epoch 1/15 - Policy Loss: 0.9041, Value Loss: 0.2299, Total Loss: 1.1340, LR: 0.001676
2025-04-26 16:42:39,360 [INFO] Epoch 2/15 - Policy Loss: 0.8936, Value Loss: 0.2232, Total Loss: 1.1169, LR: 0.003326
2025-04-26 16:43:09,721 [INFO] Epoch 3/15 - Policy Loss: 0.8873, Value Loss: 0.2191, Total Loss: 1.1065, LR: 0.004976
2025-04-26 16:43:39,366 [INFO] Epoch 4/15 - Policy Loss: 0.8829, Value Loss: 0.2176, Total Loss: 1.1005, LR: 0.003374
2025-04-26 16:44:07,146 [INFO] Epoch 5/15 - Policy Loss: 0.8782, Value Loss: 0.2154, Total Loss: 1.0936, LR: 0.001724
2025-04-26 16:44:34,043 [INFO] Epoch 6/15 - Policy Loss: 0.8749, Value Loss: 0.2136, Total Loss: 1.0885, LR: 0.000074
2025-04-26 16:45:00,775 [INFO] Epoch 7/15 - Policy Loss: 0.8722, Value Loss: 0.2125, Total Loss: 1.0847, LR: 0.001676
2025-04-26 16:45:27,503 [INFO] Epoch 8/15 - Policy Loss: 0.8705, Value Loss: 0.2118, Total Loss: 1.0823, LR: 0.003326
2025-04-26 16:45:54,252 [INFO] Epoch 9/15 - Policy Loss: 0.8696, Value Loss: 0.2110, Total Loss: 1.0806, LR: 0.004976
2025-04-26 16:46:21,306 [INFO] Epoch 10/15 - Policy Loss: 0.8687, Value Loss: 0.2105, Total Loss: 1.0792, LR: 0.003374
2025-04-26 16:46:48,090 [INFO] Epoch 11/15 - Policy Loss: 0.8670, Value Loss: 0.2097, Total Loss: 1.0767, LR: 0.001724
2025-04-26 16:47:14,863 [INFO] Epoch 12/15 - Policy Loss: 0.8655, Value Loss: 0.2090, Total Loss: 1.0745, LR: 0.000074
2025-04-26 16:47:41,613 [INFO] Epoch 13/15 - Policy Loss: 0.8638, Value Loss: 0.2082, Total Loss: 1.0719, LR: 0.001676
2025-04-26 16:48:08,402 [INFO] Epoch 14/15 - Policy Loss: 0.8626, Value Loss: 0.2075, Total Loss: 1.0701, LR: 0.003326
2025-04-26 16:48:35,140 [INFO] Epoch 15/15 - Policy Loss: 0.8618, Value Loss: 0.2074, Total Loss: 1.0692, LR: 0.004976
2025-04-26 16:48:35,162 [INFO] 训练完成，总损失: 1.0692
2025-04-26 16:48:35,162 [INFO] 保存迭代 189 的模型
2025-04-26 16:48:35,744 [INFO] Model saved to ./models/best.pt
2025-04-26 16:48:36,146 [INFO] Model saved to ./models/iteration_189.pt
2025-04-26 16:48:36,147 [INFO] 所有训练迭代完成
2025-04-26 16:48:36,147 [INFO] 开始迭代 190/300
2025-04-26 16:48:36,147 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 16:57:35,160 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 16:57:35,160 [INFO] 保存训练样本
2025-04-26 16:57:39,456 [INFO] 使用 140448 个样本训练神经网络
2025-04-26 16:57:39,456 [INFO] Training with 140448 examples
2025-04-26 16:57:39,456 [INFO] 总训练步数: 1020, 每轮次批次数: 68
2025-04-26 16:57:39,527 [INFO] 循环学习率周期大小: 204 步
2025-04-26 16:58:06,286 [INFO] Epoch 1/15 - Policy Loss: 0.8984, Value Loss: 0.2406, Total Loss: 1.1390, LR: 0.001676
2025-04-26 16:58:32,973 [INFO] Epoch 2/15 - Policy Loss: 0.8923, Value Loss: 0.2356, Total Loss: 1.1279, LR: 0.003326
2025-04-26 16:58:59,811 [INFO] Epoch 3/15 - Policy Loss: 0.8886, Value Loss: 0.2312, Total Loss: 1.1199, LR: 0.004976
2025-04-26 16:59:26,661 [INFO] Epoch 4/15 - Policy Loss: 0.8854, Value Loss: 0.2294, Total Loss: 1.1148, LR: 0.003374
2025-04-26 16:59:53,227 [INFO] Epoch 5/15 - Policy Loss: 0.8812, Value Loss: 0.2274, Total Loss: 1.1086, LR: 0.001724
2025-04-26 17:00:20,086 [INFO] Epoch 6/15 - Policy Loss: 0.8778, Value Loss: 0.2255, Total Loss: 1.1033, LR: 0.000074
2025-04-26 17:00:47,264 [INFO] Epoch 7/15 - Policy Loss: 0.8747, Value Loss: 0.2238, Total Loss: 1.0985, LR: 0.001676
2025-04-26 17:01:14,014 [INFO] Epoch 8/15 - Policy Loss: 0.8720, Value Loss: 0.2230, Total Loss: 1.0949, LR: 0.003326
2025-04-26 17:01:40,680 [INFO] Epoch 9/15 - Policy Loss: 0.8701, Value Loss: 0.2223, Total Loss: 1.0924, LR: 0.004976
2025-04-26 17:02:07,402 [INFO] Epoch 10/15 - Policy Loss: 0.8686, Value Loss: 0.2216, Total Loss: 1.0901, LR: 0.003374
2025-04-26 17:02:34,039 [INFO] Epoch 11/15 - Policy Loss: 0.8675, Value Loss: 0.2208, Total Loss: 1.0882, LR: 0.001724
2025-04-26 17:03:00,749 [INFO] Epoch 12/15 - Policy Loss: 0.8660, Value Loss: 0.2202, Total Loss: 1.0862, LR: 0.000074
2025-04-26 17:03:32,878 [INFO] Epoch 13/15 - Policy Loss: 0.8648, Value Loss: 0.2195, Total Loss: 1.0844, LR: 0.001676
2025-04-26 17:03:59,931 [INFO] Epoch 14/15 - Policy Loss: 0.8636, Value Loss: 0.2188, Total Loss: 1.0824, LR: 0.003326
2025-04-26 17:04:26,676 [INFO] Epoch 15/15 - Policy Loss: 0.8626, Value Loss: 0.2184, Total Loss: 1.0810, LR: 0.004976
2025-04-26 17:04:26,696 [INFO] 训练完成，总损失: 1.0810
2025-04-26 17:04:26,696 [INFO] 保存迭代 190 的模型
2025-04-26 17:04:27,297 [INFO] Model saved to ./models/best.pt
2025-04-26 17:04:27,756 [INFO] Model saved to ./models/iteration_190.pt
2025-04-26 17:04:27,757 [INFO] 所有训练迭代完成
2025-04-26 17:04:27,757 [INFO] 开始迭代 191/300
2025-04-26 17:04:27,757 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 17:16:07,721 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 17:16:07,725 [INFO] 保存训练样本
2025-04-26 17:16:14,248 [INFO] 使用 141200 个样本训练神经网络
2025-04-26 17:16:14,249 [INFO] Training with 141200 examples
2025-04-26 17:16:14,249 [INFO] 总训练步数: 1020, 每轮次批次数: 68
2025-04-26 17:16:14,356 [INFO] 循环学习率周期大小: 204 步
2025-04-26 17:17:12,433 [INFO] Epoch 1/15 - Policy Loss: 0.8938, Value Loss: 0.2496, Total Loss: 1.1434, LR: 0.001676
2025-04-26 17:18:02,694 [INFO] Epoch 2/15 - Policy Loss: 0.8913, Value Loss: 0.2449, Total Loss: 1.1363, LR: 0.003326
2025-04-26 17:18:59,161 [INFO] Epoch 3/15 - Policy Loss: 0.8877, Value Loss: 0.2421, Total Loss: 1.1298, LR: 0.004976
2025-04-26 17:19:50,909 [INFO] Epoch 4/15 - Policy Loss: 0.8829, Value Loss: 0.2398, Total Loss: 1.1228, LR: 0.003374
2025-04-26 17:20:47,200 [INFO] Epoch 5/15 - Policy Loss: 0.8794, Value Loss: 0.2381, Total Loss: 1.1175, LR: 0.001724
2025-04-26 17:21:39,427 [INFO] Epoch 6/15 - Policy Loss: 0.8760, Value Loss: 0.2362, Total Loss: 1.1122, LR: 0.000074
2025-04-26 17:22:33,488 [INFO] Epoch 7/15 - Policy Loss: 0.8729, Value Loss: 0.2346, Total Loss: 1.1075, LR: 0.001676
2025-04-26 17:23:28,348 [INFO] Epoch 8/15 - Policy Loss: 0.8707, Value Loss: 0.2330, Total Loss: 1.1037, LR: 0.003326
2025-04-26 17:24:19,697 [INFO] Epoch 9/15 - Policy Loss: 0.8692, Value Loss: 0.2320, Total Loss: 1.1012, LR: 0.004976
2025-04-26 17:25:16,917 [INFO] Epoch 10/15 - Policy Loss: 0.8682, Value Loss: 0.2311, Total Loss: 1.0993, LR: 0.003374
2025-04-26 17:26:05,947 [INFO] Epoch 11/15 - Policy Loss: 0.8664, Value Loss: 0.2300, Total Loss: 1.0964, LR: 0.001724
2025-04-26 17:27:03,810 [INFO] Epoch 12/15 - Policy Loss: 0.8650, Value Loss: 0.2293, Total Loss: 1.0943, LR: 0.000074
2025-04-26 17:27:53,684 [INFO] Epoch 13/15 - Policy Loss: 0.8637, Value Loss: 0.2284, Total Loss: 1.0921, LR: 0.001676
2025-04-26 17:28:51,663 [INFO] Epoch 14/15 - Policy Loss: 0.8624, Value Loss: 0.2278, Total Loss: 1.0901, LR: 0.003326
2025-04-26 17:29:40,422 [INFO] Epoch 15/15 - Policy Loss: 0.8615, Value Loss: 0.2275, Total Loss: 1.0890, LR: 0.004976
2025-04-26 17:29:40,446 [INFO] 训练完成，总损失: 1.0890
2025-04-26 17:29:40,446 [INFO] 保存迭代 191 的模型
2025-04-26 17:29:41,007 [INFO] Model saved to ./models/best.pt
2025-04-26 17:29:41,405 [INFO] Model saved to ./models/iteration_191.pt
2025-04-26 17:29:41,406 [INFO] 所有训练迭代完成
2025-04-26 17:29:41,406 [INFO] 开始迭代 192/300
2025-04-26 17:29:41,406 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 17:42:48,121 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 17:42:48,122 [INFO] 保存训练样本
2025-04-26 17:42:53,359 [INFO] 使用 143376 个样本训练神经网络
2025-04-26 17:42:53,359 [INFO] Training with 143376 examples
2025-04-26 17:42:53,360 [INFO] 总训练步数: 1050, 每轮次批次数: 70
2025-04-26 17:42:53,849 [INFO] 循环学习率周期大小: 210 步
2025-04-26 17:43:52,319 [INFO] Epoch 1/15 - Policy Loss: 0.8951, Value Loss: 0.2446, Total Loss: 1.1397, LR: 0.001676
2025-04-26 17:44:43,452 [INFO] Epoch 2/15 - Policy Loss: 0.8886, Value Loss: 0.2387, Total Loss: 1.1273, LR: 0.003326
2025-04-26 17:45:42,622 [INFO] Epoch 3/15 - Policy Loss: 0.8832, Value Loss: 0.2368, Total Loss: 1.1200, LR: 0.004976
2025-04-26 17:46:34,461 [INFO] Epoch 4/15 - Policy Loss: 0.8791, Value Loss: 0.2354, Total Loss: 1.1145, LR: 0.003374
2025-04-26 17:47:34,221 [INFO] Epoch 5/15 - Policy Loss: 0.8753, Value Loss: 0.2345, Total Loss: 1.1098, LR: 0.001724
2025-04-26 17:48:24,700 [INFO] Epoch 6/15 - Policy Loss: 0.8727, Value Loss: 0.2324, Total Loss: 1.1052, LR: 0.000074
2025-04-26 17:49:24,044 [INFO] Epoch 7/15 - Policy Loss: 0.8692, Value Loss: 0.2313, Total Loss: 1.1005, LR: 0.001676
2025-04-26 17:50:15,242 [INFO] Epoch 8/15 - Policy Loss: 0.8672, Value Loss: 0.2303, Total Loss: 1.0975, LR: 0.003326
2025-04-26 17:51:14,766 [INFO] Epoch 9/15 - Policy Loss: 0.8665, Value Loss: 0.2297, Total Loss: 1.0963, LR: 0.004976
2025-04-26 17:52:04,422 [INFO] Epoch 10/15 - Policy Loss: 0.8651, Value Loss: 0.2293, Total Loss: 1.0944, LR: 0.003374
2025-04-26 17:53:03,609 [INFO] Epoch 11/15 - Policy Loss: 0.8641, Value Loss: 0.2286, Total Loss: 1.0927, LR: 0.001724
2025-04-26 17:53:56,292 [INFO] Epoch 12/15 - Policy Loss: 0.8623, Value Loss: 0.2280, Total Loss: 1.0903, LR: 0.000074
2025-04-26 17:54:55,671 [INFO] Epoch 13/15 - Policy Loss: 0.8607, Value Loss: 0.2272, Total Loss: 1.0880, LR: 0.001676
2025-04-26 17:55:47,640 [INFO] Epoch 14/15 - Policy Loss: 0.8594, Value Loss: 0.2266, Total Loss: 1.0860, LR: 0.003326
2025-04-26 17:56:47,436 [INFO] Epoch 15/15 - Policy Loss: 0.8587, Value Loss: 0.2263, Total Loss: 1.0850, LR: 0.004976
2025-04-26 17:56:47,458 [INFO] 训练完成，总损失: 1.0850
2025-04-26 17:56:47,459 [INFO] 保存迭代 192 的模型
2025-04-26 17:56:47,914 [INFO] Model saved to ./models/best.pt
2025-04-26 17:56:48,225 [INFO] Model saved to ./models/iteration_192.pt
2025-04-26 17:56:48,225 [INFO] 所有训练迭代完成
2025-04-26 17:56:48,225 [INFO] 开始迭代 193/300
2025-04-26 17:56:48,225 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 18:12:09,604 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 18:12:09,605 [INFO] 保存训练样本
2025-04-26 18:12:13,977 [INFO] 使用 146456 个样本训练神经网络
2025-04-26 18:12:13,977 [INFO] Training with 146456 examples
2025-04-26 18:12:13,978 [INFO] 总训练步数: 1065, 每轮次批次数: 71
2025-04-26 18:12:14,429 [INFO] 循环学习率周期大小: 213 步
2025-04-26 18:13:14,445 [INFO] Epoch 1/15 - Policy Loss: 0.9065, Value Loss: 0.2651, Total Loss: 1.1716, LR: 0.001677
2025-04-26 18:14:08,238 [INFO] Epoch 2/15 - Policy Loss: 0.9001, Value Loss: 0.2597, Total Loss: 1.1597, LR: 0.003327
2025-04-26 18:15:08,591 [INFO] Epoch 3/15 - Policy Loss: 0.8968, Value Loss: 0.2561, Total Loss: 1.1529, LR: 0.004977
2025-04-26 18:16:00,931 [INFO] Epoch 4/15 - Policy Loss: 0.8917, Value Loss: 0.2527, Total Loss: 1.1444, LR: 0.003373
2025-04-26 18:17:00,271 [INFO] Epoch 5/15 - Policy Loss: 0.8876, Value Loss: 0.2499, Total Loss: 1.1375, LR: 0.001723
2025-04-26 18:17:54,653 [INFO] Epoch 6/15 - Policy Loss: 0.8837, Value Loss: 0.2473, Total Loss: 1.1310, LR: 0.000073
2025-04-26 18:18:55,372 [INFO] Epoch 7/15 - Policy Loss: 0.8804, Value Loss: 0.2450, Total Loss: 1.1254, LR: 0.001677
2025-04-26 18:19:47,787 [INFO] Epoch 8/15 - Policy Loss: 0.8773, Value Loss: 0.2435, Total Loss: 1.1207, LR: 0.003327
2025-04-26 18:20:48,163 [INFO] Epoch 9/15 - Policy Loss: 0.8746, Value Loss: 0.2421, Total Loss: 1.1167, LR: 0.004977
2025-04-26 18:21:41,160 [INFO] Epoch 10/15 - Policy Loss: 0.8724, Value Loss: 0.2411, Total Loss: 1.1135, LR: 0.003373
2025-04-26 18:22:40,105 [INFO] Epoch 11/15 - Policy Loss: 0.8710, Value Loss: 0.2399, Total Loss: 1.1109, LR: 0.001723
2025-04-26 18:23:35,970 [INFO] Epoch 12/15 - Policy Loss: 0.8690, Value Loss: 0.2388, Total Loss: 1.1078, LR: 0.000073
2025-04-26 18:24:32,050 [INFO] Epoch 13/15 - Policy Loss: 0.8672, Value Loss: 0.2378, Total Loss: 1.1050, LR: 0.001677
2025-04-26 18:25:30,464 [INFO] Epoch 14/15 - Policy Loss: 0.8656, Value Loss: 0.2369, Total Loss: 1.1025, LR: 0.003327
2025-04-26 18:26:23,097 [INFO] Epoch 15/15 - Policy Loss: 0.8643, Value Loss: 0.2362, Total Loss: 1.1006, LR: 0.004977
2025-04-26 18:26:23,140 [INFO] 训练完成，总损失: 1.1006
2025-04-26 18:26:23,140 [INFO] 保存迭代 193 的模型
2025-04-26 18:26:23,906 [INFO] Model saved to ./models/best.pt
2025-04-26 18:26:24,368 [INFO] Model saved to ./models/iteration_193.pt
2025-04-26 18:26:24,369 [INFO] 所有训练迭代完成
2025-04-26 18:26:24,369 [INFO] 开始迭代 194/300
2025-04-26 18:26:24,369 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 18:40:44,002 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 18:40:44,005 [INFO] 保存训练样本
2025-04-26 18:40:48,899 [INFO] 使用 148040 个样本训练神经网络
2025-04-26 18:40:48,899 [INFO] Training with 148040 examples
2025-04-26 18:40:48,900 [INFO] 总训练步数: 1080, 每轮次批次数: 72
2025-04-26 18:40:48,956 [INFO] 循环学习率周期大小: 216 步
2025-04-26 18:41:39,156 [INFO] Epoch 1/15 - Policy Loss: 0.8908, Value Loss: 0.2531, Total Loss: 1.1438, LR: 0.001677
2025-04-26 18:42:40,612 [INFO] Epoch 2/15 - Policy Loss: 0.8851, Value Loss: 0.2498, Total Loss: 1.1349, LR: 0.003327
2025-04-26 18:43:33,272 [INFO] Epoch 3/15 - Policy Loss: 0.8793, Value Loss: 0.2455, Total Loss: 1.1248, LR: 0.004977
2025-04-26 18:44:34,068 [INFO] Epoch 4/15 - Policy Loss: 0.8746, Value Loss: 0.2428, Total Loss: 1.1174, LR: 0.003373
2025-04-26 18:45:25,338 [INFO] Epoch 5/15 - Policy Loss: 0.8701, Value Loss: 0.2407, Total Loss: 1.1107, LR: 0.001723
2025-04-26 18:46:25,265 [INFO] Epoch 6/15 - Policy Loss: 0.8667, Value Loss: 0.2388, Total Loss: 1.1056, LR: 0.000073
2025-04-26 18:47:20,516 [INFO] Epoch 7/15 - Policy Loss: 0.8641, Value Loss: 0.2369, Total Loss: 1.1010, LR: 0.001677
2025-04-26 18:48:21,755 [INFO] Epoch 8/15 - Policy Loss: 0.8622, Value Loss: 0.2358, Total Loss: 1.0980, LR: 0.003327
2025-04-26 18:49:15,152 [INFO] Epoch 9/15 - Policy Loss: 0.8610, Value Loss: 0.2353, Total Loss: 1.0963, LR: 0.004977
2025-04-26 18:50:16,598 [INFO] Epoch 10/15 - Policy Loss: 0.8597, Value Loss: 0.2346, Total Loss: 1.0943, LR: 0.003373
2025-04-26 18:51:09,957 [INFO] Epoch 11/15 - Policy Loss: 0.8578, Value Loss: 0.2336, Total Loss: 1.0915, LR: 0.001723
2025-04-26 18:52:11,463 [INFO] Epoch 12/15 - Policy Loss: 0.8562, Value Loss: 0.2329, Total Loss: 1.0891, LR: 0.000073
2025-04-26 18:53:03,385 [INFO] Epoch 13/15 - Policy Loss: 0.8551, Value Loss: 0.2321, Total Loss: 1.0872, LR: 0.001677
2025-04-26 18:54:04,784 [INFO] Epoch 14/15 - Policy Loss: 0.8540, Value Loss: 0.2316, Total Loss: 1.0856, LR: 0.003327
2025-04-26 18:55:00,030 [INFO] Epoch 15/15 - Policy Loss: 0.8532, Value Loss: 0.2312, Total Loss: 1.0844, LR: 0.004977
2025-04-26 18:55:00,056 [INFO] 训练完成，总损失: 1.0844
2025-04-26 18:55:00,056 [INFO] 保存迭代 194 的模型
2025-04-26 18:55:00,600 [INFO] Model saved to ./models/best.pt
2025-04-26 18:55:00,892 [INFO] Model saved to ./models/iteration_194.pt
2025-04-26 18:55:00,892 [INFO] 所有训练迭代完成
2025-04-26 18:55:00,892 [INFO] 开始迭代 195/300
2025-04-26 18:55:00,892 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 19:09:12,346 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 19:09:12,347 [INFO] 保存训练样本
2025-04-26 19:09:17,387 [INFO] 使用 149632 个样本训练神经网络
2025-04-26 19:09:17,387 [INFO] Training with 149632 examples
2025-04-26 19:09:17,388 [INFO] 总训练步数: 1095, 每轮次批次数: 73
2025-04-26 19:09:17,462 [INFO] 循环学习率周期大小: 219 步
2025-04-26 19:10:09,444 [INFO] Epoch 1/15 - Policy Loss: 0.8798, Value Loss: 0.2655, Total Loss: 1.1453, LR: 0.001677
2025-04-26 19:11:10,269 [INFO] Epoch 2/15 - Policy Loss: 0.8736, Value Loss: 0.2590, Total Loss: 1.1326, LR: 0.003327
2025-04-26 19:12:04,359 [INFO] Epoch 3/15 - Policy Loss: 0.8706, Value Loss: 0.2542, Total Loss: 1.1248, LR: 0.004977
2025-04-26 19:13:03,242 [INFO] Epoch 4/15 - Policy Loss: 0.8671, Value Loss: 0.2513, Total Loss: 1.1184, LR: 0.003373
2025-04-26 19:14:03,957 [INFO] Epoch 5/15 - Policy Loss: 0.8636, Value Loss: 0.2490, Total Loss: 1.1125, LR: 0.001723
2025-04-26 19:15:05,854 [INFO] Epoch 6/15 - Policy Loss: 0.8600, Value Loss: 0.2467, Total Loss: 1.1067, LR: 0.000073
2025-04-26 19:16:07,380 [INFO] Epoch 7/15 - Policy Loss: 0.8575, Value Loss: 0.2448, Total Loss: 1.1023, LR: 0.001677
2025-04-26 19:17:08,479 [INFO] Epoch 8/15 - Policy Loss: 0.8559, Value Loss: 0.2438, Total Loss: 1.0996, LR: 0.003327
2025-04-26 19:18:10,115 [INFO] Epoch 9/15 - Policy Loss: 0.8541, Value Loss: 0.2427, Total Loss: 1.0969, LR: 0.004977
2025-04-26 19:19:03,623 [INFO] Epoch 10/15 - Policy Loss: 0.8529, Value Loss: 0.2419, Total Loss: 1.0948, LR: 0.003373
2025-04-26 19:20:05,610 [INFO] Epoch 11/15 - Policy Loss: 0.8515, Value Loss: 0.2412, Total Loss: 1.0927, LR: 0.001723
2025-04-26 19:21:00,732 [INFO] Epoch 12/15 - Policy Loss: 0.8499, Value Loss: 0.2403, Total Loss: 1.0902, LR: 0.000073
2025-04-26 19:22:02,383 [INFO] Epoch 13/15 - Policy Loss: 0.8483, Value Loss: 0.2397, Total Loss: 1.0879, LR: 0.001677
2025-04-26 19:23:03,979 [INFO] Epoch 14/15 - Policy Loss: 0.8477, Value Loss: 0.2390, Total Loss: 1.0867, LR: 0.003327
2025-04-26 19:24:04,703 [INFO] Epoch 15/15 - Policy Loss: 0.8467, Value Loss: 0.2384, Total Loss: 1.0851, LR: 0.004977
2025-04-26 19:24:04,724 [INFO] 训练完成，总损失: 1.0851
2025-04-26 19:24:04,724 [INFO] 保存迭代 195 的模型
2025-04-26 19:24:05,391 [INFO] Model saved to ./models/best.pt
2025-04-26 19:24:05,909 [INFO] Model saved to ./models/iteration_195.pt
2025-04-26 19:24:05,909 [INFO] 所有训练迭代完成
2025-04-26 19:24:05,909 [INFO] 开始迭代 196/300
2025-04-26 19:24:05,909 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 19:36:14,800 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 19:36:14,801 [INFO] 保存训练样本
2025-04-26 19:36:19,261 [INFO] 使用 150400 个样本训练神经网络
2025-04-26 19:36:19,261 [INFO] Training with 150400 examples
2025-04-26 19:36:19,261 [INFO] 总训练步数: 1095, 每轮次批次数: 73
2025-04-26 19:36:19,711 [INFO] 循环学习率周期大小: 219 步
2025-04-26 19:37:21,157 [INFO] Epoch 1/15 - Policy Loss: 0.8740, Value Loss: 0.2579, Total Loss: 1.1319, LR: 0.001677
2025-04-26 19:38:22,613 [INFO] Epoch 2/15 - Policy Loss: 0.8678, Value Loss: 0.2538, Total Loss: 1.1216, LR: 0.003327
2025-04-26 19:39:16,467 [INFO] Epoch 3/15 - Policy Loss: 0.8643, Value Loss: 0.2506, Total Loss: 1.1148, LR: 0.004977
2025-04-26 19:40:18,527 [INFO] Epoch 4/15 - Policy Loss: 0.8609, Value Loss: 0.2482, Total Loss: 1.1091, LR: 0.003373
2025-04-26 19:41:12,526 [INFO] Epoch 5/15 - Policy Loss: 0.8573, Value Loss: 0.2465, Total Loss: 1.1038, LR: 0.001723
2025-04-26 19:42:14,610 [INFO] Epoch 6/15 - Policy Loss: 0.8551, Value Loss: 0.2449, Total Loss: 1.0999, LR: 0.000073
2025-04-26 19:43:16,269 [INFO] Epoch 7/15 - Policy Loss: 0.8531, Value Loss: 0.2432, Total Loss: 1.0963, LR: 0.001677
2025-04-26 19:44:18,131 [INFO] Epoch 8/15 - Policy Loss: 0.8515, Value Loss: 0.2420, Total Loss: 1.0935, LR: 0.003327
2025-04-26 19:45:20,141 [INFO] Epoch 9/15 - Policy Loss: 0.8504, Value Loss: 0.2410, Total Loss: 1.0915, LR: 0.004977
2025-04-26 19:46:21,784 [INFO] Epoch 10/15 - Policy Loss: 0.8494, Value Loss: 0.2406, Total Loss: 1.0900, LR: 0.003373
2025-04-26 19:47:24,041 [INFO] Epoch 11/15 - Policy Loss: 0.8486, Value Loss: 0.2402, Total Loss: 1.0887, LR: 0.001723
2025-04-26 19:48:25,943 [INFO] Epoch 12/15 - Policy Loss: 0.8475, Value Loss: 0.2393, Total Loss: 1.0868, LR: 0.000073
2025-04-26 19:49:28,027 [INFO] Epoch 13/15 - Policy Loss: 0.8460, Value Loss: 0.2387, Total Loss: 1.0847, LR: 0.001677
2025-04-26 19:50:30,239 [INFO] Epoch 14/15 - Policy Loss: 0.8447, Value Loss: 0.2379, Total Loss: 1.0826, LR: 0.003327
2025-04-26 19:51:31,690 [INFO] Epoch 15/15 - Policy Loss: 0.8438, Value Loss: 0.2375, Total Loss: 1.0813, LR: 0.004977
2025-04-26 19:51:31,735 [INFO] 训练完成，总损失: 1.0813
2025-04-26 19:51:31,736 [INFO] 保存迭代 196 的模型
2025-04-26 19:51:32,369 [INFO] Model saved to ./models/best.pt
2025-04-26 19:51:32,813 [INFO] Model saved to ./models/iteration_196.pt
2025-04-26 19:51:32,814 [INFO] 所有训练迭代完成
2025-04-26 19:51:32,814 [INFO] 开始迭代 197/300
2025-04-26 19:51:32,814 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 20:04:55,527 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 20:04:55,528 [INFO] 保存训练样本
2025-04-26 20:05:00,220 [INFO] 使用 152392 个样本训练神经网络
2025-04-26 20:05:00,221 [INFO] Training with 152392 examples
2025-04-26 20:05:00,221 [INFO] 总训练步数: 1110, 每轮次批次数: 74
2025-04-26 20:05:00,621 [INFO] 循环学习率周期大小: 222 步
2025-04-26 20:05:55,549 [INFO] Epoch 1/15 - Policy Loss: 0.8847, Value Loss: 0.2754, Total Loss: 1.1600, LR: 0.001678
2025-04-26 20:06:58,316 [INFO] Epoch 2/15 - Policy Loss: 0.8812, Value Loss: 0.2677, Total Loss: 1.1488, LR: 0.003328
2025-04-26 20:07:53,024 [INFO] Epoch 3/15 - Policy Loss: 0.8768, Value Loss: 0.2637, Total Loss: 1.1404, LR: 0.004978
2025-04-26 20:08:55,721 [INFO] Epoch 4/15 - Policy Loss: 0.8716, Value Loss: 0.2599, Total Loss: 1.1315, LR: 0.003372
2025-04-26 20:09:49,996 [INFO] Epoch 5/15 - Policy Loss: 0.8667, Value Loss: 0.2575, Total Loss: 1.1242, LR: 0.001722
2025-04-26 20:10:53,184 [INFO] Epoch 6/15 - Policy Loss: 0.8629, Value Loss: 0.2555, Total Loss: 1.1184, LR: 0.000072
2025-04-26 20:11:55,669 [INFO] Epoch 7/15 - Policy Loss: 0.8595, Value Loss: 0.2539, Total Loss: 1.1134, LR: 0.001678
2025-04-26 20:12:49,602 [INFO] Epoch 8/15 - Policy Loss: 0.8573, Value Loss: 0.2525, Total Loss: 1.1098, LR: 0.003328
2025-04-26 20:13:50,863 [INFO] Epoch 9/15 - Policy Loss: 0.8557, Value Loss: 0.2516, Total Loss: 1.1074, LR: 0.004978
2025-04-26 20:14:52,647 [INFO] Epoch 10/15 - Policy Loss: 0.8548, Value Loss: 0.2510, Total Loss: 1.1058, LR: 0.003372
2025-04-26 20:15:43,260 [INFO] Epoch 11/15 - Policy Loss: 0.8534, Value Loss: 0.2501, Total Loss: 1.1035, LR: 0.001722
2025-04-26 20:16:29,013 [INFO] Epoch 12/15 - Policy Loss: 0.8519, Value Loss: 0.2494, Total Loss: 1.1013, LR: 0.000072
2025-04-26 20:17:13,460 [INFO] Epoch 13/15 - Policy Loss: 0.8504, Value Loss: 0.2486, Total Loss: 1.0990, LR: 0.001678
2025-04-26 20:17:53,629 [INFO] Epoch 14/15 - Policy Loss: 0.8494, Value Loss: 0.2481, Total Loss: 1.0975, LR: 0.003328
2025-04-26 20:18:37,224 [INFO] Epoch 15/15 - Policy Loss: 0.8486, Value Loss: 0.2476, Total Loss: 1.0962, LR: 0.004978
2025-04-26 20:18:37,262 [INFO] 训练完成，总损失: 1.0962
2025-04-26 20:18:37,262 [INFO] 保存迭代 197 的模型
2025-04-26 20:18:37,888 [INFO] Model saved to ./models/best.pt
2025-04-26 20:18:38,419 [INFO] Model saved to ./models/iteration_197.pt
2025-04-26 20:18:38,419 [INFO] 所有训练迭代完成
2025-04-26 20:18:38,420 [INFO] 开始迭代 198/300
2025-04-26 20:18:38,420 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 20:32:01,488 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 20:32:01,488 [INFO] 保存训练样本
2025-04-26 20:32:07,176 [INFO] 使用 153696 个样本训练神经网络
2025-04-26 20:32:07,176 [INFO] Training with 153696 examples
2025-04-26 20:32:07,177 [INFO] 总训练步数: 1125, 每轮次批次数: 75
2025-04-26 20:32:07,281 [INFO] 循环学习率周期大小: 225 步
2025-04-26 20:32:51,992 [INFO] Epoch 1/15 - Policy Loss: 0.8865, Value Loss: 0.2765, Total Loss: 1.1631, LR: 0.001678
2025-04-26 20:33:30,760 [INFO] Epoch 2/15 - Policy Loss: 0.8794, Value Loss: 0.2726, Total Loss: 1.1520, LR: 0.003328
2025-04-26 20:34:18,278 [INFO] Epoch 3/15 - Policy Loss: 0.8747, Value Loss: 0.2694, Total Loss: 1.1442, LR: 0.004978
2025-04-26 20:35:04,814 [INFO] Epoch 4/15 - Policy Loss: 0.8710, Value Loss: 0.2672, Total Loss: 1.1382, LR: 0.003372
2025-04-26 20:35:49,111 [INFO] Epoch 5/15 - Policy Loss: 0.8667, Value Loss: 0.2651, Total Loss: 1.1318, LR: 0.001722
2025-04-26 20:36:26,178 [INFO] Epoch 6/15 - Policy Loss: 0.8627, Value Loss: 0.2636, Total Loss: 1.1263, LR: 0.000072
2025-04-26 20:37:13,741 [INFO] Epoch 7/15 - Policy Loss: 0.8597, Value Loss: 0.2624, Total Loss: 1.1221, LR: 0.001678
2025-04-26 20:37:52,959 [INFO] Epoch 8/15 - Policy Loss: 0.8568, Value Loss: 0.2609, Total Loss: 1.1177, LR: 0.003328
2025-04-26 20:38:33,724 [INFO] Epoch 9/15 - Policy Loss: 0.8556, Value Loss: 0.2603, Total Loss: 1.1158, LR: 0.004978
2025-04-26 20:39:14,699 [INFO] Epoch 10/15 - Policy Loss: 0.8544, Value Loss: 0.2599, Total Loss: 1.1142, LR: 0.003372
2025-04-26 20:40:09,495 [INFO] Epoch 11/15 - Policy Loss: 0.8528, Value Loss: 0.2592, Total Loss: 1.1120, LR: 0.001722
2025-04-26 20:41:02,535 [INFO] Epoch 12/15 - Policy Loss: 0.8514, Value Loss: 0.2585, Total Loss: 1.1099, LR: 0.000072
2025-04-26 20:41:52,844 [INFO] Epoch 13/15 - Policy Loss: 0.8499, Value Loss: 0.2579, Total Loss: 1.1078, LR: 0.001678
2025-04-26 20:42:31,198 [INFO] Epoch 14/15 - Policy Loss: 0.8485, Value Loss: 0.2573, Total Loss: 1.1058, LR: 0.003328
2025-04-26 20:43:22,396 [INFO] Epoch 15/15 - Policy Loss: 0.8472, Value Loss: 0.2568, Total Loss: 1.1040, LR: 0.004978
2025-04-26 20:43:22,429 [INFO] 训练完成，总损失: 1.1040
2025-04-26 20:43:22,430 [INFO] 保存迭代 198 的模型
2025-04-26 20:43:23,248 [INFO] Model saved to ./models/best.pt
2025-04-26 20:43:23,665 [INFO] Model saved to ./models/iteration_198.pt
2025-04-26 20:43:23,665 [INFO] 所有训练迭代完成
2025-04-26 20:43:23,665 [INFO] 开始迭代 199/300
2025-04-26 20:43:23,665 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 20:55:26,166 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 20:55:26,166 [INFO] 保存训练样本
2025-04-26 20:55:30,736 [INFO] 使用 154112 个样本训练神经网络
2025-04-26 20:55:30,736 [INFO] Training with 154112 examples
2025-04-26 20:55:30,737 [INFO] 总训练步数: 1125, 每轮次批次数: 75
2025-04-26 20:55:30,816 [INFO] 循环学习率周期大小: 225 步
2025-04-26 20:56:12,721 [INFO] Epoch 1/15 - Policy Loss: 0.8716, Value Loss: 0.2776, Total Loss: 1.1491, LR: 0.001678
2025-04-26 20:56:57,031 [INFO] Epoch 2/15 - Policy Loss: 0.8651, Value Loss: 0.2721, Total Loss: 1.1372, LR: 0.003328
2025-04-26 20:57:40,856 [INFO] Epoch 3/15 - Policy Loss: 0.8620, Value Loss: 0.2679, Total Loss: 1.1299, LR: 0.004978
2025-04-26 20:58:21,997 [INFO] Epoch 4/15 - Policy Loss: 0.8604, Value Loss: 0.2653, Total Loss: 1.1257, LR: 0.003372
2025-04-26 20:59:03,464 [INFO] Epoch 5/15 - Policy Loss: 0.8576, Value Loss: 0.2632, Total Loss: 1.1208, LR: 0.001722
2025-04-26 20:59:50,940 [INFO] Epoch 6/15 - Policy Loss: 0.8546, Value Loss: 0.2615, Total Loss: 1.1161, LR: 0.000072
2025-04-26 21:00:32,136 [INFO] Epoch 7/15 - Policy Loss: 0.8524, Value Loss: 0.2600, Total Loss: 1.1124, LR: 0.001678
2025-04-26 21:01:21,879 [INFO] Epoch 8/15 - Policy Loss: 0.8507, Value Loss: 0.2590, Total Loss: 1.1097, LR: 0.003328
2025-04-26 21:02:01,912 [INFO] Epoch 9/15 - Policy Loss: 0.8495, Value Loss: 0.2583, Total Loss: 1.1079, LR: 0.004978
2025-04-26 21:02:48,796 [INFO] Epoch 10/15 - Policy Loss: 0.8484, Value Loss: 0.2575, Total Loss: 1.1059, LR: 0.003372
2025-04-26 21:03:32,116 [INFO] Epoch 11/15 - Policy Loss: 0.8467, Value Loss: 0.2567, Total Loss: 1.1034, LR: 0.001722
2025-04-26 21:04:12,109 [INFO] Epoch 12/15 - Policy Loss: 0.8451, Value Loss: 0.2561, Total Loss: 1.1013, LR: 0.000072
2025-04-26 21:04:53,221 [INFO] Epoch 13/15 - Policy Loss: 0.8438, Value Loss: 0.2554, Total Loss: 1.0992, LR: 0.001678
2025-04-26 21:05:49,712 [INFO] Epoch 14/15 - Policy Loss: 0.8428, Value Loss: 0.2549, Total Loss: 1.0977, LR: 0.003328
2025-04-26 21:06:37,485 [INFO] Epoch 15/15 - Policy Loss: 0.8419, Value Loss: 0.2545, Total Loss: 1.0964, LR: 0.004978
2025-04-26 21:06:37,512 [INFO] 训练完成，总损失: 1.0964
2025-04-26 21:06:37,512 [INFO] 保存迭代 199 的模型
2025-04-26 21:06:38,229 [INFO] Model saved to ./models/best.pt
2025-04-26 21:06:38,680 [INFO] Model saved to ./models/iteration_199.pt
2025-04-26 21:06:38,681 [INFO] 所有训练迭代完成
2025-04-26 21:06:38,681 [INFO] 开始迭代 200/300
2025-04-26 21:06:38,681 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 21:18:52,353 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 21:18:52,354 [INFO] 保存训练样本
2025-04-26 21:18:58,144 [INFO] 使用 155520 个样本训练神经网络
2025-04-26 21:18:58,144 [INFO] Training with 155520 examples
2025-04-26 21:18:58,145 [INFO] 总训练步数: 1125, 每轮次批次数: 75
2025-04-26 21:18:58,552 [INFO] 循环学习率周期大小: 225 步
2025-04-26 21:19:48,958 [INFO] Epoch 1/15 - Policy Loss: 0.8802, Value Loss: 0.2842, Total Loss: 1.1644, LR: 0.001678
2025-04-26 21:20:25,413 [INFO] Epoch 2/15 - Policy Loss: 0.8741, Value Loss: 0.2777, Total Loss: 1.1518, LR: 0.003328
2025-04-26 21:21:09,696 [INFO] Epoch 3/15 - Policy Loss: 0.8679, Value Loss: 0.2742, Total Loss: 1.1421, LR: 0.004978
2025-04-26 21:21:56,284 [INFO] Epoch 4/15 - Policy Loss: 0.8649, Value Loss: 0.2718, Total Loss: 1.1367, LR: 0.003372
2025-04-26 21:22:40,783 [INFO] Epoch 5/15 - Policy Loss: 0.8615, Value Loss: 0.2691, Total Loss: 1.1306, LR: 0.001722
2025-04-26 21:23:25,831 [INFO] Epoch 6/15 - Policy Loss: 0.8582, Value Loss: 0.2663, Total Loss: 1.1245, LR: 0.000072
2025-04-26 21:24:16,309 [INFO] Epoch 7/15 - Policy Loss: 0.8551, Value Loss: 0.2644, Total Loss: 1.1195, LR: 0.001678
2025-04-26 21:25:06,173 [INFO] Epoch 8/15 - Policy Loss: 0.8531, Value Loss: 0.2627, Total Loss: 1.1158, LR: 0.003328
2025-04-26 21:26:09,757 [INFO] Epoch 9/15 - Policy Loss: 0.8514, Value Loss: 0.2619, Total Loss: 1.1133, LR: 0.004978
2025-04-26 21:26:50,090 [INFO] Epoch 10/15 - Policy Loss: 0.8503, Value Loss: 0.2615, Total Loss: 1.1118, LR: 0.003372
2025-04-26 21:27:42,729 [INFO] Epoch 11/15 - Policy Loss: 0.8495, Value Loss: 0.2611, Total Loss: 1.1106, LR: 0.001722
2025-04-26 21:28:25,621 [INFO] Epoch 12/15 - Policy Loss: 0.8481, Value Loss: 0.2604, Total Loss: 1.1084, LR: 0.000072
2025-04-26 21:29:14,593 [INFO] Epoch 13/15 - Policy Loss: 0.8469, Value Loss: 0.2594, Total Loss: 1.1064, LR: 0.001678
2025-04-26 21:29:59,452 [INFO] Epoch 14/15 - Policy Loss: 0.8457, Value Loss: 0.2587, Total Loss: 1.1044, LR: 0.003328
2025-04-26 21:30:35,968 [INFO] Epoch 15/15 - Policy Loss: 0.8446, Value Loss: 0.2583, Total Loss: 1.1029, LR: 0.004978
2025-04-26 21:30:36,012 [INFO] 训练完成，总损失: 1.1029
2025-04-26 21:30:36,013 [INFO] 保存迭代 200 的模型
2025-04-26 21:30:36,676 [INFO] Model saved to ./models/best.pt
2025-04-26 21:30:37,101 [INFO] Model saved to ./models/iteration_200.pt
2025-04-26 21:30:37,101 [INFO] 所有训练迭代完成
2025-04-26 21:30:37,101 [INFO] 开始迭代 201/300
2025-04-26 21:30:37,101 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 21:41:45,481 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 21:41:45,482 [INFO] 保存训练样本
2025-04-26 21:41:50,884 [INFO] 使用 156664 个样本训练神经网络
2025-04-26 21:41:50,885 [INFO] Training with 156664 examples
2025-04-26 21:41:50,885 [INFO] 总训练步数: 1140, 每轮次批次数: 76
2025-04-26 21:41:51,634 [INFO] 循环学习率周期大小: 228 步
2025-04-26 21:42:30,256 [INFO] Epoch 1/15 - Policy Loss: 0.8627, Value Loss: 0.2733, Total Loss: 1.1361, LR: 0.001678
2025-04-26 21:43:18,465 [INFO] Epoch 2/15 - Policy Loss: 0.8559, Value Loss: 0.2690, Total Loss: 1.1249, LR: 0.003328
2025-04-26 21:43:55,619 [INFO] Epoch 3/15 - Policy Loss: 0.8530, Value Loss: 0.2669, Total Loss: 1.1198, LR: 0.004978
2025-04-26 21:44:39,951 [INFO] Epoch 4/15 - Policy Loss: 0.8514, Value Loss: 0.2646, Total Loss: 1.1160, LR: 0.003372
2025-04-26 21:45:31,098 [INFO] Epoch 5/15 - Policy Loss: 0.8494, Value Loss: 0.2626, Total Loss: 1.1120, LR: 0.001722
2025-04-26 21:46:20,692 [INFO] Epoch 6/15 - Policy Loss: 0.8464, Value Loss: 0.2610, Total Loss: 1.1074, LR: 0.000072
2025-04-26 21:47:05,513 [INFO] Epoch 7/15 - Policy Loss: 0.8443, Value Loss: 0.2599, Total Loss: 1.1041, LR: 0.001678
2025-04-26 21:47:50,976 [INFO] Epoch 8/15 - Policy Loss: 0.8429, Value Loss: 0.2592, Total Loss: 1.1021, LR: 0.003328
2025-04-26 21:48:32,164 [INFO] Epoch 9/15 - Policy Loss: 0.8418, Value Loss: 0.2583, Total Loss: 1.1001, LR: 0.004978
2025-04-26 21:49:13,024 [INFO] Epoch 10/15 - Policy Loss: 0.8410, Value Loss: 0.2580, Total Loss: 1.0990, LR: 0.003372
2025-04-26 21:50:00,260 [INFO] Epoch 11/15 - Policy Loss: 0.8398, Value Loss: 0.2574, Total Loss: 1.0972, LR: 0.001722
2025-04-26 21:50:43,187 [INFO] Epoch 12/15 - Policy Loss: 0.8389, Value Loss: 0.2568, Total Loss: 1.0956, LR: 0.000072
2025-04-26 21:51:29,472 [INFO] Epoch 13/15 - Policy Loss: 0.8383, Value Loss: 0.2563, Total Loss: 1.0946, LR: 0.001678
2025-04-26 21:52:13,119 [INFO] Epoch 14/15 - Policy Loss: 0.8373, Value Loss: 0.2559, Total Loss: 1.0932, LR: 0.003328
2025-04-26 21:52:59,524 [INFO] Epoch 15/15 - Policy Loss: 0.8367, Value Loss: 0.2555, Total Loss: 1.0922, LR: 0.004978
2025-04-26 21:52:59,589 [INFO] 训练完成，总损失: 1.0922
2025-04-26 21:52:59,596 [INFO] 保存迭代 201 的模型
2025-04-26 21:53:00,411 [INFO] Model saved to ./models/best.pt
2025-04-26 21:53:00,776 [INFO] Model saved to ./models/iteration_201.pt
2025-04-26 21:53:00,776 [INFO] 所有训练迭代完成
2025-04-26 21:53:00,776 [INFO] 开始迭代 202/300
2025-04-26 21:53:00,776 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 22:05:03,567 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 22:05:03,568 [INFO] 保存训练样本
2025-04-26 22:05:08,545 [INFO] 使用 157984 个样本训练神经网络
2025-04-26 22:05:08,545 [INFO] Training with 157984 examples
2025-04-26 22:05:08,545 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-26 22:05:08,605 [INFO] 循环学习率周期大小: 231 步
2025-04-26 22:05:58,909 [INFO] Epoch 1/15 - Policy Loss: 0.8751, Value Loss: 0.2754, Total Loss: 1.1505, LR: 0.001679
2025-04-26 22:06:57,701 [INFO] Epoch 2/15 - Policy Loss: 0.8654, Value Loss: 0.2709, Total Loss: 1.1362, LR: 0.003329
2025-04-26 22:07:38,065 [INFO] Epoch 3/15 - Policy Loss: 0.8620, Value Loss: 0.2675, Total Loss: 1.1295, LR: 0.004979
2025-04-26 22:08:23,561 [INFO] Epoch 4/15 - Policy Loss: 0.8587, Value Loss: 0.2653, Total Loss: 1.1240, LR: 0.003371
2025-04-26 22:09:12,947 [INFO] Epoch 5/15 - Policy Loss: 0.8556, Value Loss: 0.2628, Total Loss: 1.1184, LR: 0.001721
2025-04-26 22:09:59,789 [INFO] Epoch 6/15 - Policy Loss: 0.8526, Value Loss: 0.2611, Total Loss: 1.1137, LR: 0.000071
2025-04-26 22:10:55,880 [INFO] Epoch 7/15 - Policy Loss: 0.8490, Value Loss: 0.2593, Total Loss: 1.1083, LR: 0.001679
2025-04-26 22:11:41,127 [INFO] Epoch 8/15 - Policy Loss: 0.8471, Value Loss: 0.2583, Total Loss: 1.1054, LR: 0.003329
2025-04-26 22:12:23,639 [INFO] Epoch 9/15 - Policy Loss: 0.8460, Value Loss: 0.2576, Total Loss: 1.1037, LR: 0.004979
2025-04-26 22:13:11,410 [INFO] Epoch 10/15 - Policy Loss: 0.8458, Value Loss: 0.2574, Total Loss: 1.1032, LR: 0.003371
2025-04-26 22:13:52,306 [INFO] Epoch 11/15 - Policy Loss: 0.8446, Value Loss: 0.2569, Total Loss: 1.1015, LR: 0.001721
2025-04-26 22:14:43,417 [INFO] Epoch 12/15 - Policy Loss: 0.8432, Value Loss: 0.2562, Total Loss: 1.0994, LR: 0.000071
2025-04-26 22:15:28,361 [INFO] Epoch 13/15 - Policy Loss: 0.8419, Value Loss: 0.2555, Total Loss: 1.0974, LR: 0.001679
2025-04-26 22:16:18,835 [INFO] Epoch 14/15 - Policy Loss: 0.8410, Value Loss: 0.2548, Total Loss: 1.0958, LR: 0.003329
2025-04-26 22:17:05,065 [INFO] Epoch 15/15 - Policy Loss: 0.8399, Value Loss: 0.2541, Total Loss: 1.0940, LR: 0.004979
2025-04-26 22:17:05,120 [INFO] 训练完成，总损失: 1.0940
2025-04-26 22:17:05,120 [INFO] 保存迭代 202 的模型
2025-04-26 22:17:05,884 [INFO] Model saved to ./models/best.pt
2025-04-26 22:17:06,363 [INFO] Model saved to ./models/iteration_202.pt
2025-04-26 22:17:06,363 [INFO] 所有训练迭代完成
2025-04-26 22:17:06,363 [INFO] 开始迭代 203/300
2025-04-26 22:17:06,363 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 22:28:37,117 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 22:28:37,117 [INFO] 保存训练样本
2025-04-26 22:28:43,276 [INFO] 使用 159024 个样本训练神经网络
2025-04-26 22:28:43,277 [INFO] Training with 159024 examples
2025-04-26 22:28:43,277 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-26 22:28:43,746 [INFO] 循环学习率周期大小: 231 步
2025-04-26 22:29:24,227 [INFO] Epoch 1/15 - Policy Loss: 0.8767, Value Loss: 0.2814, Total Loss: 1.1580, LR: 0.001679
2025-04-26 22:30:09,619 [INFO] Epoch 2/15 - Policy Loss: 0.8665, Value Loss: 0.2764, Total Loss: 1.1429, LR: 0.003329
2025-04-26 22:30:49,979 [INFO] Epoch 3/15 - Policy Loss: 0.8624, Value Loss: 0.2726, Total Loss: 1.1350, LR: 0.004979
2025-04-26 22:31:35,604 [INFO] Epoch 4/15 - Policy Loss: 0.8595, Value Loss: 0.2701, Total Loss: 1.1297, LR: 0.003371
2025-04-26 22:32:14,753 [INFO] Epoch 5/15 - Policy Loss: 0.8563, Value Loss: 0.2686, Total Loss: 1.1249, LR: 0.001721
2025-04-26 22:32:58,356 [INFO] Epoch 6/15 - Policy Loss: 0.8527, Value Loss: 0.2664, Total Loss: 1.1191, LR: 0.000071
2025-04-26 22:33:48,135 [INFO] Epoch 7/15 - Policy Loss: 0.8498, Value Loss: 0.2642, Total Loss: 1.1140, LR: 0.001679
2025-04-26 22:34:29,392 [INFO] Epoch 8/15 - Policy Loss: 0.8479, Value Loss: 0.2634, Total Loss: 1.1112, LR: 0.003329
2025-04-26 22:35:11,221 [INFO] Epoch 9/15 - Policy Loss: 0.8463, Value Loss: 0.2623, Total Loss: 1.1086, LR: 0.004979
2025-04-26 22:36:04,395 [INFO] Epoch 10/15 - Policy Loss: 0.8449, Value Loss: 0.2615, Total Loss: 1.1064, LR: 0.003371
2025-04-26 22:36:41,646 [INFO] Epoch 11/15 - Policy Loss: 0.8438, Value Loss: 0.2607, Total Loss: 1.1044, LR: 0.001721
2025-04-26 22:37:27,535 [INFO] Epoch 12/15 - Policy Loss: 0.8421, Value Loss: 0.2599, Total Loss: 1.1020, LR: 0.000071
2025-04-26 22:38:18,264 [INFO] Epoch 13/15 - Policy Loss: 0.8405, Value Loss: 0.2592, Total Loss: 1.0997, LR: 0.001679
2025-04-26 22:39:06,986 [INFO] Epoch 14/15 - Policy Loss: 0.8394, Value Loss: 0.2586, Total Loss: 1.0980, LR: 0.003329
2025-04-26 22:39:55,307 [INFO] Epoch 15/15 - Policy Loss: 0.8384, Value Loss: 0.2581, Total Loss: 1.0965, LR: 0.004979
2025-04-26 22:39:55,329 [INFO] 训练完成，总损失: 1.0965
2025-04-26 22:39:55,329 [INFO] 保存迭代 203 的模型
2025-04-26 22:39:55,799 [INFO] Model saved to ./models/best.pt
2025-04-26 22:39:56,144 [INFO] Model saved to ./models/iteration_203.pt
2025-04-26 22:39:56,145 [INFO] 所有训练迭代完成
2025-04-26 22:39:56,145 [INFO] 开始迭代 204/300
2025-04-26 22:39:56,145 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 22:51:14,856 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 22:51:14,856 [INFO] 保存训练样本
2025-04-26 22:51:19,514 [INFO] 使用 159816 个样本训练神经网络
2025-04-26 22:51:19,515 [INFO] Training with 159816 examples
2025-04-26 22:51:19,515 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-26 22:51:20,083 [INFO] 循环学习率周期大小: 234 步
2025-04-26 22:52:14,572 [INFO] Epoch 1/15 - Policy Loss: 0.8651, Value Loss: 0.2749, Total Loss: 1.1400, LR: 0.001679
2025-04-26 22:52:58,879 [INFO] Epoch 2/15 - Policy Loss: 0.8596, Value Loss: 0.2701, Total Loss: 1.1297, LR: 0.003329
2025-04-26 22:53:37,612 [INFO] Epoch 3/15 - Policy Loss: 0.8580, Value Loss: 0.2693, Total Loss: 1.1273, LR: 0.004979
2025-04-26 22:54:27,003 [INFO] Epoch 4/15 - Policy Loss: 0.8567, Value Loss: 0.2681, Total Loss: 1.1248, LR: 0.003371
2025-04-26 22:55:18,387 [INFO] Epoch 5/15 - Policy Loss: 0.8522, Value Loss: 0.2662, Total Loss: 1.1184, LR: 0.001721
2025-04-26 22:56:05,654 [INFO] Epoch 6/15 - Policy Loss: 0.8502, Value Loss: 0.2647, Total Loss: 1.1150, LR: 0.000071
2025-04-26 22:56:51,073 [INFO] Epoch 7/15 - Policy Loss: 0.8481, Value Loss: 0.2634, Total Loss: 1.1115, LR: 0.001679
2025-04-26 22:57:31,869 [INFO] Epoch 8/15 - Policy Loss: 0.8462, Value Loss: 0.2628, Total Loss: 1.1090, LR: 0.003329
2025-04-26 22:58:19,460 [INFO] Epoch 9/15 - Policy Loss: 0.8447, Value Loss: 0.2621, Total Loss: 1.1067, LR: 0.004979
2025-04-26 22:59:10,980 [INFO] Epoch 10/15 - Policy Loss: 0.8438, Value Loss: 0.2618, Total Loss: 1.1057, LR: 0.003371
2025-04-26 22:59:58,948 [INFO] Epoch 11/15 - Policy Loss: 0.8435, Value Loss: 0.2613, Total Loss: 1.1048, LR: 0.001721
2025-04-26 23:00:48,824 [INFO] Epoch 12/15 - Policy Loss: 0.8420, Value Loss: 0.2609, Total Loss: 1.1029, LR: 0.000071
2025-04-26 23:01:27,683 [INFO] Epoch 13/15 - Policy Loss: 0.8405, Value Loss: 0.2602, Total Loss: 1.1007, LR: 0.001679
2025-04-26 23:02:24,228 [INFO] Epoch 14/15 - Policy Loss: 0.8396, Value Loss: 0.2600, Total Loss: 1.0997, LR: 0.003329
2025-04-26 23:03:19,655 [INFO] Epoch 15/15 - Policy Loss: 0.8389, Value Loss: 0.2597, Total Loss: 1.0986, LR: 0.004979
2025-04-26 23:03:19,692 [INFO] 训练完成，总损失: 1.0986
2025-04-26 23:03:19,693 [INFO] 保存迭代 204 的模型
2025-04-26 23:03:20,372 [INFO] Model saved to ./models/best.pt
2025-04-26 23:03:20,788 [INFO] Model saved to ./models/iteration_204.pt
2025-04-26 23:03:20,789 [INFO] 所有训练迭代完成
2025-04-26 23:03:20,789 [INFO] 开始迭代 205/300
2025-04-26 23:03:20,789 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 23:13:45,959 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 23:13:45,960 [INFO] 保存训练样本
2025-04-26 23:13:50,189 [INFO] 使用 159272 个样本训练神经网络
2025-04-26 23:13:50,189 [INFO] Training with 159272 examples
2025-04-26 23:13:50,189 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-26 23:13:50,643 [INFO] 循环学习率周期大小: 231 步
2025-04-26 23:14:33,071 [INFO] Epoch 1/15 - Policy Loss: 0.8681, Value Loss: 0.2705, Total Loss: 1.1386, LR: 0.001679
2025-04-26 23:15:18,435 [INFO] Epoch 2/15 - Policy Loss: 0.8712, Value Loss: 0.2663, Total Loss: 1.1374, LR: 0.003329
2025-04-26 23:15:59,747 [INFO] Epoch 3/15 - Policy Loss: 0.8662, Value Loss: 0.2638, Total Loss: 1.1300, LR: 0.004979
2025-04-26 23:16:45,256 [INFO] Epoch 4/15 - Policy Loss: 0.8640, Value Loss: 0.2623, Total Loss: 1.1264, LR: 0.003371
2025-04-26 23:17:25,619 [INFO] Epoch 5/15 - Policy Loss: 0.8625, Value Loss: 0.2614, Total Loss: 1.1239, LR: 0.001721
2025-04-26 23:18:10,463 [INFO] Epoch 6/15 - Policy Loss: 0.8594, Value Loss: 0.2598, Total Loss: 1.1192, LR: 0.000071
2025-04-26 23:18:53,349 [INFO] Epoch 7/15 - Policy Loss: 0.8572, Value Loss: 0.2584, Total Loss: 1.1156, LR: 0.001679
2025-04-26 23:19:42,384 [INFO] Epoch 8/15 - Policy Loss: 0.8549, Value Loss: 0.2574, Total Loss: 1.1123, LR: 0.003329
2025-04-26 23:20:25,335 [INFO] Epoch 9/15 - Policy Loss: 0.8541, Value Loss: 0.2569, Total Loss: 1.1109, LR: 0.004979
2025-04-26 23:21:10,367 [INFO] Epoch 10/15 - Policy Loss: 0.8526, Value Loss: 0.2563, Total Loss: 1.1089, LR: 0.003371
2025-04-26 23:21:53,677 [INFO] Epoch 11/15 - Policy Loss: 0.8511, Value Loss: 0.2555, Total Loss: 1.1066, LR: 0.001721
2025-04-26 23:22:39,734 [INFO] Epoch 12/15 - Policy Loss: 0.8494, Value Loss: 0.2549, Total Loss: 1.1042, LR: 0.000071
2025-04-26 23:23:29,090 [INFO] Epoch 13/15 - Policy Loss: 0.8483, Value Loss: 0.2543, Total Loss: 1.1026, LR: 0.001679
2025-04-26 23:24:12,941 [INFO] Epoch 14/15 - Policy Loss: 0.8471, Value Loss: 0.2540, Total Loss: 1.1011, LR: 0.003329
2025-04-26 23:24:54,620 [INFO] Epoch 15/15 - Policy Loss: 0.8461, Value Loss: 0.2534, Total Loss: 1.0995, LR: 0.004979
2025-04-26 23:24:54,658 [INFO] 训练完成，总损失: 1.0995
2025-04-26 23:24:54,658 [INFO] 保存迭代 205 的模型
2025-04-26 23:24:55,321 [INFO] Model saved to ./models/best.pt
2025-04-26 23:24:55,728 [INFO] Model saved to ./models/iteration_205.pt
2025-04-26 23:24:55,728 [INFO] 所有训练迭代完成
2025-04-26 23:24:55,728 [INFO] 开始迭代 206/300
2025-04-26 23:24:55,728 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 23:35:55,284 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 23:35:55,285 [INFO] 保存训练样本
2025-04-26 23:36:01,810 [INFO] 使用 159296 个样本训练神经网络
2025-04-26 23:36:01,811 [INFO] Training with 159296 examples
2025-04-26 23:36:01,811 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-26 23:36:01,933 [INFO] 循环学习率周期大小: 231 步
2025-04-26 23:36:46,857 [INFO] Epoch 1/15 - Policy Loss: 0.8838, Value Loss: 0.2801, Total Loss: 1.1639, LR: 0.001679
2025-04-26 23:37:33,091 [INFO] Epoch 2/15 - Policy Loss: 0.8808, Value Loss: 0.2748, Total Loss: 1.1555, LR: 0.003329
2025-04-26 23:38:22,063 [INFO] Epoch 3/15 - Policy Loss: 0.8771, Value Loss: 0.2718, Total Loss: 1.1489, LR: 0.004979
2025-04-26 23:39:08,272 [INFO] Epoch 4/15 - Policy Loss: 0.8739, Value Loss: 0.2692, Total Loss: 1.1431, LR: 0.003371
2025-04-26 23:39:54,952 [INFO] Epoch 5/15 - Policy Loss: 0.8706, Value Loss: 0.2667, Total Loss: 1.1372, LR: 0.001721
2025-04-26 23:40:35,380 [INFO] Epoch 6/15 - Policy Loss: 0.8665, Value Loss: 0.2643, Total Loss: 1.1308, LR: 0.000071
2025-04-26 23:41:22,433 [INFO] Epoch 7/15 - Policy Loss: 0.8638, Value Loss: 0.2629, Total Loss: 1.1267, LR: 0.001679
2025-04-26 23:42:07,534 [INFO] Epoch 8/15 - Policy Loss: 0.8616, Value Loss: 0.2617, Total Loss: 1.1233, LR: 0.003329
2025-04-26 23:42:53,461 [INFO] Epoch 9/15 - Policy Loss: 0.8599, Value Loss: 0.2608, Total Loss: 1.1207, LR: 0.004979
2025-04-26 23:43:41,115 [INFO] Epoch 10/15 - Policy Loss: 0.8590, Value Loss: 0.2603, Total Loss: 1.1193, LR: 0.003371
2025-04-26 23:44:24,696 [INFO] Epoch 11/15 - Policy Loss: 0.8579, Value Loss: 0.2595, Total Loss: 1.1174, LR: 0.001721
2025-04-26 23:45:05,324 [INFO] Epoch 12/15 - Policy Loss: 0.8564, Value Loss: 0.2587, Total Loss: 1.1151, LR: 0.000071
2025-04-26 23:45:50,428 [INFO] Epoch 13/15 - Policy Loss: 0.8553, Value Loss: 0.2579, Total Loss: 1.1132, LR: 0.001679
2025-04-26 23:46:30,120 [INFO] Epoch 14/15 - Policy Loss: 0.8539, Value Loss: 0.2574, Total Loss: 1.1112, LR: 0.003329
2025-04-26 23:47:16,769 [INFO] Epoch 15/15 - Policy Loss: 0.8530, Value Loss: 0.2569, Total Loss: 1.1099, LR: 0.004979
2025-04-26 23:47:16,809 [INFO] 训练完成，总损失: 1.1099
2025-04-26 23:47:16,809 [INFO] 保存迭代 206 的模型
2025-04-26 23:47:17,705 [INFO] Model saved to ./models/best.pt
2025-04-26 23:47:18,264 [INFO] Model saved to ./models/iteration_206.pt
2025-04-26 23:47:18,265 [INFO] 所有训练迭代完成
2025-04-26 23:47:18,265 [INFO] 开始迭代 207/300
2025-04-26 23:47:18,265 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-26 23:59:06,142 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-26 23:59:06,143 [INFO] 保存训练样本
2025-04-26 23:59:10,933 [INFO] 使用 159584 个样本训练神经网络
2025-04-26 23:59:10,933 [INFO] Training with 159584 examples
2025-04-26 23:59:10,934 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-26 23:59:11,568 [INFO] 循环学习率周期大小: 231 步
2025-04-26 23:59:50,529 [INFO] Epoch 1/15 - Policy Loss: 0.8967, Value Loss: 0.2640, Total Loss: 1.1608, LR: 0.001679
2025-04-27 00:00:32,074 [INFO] Epoch 2/15 - Policy Loss: 0.8910, Value Loss: 0.2620, Total Loss: 1.1530, LR: 0.003329
2025-04-27 00:01:17,284 [INFO] Epoch 3/15 - Policy Loss: 0.8876, Value Loss: 0.2601, Total Loss: 1.1478, LR: 0.004979
2025-04-27 00:01:58,060 [INFO] Epoch 4/15 - Policy Loss: 0.8843, Value Loss: 0.2581, Total Loss: 1.1424, LR: 0.003371
2025-04-27 00:02:46,612 [INFO] Epoch 5/15 - Policy Loss: 0.8817, Value Loss: 0.2566, Total Loss: 1.1383, LR: 0.001721
2025-04-27 00:03:29,674 [INFO] Epoch 6/15 - Policy Loss: 0.8780, Value Loss: 0.2550, Total Loss: 1.1330, LR: 0.000071
2025-04-27 00:04:10,599 [INFO] Epoch 7/15 - Policy Loss: 0.8747, Value Loss: 0.2531, Total Loss: 1.1278, LR: 0.001679
2025-04-27 00:04:56,003 [INFO] Epoch 8/15 - Policy Loss: 0.8723, Value Loss: 0.2517, Total Loss: 1.1240, LR: 0.003329
2025-04-27 00:05:36,751 [INFO] Epoch 9/15 - Policy Loss: 0.8705, Value Loss: 0.2509, Total Loss: 1.1214, LR: 0.004979
2025-04-27 00:06:24,649 [INFO] Epoch 10/15 - Policy Loss: 0.8691, Value Loss: 0.2502, Total Loss: 1.1193, LR: 0.003371
2025-04-27 00:07:18,750 [INFO] Epoch 11/15 - Policy Loss: 0.8676, Value Loss: 0.2496, Total Loss: 1.1172, LR: 0.001721
2025-04-27 00:08:04,335 [INFO] Epoch 12/15 - Policy Loss: 0.8661, Value Loss: 0.2486, Total Loss: 1.1147, LR: 0.000071
2025-04-27 00:08:56,244 [INFO] Epoch 13/15 - Policy Loss: 0.8649, Value Loss: 0.2481, Total Loss: 1.1130, LR: 0.001679
2025-04-27 00:09:46,403 [INFO] Epoch 14/15 - Policy Loss: 0.8638, Value Loss: 0.2473, Total Loss: 1.1111, LR: 0.003329
2025-04-27 00:10:33,485 [INFO] Epoch 15/15 - Policy Loss: 0.8628, Value Loss: 0.2468, Total Loss: 1.1096, LR: 0.004979
2025-04-27 00:10:33,531 [INFO] 训练完成，总损失: 1.1096
2025-04-27 00:10:33,531 [INFO] 保存迭代 207 的模型
2025-04-27 00:10:34,234 [INFO] Model saved to ./models/best.pt
2025-04-27 00:10:34,759 [INFO] Model saved to ./models/iteration_207.pt
2025-04-27 00:10:34,759 [INFO] 所有训练迭代完成
2025-04-27 00:10:34,760 [INFO] 开始迭代 208/300
2025-04-27 00:10:34,760 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 00:24:26,148 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 00:24:26,149 [INFO] 保存训练样本
2025-04-27 00:24:31,298 [INFO] 使用 160840 个样本训练神经网络
2025-04-27 00:24:31,298 [INFO] Training with 160840 examples
2025-04-27 00:24:31,299 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 00:24:31,783 [INFO] 循环学习率周期大小: 234 步
2025-04-27 00:25:12,780 [INFO] Epoch 1/15 - Policy Loss: 0.9025, Value Loss: 0.2581, Total Loss: 1.1606, LR: 0.001679
2025-04-27 00:26:03,667 [INFO] Epoch 2/15 - Policy Loss: 0.8977, Value Loss: 0.2529, Total Loss: 1.1507, LR: 0.003329
2025-04-27 00:26:46,016 [INFO] Epoch 3/15 - Policy Loss: 0.8957, Value Loss: 0.2521, Total Loss: 1.1477, LR: 0.004979
2025-04-27 00:27:35,751 [INFO] Epoch 4/15 - Policy Loss: 0.8920, Value Loss: 0.2508, Total Loss: 1.1428, LR: 0.003371
2025-04-27 00:28:24,839 [INFO] Epoch 5/15 - Policy Loss: 0.8882, Value Loss: 0.2493, Total Loss: 1.1375, LR: 0.001721
2025-04-27 00:29:14,095 [INFO] Epoch 6/15 - Policy Loss: 0.8845, Value Loss: 0.2479, Total Loss: 1.1324, LR: 0.000071
2025-04-27 00:29:56,093 [INFO] Epoch 7/15 - Policy Loss: 0.8815, Value Loss: 0.2470, Total Loss: 1.1284, LR: 0.001679
2025-04-27 00:30:47,081 [INFO] Epoch 8/15 - Policy Loss: 0.8787, Value Loss: 0.2456, Total Loss: 1.1243, LR: 0.003329
2025-04-27 00:31:35,588 [INFO] Epoch 9/15 - Policy Loss: 0.8766, Value Loss: 0.2450, Total Loss: 1.1216, LR: 0.004979
2025-04-27 00:32:23,684 [INFO] Epoch 10/15 - Policy Loss: 0.8752, Value Loss: 0.2446, Total Loss: 1.1198, LR: 0.003371
2025-04-27 00:33:11,257 [INFO] Epoch 11/15 - Policy Loss: 0.8733, Value Loss: 0.2440, Total Loss: 1.1174, LR: 0.001721
2025-04-27 00:34:02,887 [INFO] Epoch 12/15 - Policy Loss: 0.8721, Value Loss: 0.2435, Total Loss: 1.1156, LR: 0.000071
2025-04-27 00:34:46,283 [INFO] Epoch 13/15 - Policy Loss: 0.8704, Value Loss: 0.2427, Total Loss: 1.1132, LR: 0.001679
2025-04-27 00:35:31,712 [INFO] Epoch 14/15 - Policy Loss: 0.8687, Value Loss: 0.2422, Total Loss: 1.1109, LR: 0.003329
2025-04-27 00:36:12,887 [INFO] Epoch 15/15 - Policy Loss: 0.8677, Value Loss: 0.2418, Total Loss: 1.1095, LR: 0.004979
2025-04-27 00:36:12,924 [INFO] 训练完成，总损失: 1.1095
2025-04-27 00:36:12,924 [INFO] 保存迭代 208 的模型
2025-04-27 00:36:13,582 [INFO] Model saved to ./models/best.pt
2025-04-27 00:36:13,988 [INFO] Model saved to ./models/iteration_208.pt
2025-04-27 00:36:13,988 [INFO] 所有训练迭代完成
2025-04-27 00:36:13,988 [INFO] 开始迭代 209/300
2025-04-27 00:36:13,988 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 00:48:02,626 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 00:48:02,626 [INFO] 保存训练样本
2025-04-27 00:48:08,309 [INFO] 使用 160640 个样本训练神经网络
2025-04-27 00:48:08,309 [INFO] Training with 160640 examples
2025-04-27 00:48:08,311 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 00:48:08,373 [INFO] 循环学习率周期大小: 234 步
2025-04-27 00:48:56,646 [INFO] Epoch 1/15 - Policy Loss: 0.9000, Value Loss: 0.2600, Total Loss: 1.1600, LR: 0.001679
2025-04-27 00:49:43,339 [INFO] Epoch 2/15 - Policy Loss: 0.8946, Value Loss: 0.2551, Total Loss: 1.1498, LR: 0.003329
2025-04-27 00:50:29,747 [INFO] Epoch 3/15 - Policy Loss: 0.8916, Value Loss: 0.2518, Total Loss: 1.1434, LR: 0.004979
2025-04-27 00:51:10,752 [INFO] Epoch 4/15 - Policy Loss: 0.8877, Value Loss: 0.2508, Total Loss: 1.1385, LR: 0.003371
2025-04-27 00:52:08,878 [INFO] Epoch 5/15 - Policy Loss: 0.8846, Value Loss: 0.2492, Total Loss: 1.1338, LR: 0.001721
2025-04-27 00:52:53,073 [INFO] Epoch 6/15 - Policy Loss: 0.8806, Value Loss: 0.2481, Total Loss: 1.1286, LR: 0.000071
2025-04-27 00:53:36,421 [INFO] Epoch 7/15 - Policy Loss: 0.8781, Value Loss: 0.2471, Total Loss: 1.1252, LR: 0.001679
2025-04-27 00:54:25,916 [INFO] Epoch 8/15 - Policy Loss: 0.8762, Value Loss: 0.2462, Total Loss: 1.1224, LR: 0.003329
2025-04-27 00:55:13,678 [INFO] Epoch 9/15 - Policy Loss: 0.8750, Value Loss: 0.2453, Total Loss: 1.1203, LR: 0.004979
2025-04-27 00:56:05,008 [INFO] Epoch 10/15 - Policy Loss: 0.8738, Value Loss: 0.2450, Total Loss: 1.1188, LR: 0.003371
2025-04-27 00:56:53,008 [INFO] Epoch 11/15 - Policy Loss: 0.8727, Value Loss: 0.2446, Total Loss: 1.1173, LR: 0.001721
2025-04-27 00:57:41,607 [INFO] Epoch 12/15 - Policy Loss: 0.8711, Value Loss: 0.2442, Total Loss: 1.1153, LR: 0.000071
2025-04-27 00:58:25,385 [INFO] Epoch 13/15 - Policy Loss: 0.8697, Value Loss: 0.2436, Total Loss: 1.1133, LR: 0.001679
2025-04-27 00:59:12,285 [INFO] Epoch 14/15 - Policy Loss: 0.8686, Value Loss: 0.2435, Total Loss: 1.1122, LR: 0.003329
2025-04-27 00:59:58,382 [INFO] Epoch 15/15 - Policy Loss: 0.8674, Value Loss: 0.2432, Total Loss: 1.1105, LR: 0.004979
2025-04-27 00:59:58,415 [INFO] 训练完成，总损失: 1.1105
2025-04-27 00:59:58,415 [INFO] 保存迭代 209 的模型
2025-04-27 00:59:58,968 [INFO] Model saved to ./models/best.pt
2025-04-27 00:59:59,370 [INFO] Model saved to ./models/iteration_209.pt
2025-04-27 00:59:59,371 [INFO] 所有训练迭代完成
2025-04-27 00:59:59,371 [INFO] 开始迭代 210/300
2025-04-27 00:59:59,371 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 01:11:29,197 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 01:11:29,198 [INFO] 保存训练样本
2025-04-27 01:11:35,278 [INFO] 使用 160840 个样本训练神经网络
2025-04-27 01:11:35,278 [INFO] Training with 160840 examples
2025-04-27 01:11:35,278 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 01:11:35,736 [INFO] 循环学习率周期大小: 234 步
2025-04-27 01:12:22,025 [INFO] Epoch 1/15 - Policy Loss: 0.8874, Value Loss: 0.2676, Total Loss: 1.1550, LR: 0.001679
2025-04-27 01:13:04,554 [INFO] Epoch 2/15 - Policy Loss: 0.8809, Value Loss: 0.2649, Total Loss: 1.1458, LR: 0.003329
2025-04-27 01:13:50,176 [INFO] Epoch 3/15 - Policy Loss: 0.8796, Value Loss: 0.2635, Total Loss: 1.1430, LR: 0.004979
2025-04-27 01:14:36,441 [INFO] Epoch 4/15 - Policy Loss: 0.8784, Value Loss: 0.2617, Total Loss: 1.1401, LR: 0.003371
2025-04-27 01:15:18,877 [INFO] Epoch 5/15 - Policy Loss: 0.8749, Value Loss: 0.2596, Total Loss: 1.1345, LR: 0.001721
2025-04-27 01:16:03,552 [INFO] Epoch 6/15 - Policy Loss: 0.8724, Value Loss: 0.2582, Total Loss: 1.1306, LR: 0.000071
2025-04-27 01:16:50,510 [INFO] Epoch 7/15 - Policy Loss: 0.8701, Value Loss: 0.2571, Total Loss: 1.1272, LR: 0.001679
2025-04-27 01:17:31,075 [INFO] Epoch 8/15 - Policy Loss: 0.8682, Value Loss: 0.2559, Total Loss: 1.1240, LR: 0.003329
2025-04-27 01:18:17,093 [INFO] Epoch 9/15 - Policy Loss: 0.8666, Value Loss: 0.2551, Total Loss: 1.1217, LR: 0.004979
2025-04-27 01:19:08,510 [INFO] Epoch 10/15 - Policy Loss: 0.8659, Value Loss: 0.2546, Total Loss: 1.1206, LR: 0.003371
2025-04-27 01:19:59,562 [INFO] Epoch 11/15 - Policy Loss: 0.8646, Value Loss: 0.2538, Total Loss: 1.1184, LR: 0.001721
2025-04-27 01:20:42,538 [INFO] Epoch 12/15 - Policy Loss: 0.8629, Value Loss: 0.2532, Total Loss: 1.1161, LR: 0.000071
2025-04-27 01:21:28,668 [INFO] Epoch 13/15 - Policy Loss: 0.8618, Value Loss: 0.2525, Total Loss: 1.1142, LR: 0.001679
2025-04-27 01:22:18,009 [INFO] Epoch 14/15 - Policy Loss: 0.8605, Value Loss: 0.2516, Total Loss: 1.1121, LR: 0.003329
2025-04-27 01:23:09,139 [INFO] Epoch 15/15 - Policy Loss: 0.8602, Value Loss: 0.2511, Total Loss: 1.1112, LR: 0.004979
2025-04-27 01:23:09,175 [INFO] 训练完成，总损失: 1.1112
2025-04-27 01:23:09,175 [INFO] 保存迭代 210 的模型
2025-04-27 01:23:09,783 [INFO] Model saved to ./models/best.pt
2025-04-27 01:23:10,319 [INFO] Model saved to ./models/iteration_210.pt
2025-04-27 01:23:10,319 [INFO] 所有训练迭代完成
2025-04-27 01:23:10,319 [INFO] 开始迭代 211/300
2025-04-27 01:23:10,320 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 01:35:48,025 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 01:35:48,026 [INFO] 保存训练样本
2025-04-27 01:35:54,248 [INFO] 使用 161712 个样本训练神经网络
2025-04-27 01:35:54,248 [INFO] Training with 161712 examples
2025-04-27 01:35:54,249 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 01:35:54,853 [INFO] 循环学习率周期大小: 234 步
2025-04-27 01:36:48,557 [INFO] Epoch 1/15 - Policy Loss: 0.8836, Value Loss: 0.2613, Total Loss: 1.1449, LR: 0.001679
2025-04-27 01:37:29,831 [INFO] Epoch 2/15 - Policy Loss: 0.8796, Value Loss: 0.2592, Total Loss: 1.1388, LR: 0.003329
2025-04-27 01:38:26,771 [INFO] Epoch 3/15 - Policy Loss: 0.8777, Value Loss: 0.2580, Total Loss: 1.1356, LR: 0.004979
2025-04-27 01:39:21,781 [INFO] Epoch 4/15 - Policy Loss: 0.8758, Value Loss: 0.2564, Total Loss: 1.1322, LR: 0.003371
2025-04-27 01:40:10,666 [INFO] Epoch 5/15 - Policy Loss: 0.8738, Value Loss: 0.2541, Total Loss: 1.1279, LR: 0.001721
2025-04-27 01:41:02,837 [INFO] Epoch 6/15 - Policy Loss: 0.8714, Value Loss: 0.2523, Total Loss: 1.1237, LR: 0.000071
2025-04-27 01:41:52,931 [INFO] Epoch 7/15 - Policy Loss: 0.8687, Value Loss: 0.2508, Total Loss: 1.1196, LR: 0.001679
2025-04-27 01:42:46,795 [INFO] Epoch 8/15 - Policy Loss: 0.8660, Value Loss: 0.2501, Total Loss: 1.1161, LR: 0.003329
2025-04-27 01:43:40,090 [INFO] Epoch 9/15 - Policy Loss: 0.8647, Value Loss: 0.2492, Total Loss: 1.1139, LR: 0.004979
2025-04-27 01:44:23,714 [INFO] Epoch 10/15 - Policy Loss: 0.8641, Value Loss: 0.2489, Total Loss: 1.1131, LR: 0.003371
2025-04-27 01:45:10,503 [INFO] Epoch 11/15 - Policy Loss: 0.8625, Value Loss: 0.2481, Total Loss: 1.1107, LR: 0.001721
2025-04-27 01:45:55,615 [INFO] Epoch 12/15 - Policy Loss: 0.8616, Value Loss: 0.2473, Total Loss: 1.1089, LR: 0.000071
2025-04-27 01:46:33,079 [INFO] Epoch 13/15 - Policy Loss: 0.8603, Value Loss: 0.2467, Total Loss: 1.1070, LR: 0.001679
2025-04-27 01:47:23,645 [INFO] Epoch 14/15 - Policy Loss: 0.8594, Value Loss: 0.2459, Total Loss: 1.1053, LR: 0.003329
2025-04-27 01:48:09,525 [INFO] Epoch 15/15 - Policy Loss: 0.8587, Value Loss: 0.2453, Total Loss: 1.1040, LR: 0.004979
2025-04-27 01:48:09,560 [INFO] 训练完成，总损失: 1.1040
2025-04-27 01:48:09,560 [INFO] 保存迭代 211 的模型
2025-04-27 01:48:10,211 [INFO] Model saved to ./models/best.pt
2025-04-27 01:48:10,607 [INFO] Model saved to ./models/iteration_211.pt
2025-04-27 01:48:10,607 [INFO] 所有训练迭代完成
2025-04-27 01:48:10,607 [INFO] 开始迭代 212/300
2025-04-27 01:48:10,608 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 02:01:18,366 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 02:01:18,366 [INFO] 保存训练样本
2025-04-27 02:01:24,270 [INFO] 使用 161872 个样本训练神经网络
2025-04-27 02:01:24,271 [INFO] Training with 161872 examples
2025-04-27 02:01:24,271 [INFO] 总训练步数: 1185, 每轮次批次数: 79
2025-04-27 02:01:24,365 [INFO] 循环学习率周期大小: 237 步
2025-04-27 02:02:13,886 [INFO] Epoch 1/15 - Policy Loss: 0.8923, Value Loss: 0.2634, Total Loss: 1.1557, LR: 0.001679
2025-04-27 02:03:02,437 [INFO] Epoch 2/15 - Policy Loss: 0.8872, Value Loss: 0.2630, Total Loss: 1.1502, LR: 0.003329
2025-04-27 02:03:53,421 [INFO] Epoch 3/15 - Policy Loss: 0.8815, Value Loss: 0.2609, Total Loss: 1.1424, LR: 0.004979
2025-04-27 02:04:35,115 [INFO] Epoch 4/15 - Policy Loss: 0.8773, Value Loss: 0.2591, Total Loss: 1.1364, LR: 0.003371
2025-04-27 02:05:14,999 [INFO] Epoch 5/15 - Policy Loss: 0.8733, Value Loss: 0.2573, Total Loss: 1.1306, LR: 0.001721
2025-04-27 02:05:54,443 [INFO] Epoch 6/15 - Policy Loss: 0.8702, Value Loss: 0.2561, Total Loss: 1.1263, LR: 0.000071
2025-04-27 02:06:35,995 [INFO] Epoch 7/15 - Policy Loss: 0.8672, Value Loss: 0.2554, Total Loss: 1.1225, LR: 0.001679
2025-04-27 02:07:26,839 [INFO] Epoch 8/15 - Policy Loss: 0.8647, Value Loss: 0.2540, Total Loss: 1.1188, LR: 0.003329
2025-04-27 02:08:14,506 [INFO] Epoch 9/15 - Policy Loss: 0.8638, Value Loss: 0.2534, Total Loss: 1.1172, LR: 0.004979
2025-04-27 02:08:56,053 [INFO] Epoch 10/15 - Policy Loss: 0.8630, Value Loss: 0.2529, Total Loss: 1.1159, LR: 0.003371
2025-04-27 02:09:45,604 [INFO] Epoch 11/15 - Policy Loss: 0.8620, Value Loss: 0.2523, Total Loss: 1.1143, LR: 0.001721
2025-04-27 02:10:36,797 [INFO] Epoch 12/15 - Policy Loss: 0.8605, Value Loss: 0.2515, Total Loss: 1.1120, LR: 0.000071
2025-04-27 02:11:16,336 [INFO] Epoch 13/15 - Policy Loss: 0.8593, Value Loss: 0.2507, Total Loss: 1.1100, LR: 0.001679
2025-04-27 02:11:57,850 [INFO] Epoch 14/15 - Policy Loss: 0.8580, Value Loss: 0.2502, Total Loss: 1.1082, LR: 0.003329
2025-04-27 02:12:44,061 [INFO] Epoch 15/15 - Policy Loss: 0.8574, Value Loss: 0.2501, Total Loss: 1.1075, LR: 0.004979
2025-04-27 02:12:44,096 [INFO] 训练完成，总损失: 1.1075
2025-04-27 02:12:44,096 [INFO] 保存迭代 212 的模型
2025-04-27 02:12:44,693 [INFO] Model saved to ./models/best.pt
2025-04-27 02:12:45,104 [INFO] Model saved to ./models/iteration_212.pt
2025-04-27 02:12:45,104 [INFO] 所有训练迭代完成
2025-04-27 02:12:45,104 [INFO] 开始迭代 213/300
2025-04-27 02:12:45,104 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 02:25:46,917 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 02:25:46,918 [INFO] 保存训练样本
2025-04-27 02:25:52,669 [INFO] 使用 160960 个样本训练神经网络
2025-04-27 02:25:52,669 [INFO] Training with 160960 examples
2025-04-27 02:25:52,670 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 02:25:53,408 [INFO] 循环学习率周期大小: 234 步
2025-04-27 02:26:34,383 [INFO] Epoch 1/15 - Policy Loss: 0.8983, Value Loss: 0.2606, Total Loss: 1.1589, LR: 0.001679
2025-04-27 02:27:22,456 [INFO] Epoch 2/15 - Policy Loss: 0.8898, Value Loss: 0.2549, Total Loss: 1.1447, LR: 0.003329
2025-04-27 02:28:06,672 [INFO] Epoch 3/15 - Policy Loss: 0.8849, Value Loss: 0.2531, Total Loss: 1.1380, LR: 0.004979
2025-04-27 02:28:52,039 [INFO] Epoch 4/15 - Policy Loss: 0.8805, Value Loss: 0.2521, Total Loss: 1.1326, LR: 0.003371
2025-04-27 02:29:37,707 [INFO] Epoch 5/15 - Policy Loss: 0.8771, Value Loss: 0.2509, Total Loss: 1.1280, LR: 0.001721
2025-04-27 02:30:24,532 [INFO] Epoch 6/15 - Policy Loss: 0.8731, Value Loss: 0.2493, Total Loss: 1.1225, LR: 0.000071
2025-04-27 02:31:05,254 [INFO] Epoch 7/15 - Policy Loss: 0.8706, Value Loss: 0.2479, Total Loss: 1.1185, LR: 0.001679
2025-04-27 02:31:50,729 [INFO] Epoch 8/15 - Policy Loss: 0.8688, Value Loss: 0.2465, Total Loss: 1.1153, LR: 0.003329
2025-04-27 02:32:27,809 [INFO] Epoch 9/15 - Policy Loss: 0.8670, Value Loss: 0.2461, Total Loss: 1.1131, LR: 0.004979
2025-04-27 02:33:13,987 [INFO] Epoch 10/15 - Policy Loss: 0.8661, Value Loss: 0.2457, Total Loss: 1.1117, LR: 0.003371
2025-04-27 02:33:54,879 [INFO] Epoch 11/15 - Policy Loss: 0.8645, Value Loss: 0.2453, Total Loss: 1.1098, LR: 0.001721
2025-04-27 02:34:40,522 [INFO] Epoch 12/15 - Policy Loss: 0.8630, Value Loss: 0.2448, Total Loss: 1.1078, LR: 0.000071
2025-04-27 02:35:37,002 [INFO] Epoch 13/15 - Policy Loss: 0.8616, Value Loss: 0.2443, Total Loss: 1.1059, LR: 0.001679
2025-04-27 02:36:22,979 [INFO] Epoch 14/15 - Policy Loss: 0.8604, Value Loss: 0.2437, Total Loss: 1.1041, LR: 0.003329
2025-04-27 02:37:09,712 [INFO] Epoch 15/15 - Policy Loss: 0.8599, Value Loss: 0.2435, Total Loss: 1.1033, LR: 0.004979
2025-04-27 02:37:09,743 [INFO] 训练完成，总损失: 1.1033
2025-04-27 02:37:09,743 [INFO] 保存迭代 213 的模型
2025-04-27 02:37:10,332 [INFO] Model saved to ./models/best.pt
2025-04-27 02:37:10,730 [INFO] Model saved to ./models/iteration_213.pt
2025-04-27 02:37:10,731 [INFO] 所有训练迭代完成
2025-04-27 02:37:10,731 [INFO] 开始迭代 214/300
2025-04-27 02:37:10,731 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 02:50:07,303 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 02:50:07,304 [INFO] 保存训练样本
2025-04-27 02:50:11,759 [INFO] 使用 161000 个样本训练神经网络
2025-04-27 02:50:11,759 [INFO] Training with 161000 examples
2025-04-27 02:50:11,760 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 02:50:12,225 [INFO] 循环学习率周期大小: 234 步
2025-04-27 02:50:59,491 [INFO] Epoch 1/15 - Policy Loss: 0.8921, Value Loss: 0.2626, Total Loss: 1.1547, LR: 0.001679
2025-04-27 02:51:46,593 [INFO] Epoch 2/15 - Policy Loss: 0.8838, Value Loss: 0.2614, Total Loss: 1.1452, LR: 0.003329
2025-04-27 02:52:32,654 [INFO] Epoch 3/15 - Policy Loss: 0.8815, Value Loss: 0.2601, Total Loss: 1.1416, LR: 0.004979
2025-04-27 02:53:19,469 [INFO] Epoch 4/15 - Policy Loss: 0.8779, Value Loss: 0.2587, Total Loss: 1.1366, LR: 0.003371
2025-04-27 02:54:14,611 [INFO] Epoch 5/15 - Policy Loss: 0.8748, Value Loss: 0.2572, Total Loss: 1.1320, LR: 0.001721
2025-04-27 02:55:12,704 [INFO] Epoch 6/15 - Policy Loss: 0.8718, Value Loss: 0.2555, Total Loss: 1.1273, LR: 0.000071
2025-04-27 02:55:53,643 [INFO] Epoch 7/15 - Policy Loss: 0.8690, Value Loss: 0.2540, Total Loss: 1.1230, LR: 0.001679
2025-04-27 02:56:38,257 [INFO] Epoch 8/15 - Policy Loss: 0.8669, Value Loss: 0.2527, Total Loss: 1.1196, LR: 0.003329
2025-04-27 02:57:28,511 [INFO] Epoch 9/15 - Policy Loss: 0.8655, Value Loss: 0.2520, Total Loss: 1.1175, LR: 0.004979
2025-04-27 02:58:25,352 [INFO] Epoch 10/15 - Policy Loss: 0.8644, Value Loss: 0.2516, Total Loss: 1.1159, LR: 0.003371
2025-04-27 02:59:12,552 [INFO] Epoch 11/15 - Policy Loss: 0.8633, Value Loss: 0.2508, Total Loss: 1.1141, LR: 0.001721
2025-04-27 03:00:08,037 [INFO] Epoch 12/15 - Policy Loss: 0.8616, Value Loss: 0.2498, Total Loss: 1.1114, LR: 0.000071
2025-04-27 03:01:07,767 [INFO] Epoch 13/15 - Policy Loss: 0.8604, Value Loss: 0.2493, Total Loss: 1.1097, LR: 0.001679
2025-04-27 03:01:53,740 [INFO] Epoch 14/15 - Policy Loss: 0.8594, Value Loss: 0.2487, Total Loss: 1.1081, LR: 0.003329
2025-04-27 03:02:45,419 [INFO] Epoch 15/15 - Policy Loss: 0.8585, Value Loss: 0.2482, Total Loss: 1.1067, LR: 0.004979
2025-04-27 03:02:45,472 [INFO] 训练完成，总损失: 1.1067
2025-04-27 03:02:45,472 [INFO] 保存迭代 214 的模型
2025-04-27 03:02:46,322 [INFO] Model saved to ./models/best.pt
2025-04-27 03:02:46,717 [INFO] Model saved to ./models/iteration_214.pt
2025-04-27 03:02:46,718 [INFO] 所有训练迭代完成
2025-04-27 03:02:46,719 [INFO] 开始迭代 215/300
2025-04-27 03:02:46,719 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 03:14:19,237 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 03:14:19,238 [INFO] 保存训练样本
2025-04-27 03:14:25,839 [INFO] 使用 159520 个样本训练神经网络
2025-04-27 03:14:25,840 [INFO] Training with 159520 examples
2025-04-27 03:14:25,840 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-27 03:14:25,947 [INFO] 循环学习率周期大小: 231 步
2025-04-27 03:15:11,554 [INFO] Epoch 1/15 - Policy Loss: 0.8926, Value Loss: 0.2597, Total Loss: 1.1524, LR: 0.001679
2025-04-27 03:16:02,430 [INFO] Epoch 2/15 - Policy Loss: 0.8849, Value Loss: 0.2562, Total Loss: 1.1411, LR: 0.003329
2025-04-27 03:17:02,181 [INFO] Epoch 3/15 - Policy Loss: 0.8816, Value Loss: 0.2543, Total Loss: 1.1359, LR: 0.004979
2025-04-27 03:17:48,752 [INFO] Epoch 4/15 - Policy Loss: 0.8785, Value Loss: 0.2533, Total Loss: 1.1318, LR: 0.003371
2025-04-27 03:18:33,149 [INFO] Epoch 5/15 - Policy Loss: 0.8768, Value Loss: 0.2527, Total Loss: 1.1295, LR: 0.001721
2025-04-27 03:19:20,842 [INFO] Epoch 6/15 - Policy Loss: 0.8751, Value Loss: 0.2514, Total Loss: 1.1265, LR: 0.000071
2025-04-27 03:20:12,559 [INFO] Epoch 7/15 - Policy Loss: 0.8718, Value Loss: 0.2504, Total Loss: 1.1222, LR: 0.001679
2025-04-27 03:21:16,777 [INFO] Epoch 8/15 - Policy Loss: 0.8703, Value Loss: 0.2495, Total Loss: 1.1197, LR: 0.003329
2025-04-27 03:22:02,895 [INFO] Epoch 9/15 - Policy Loss: 0.8689, Value Loss: 0.2490, Total Loss: 1.1180, LR: 0.004979
2025-04-27 03:22:47,198 [INFO] Epoch 10/15 - Policy Loss: 0.8683, Value Loss: 0.2485, Total Loss: 1.1169, LR: 0.003371
2025-04-27 03:23:27,937 [INFO] Epoch 11/15 - Policy Loss: 0.8669, Value Loss: 0.2481, Total Loss: 1.1150, LR: 0.001721
2025-04-27 03:24:10,816 [INFO] Epoch 12/15 - Policy Loss: 0.8657, Value Loss: 0.2475, Total Loss: 1.1132, LR: 0.000071
2025-04-27 03:25:00,238 [INFO] Epoch 13/15 - Policy Loss: 0.8643, Value Loss: 0.2469, Total Loss: 1.1112, LR: 0.001679
2025-04-27 03:25:47,658 [INFO] Epoch 14/15 - Policy Loss: 0.8636, Value Loss: 0.2467, Total Loss: 1.1102, LR: 0.003329
2025-04-27 03:26:39,738 [INFO] Epoch 15/15 - Policy Loss: 0.8631, Value Loss: 0.2464, Total Loss: 1.1096, LR: 0.004979
2025-04-27 03:26:39,767 [INFO] 训练完成，总损失: 1.1096
2025-04-27 03:26:39,767 [INFO] 保存迭代 215 的模型
2025-04-27 03:26:40,375 [INFO] Model saved to ./models/best.pt
2025-04-27 03:26:40,826 [INFO] Model saved to ./models/iteration_215.pt
2025-04-27 03:26:40,827 [INFO] 所有训练迭代完成
2025-04-27 03:26:40,827 [INFO] 开始迭代 216/300
2025-04-27 03:26:40,827 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 03:38:04,576 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 03:38:04,577 [INFO] 保存训练样本
2025-04-27 03:38:10,508 [INFO] 使用 159576 个样本训练神经网络
2025-04-27 03:38:10,508 [INFO] Training with 159576 examples
2025-04-27 03:38:10,509 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-27 03:38:10,607 [INFO] 循环学习率周期大小: 231 步
2025-04-27 03:38:59,674 [INFO] Epoch 1/15 - Policy Loss: 0.8855, Value Loss: 0.2586, Total Loss: 1.1441, LR: 0.001679
2025-04-27 03:39:53,988 [INFO] Epoch 2/15 - Policy Loss: 0.8810, Value Loss: 0.2550, Total Loss: 1.1360, LR: 0.003329
2025-04-27 03:40:25,051 [INFO] Epoch 3/15 - Policy Loss: 0.8789, Value Loss: 0.2527, Total Loss: 1.1316, LR: 0.004979
2025-04-27 03:41:05,451 [INFO] Epoch 4/15 - Policy Loss: 0.8767, Value Loss: 0.2520, Total Loss: 1.1286, LR: 0.003371
2025-04-27 03:41:52,226 [INFO] Epoch 5/15 - Policy Loss: 0.8737, Value Loss: 0.2509, Total Loss: 1.1245, LR: 0.001721
2025-04-27 03:42:40,623 [INFO] Epoch 6/15 - Policy Loss: 0.8720, Value Loss: 0.2494, Total Loss: 1.1215, LR: 0.000071
2025-04-27 03:43:23,465 [INFO] Epoch 7/15 - Policy Loss: 0.8699, Value Loss: 0.2478, Total Loss: 1.1177, LR: 0.001679
2025-04-27 03:44:09,031 [INFO] Epoch 8/15 - Policy Loss: 0.8680, Value Loss: 0.2473, Total Loss: 1.1154, LR: 0.003329
2025-04-27 03:44:54,559 [INFO] Epoch 9/15 - Policy Loss: 0.8674, Value Loss: 0.2469, Total Loss: 1.1143, LR: 0.004979
2025-04-27 03:45:40,718 [INFO] Epoch 10/15 - Policy Loss: 0.8673, Value Loss: 0.2469, Total Loss: 1.1142, LR: 0.003371
2025-04-27 03:46:18,119 [INFO] Epoch 11/15 - Policy Loss: 0.8660, Value Loss: 0.2467, Total Loss: 1.1126, LR: 0.001721
2025-04-27 03:46:58,897 [INFO] Epoch 12/15 - Policy Loss: 0.8644, Value Loss: 0.2460, Total Loss: 1.1104, LR: 0.000071
2025-04-27 03:47:46,975 [INFO] Epoch 13/15 - Policy Loss: 0.8634, Value Loss: 0.2453, Total Loss: 1.1087, LR: 0.001679
2025-04-27 03:48:34,204 [INFO] Epoch 14/15 - Policy Loss: 0.8625, Value Loss: 0.2449, Total Loss: 1.1074, LR: 0.003329
2025-04-27 03:49:10,788 [INFO] Epoch 15/15 - Policy Loss: 0.8623, Value Loss: 0.2448, Total Loss: 1.1070, LR: 0.004979
2025-04-27 03:49:10,867 [INFO] 训练完成，总损失: 1.1070
2025-04-27 03:49:10,867 [INFO] 保存迭代 216 的模型
2025-04-27 03:49:11,724 [INFO] Model saved to ./models/best.pt
2025-04-27 03:49:12,218 [INFO] Model saved to ./models/iteration_216.pt
2025-04-27 03:49:12,218 [INFO] 所有训练迭代完成
2025-04-27 03:49:12,219 [INFO] 开始迭代 217/300
2025-04-27 03:49:12,219 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 04:02:18,397 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 04:02:18,399 [INFO] 保存训练样本
2025-04-27 04:02:24,168 [INFO] 使用 159864 个样本训练神经网络
2025-04-27 04:02:24,169 [INFO] Training with 159864 examples
2025-04-27 04:02:24,169 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 04:02:24,845 [INFO] 循环学习率周期大小: 234 步
2025-04-27 04:03:05,780 [INFO] Epoch 1/15 - Policy Loss: 0.9231, Value Loss: 0.2480, Total Loss: 1.1711, LR: 0.001679
2025-04-27 04:03:55,991 [INFO] Epoch 2/15 - Policy Loss: 0.9150, Value Loss: 0.2451, Total Loss: 1.1601, LR: 0.003329
2025-04-27 04:04:32,188 [INFO] Epoch 3/15 - Policy Loss: 0.9087, Value Loss: 0.2441, Total Loss: 1.1527, LR: 0.004979
2025-04-27 04:05:25,417 [INFO] Epoch 4/15 - Policy Loss: 0.9037, Value Loss: 0.2421, Total Loss: 1.1458, LR: 0.003371
2025-04-27 04:06:12,217 [INFO] Epoch 5/15 - Policy Loss: 0.8984, Value Loss: 0.2409, Total Loss: 1.1392, LR: 0.001721
2025-04-27 04:06:51,731 [INFO] Epoch 6/15 - Policy Loss: 0.8941, Value Loss: 0.2395, Total Loss: 1.1336, LR: 0.000071
2025-04-27 04:07:43,288 [INFO] Epoch 7/15 - Policy Loss: 0.8912, Value Loss: 0.2386, Total Loss: 1.1298, LR: 0.001679
2025-04-27 04:08:25,284 [INFO] Epoch 8/15 - Policy Loss: 0.8883, Value Loss: 0.2378, Total Loss: 1.1261, LR: 0.003329
2025-04-27 04:09:14,033 [INFO] Epoch 9/15 - Policy Loss: 0.8855, Value Loss: 0.2369, Total Loss: 1.1225, LR: 0.004979
2025-04-27 04:10:06,188 [INFO] Epoch 10/15 - Policy Loss: 0.8841, Value Loss: 0.2366, Total Loss: 1.1208, LR: 0.003371
2025-04-27 04:10:54,206 [INFO] Epoch 11/15 - Policy Loss: 0.8826, Value Loss: 0.2361, Total Loss: 1.1187, LR: 0.001721
2025-04-27 04:11:39,884 [INFO] Epoch 12/15 - Policy Loss: 0.8803, Value Loss: 0.2355, Total Loss: 1.1158, LR: 0.000071
2025-04-27 04:12:28,705 [INFO] Epoch 13/15 - Policy Loss: 0.8791, Value Loss: 0.2350, Total Loss: 1.1141, LR: 0.001679
2025-04-27 04:13:15,916 [INFO] Epoch 14/15 - Policy Loss: 0.8776, Value Loss: 0.2345, Total Loss: 1.1121, LR: 0.003329
2025-04-27 04:13:55,494 [INFO] Epoch 15/15 - Policy Loss: 0.8764, Value Loss: 0.2340, Total Loss: 1.1104, LR: 0.004979
2025-04-27 04:13:55,531 [INFO] 训练完成，总损失: 1.1104
2025-04-27 04:13:55,531 [INFO] 保存迭代 217 的模型
2025-04-27 04:13:56,096 [INFO] Model saved to ./models/best.pt
2025-04-27 04:13:56,493 [INFO] Model saved to ./models/iteration_217.pt
2025-04-27 04:13:56,494 [INFO] 所有训练迭代完成
2025-04-27 04:13:56,494 [INFO] 开始迭代 218/300
2025-04-27 04:13:56,494 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 04:25:10,739 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 04:25:10,740 [INFO] 保存训练样本
2025-04-27 04:25:15,510 [INFO] 使用 159080 个样本训练神经网络
2025-04-27 04:25:15,510 [INFO] Training with 159080 examples
2025-04-27 04:25:15,511 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-27 04:25:16,052 [INFO] 循环学习率周期大小: 231 步
2025-04-27 04:25:56,561 [INFO] Epoch 1/15 - Policy Loss: 0.9116, Value Loss: 0.2329, Total Loss: 1.1445, LR: 0.001679
2025-04-27 04:26:32,794 [INFO] Epoch 2/15 - Policy Loss: 0.9083, Value Loss: 0.2304, Total Loss: 1.1388, LR: 0.003329
2025-04-27 04:27:21,893 [INFO] Epoch 3/15 - Policy Loss: 0.9040, Value Loss: 0.2289, Total Loss: 1.1329, LR: 0.004979
2025-04-27 04:28:13,368 [INFO] Epoch 4/15 - Policy Loss: 0.8994, Value Loss: 0.2277, Total Loss: 1.1270, LR: 0.003371
2025-04-27 04:28:55,985 [INFO] Epoch 5/15 - Policy Loss: 0.8955, Value Loss: 0.2271, Total Loss: 1.1226, LR: 0.001721
2025-04-27 04:29:40,749 [INFO] Epoch 6/15 - Policy Loss: 0.8916, Value Loss: 0.2257, Total Loss: 1.1173, LR: 0.000071
2025-04-27 04:30:29,968 [INFO] Epoch 7/15 - Policy Loss: 0.8885, Value Loss: 0.2248, Total Loss: 1.1133, LR: 0.001679
2025-04-27 04:31:07,830 [INFO] Epoch 8/15 - Policy Loss: 0.8860, Value Loss: 0.2241, Total Loss: 1.1101, LR: 0.003329
2025-04-27 04:31:45,218 [INFO] Epoch 9/15 - Policy Loss: 0.8844, Value Loss: 0.2235, Total Loss: 1.1079, LR: 0.004979
2025-04-27 04:32:34,948 [INFO] Epoch 10/15 - Policy Loss: 0.8839, Value Loss: 0.2230, Total Loss: 1.1069, LR: 0.003371
2025-04-27 04:33:37,729 [INFO] Epoch 11/15 - Policy Loss: 0.8822, Value Loss: 0.2225, Total Loss: 1.1046, LR: 0.001721
2025-04-27 04:34:26,248 [INFO] Epoch 12/15 - Policy Loss: 0.8808, Value Loss: 0.2222, Total Loss: 1.1030, LR: 0.000071
2025-04-27 04:35:16,459 [INFO] Epoch 13/15 - Policy Loss: 0.8792, Value Loss: 0.2215, Total Loss: 1.1007, LR: 0.001679
2025-04-27 04:36:03,543 [INFO] Epoch 14/15 - Policy Loss: 0.8780, Value Loss: 0.2211, Total Loss: 1.0991, LR: 0.003329
2025-04-27 04:36:45,349 [INFO] Epoch 15/15 - Policy Loss: 0.8770, Value Loss: 0.2208, Total Loss: 1.0978, LR: 0.004979
2025-04-27 04:36:45,374 [INFO] 训练完成，总损失: 1.0978
2025-04-27 04:36:45,375 [INFO] 保存迭代 218 的模型
2025-04-27 04:36:46,116 [INFO] Model saved to ./models/best.pt
2025-04-27 04:36:46,691 [INFO] Model saved to ./models/iteration_218.pt
2025-04-27 04:36:46,692 [INFO] 所有训练迭代完成
2025-04-27 04:36:46,692 [INFO] 开始迭代 219/300
2025-04-27 04:36:46,692 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 04:50:07,319 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 04:50:07,319 [INFO] 保存训练样本
2025-04-27 04:50:13,388 [INFO] 使用 159432 个样本训练神经网络
2025-04-27 04:50:13,389 [INFO] Training with 159432 examples
2025-04-27 04:50:13,389 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-27 04:50:13,520 [INFO] 循环学习率周期大小: 231 步
2025-04-27 04:50:54,349 [INFO] Epoch 1/15 - Policy Loss: 0.9208, Value Loss: 0.2471, Total Loss: 1.1679, LR: 0.001679
2025-04-27 04:51:40,227 [INFO] Epoch 2/15 - Policy Loss: 0.9151, Value Loss: 0.2419, Total Loss: 1.1570, LR: 0.003329
2025-04-27 04:52:20,056 [INFO] Epoch 3/15 - Policy Loss: 0.9108, Value Loss: 0.2396, Total Loss: 1.1504, LR: 0.004979
2025-04-27 04:53:02,304 [INFO] Epoch 4/15 - Policy Loss: 0.9084, Value Loss: 0.2380, Total Loss: 1.1464, LR: 0.003371
2025-04-27 04:53:47,820 [INFO] Epoch 5/15 - Policy Loss: 0.9046, Value Loss: 0.2358, Total Loss: 1.1404, LR: 0.001721
2025-04-27 04:54:39,389 [INFO] Epoch 6/15 - Policy Loss: 0.9017, Value Loss: 0.2344, Total Loss: 1.1361, LR: 0.000071
2025-04-27 04:55:27,620 [INFO] Epoch 7/15 - Policy Loss: 0.8989, Value Loss: 0.2331, Total Loss: 1.1320, LR: 0.001679
2025-04-27 04:56:11,050 [INFO] Epoch 8/15 - Policy Loss: 0.8963, Value Loss: 0.2321, Total Loss: 1.1284, LR: 0.003329
2025-04-27 04:56:58,297 [INFO] Epoch 9/15 - Policy Loss: 0.8944, Value Loss: 0.2312, Total Loss: 1.1256, LR: 0.004979
2025-04-27 04:57:42,524 [INFO] Epoch 10/15 - Policy Loss: 0.8927, Value Loss: 0.2308, Total Loss: 1.1234, LR: 0.003371
2025-04-27 04:58:28,553 [INFO] Epoch 11/15 - Policy Loss: 0.8915, Value Loss: 0.2304, Total Loss: 1.1220, LR: 0.001721
2025-04-27 04:59:08,331 [INFO] Epoch 12/15 - Policy Loss: 0.8901, Value Loss: 0.2298, Total Loss: 1.1199, LR: 0.000071
2025-04-27 04:59:46,170 [INFO] Epoch 13/15 - Policy Loss: 0.8884, Value Loss: 0.2289, Total Loss: 1.1173, LR: 0.001679
2025-04-27 05:00:31,183 [INFO] Epoch 14/15 - Policy Loss: 0.8871, Value Loss: 0.2282, Total Loss: 1.1153, LR: 0.003329
2025-04-27 05:01:11,851 [INFO] Epoch 15/15 - Policy Loss: 0.8860, Value Loss: 0.2278, Total Loss: 1.1138, LR: 0.004979
2025-04-27 05:01:11,885 [INFO] 训练完成，总损失: 1.1138
2025-04-27 05:01:11,885 [INFO] 保存迭代 219 的模型
2025-04-27 05:01:12,527 [INFO] Model saved to ./models/best.pt
2025-04-27 05:01:12,968 [INFO] Model saved to ./models/iteration_219.pt
2025-04-27 05:01:12,969 [INFO] 所有训练迭代完成
2025-04-27 05:01:12,969 [INFO] 开始迭代 220/300
2025-04-27 05:01:12,969 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 05:12:52,613 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 05:12:52,613 [INFO] 保存训练样本
2025-04-27 05:12:59,135 [INFO] 使用 159168 个样本训练神经网络
2025-04-27 05:12:59,135 [INFO] Training with 159168 examples
2025-04-27 05:12:59,136 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-27 05:12:59,797 [INFO] 循环学习率周期大小: 231 步
2025-04-27 05:13:45,805 [INFO] Epoch 1/15 - Policy Loss: 0.9153, Value Loss: 0.2285, Total Loss: 1.1438, LR: 0.001679
2025-04-27 05:14:27,124 [INFO] Epoch 2/15 - Policy Loss: 0.9107, Value Loss: 0.2264, Total Loss: 1.1371, LR: 0.003329
2025-04-27 05:15:08,928 [INFO] Epoch 3/15 - Policy Loss: 0.9080, Value Loss: 0.2247, Total Loss: 1.1327, LR: 0.004979
2025-04-27 05:15:53,264 [INFO] Epoch 4/15 - Policy Loss: 0.9053, Value Loss: 0.2237, Total Loss: 1.1290, LR: 0.003371
2025-04-27 05:16:33,957 [INFO] Epoch 5/15 - Policy Loss: 0.9021, Value Loss: 0.2218, Total Loss: 1.1240, LR: 0.001721
2025-04-27 05:17:26,273 [INFO] Epoch 6/15 - Policy Loss: 0.8998, Value Loss: 0.2203, Total Loss: 1.1200, LR: 0.000071
2025-04-27 05:18:16,086 [INFO] Epoch 7/15 - Policy Loss: 0.8976, Value Loss: 0.2195, Total Loss: 1.1171, LR: 0.001679
2025-04-27 05:18:56,737 [INFO] Epoch 8/15 - Policy Loss: 0.8952, Value Loss: 0.2184, Total Loss: 1.1136, LR: 0.003329
2025-04-27 05:19:43,437 [INFO] Epoch 9/15 - Policy Loss: 0.8935, Value Loss: 0.2182, Total Loss: 1.1117, LR: 0.004979
2025-04-27 05:20:24,632 [INFO] Epoch 10/15 - Policy Loss: 0.8928, Value Loss: 0.2178, Total Loss: 1.1106, LR: 0.003371
2025-04-27 05:21:08,238 [INFO] Epoch 11/15 - Policy Loss: 0.8915, Value Loss: 0.2170, Total Loss: 1.1084, LR: 0.001721
2025-04-27 05:21:55,868 [INFO] Epoch 12/15 - Policy Loss: 0.8904, Value Loss: 0.2164, Total Loss: 1.1068, LR: 0.000071
2025-04-27 05:22:45,863 [INFO] Epoch 13/15 - Policy Loss: 0.8890, Value Loss: 0.2158, Total Loss: 1.1049, LR: 0.001679
2025-04-27 05:23:23,014 [INFO] Epoch 14/15 - Policy Loss: 0.8878, Value Loss: 0.2153, Total Loss: 1.1031, LR: 0.003329
2025-04-27 05:24:08,197 [INFO] Epoch 15/15 - Policy Loss: 0.8867, Value Loss: 0.2149, Total Loss: 1.1016, LR: 0.004979
2025-04-27 05:24:08,237 [INFO] 训练完成，总损失: 1.1016
2025-04-27 05:24:08,237 [INFO] 保存迭代 220 的模型
2025-04-27 05:24:08,877 [INFO] Model saved to ./models/best.pt
2025-04-27 05:24:09,334 [INFO] Model saved to ./models/iteration_220.pt
2025-04-27 05:24:09,334 [INFO] 所有训练迭代完成
2025-04-27 05:24:09,334 [INFO] 开始迭代 221/300
2025-04-27 05:24:09,334 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 05:35:05,652 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 05:35:05,653 [INFO] 保存训练样本
2025-04-27 05:35:10,563 [INFO] 使用 159496 个样本训练神经网络
2025-04-27 05:35:10,563 [INFO] Training with 159496 examples
2025-04-27 05:35:10,564 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-27 05:35:11,095 [INFO] 循环学习率周期大小: 231 步
2025-04-27 05:35:54,921 [INFO] Epoch 1/15 - Policy Loss: 0.9278, Value Loss: 0.2187, Total Loss: 1.1465, LR: 0.001679
2025-04-27 05:36:44,923 [INFO] Epoch 2/15 - Policy Loss: 0.9210, Value Loss: 0.2157, Total Loss: 1.1367, LR: 0.003329
2025-04-27 05:37:25,375 [INFO] Epoch 3/15 - Policy Loss: 0.9163, Value Loss: 0.2144, Total Loss: 1.1307, LR: 0.004979
2025-04-27 05:38:12,401 [INFO] Epoch 4/15 - Policy Loss: 0.9121, Value Loss: 0.2148, Total Loss: 1.1269, LR: 0.003371
2025-04-27 05:38:53,295 [INFO] Epoch 5/15 - Policy Loss: 0.9094, Value Loss: 0.2140, Total Loss: 1.1233, LR: 0.001721
2025-04-27 05:39:38,677 [INFO] Epoch 6/15 - Policy Loss: 0.9057, Value Loss: 0.2130, Total Loss: 1.1186, LR: 0.000071
2025-04-27 05:40:25,650 [INFO] Epoch 7/15 - Policy Loss: 0.9024, Value Loss: 0.2122, Total Loss: 1.1146, LR: 0.001679
2025-04-27 05:41:15,672 [INFO] Epoch 8/15 - Policy Loss: 0.9002, Value Loss: 0.2114, Total Loss: 1.1116, LR: 0.003329
2025-04-27 05:41:51,913 [INFO] Epoch 9/15 - Policy Loss: 0.8984, Value Loss: 0.2113, Total Loss: 1.1097, LR: 0.004979
2025-04-27 05:42:41,814 [INFO] Epoch 10/15 - Policy Loss: 0.8977, Value Loss: 0.2109, Total Loss: 1.1086, LR: 0.003371
2025-04-27 05:43:31,659 [INFO] Epoch 11/15 - Policy Loss: 0.8966, Value Loss: 0.2107, Total Loss: 1.1072, LR: 0.001721
2025-04-27 05:44:14,295 [INFO] Epoch 12/15 - Policy Loss: 0.8952, Value Loss: 0.2100, Total Loss: 1.1052, LR: 0.000071
2025-04-27 05:45:00,833 [INFO] Epoch 13/15 - Policy Loss: 0.8937, Value Loss: 0.2092, Total Loss: 1.1029, LR: 0.001679
2025-04-27 05:45:41,947 [INFO] Epoch 14/15 - Policy Loss: 0.8925, Value Loss: 0.2089, Total Loss: 1.1014, LR: 0.003329
2025-04-27 05:46:30,949 [INFO] Epoch 15/15 - Policy Loss: 0.8917, Value Loss: 0.2086, Total Loss: 1.1003, LR: 0.004979
2025-04-27 05:46:30,977 [INFO] 训练完成，总损失: 1.1003
2025-04-27 05:46:30,977 [INFO] 保存迭代 221 的模型
2025-04-27 05:46:31,518 [INFO] Model saved to ./models/best.pt
2025-04-27 05:46:31,944 [INFO] Model saved to ./models/iteration_221.pt
2025-04-27 05:46:31,945 [INFO] 所有训练迭代完成
2025-04-27 05:46:31,945 [INFO] 开始迭代 222/300
2025-04-27 05:46:31,945 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 05:58:08,431 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 05:58:08,432 [INFO] 保存训练样本
2025-04-27 05:58:13,467 [INFO] 使用 158864 个样本训练神经网络
2025-04-27 05:58:13,467 [INFO] Training with 158864 examples
2025-04-27 05:58:13,468 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-27 05:58:14,149 [INFO] 循环学习率周期大小: 231 步
2025-04-27 05:58:56,275 [INFO] Epoch 1/15 - Policy Loss: 0.9230, Value Loss: 0.2314, Total Loss: 1.1544, LR: 0.001679
2025-04-27 05:59:40,858 [INFO] Epoch 2/15 - Policy Loss: 0.9179, Value Loss: 0.2281, Total Loss: 1.1461, LR: 0.003329
2025-04-27 06:00:30,657 [INFO] Epoch 3/15 - Policy Loss: 0.9146, Value Loss: 0.2267, Total Loss: 1.1413, LR: 0.004979
2025-04-27 06:01:12,417 [INFO] Epoch 4/15 - Policy Loss: 0.9113, Value Loss: 0.2243, Total Loss: 1.1357, LR: 0.003371
2025-04-27 06:01:54,329 [INFO] Epoch 5/15 - Policy Loss: 0.9089, Value Loss: 0.2223, Total Loss: 1.1312, LR: 0.001721
2025-04-27 06:02:33,417 [INFO] Epoch 6/15 - Policy Loss: 0.9062, Value Loss: 0.2212, Total Loss: 1.1274, LR: 0.000071
2025-04-27 06:03:24,521 [INFO] Epoch 7/15 - Policy Loss: 0.9043, Value Loss: 0.2201, Total Loss: 1.1244, LR: 0.001679
2025-04-27 06:04:16,295 [INFO] Epoch 8/15 - Policy Loss: 0.9022, Value Loss: 0.2193, Total Loss: 1.1215, LR: 0.003329
2025-04-27 06:04:57,776 [INFO] Epoch 9/15 - Policy Loss: 0.9010, Value Loss: 0.2185, Total Loss: 1.1195, LR: 0.004979
2025-04-27 06:05:43,637 [INFO] Epoch 10/15 - Policy Loss: 0.8997, Value Loss: 0.2181, Total Loss: 1.1178, LR: 0.003371
2025-04-27 06:06:29,142 [INFO] Epoch 11/15 - Policy Loss: 0.8985, Value Loss: 0.2176, Total Loss: 1.1161, LR: 0.001721
2025-04-27 06:07:12,314 [INFO] Epoch 12/15 - Policy Loss: 0.8977, Value Loss: 0.2168, Total Loss: 1.1145, LR: 0.000071
2025-04-27 06:07:52,985 [INFO] Epoch 13/15 - Policy Loss: 0.8962, Value Loss: 0.2163, Total Loss: 1.1125, LR: 0.001679
2025-04-27 06:08:41,825 [INFO] Epoch 14/15 - Policy Loss: 0.8952, Value Loss: 0.2158, Total Loss: 1.1111, LR: 0.003329
2025-04-27 06:09:31,172 [INFO] Epoch 15/15 - Policy Loss: 0.8943, Value Loss: 0.2153, Total Loss: 1.1097, LR: 0.004979
2025-04-27 06:09:31,197 [INFO] 训练完成，总损失: 1.1097
2025-04-27 06:09:31,197 [INFO] 保存迭代 222 的模型
2025-04-27 06:09:31,816 [INFO] Model saved to ./models/best.pt
2025-04-27 06:09:32,253 [INFO] Model saved to ./models/iteration_222.pt
2025-04-27 06:09:32,253 [INFO] 所有训练迭代完成
2025-04-27 06:09:32,253 [INFO] 开始迭代 223/300
2025-04-27 06:09:32,253 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 06:22:44,423 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 06:22:44,424 [INFO] 保存训练样本
2025-04-27 06:22:50,329 [INFO] 使用 159552 个样本训练神经网络
2025-04-27 06:22:50,330 [INFO] Training with 159552 examples
2025-04-27 06:22:50,331 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-27 06:22:50,416 [INFO] 循环学习率周期大小: 231 步
2025-04-27 06:23:40,130 [INFO] Epoch 1/15 - Policy Loss: 0.9447, Value Loss: 0.2376, Total Loss: 1.1822, LR: 0.001679
2025-04-27 06:24:23,471 [INFO] Epoch 2/15 - Policy Loss: 0.9367, Value Loss: 0.2354, Total Loss: 1.1721, LR: 0.003329
2025-04-27 06:25:05,645 [INFO] Epoch 3/15 - Policy Loss: 0.9301, Value Loss: 0.2316, Total Loss: 1.1617, LR: 0.004979
2025-04-27 06:25:45,976 [INFO] Epoch 4/15 - Policy Loss: 0.9255, Value Loss: 0.2302, Total Loss: 1.1557, LR: 0.003371
2025-04-27 06:26:34,188 [INFO] Epoch 5/15 - Policy Loss: 0.9220, Value Loss: 0.2285, Total Loss: 1.1505, LR: 0.001721
2025-04-27 06:27:11,452 [INFO] Epoch 6/15 - Policy Loss: 0.9179, Value Loss: 0.2262, Total Loss: 1.1441, LR: 0.000071
2025-04-27 06:27:58,338 [INFO] Epoch 7/15 - Policy Loss: 0.9144, Value Loss: 0.2243, Total Loss: 1.1387, LR: 0.001679
2025-04-27 06:28:39,957 [INFO] Epoch 8/15 - Policy Loss: 0.9118, Value Loss: 0.2231, Total Loss: 1.1349, LR: 0.003329
2025-04-27 06:29:28,231 [INFO] Epoch 9/15 - Policy Loss: 0.9104, Value Loss: 0.2222, Total Loss: 1.1326, LR: 0.004979
2025-04-27 06:30:16,191 [INFO] Epoch 10/15 - Policy Loss: 0.9091, Value Loss: 0.2214, Total Loss: 1.1305, LR: 0.003371
2025-04-27 06:31:02,095 [INFO] Epoch 11/15 - Policy Loss: 0.9080, Value Loss: 0.2203, Total Loss: 1.1284, LR: 0.001721
2025-04-27 06:31:42,532 [INFO] Epoch 12/15 - Policy Loss: 0.9063, Value Loss: 0.2192, Total Loss: 1.1255, LR: 0.000071
2025-04-27 06:32:27,775 [INFO] Epoch 13/15 - Policy Loss: 0.9047, Value Loss: 0.2183, Total Loss: 1.1230, LR: 0.001679
2025-04-27 06:33:23,044 [INFO] Epoch 14/15 - Policy Loss: 0.9036, Value Loss: 0.2177, Total Loss: 1.1213, LR: 0.003329
2025-04-27 06:34:05,447 [INFO] Epoch 15/15 - Policy Loss: 0.9027, Value Loss: 0.2171, Total Loss: 1.1198, LR: 0.004979
2025-04-27 06:34:05,560 [INFO] 训练完成，总损失: 1.1198
2025-04-27 06:34:05,561 [INFO] 保存迭代 223 的模型
2025-04-27 06:34:06,384 [INFO] Model saved to ./models/best.pt
2025-04-27 06:34:07,054 [INFO] Model saved to ./models/iteration_223.pt
2025-04-27 06:34:07,055 [INFO] 所有训练迭代完成
2025-04-27 06:34:07,055 [INFO] 开始迭代 224/300
2025-04-27 06:34:07,055 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 06:45:05,857 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 06:45:05,857 [INFO] 保存训练样本
2025-04-27 06:45:12,365 [INFO] 使用 159280 个样本训练神经网络
2025-04-27 06:45:12,366 [INFO] Training with 159280 examples
2025-04-27 06:45:12,367 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-27 06:45:12,877 [INFO] 循环学习率周期大小: 231 步
2025-04-27 06:46:04,041 [INFO] Epoch 1/15 - Policy Loss: 0.9285, Value Loss: 0.2224, Total Loss: 1.1509, LR: 0.001679
2025-04-27 06:46:49,505 [INFO] Epoch 2/15 - Policy Loss: 0.9233, Value Loss: 0.2183, Total Loss: 1.1416, LR: 0.003329
2025-04-27 06:47:29,966 [INFO] Epoch 3/15 - Policy Loss: 0.9186, Value Loss: 0.2166, Total Loss: 1.1352, LR: 0.004979
2025-04-27 06:48:18,881 [INFO] Epoch 4/15 - Policy Loss: 0.9165, Value Loss: 0.2156, Total Loss: 1.1321, LR: 0.003371
2025-04-27 06:48:58,137 [INFO] Epoch 5/15 - Policy Loss: 0.9145, Value Loss: 0.2141, Total Loss: 1.1286, LR: 0.001721
2025-04-27 06:49:47,979 [INFO] Epoch 6/15 - Policy Loss: 0.9120, Value Loss: 0.2130, Total Loss: 1.1250, LR: 0.000071
2025-04-27 06:50:28,407 [INFO] Epoch 7/15 - Policy Loss: 0.9095, Value Loss: 0.2119, Total Loss: 1.1213, LR: 0.001679
2025-04-27 06:51:15,220 [INFO] Epoch 8/15 - Policy Loss: 0.9071, Value Loss: 0.2112, Total Loss: 1.1182, LR: 0.003329
2025-04-27 06:51:57,129 [INFO] Epoch 9/15 - Policy Loss: 0.9056, Value Loss: 0.2109, Total Loss: 1.1165, LR: 0.004979
2025-04-27 06:52:46,983 [INFO] Epoch 10/15 - Policy Loss: 0.9042, Value Loss: 0.2107, Total Loss: 1.1149, LR: 0.003371
2025-04-27 06:53:32,184 [INFO] Epoch 11/15 - Policy Loss: 0.9029, Value Loss: 0.2101, Total Loss: 1.1130, LR: 0.001721
2025-04-27 06:54:18,669 [INFO] Epoch 12/15 - Policy Loss: 0.9012, Value Loss: 0.2097, Total Loss: 1.1109, LR: 0.000071
2025-04-27 06:54:55,464 [INFO] Epoch 13/15 - Policy Loss: 0.8996, Value Loss: 0.2089, Total Loss: 1.1085, LR: 0.001679
2025-04-27 06:55:38,515 [INFO] Epoch 14/15 - Policy Loss: 0.8982, Value Loss: 0.2085, Total Loss: 1.1067, LR: 0.003329
2025-04-27 06:56:21,183 [INFO] Epoch 15/15 - Policy Loss: 0.8975, Value Loss: 0.2083, Total Loss: 1.1058, LR: 0.004979
2025-04-27 06:56:21,220 [INFO] 训练完成，总损失: 1.1058
2025-04-27 06:56:21,220 [INFO] 保存迭代 224 的模型
2025-04-27 06:56:21,833 [INFO] Model saved to ./models/best.pt
2025-04-27 06:56:22,225 [INFO] Model saved to ./models/iteration_224.pt
2025-04-27 06:56:22,226 [INFO] 所有训练迭代完成
2025-04-27 06:56:22,227 [INFO] 开始迭代 225/300
2025-04-27 06:56:22,227 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 07:07:04,451 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 07:07:04,451 [INFO] 保存训练样本
2025-04-27 07:07:09,495 [INFO] 使用 159296 个样本训练神经网络
2025-04-27 07:07:09,495 [INFO] Training with 159296 examples
2025-04-27 07:07:09,496 [INFO] 总训练步数: 1155, 每轮次批次数: 77
2025-04-27 07:07:09,998 [INFO] 循环学习率周期大小: 231 步
2025-04-27 07:08:07,922 [INFO] Epoch 1/15 - Policy Loss: 0.9251, Value Loss: 0.2261, Total Loss: 1.1512, LR: 0.001679
2025-04-27 07:08:54,052 [INFO] Epoch 2/15 - Policy Loss: 0.9224, Value Loss: 0.2260, Total Loss: 1.1484, LR: 0.003329
2025-04-27 07:09:39,199 [INFO] Epoch 3/15 - Policy Loss: 0.9210, Value Loss: 0.2245, Total Loss: 1.1455, LR: 0.004979
2025-04-27 07:10:27,104 [INFO] Epoch 4/15 - Policy Loss: 0.9169, Value Loss: 0.2227, Total Loss: 1.1396, LR: 0.003371
2025-04-27 07:11:21,447 [INFO] Epoch 5/15 - Policy Loss: 0.9136, Value Loss: 0.2206, Total Loss: 1.1342, LR: 0.001721
2025-04-27 07:11:58,647 [INFO] Epoch 6/15 - Policy Loss: 0.9108, Value Loss: 0.2187, Total Loss: 1.1295, LR: 0.000071
2025-04-27 07:12:47,399 [INFO] Epoch 7/15 - Policy Loss: 0.9077, Value Loss: 0.2172, Total Loss: 1.1249, LR: 0.001679
2025-04-27 07:13:52,613 [INFO] Epoch 8/15 - Policy Loss: 0.9049, Value Loss: 0.2162, Total Loss: 1.1211, LR: 0.003329
2025-04-27 07:14:30,963 [INFO] Epoch 9/15 - Policy Loss: 0.9033, Value Loss: 0.2156, Total Loss: 1.1189, LR: 0.004979
2025-04-27 07:15:16,091 [INFO] Epoch 10/15 - Policy Loss: 0.9027, Value Loss: 0.2150, Total Loss: 1.1178, LR: 0.003371
2025-04-27 07:16:08,551 [INFO] Epoch 11/15 - Policy Loss: 0.9017, Value Loss: 0.2143, Total Loss: 1.1160, LR: 0.001721
2025-04-27 07:16:54,441 [INFO] Epoch 12/15 - Policy Loss: 0.9005, Value Loss: 0.2133, Total Loss: 1.1138, LR: 0.000071
2025-04-27 07:17:43,799 [INFO] Epoch 13/15 - Policy Loss: 0.8989, Value Loss: 0.2130, Total Loss: 1.1118, LR: 0.001679
2025-04-27 07:18:23,924 [INFO] Epoch 14/15 - Policy Loss: 0.8979, Value Loss: 0.2124, Total Loss: 1.1104, LR: 0.003329
2025-04-27 07:19:10,167 [INFO] Epoch 15/15 - Policy Loss: 0.8968, Value Loss: 0.2120, Total Loss: 1.1088, LR: 0.004979
2025-04-27 07:19:10,205 [INFO] 训练完成，总损失: 1.1088
2025-04-27 07:19:10,205 [INFO] 保存迭代 225 的模型
2025-04-27 07:19:10,837 [INFO] Model saved to ./models/best.pt
2025-04-27 07:19:11,255 [INFO] Model saved to ./models/iteration_225.pt
2025-04-27 07:19:11,256 [INFO] 所有训练迭代完成
2025-04-27 07:19:11,256 [INFO] 开始迭代 226/300
2025-04-27 07:19:11,256 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 07:31:08,619 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 07:31:08,620 [INFO] 保存训练样本
2025-04-27 07:31:13,744 [INFO] 使用 159928 个样本训练神经网络
2025-04-27 07:31:13,744 [INFO] Training with 159928 examples
2025-04-27 07:31:13,745 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 07:31:13,815 [INFO] 循环学习率周期大小: 234 步
2025-04-27 07:31:56,434 [INFO] Epoch 1/15 - Policy Loss: 0.9243, Value Loss: 0.2135, Total Loss: 1.1378, LR: 0.001679
2025-04-27 07:32:50,066 [INFO] Epoch 2/15 - Policy Loss: 0.9210, Value Loss: 0.2137, Total Loss: 1.1346, LR: 0.003329
2025-04-27 07:33:36,688 [INFO] Epoch 3/15 - Policy Loss: 0.9180, Value Loss: 0.2126, Total Loss: 1.1306, LR: 0.004979
2025-04-27 07:34:24,419 [INFO] Epoch 4/15 - Policy Loss: 0.9149, Value Loss: 0.2122, Total Loss: 1.1271, LR: 0.003371
2025-04-27 07:35:30,378 [INFO] Epoch 5/15 - Policy Loss: 0.9113, Value Loss: 0.2105, Total Loss: 1.1218, LR: 0.001721
2025-04-27 07:36:28,752 [INFO] Epoch 6/15 - Policy Loss: 0.9082, Value Loss: 0.2092, Total Loss: 1.1174, LR: 0.000071
2025-04-27 07:37:06,342 [INFO] Epoch 7/15 - Policy Loss: 0.9060, Value Loss: 0.2080, Total Loss: 1.1140, LR: 0.001679
2025-04-27 07:37:52,115 [INFO] Epoch 8/15 - Policy Loss: 0.9031, Value Loss: 0.2077, Total Loss: 1.1108, LR: 0.003329
2025-04-27 07:38:39,973 [INFO] Epoch 9/15 - Policy Loss: 0.9015, Value Loss: 0.2073, Total Loss: 1.1088, LR: 0.004979
2025-04-27 07:39:21,536 [INFO] Epoch 10/15 - Policy Loss: 0.9003, Value Loss: 0.2070, Total Loss: 1.1073, LR: 0.003371
2025-04-27 07:40:06,877 [INFO] Epoch 11/15 - Policy Loss: 0.8989, Value Loss: 0.2064, Total Loss: 1.1053, LR: 0.001721
2025-04-27 07:40:52,647 [INFO] Epoch 12/15 - Policy Loss: 0.8977, Value Loss: 0.2060, Total Loss: 1.1038, LR: 0.000071
2025-04-27 07:41:34,800 [INFO] Epoch 13/15 - Policy Loss: 0.8962, Value Loss: 0.2053, Total Loss: 1.1015, LR: 0.001679
2025-04-27 07:42:22,251 [INFO] Epoch 14/15 - Policy Loss: 0.8949, Value Loss: 0.2047, Total Loss: 1.0996, LR: 0.003329
2025-04-27 07:43:07,812 [INFO] Epoch 15/15 - Policy Loss: 0.8939, Value Loss: 0.2044, Total Loss: 1.0983, LR: 0.004979
2025-04-27 07:43:07,854 [INFO] 训练完成，总损失: 1.0983
2025-04-27 07:43:07,855 [INFO] 保存迭代 226 的模型
2025-04-27 07:43:08,638 [INFO] Model saved to ./models/best.pt
2025-04-27 07:43:09,072 [INFO] Model saved to ./models/iteration_226.pt
2025-04-27 07:43:09,073 [INFO] 所有训练迭代完成
2025-04-27 07:43:09,073 [INFO] 开始迭代 227/300
2025-04-27 07:43:09,073 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 07:57:14,867 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 07:57:14,867 [INFO] 保存训练样本
2025-04-27 07:57:19,183 [INFO] 使用 160632 个样本训练神经网络
2025-04-27 07:57:19,184 [INFO] Training with 160632 examples
2025-04-27 07:57:19,184 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 07:57:19,688 [INFO] 循环学习率周期大小: 234 步
2025-04-27 07:58:04,656 [INFO] Epoch 1/15 - Policy Loss: 0.9235, Value Loss: 0.2269, Total Loss: 1.1504, LR: 0.001679
2025-04-27 07:58:50,363 [INFO] Epoch 2/15 - Policy Loss: 0.9180, Value Loss: 0.2244, Total Loss: 1.1424, LR: 0.003329
2025-04-27 07:59:33,937 [INFO] Epoch 3/15 - Policy Loss: 0.9133, Value Loss: 0.2219, Total Loss: 1.1351, LR: 0.004979
2025-04-27 08:00:19,500 [INFO] Epoch 4/15 - Policy Loss: 0.9111, Value Loss: 0.2197, Total Loss: 1.1308, LR: 0.003371
2025-04-27 08:01:04,104 [INFO] Epoch 5/15 - Policy Loss: 0.9079, Value Loss: 0.2180, Total Loss: 1.1260, LR: 0.001721
2025-04-27 08:01:48,719 [INFO] Epoch 6/15 - Policy Loss: 0.9047, Value Loss: 0.2160, Total Loss: 1.1207, LR: 0.000071
2025-04-27 08:02:37,211 [INFO] Epoch 7/15 - Policy Loss: 0.9024, Value Loss: 0.2147, Total Loss: 1.1171, LR: 0.001679
2025-04-27 08:03:14,926 [INFO] Epoch 8/15 - Policy Loss: 0.9002, Value Loss: 0.2131, Total Loss: 1.1133, LR: 0.003329
2025-04-27 08:04:05,308 [INFO] Epoch 9/15 - Policy Loss: 0.8987, Value Loss: 0.2123, Total Loss: 1.1111, LR: 0.004979
2025-04-27 08:04:50,897 [INFO] Epoch 10/15 - Policy Loss: 0.8973, Value Loss: 0.2116, Total Loss: 1.1089, LR: 0.003371
2025-04-27 08:05:31,173 [INFO] Epoch 11/15 - Policy Loss: 0.8963, Value Loss: 0.2107, Total Loss: 1.1071, LR: 0.001721
2025-04-27 08:06:12,454 [INFO] Epoch 12/15 - Policy Loss: 0.8950, Value Loss: 0.2099, Total Loss: 1.1049, LR: 0.000071
2025-04-27 08:07:02,409 [INFO] Epoch 13/15 - Policy Loss: 0.8938, Value Loss: 0.2091, Total Loss: 1.1029, LR: 0.001679
2025-04-27 08:07:51,010 [INFO] Epoch 14/15 - Policy Loss: 0.8930, Value Loss: 0.2086, Total Loss: 1.1016, LR: 0.003329
2025-04-27 08:08:38,816 [INFO] Epoch 15/15 - Policy Loss: 0.8920, Value Loss: 0.2080, Total Loss: 1.1000, LR: 0.004979
2025-04-27 08:08:38,853 [INFO] 训练完成，总损失: 1.1000
2025-04-27 08:08:38,853 [INFO] 保存迭代 227 的模型
2025-04-27 08:08:39,436 [INFO] Model saved to ./models/best.pt
2025-04-27 08:08:39,832 [INFO] Model saved to ./models/iteration_227.pt
2025-04-27 08:08:39,832 [INFO] 所有训练迭代完成
2025-04-27 08:08:39,832 [INFO] 开始迭代 228/300
2025-04-27 08:08:39,832 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 08:20:49,035 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 08:20:49,036 [INFO] 保存训练样本
2025-04-27 08:20:53,057 [INFO] 使用 160368 个样本训练神经网络
2025-04-27 08:20:53,057 [INFO] Training with 160368 examples
2025-04-27 08:20:53,057 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 08:20:53,679 [INFO] 循环学习率周期大小: 234 步
2025-04-27 08:21:41,529 [INFO] Epoch 1/15 - Policy Loss: 0.9284, Value Loss: 0.2233, Total Loss: 1.1516, LR: 0.001679
2025-04-27 08:22:22,542 [INFO] Epoch 2/15 - Policy Loss: 0.9194, Value Loss: 0.2200, Total Loss: 1.1394, LR: 0.003329
2025-04-27 08:23:12,853 [INFO] Epoch 3/15 - Policy Loss: 0.9154, Value Loss: 0.2186, Total Loss: 1.1340, LR: 0.004979
2025-04-27 08:23:59,617 [INFO] Epoch 4/15 - Policy Loss: 0.9127, Value Loss: 0.2176, Total Loss: 1.1303, LR: 0.003371
2025-04-27 08:24:42,090 [INFO] Epoch 5/15 - Policy Loss: 0.9100, Value Loss: 0.2167, Total Loss: 1.1267, LR: 0.001721
2025-04-27 08:25:24,109 [INFO] Epoch 6/15 - Policy Loss: 0.9060, Value Loss: 0.2148, Total Loss: 1.1208, LR: 0.000071
2025-04-27 08:26:13,094 [INFO] Epoch 7/15 - Policy Loss: 0.9032, Value Loss: 0.2128, Total Loss: 1.1160, LR: 0.001679
2025-04-27 08:26:59,499 [INFO] Epoch 8/15 - Policy Loss: 0.9004, Value Loss: 0.2116, Total Loss: 1.1119, LR: 0.003329
2025-04-27 08:27:40,233 [INFO] Epoch 9/15 - Policy Loss: 0.8988, Value Loss: 0.2112, Total Loss: 1.1100, LR: 0.004979
2025-04-27 08:28:22,906 [INFO] Epoch 10/15 - Policy Loss: 0.8982, Value Loss: 0.2108, Total Loss: 1.1090, LR: 0.003371
2025-04-27 08:29:11,777 [INFO] Epoch 11/15 - Policy Loss: 0.8976, Value Loss: 0.2103, Total Loss: 1.1079, LR: 0.001721
2025-04-27 08:29:59,995 [INFO] Epoch 12/15 - Policy Loss: 0.8962, Value Loss: 0.2097, Total Loss: 1.1059, LR: 0.000071
2025-04-27 08:30:47,079 [INFO] Epoch 13/15 - Policy Loss: 0.8950, Value Loss: 0.2092, Total Loss: 1.1042, LR: 0.001679
2025-04-27 08:31:28,213 [INFO] Epoch 14/15 - Policy Loss: 0.8936, Value Loss: 0.2087, Total Loss: 1.1023, LR: 0.003329
2025-04-27 08:32:14,620 [INFO] Epoch 15/15 - Policy Loss: 0.8927, Value Loss: 0.2082, Total Loss: 1.1009, LR: 0.004979
2025-04-27 08:32:14,658 [INFO] 训练完成，总损失: 1.1009
2025-04-27 08:32:14,659 [INFO] 保存迭代 228 的模型
2025-04-27 08:32:15,245 [INFO] Model saved to ./models/best.pt
2025-04-27 08:32:15,653 [INFO] Model saved to ./models/iteration_228.pt
2025-04-27 08:32:15,654 [INFO] 所有训练迭代完成
2025-04-27 08:32:15,654 [INFO] 开始迭代 229/300
2025-04-27 08:32:15,654 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 08:44:30,533 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 08:44:30,534 [INFO] 保存训练样本
2025-04-27 08:44:36,216 [INFO] 使用 160240 个样本训练神经网络
2025-04-27 08:44:36,216 [INFO] Training with 160240 examples
2025-04-27 08:44:36,216 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 08:44:36,338 [INFO] 循环学习率周期大小: 234 步
2025-04-27 08:45:28,832 [INFO] Epoch 1/15 - Policy Loss: 0.9232, Value Loss: 0.2158, Total Loss: 1.1390, LR: 0.001679
2025-04-27 08:46:18,443 [INFO] Epoch 2/15 - Policy Loss: 0.9150, Value Loss: 0.2124, Total Loss: 1.1273, LR: 0.003329
2025-04-27 08:47:06,869 [INFO] Epoch 3/15 - Policy Loss: 0.9140, Value Loss: 0.2111, Total Loss: 1.1251, LR: 0.004979
2025-04-27 08:47:55,660 [INFO] Epoch 4/15 - Policy Loss: 0.9120, Value Loss: 0.2101, Total Loss: 1.1221, LR: 0.003371
2025-04-27 08:48:48,312 [INFO] Epoch 5/15 - Policy Loss: 0.9094, Value Loss: 0.2086, Total Loss: 1.1180, LR: 0.001721
2025-04-27 08:49:42,205 [INFO] Epoch 6/15 - Policy Loss: 0.9053, Value Loss: 0.2073, Total Loss: 1.1125, LR: 0.000071
2025-04-27 08:50:35,895 [INFO] Epoch 7/15 - Policy Loss: 0.9030, Value Loss: 0.2063, Total Loss: 1.1093, LR: 0.001679
2025-04-27 08:51:16,835 [INFO] Epoch 8/15 - Policy Loss: 0.9011, Value Loss: 0.2051, Total Loss: 1.1063, LR: 0.003329
2025-04-27 08:52:02,381 [INFO] Epoch 9/15 - Policy Loss: 0.8997, Value Loss: 0.2044, Total Loss: 1.1040, LR: 0.004979
2025-04-27 08:52:44,251 [INFO] Epoch 10/15 - Policy Loss: 0.8988, Value Loss: 0.2041, Total Loss: 1.1029, LR: 0.003371
2025-04-27 08:53:27,001 [INFO] Epoch 11/15 - Policy Loss: 0.8971, Value Loss: 0.2036, Total Loss: 1.1007, LR: 0.001721
2025-04-27 08:54:17,473 [INFO] Epoch 12/15 - Policy Loss: 0.8955, Value Loss: 0.2033, Total Loss: 1.0988, LR: 0.000071
2025-04-27 08:55:00,310 [INFO] Epoch 13/15 - Policy Loss: 0.8942, Value Loss: 0.2026, Total Loss: 1.0968, LR: 0.001679
2025-04-27 08:55:45,200 [INFO] Epoch 14/15 - Policy Loss: 0.8930, Value Loss: 0.2022, Total Loss: 1.0952, LR: 0.003329
2025-04-27 08:56:37,158 [INFO] Epoch 15/15 - Policy Loss: 0.8926, Value Loss: 0.2017, Total Loss: 1.0943, LR: 0.004979
2025-04-27 08:56:37,212 [INFO] 训练完成，总损失: 1.0943
2025-04-27 08:56:37,212 [INFO] 保存迭代 229 的模型
2025-04-27 08:56:38,599 [INFO] Model saved to ./models/best.pt
2025-04-27 08:56:39,004 [INFO] Model saved to ./models/iteration_229.pt
2025-04-27 08:56:39,005 [INFO] 所有训练迭代完成
2025-04-27 08:56:39,005 [INFO] 开始迭代 230/300
2025-04-27 08:56:39,005 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 09:09:20,260 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 09:09:20,260 [INFO] 保存训练样本
2025-04-27 09:09:26,493 [INFO] 使用 160760 个样本训练神经网络
2025-04-27 09:09:26,493 [INFO] Training with 160760 examples
2025-04-27 09:09:26,494 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 09:09:27,140 [INFO] 循环学习率周期大小: 234 步
2025-04-27 09:10:18,074 [INFO] Epoch 1/15 - Policy Loss: 0.9205, Value Loss: 0.2084, Total Loss: 1.1289, LR: 0.001679
2025-04-27 09:11:00,308 [INFO] Epoch 2/15 - Policy Loss: 0.9174, Value Loss: 0.2060, Total Loss: 1.1234, LR: 0.003329
2025-04-27 09:11:41,683 [INFO] Epoch 3/15 - Policy Loss: 0.9135, Value Loss: 0.2041, Total Loss: 1.1177, LR: 0.004979
2025-04-27 09:12:32,107 [INFO] Epoch 4/15 - Policy Loss: 0.9108, Value Loss: 0.2027, Total Loss: 1.1135, LR: 0.003371
2025-04-27 09:13:13,257 [INFO] Epoch 5/15 - Policy Loss: 0.9083, Value Loss: 0.2012, Total Loss: 1.1095, LR: 0.001721
2025-04-27 09:13:55,041 [INFO] Epoch 6/15 - Policy Loss: 0.9057, Value Loss: 0.1999, Total Loss: 1.1056, LR: 0.000071
2025-04-27 09:14:37,616 [INFO] Epoch 7/15 - Policy Loss: 0.9042, Value Loss: 0.1986, Total Loss: 1.1028, LR: 0.001679
2025-04-27 09:15:13,581 [INFO] Epoch 8/15 - Policy Loss: 0.9023, Value Loss: 0.1975, Total Loss: 1.0998, LR: 0.003329
2025-04-27 09:15:59,440 [INFO] Epoch 9/15 - Policy Loss: 0.9008, Value Loss: 0.1972, Total Loss: 1.0980, LR: 0.004979
2025-04-27 09:16:45,160 [INFO] Epoch 10/15 - Policy Loss: 0.8994, Value Loss: 0.1967, Total Loss: 1.0960, LR: 0.003371
2025-04-27 09:17:27,043 [INFO] Epoch 11/15 - Policy Loss: 0.8981, Value Loss: 0.1961, Total Loss: 1.0942, LR: 0.001721
2025-04-27 09:18:08,106 [INFO] Epoch 12/15 - Policy Loss: 0.8969, Value Loss: 0.1954, Total Loss: 1.0923, LR: 0.000071
2025-04-27 09:19:00,027 [INFO] Epoch 13/15 - Policy Loss: 0.8954, Value Loss: 0.1946, Total Loss: 1.0900, LR: 0.001679
2025-04-27 09:19:45,659 [INFO] Epoch 14/15 - Policy Loss: 0.8941, Value Loss: 0.1941, Total Loss: 1.0882, LR: 0.003329
2025-04-27 09:20:34,799 [INFO] Epoch 15/15 - Policy Loss: 0.8933, Value Loss: 0.1939, Total Loss: 1.0873, LR: 0.004979
2025-04-27 09:20:34,841 [INFO] 训练完成，总损失: 1.0873
2025-04-27 09:20:34,841 [INFO] 保存迭代 230 的模型
2025-04-27 09:20:35,660 [INFO] Model saved to ./models/best.pt
2025-04-27 09:20:36,120 [INFO] Model saved to ./models/iteration_230.pt
2025-04-27 09:20:36,120 [INFO] 所有训练迭代完成
2025-04-27 09:20:36,120 [INFO] 开始迭代 231/300
2025-04-27 09:20:36,120 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 09:33:32,936 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 09:33:32,936 [INFO] 保存训练样本
2025-04-27 09:33:38,412 [INFO] 使用 160936 个样本训练神经网络
2025-04-27 09:33:38,412 [INFO] Training with 160936 examples
2025-04-27 09:33:38,413 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 09:33:38,933 [INFO] 循环学习率周期大小: 234 步
2025-04-27 09:34:24,756 [INFO] Epoch 1/15 - Policy Loss: 0.9283, Value Loss: 0.1989, Total Loss: 1.1272, LR: 0.001679
2025-04-27 09:35:07,142 [INFO] Epoch 2/15 - Policy Loss: 0.9266, Value Loss: 0.1971, Total Loss: 1.1238, LR: 0.003329
2025-04-27 09:35:49,324 [INFO] Epoch 3/15 - Policy Loss: 0.9220, Value Loss: 0.1950, Total Loss: 1.1170, LR: 0.004979
2025-04-27 09:36:34,901 [INFO] Epoch 4/15 - Policy Loss: 0.9172, Value Loss: 0.1936, Total Loss: 1.1109, LR: 0.003371
2025-04-27 09:37:26,835 [INFO] Epoch 5/15 - Policy Loss: 0.9129, Value Loss: 0.1924, Total Loss: 1.1053, LR: 0.001721
2025-04-27 09:38:16,006 [INFO] Epoch 6/15 - Policy Loss: 0.9097, Value Loss: 0.1912, Total Loss: 1.1009, LR: 0.000071
2025-04-27 09:38:54,259 [INFO] Epoch 7/15 - Policy Loss: 0.9070, Value Loss: 0.1904, Total Loss: 1.0974, LR: 0.001679
2025-04-27 09:39:44,777 [INFO] Epoch 8/15 - Policy Loss: 0.9053, Value Loss: 0.1897, Total Loss: 1.0950, LR: 0.003329
2025-04-27 09:40:30,355 [INFO] Epoch 9/15 - Policy Loss: 0.9037, Value Loss: 0.1890, Total Loss: 1.0928, LR: 0.004979
2025-04-27 09:41:18,292 [INFO] Epoch 10/15 - Policy Loss: 0.9024, Value Loss: 0.1888, Total Loss: 1.0912, LR: 0.003371
2025-04-27 09:42:08,921 [INFO] Epoch 11/15 - Policy Loss: 0.9005, Value Loss: 0.1883, Total Loss: 1.0887, LR: 0.001721
2025-04-27 09:42:59,528 [INFO] Epoch 12/15 - Policy Loss: 0.8991, Value Loss: 0.1877, Total Loss: 1.0868, LR: 0.000071
2025-04-27 09:43:47,664 [INFO] Epoch 13/15 - Policy Loss: 0.8978, Value Loss: 0.1875, Total Loss: 1.0853, LR: 0.001679
2025-04-27 09:44:32,900 [INFO] Epoch 14/15 - Policy Loss: 0.8966, Value Loss: 0.1872, Total Loss: 1.0838, LR: 0.003329
2025-04-27 09:45:18,827 [INFO] Epoch 15/15 - Policy Loss: 0.8960, Value Loss: 0.1868, Total Loss: 1.0828, LR: 0.004979
2025-04-27 09:45:18,881 [INFO] 训练完成，总损失: 1.0828
2025-04-27 09:45:18,882 [INFO] 保存迭代 231 的模型
2025-04-27 09:45:19,680 [INFO] Model saved to ./models/best.pt
2025-04-27 09:45:20,105 [INFO] Model saved to ./models/iteration_231.pt
2025-04-27 09:45:20,105 [INFO] 所有训练迭代完成
2025-04-27 09:45:20,105 [INFO] 开始迭代 232/300
2025-04-27 09:45:20,105 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 09:57:34,309 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 09:57:34,309 [INFO] 保存训练样本
2025-04-27 09:57:38,381 [INFO] 使用 160832 个样本训练神经网络
2025-04-27 09:57:38,381 [INFO] Training with 160832 examples
2025-04-27 09:57:38,381 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 09:57:38,787 [INFO] 循环学习率周期大小: 234 步
2025-04-27 09:58:25,172 [INFO] Epoch 1/15 - Policy Loss: 0.9250, Value Loss: 0.1954, Total Loss: 1.1204, LR: 0.001679
2025-04-27 09:59:06,863 [INFO] Epoch 2/15 - Policy Loss: 0.9198, Value Loss: 0.1938, Total Loss: 1.1137, LR: 0.003329
2025-04-27 09:59:49,519 [INFO] Epoch 3/15 - Policy Loss: 0.9175, Value Loss: 0.1926, Total Loss: 1.1101, LR: 0.004979
2025-04-27 10:00:31,779 [INFO] Epoch 4/15 - Policy Loss: 0.9142, Value Loss: 0.1923, Total Loss: 1.1065, LR: 0.003371
2025-04-27 10:01:19,940 [INFO] Epoch 5/15 - Policy Loss: 0.9106, Value Loss: 0.1904, Total Loss: 1.1010, LR: 0.001721
2025-04-27 10:02:06,728 [INFO] Epoch 6/15 - Policy Loss: 0.9079, Value Loss: 0.1891, Total Loss: 1.0969, LR: 0.000071
2025-04-27 10:02:45,372 [INFO] Epoch 7/15 - Policy Loss: 0.9053, Value Loss: 0.1883, Total Loss: 1.0936, LR: 0.001679
2025-04-27 10:03:30,447 [INFO] Epoch 8/15 - Policy Loss: 0.9038, Value Loss: 0.1872, Total Loss: 1.0910, LR: 0.003329
2025-04-27 10:04:11,670 [INFO] Epoch 9/15 - Policy Loss: 0.9025, Value Loss: 0.1865, Total Loss: 1.0890, LR: 0.004979
2025-04-27 10:05:02,203 [INFO] Epoch 10/15 - Policy Loss: 0.9014, Value Loss: 0.1856, Total Loss: 1.0870, LR: 0.003371
2025-04-27 10:05:54,613 [INFO] Epoch 11/15 - Policy Loss: 0.9003, Value Loss: 0.1851, Total Loss: 1.0853, LR: 0.001721
2025-04-27 10:06:49,731 [INFO] Epoch 12/15 - Policy Loss: 0.8987, Value Loss: 0.1843, Total Loss: 1.0831, LR: 0.000071
2025-04-27 10:07:36,569 [INFO] Epoch 13/15 - Policy Loss: 0.8974, Value Loss: 0.1836, Total Loss: 1.0810, LR: 0.001679
2025-04-27 10:08:32,898 [INFO] Epoch 14/15 - Policy Loss: 0.8962, Value Loss: 0.1831, Total Loss: 1.0793, LR: 0.003329
2025-04-27 10:09:15,599 [INFO] Epoch 15/15 - Policy Loss: 0.8952, Value Loss: 0.1826, Total Loss: 1.0779, LR: 0.004979
2025-04-27 10:09:15,633 [INFO] 训练完成，总损失: 1.0779
2025-04-27 10:09:15,633 [INFO] 保存迭代 232 的模型
2025-04-27 10:09:16,285 [INFO] Model saved to ./models/best.pt
2025-04-27 10:09:16,691 [INFO] Model saved to ./models/iteration_232.pt
2025-04-27 10:09:16,691 [INFO] 所有训练迭代完成
2025-04-27 10:09:16,692 [INFO] 开始迭代 233/300
2025-04-27 10:09:16,692 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 10:21:44,342 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 10:21:44,342 [INFO] 保存训练样本
2025-04-27 10:21:48,582 [INFO] 使用 160864 个样本训练神经网络
2025-04-27 10:21:48,583 [INFO] Training with 160864 examples
2025-04-27 10:21:48,583 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 10:21:48,676 [INFO] 循环学习率周期大小: 234 步
2025-04-27 10:22:36,745 [INFO] Epoch 1/15 - Policy Loss: 0.9320, Value Loss: 0.1926, Total Loss: 1.1247, LR: 0.001679
2025-04-27 10:23:20,187 [INFO] Epoch 2/15 - Policy Loss: 0.9242, Value Loss: 0.1892, Total Loss: 1.1134, LR: 0.003329
2025-04-27 10:24:05,976 [INFO] Epoch 3/15 - Policy Loss: 0.9208, Value Loss: 0.1866, Total Loss: 1.1074, LR: 0.004979
2025-04-27 10:24:46,876 [INFO] Epoch 4/15 - Policy Loss: 0.9180, Value Loss: 0.1856, Total Loss: 1.1036, LR: 0.003371
2025-04-27 10:25:28,061 [INFO] Epoch 5/15 - Policy Loss: 0.9151, Value Loss: 0.1845, Total Loss: 1.0996, LR: 0.001721
2025-04-27 10:26:18,149 [INFO] Epoch 6/15 - Policy Loss: 0.9120, Value Loss: 0.1838, Total Loss: 1.0958, LR: 0.000071
2025-04-27 10:27:08,406 [INFO] Epoch 7/15 - Policy Loss: 0.9093, Value Loss: 0.1824, Total Loss: 1.0917, LR: 0.001679
2025-04-27 10:27:52,916 [INFO] Epoch 8/15 - Policy Loss: 0.9067, Value Loss: 0.1813, Total Loss: 1.0880, LR: 0.003329
2025-04-27 10:28:34,586 [INFO] Epoch 9/15 - Policy Loss: 0.9048, Value Loss: 0.1804, Total Loss: 1.0852, LR: 0.004979
2025-04-27 10:29:20,242 [INFO] Epoch 10/15 - Policy Loss: 0.9042, Value Loss: 0.1802, Total Loss: 1.0843, LR: 0.003371
2025-04-27 10:30:01,487 [INFO] Epoch 11/15 - Policy Loss: 0.9027, Value Loss: 0.1795, Total Loss: 1.0823, LR: 0.001721
2025-04-27 10:30:52,135 [INFO] Epoch 12/15 - Policy Loss: 0.9010, Value Loss: 0.1790, Total Loss: 1.0800, LR: 0.000071
2025-04-27 10:31:42,177 [INFO] Epoch 13/15 - Policy Loss: 0.8996, Value Loss: 0.1784, Total Loss: 1.0781, LR: 0.001679
2025-04-27 10:32:47,204 [INFO] Epoch 14/15 - Policy Loss: 0.8982, Value Loss: 0.1778, Total Loss: 1.0760, LR: 0.003329
2025-04-27 10:33:35,980 [INFO] Epoch 15/15 - Policy Loss: 0.8974, Value Loss: 0.1775, Total Loss: 1.0749, LR: 0.004979
2025-04-27 10:33:36,044 [INFO] 训练完成，总损失: 1.0749
2025-04-27 10:33:36,044 [INFO] 保存迭代 233 的模型
2025-04-27 10:33:36,681 [INFO] Model saved to ./models/best.pt
2025-04-27 10:33:37,072 [INFO] Model saved to ./models/iteration_233.pt
2025-04-27 10:33:37,072 [INFO] 所有训练迭代完成
2025-04-27 10:33:37,072 [INFO] 开始迭代 234/300
2025-04-27 10:33:37,072 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 10:45:23,293 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 10:45:23,294 [INFO] 保存训练样本
2025-04-27 10:45:28,749 [INFO] 使用 160696 个样本训练神经网络
2025-04-27 10:45:28,749 [INFO] Training with 160696 examples
2025-04-27 10:45:28,749 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 10:45:28,828 [INFO] 循环学习率周期大小: 234 步
2025-04-27 10:46:20,602 [INFO] Epoch 1/15 - Policy Loss: 0.9173, Value Loss: 0.1760, Total Loss: 1.0933, LR: 0.001679
2025-04-27 10:47:06,721 [INFO] Epoch 2/15 - Policy Loss: 0.9127, Value Loss: 0.1739, Total Loss: 1.0866, LR: 0.003329
2025-04-27 10:47:52,028 [INFO] Epoch 3/15 - Policy Loss: 0.9084, Value Loss: 0.1718, Total Loss: 1.0802, LR: 0.004979
2025-04-27 10:48:37,319 [INFO] Epoch 4/15 - Policy Loss: 0.9072, Value Loss: 0.1715, Total Loss: 1.0787, LR: 0.003371
2025-04-27 10:49:30,407 [INFO] Epoch 5/15 - Policy Loss: 0.9053, Value Loss: 0.1703, Total Loss: 1.0756, LR: 0.001721
2025-04-27 10:50:11,705 [INFO] Epoch 6/15 - Policy Loss: 0.9035, Value Loss: 0.1689, Total Loss: 1.0724, LR: 0.000071
2025-04-27 10:51:05,424 [INFO] Epoch 7/15 - Policy Loss: 0.9013, Value Loss: 0.1682, Total Loss: 1.0695, LR: 0.001679
2025-04-27 10:51:57,595 [INFO] Epoch 8/15 - Policy Loss: 0.9006, Value Loss: 0.1675, Total Loss: 1.0680, LR: 0.003329
2025-04-27 10:52:45,292 [INFO] Epoch 9/15 - Policy Loss: 0.8996, Value Loss: 0.1668, Total Loss: 1.0663, LR: 0.004979
2025-04-27 10:53:23,412 [INFO] Epoch 10/15 - Policy Loss: 0.8991, Value Loss: 0.1666, Total Loss: 1.0657, LR: 0.003371
2025-04-27 10:54:16,084 [INFO] Epoch 11/15 - Policy Loss: 0.8979, Value Loss: 0.1662, Total Loss: 1.0641, LR: 0.001721
2025-04-27 10:54:59,038 [INFO] Epoch 12/15 - Policy Loss: 0.8968, Value Loss: 0.1657, Total Loss: 1.0626, LR: 0.000071
2025-04-27 10:55:40,817 [INFO] Epoch 13/15 - Policy Loss: 0.8957, Value Loss: 0.1651, Total Loss: 1.0607, LR: 0.001679
2025-04-27 10:56:26,421 [INFO] Epoch 14/15 - Policy Loss: 0.8946, Value Loss: 0.1647, Total Loss: 1.0593, LR: 0.003329
2025-04-27 10:57:21,644 [INFO] Epoch 15/15 - Policy Loss: 0.8943, Value Loss: 0.1644, Total Loss: 1.0587, LR: 0.004979
2025-04-27 10:57:21,671 [INFO] 训练完成，总损失: 1.0587
2025-04-27 10:57:21,671 [INFO] 保存迭代 234 的模型
2025-04-27 10:57:22,326 [INFO] Model saved to ./models/best.pt
2025-04-27 10:57:22,776 [INFO] Model saved to ./models/iteration_234.pt
2025-04-27 10:57:22,777 [INFO] 所有训练迭代完成
2025-04-27 10:57:22,777 [INFO] 开始迭代 235/300
2025-04-27 10:57:22,777 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 11:09:38,781 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 11:09:38,781 [INFO] 保存训练样本
2025-04-27 11:09:43,876 [INFO] 使用 161776 个样本训练神经网络
2025-04-27 11:09:43,876 [INFO] Training with 161776 examples
2025-04-27 11:09:43,877 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 11:09:44,573 [INFO] 循环学习率周期大小: 234 步
2025-04-27 11:10:31,785 [INFO] Epoch 1/15 - Policy Loss: 0.9134, Value Loss: 0.1551, Total Loss: 1.0684, LR: 0.001679
2025-04-27 11:11:12,865 [INFO] Epoch 2/15 - Policy Loss: 0.9079, Value Loss: 0.1529, Total Loss: 1.0608, LR: 0.003329
2025-04-27 11:11:58,326 [INFO] Epoch 3/15 - Policy Loss: 0.9062, Value Loss: 0.1525, Total Loss: 1.0587, LR: 0.004979
2025-04-27 11:12:40,530 [INFO] Epoch 4/15 - Policy Loss: 0.9042, Value Loss: 0.1531, Total Loss: 1.0573, LR: 0.003371
2025-04-27 11:13:22,929 [INFO] Epoch 5/15 - Policy Loss: 0.9028, Value Loss: 0.1527, Total Loss: 1.0556, LR: 0.001721
2025-04-27 11:14:08,408 [INFO] Epoch 6/15 - Policy Loss: 0.9014, Value Loss: 0.1524, Total Loss: 1.0538, LR: 0.000071
2025-04-27 11:14:50,197 [INFO] Epoch 7/15 - Policy Loss: 0.9004, Value Loss: 0.1520, Total Loss: 1.0523, LR: 0.001679
2025-04-27 11:15:36,746 [INFO] Epoch 8/15 - Policy Loss: 0.8997, Value Loss: 0.1516, Total Loss: 1.0513, LR: 0.003329
2025-04-27 11:16:19,338 [INFO] Epoch 9/15 - Policy Loss: 0.8983, Value Loss: 0.1511, Total Loss: 1.0494, LR: 0.004979
2025-04-27 11:17:05,640 [INFO] Epoch 10/15 - Policy Loss: 0.8971, Value Loss: 0.1510, Total Loss: 1.0481, LR: 0.003371
2025-04-27 11:17:51,164 [INFO] Epoch 11/15 - Policy Loss: 0.8959, Value Loss: 0.1508, Total Loss: 1.0467, LR: 0.001721
2025-04-27 11:18:32,257 [INFO] Epoch 12/15 - Policy Loss: 0.8944, Value Loss: 0.1503, Total Loss: 1.0447, LR: 0.000071
2025-04-27 11:19:20,735 [INFO] Epoch 13/15 - Policy Loss: 0.8933, Value Loss: 0.1501, Total Loss: 1.0435, LR: 0.001679
2025-04-27 11:20:06,184 [INFO] Epoch 14/15 - Policy Loss: 0.8927, Value Loss: 0.1499, Total Loss: 1.0426, LR: 0.003329
2025-04-27 11:20:50,690 [INFO] Epoch 15/15 - Policy Loss: 0.8919, Value Loss: 0.1496, Total Loss: 1.0415, LR: 0.004979
2025-04-27 11:20:50,734 [INFO] 训练完成，总损失: 1.0415
2025-04-27 11:20:50,734 [INFO] 保存迭代 235 的模型
2025-04-27 11:20:51,674 [INFO] Model saved to ./models/best.pt
2025-04-27 11:20:52,185 [INFO] Model saved to ./models/iteration_235.pt
2025-04-27 11:20:52,186 [INFO] 所有训练迭代完成
2025-04-27 11:20:52,186 [INFO] 开始迭代 236/300
2025-04-27 11:20:52,186 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 11:32:47,104 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 11:32:47,104 [INFO] 保存训练样本
2025-04-27 11:32:52,833 [INFO] 使用 162344 个样本训练神经网络
2025-04-27 11:32:52,833 [INFO] Training with 162344 examples
2025-04-27 11:32:52,834 [INFO] 总训练步数: 1185, 每轮次批次数: 79
2025-04-27 11:32:53,575 [INFO] 循环学习率周期大小: 237 步
2025-04-27 11:33:37,393 [INFO] Epoch 1/15 - Policy Loss: 0.9112, Value Loss: 0.1614, Total Loss: 1.0726, LR: 0.001679
2025-04-27 11:34:21,518 [INFO] Epoch 2/15 - Policy Loss: 0.9072, Value Loss: 0.1589, Total Loss: 1.0661, LR: 0.003329
2025-04-27 11:35:04,640 [INFO] Epoch 3/15 - Policy Loss: 0.9044, Value Loss: 0.1568, Total Loss: 1.0612, LR: 0.004979
2025-04-27 11:35:47,159 [INFO] Epoch 4/15 - Policy Loss: 0.9024, Value Loss: 0.1565, Total Loss: 1.0589, LR: 0.003371
2025-04-27 11:36:32,987 [INFO] Epoch 5/15 - Policy Loss: 0.9008, Value Loss: 0.1553, Total Loss: 1.0560, LR: 0.001721
2025-04-27 11:37:33,524 [INFO] Epoch 6/15 - Policy Loss: 0.8982, Value Loss: 0.1543, Total Loss: 1.0524, LR: 0.000071
2025-04-27 11:38:11,161 [INFO] Epoch 7/15 - Policy Loss: 0.8958, Value Loss: 0.1533, Total Loss: 1.0492, LR: 0.001679
2025-04-27 11:39:11,072 [INFO] Epoch 8/15 - Policy Loss: 0.8943, Value Loss: 0.1525, Total Loss: 1.0467, LR: 0.003329
2025-04-27 11:40:03,972 [INFO] Epoch 9/15 - Policy Loss: 0.8932, Value Loss: 0.1521, Total Loss: 1.0453, LR: 0.004979
2025-04-27 11:40:50,967 [INFO] Epoch 10/15 - Policy Loss: 0.8924, Value Loss: 0.1518, Total Loss: 1.0442, LR: 0.003371
2025-04-27 11:41:33,461 [INFO] Epoch 11/15 - Policy Loss: 0.8914, Value Loss: 0.1514, Total Loss: 1.0428, LR: 0.001721
2025-04-27 11:42:19,808 [INFO] Epoch 12/15 - Policy Loss: 0.8903, Value Loss: 0.1508, Total Loss: 1.0411, LR: 0.000071
2025-04-27 11:43:07,128 [INFO] Epoch 13/15 - Policy Loss: 0.8894, Value Loss: 0.1503, Total Loss: 1.0398, LR: 0.001679
2025-04-27 11:43:58,204 [INFO] Epoch 14/15 - Policy Loss: 0.8887, Value Loss: 0.1498, Total Loss: 1.0385, LR: 0.003329
2025-04-27 11:44:42,082 [INFO] Epoch 15/15 - Policy Loss: 0.8881, Value Loss: 0.1496, Total Loss: 1.0377, LR: 0.004979
2025-04-27 11:44:42,120 [INFO] 训练完成，总损失: 1.0377
2025-04-27 11:44:42,120 [INFO] 保存迭代 236 的模型
2025-04-27 11:44:42,791 [INFO] Model saved to ./models/best.pt
2025-04-27 11:44:43,188 [INFO] Model saved to ./models/iteration_236.pt
2025-04-27 11:44:43,189 [INFO] 所有训练迭代完成
2025-04-27 11:44:43,189 [INFO] 开始迭代 237/300
2025-04-27 11:44:43,189 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 11:55:32,652 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 11:55:32,653 [INFO] 保存训练样本
2025-04-27 11:55:36,861 [INFO] 使用 161520 个样本训练神经网络
2025-04-27 11:55:36,861 [INFO] Training with 161520 examples
2025-04-27 11:55:36,862 [INFO] 总训练步数: 1170, 每轮次批次数: 78
2025-04-27 11:55:36,912 [INFO] 循环学习率周期大小: 234 步
2025-04-27 11:56:23,203 [INFO] Epoch 1/15 - Policy Loss: 0.9055, Value Loss: 0.1520, Total Loss: 1.0575, LR: 0.001679
2025-04-27 11:57:01,069 [INFO] Epoch 2/15 - Policy Loss: 0.9022, Value Loss: 0.1502, Total Loss: 1.0524, LR: 0.003329
2025-04-27 11:57:50,485 [INFO] Epoch 3/15 - Policy Loss: 0.9001, Value Loss: 0.1493, Total Loss: 1.0495, LR: 0.004979
2025-04-27 11:58:37,730 [INFO] Epoch 4/15 - Policy Loss: 0.8975, Value Loss: 0.1491, Total Loss: 1.0466, LR: 0.003371
2025-04-27 11:59:24,672 [INFO] Epoch 5/15 - Policy Loss: 0.8955, Value Loss: 0.1486, Total Loss: 1.0441, LR: 0.001721
2025-04-27 12:00:08,593 [INFO] Epoch 6/15 - Policy Loss: 0.8927, Value Loss: 0.1479, Total Loss: 1.0406, LR: 0.000071
2025-04-27 12:01:15,046 [INFO] Epoch 7/15 - Policy Loss: 0.8911, Value Loss: 0.1475, Total Loss: 1.0386, LR: 0.001679
2025-04-27 12:02:17,968 [INFO] Epoch 8/15 - Policy Loss: 0.8893, Value Loss: 0.1468, Total Loss: 1.0361, LR: 0.003329
2025-04-27 12:03:08,297 [INFO] Epoch 9/15 - Policy Loss: 0.8882, Value Loss: 0.1465, Total Loss: 1.0348, LR: 0.004979
2025-04-27 12:03:51,905 [INFO] Epoch 10/15 - Policy Loss: 0.8876, Value Loss: 0.1466, Total Loss: 1.0342, LR: 0.003371
2025-04-27 12:04:47,468 [INFO] Epoch 11/15 - Policy Loss: 0.8869, Value Loss: 0.1462, Total Loss: 1.0331, LR: 0.001721
2025-04-27 12:05:33,953 [INFO] Epoch 12/15 - Policy Loss: 0.8861, Value Loss: 0.1457, Total Loss: 1.0318, LR: 0.000071
2025-04-27 12:06:15,816 [INFO] Epoch 13/15 - Policy Loss: 0.8845, Value Loss: 0.1452, Total Loss: 1.0297, LR: 0.001679
2025-04-27 12:07:04,407 [INFO] Epoch 14/15 - Policy Loss: 0.8836, Value Loss: 0.1449, Total Loss: 1.0285, LR: 0.003329
2025-04-27 12:07:52,614 [INFO] Epoch 15/15 - Policy Loss: 0.8828, Value Loss: 0.1447, Total Loss: 1.0274, LR: 0.004979
2025-04-27 12:07:52,657 [INFO] 训练完成，总损失: 1.0274
2025-04-27 12:07:52,657 [INFO] 保存迭代 237 的模型
2025-04-27 12:07:53,505 [INFO] Model saved to ./models/best.pt
2025-04-27 12:07:54,110 [INFO] Model saved to ./models/iteration_237.pt
2025-04-27 12:07:54,119 [INFO] 所有训练迭代完成
2025-04-27 12:07:54,119 [INFO] 开始迭代 238/300
2025-04-27 12:07:54,119 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 12:20:29,807 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 12:20:29,807 [INFO] 保存训练样本
2025-04-27 12:20:36,011 [INFO] 使用 162560 个样本训练神经网络
2025-04-27 12:20:36,012 [INFO] Training with 162560 examples
2025-04-27 12:20:36,012 [INFO] 总训练步数: 1185, 每轮次批次数: 79
2025-04-27 12:20:36,689 [INFO] 循环学习率周期大小: 237 步
2025-04-27 12:21:26,038 [INFO] Epoch 1/15 - Policy Loss: 0.9110, Value Loss: 0.1563, Total Loss: 1.0673, LR: 0.001679
2025-04-27 12:22:09,607 [INFO] Epoch 2/15 - Policy Loss: 0.9043, Value Loss: 0.1549, Total Loss: 1.0592, LR: 0.003329
2025-04-27 12:22:57,178 [INFO] Epoch 3/15 - Policy Loss: 0.9018, Value Loss: 0.1539, Total Loss: 1.0557, LR: 0.004979
2025-04-27 12:23:34,776 [INFO] Epoch 4/15 - Policy Loss: 0.8991, Value Loss: 0.1535, Total Loss: 1.0526, LR: 0.003371
2025-04-27 12:24:25,384 [INFO] Epoch 5/15 - Policy Loss: 0.8954, Value Loss: 0.1516, Total Loss: 1.0470, LR: 0.001721
2025-04-27 12:25:05,933 [INFO] Epoch 6/15 - Policy Loss: 0.8927, Value Loss: 0.1508, Total Loss: 1.0435, LR: 0.000071
2025-04-27 12:25:54,563 [INFO] Epoch 7/15 - Policy Loss: 0.8903, Value Loss: 0.1498, Total Loss: 1.0401, LR: 0.001679
2025-04-27 12:26:40,647 [INFO] Epoch 8/15 - Policy Loss: 0.8891, Value Loss: 0.1488, Total Loss: 1.0379, LR: 0.003329
2025-04-27 12:27:21,933 [INFO] Epoch 9/15 - Policy Loss: 0.8882, Value Loss: 0.1482, Total Loss: 1.0364, LR: 0.004979
2025-04-27 12:28:12,803 [INFO] Epoch 10/15 - Policy Loss: 0.8873, Value Loss: 0.1477, Total Loss: 1.0349, LR: 0.003371
2025-04-27 12:28:56,757 [INFO] Epoch 11/15 - Policy Loss: 0.8861, Value Loss: 0.1472, Total Loss: 1.0333, LR: 0.001721
2025-04-27 12:29:42,814 [INFO] Epoch 12/15 - Policy Loss: 0.8846, Value Loss: 0.1464, Total Loss: 1.0310, LR: 0.000071
2025-04-27 12:30:28,820 [INFO] Epoch 13/15 - Policy Loss: 0.8835, Value Loss: 0.1458, Total Loss: 1.0293, LR: 0.001679
2025-04-27 12:31:15,862 [INFO] Epoch 14/15 - Policy Loss: 0.8826, Value Loss: 0.1452, Total Loss: 1.0278, LR: 0.003329
2025-04-27 12:32:06,585 [INFO] Epoch 15/15 - Policy Loss: 0.8820, Value Loss: 0.1450, Total Loss: 1.0270, LR: 0.004979
2025-04-27 12:32:06,610 [INFO] 训练完成，总损失: 1.0270
2025-04-27 12:32:06,610 [INFO] 保存迭代 238 的模型
2025-04-27 12:32:07,190 [INFO] Model saved to ./models/best.pt
2025-04-27 12:32:07,599 [INFO] Model saved to ./models/iteration_238.pt
2025-04-27 12:32:07,600 [INFO] 所有训练迭代完成
2025-04-27 12:32:07,600 [INFO] 开始迭代 239/300
2025-04-27 12:32:07,600 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 12:44:12,276 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 12:44:12,277 [INFO] 保存训练样本
2025-04-27 12:44:17,696 [INFO] 使用 162400 个样本训练神经网络
2025-04-27 12:44:17,696 [INFO] Training with 162400 examples
2025-04-27 12:44:17,696 [INFO] 总训练步数: 1185, 每轮次批次数: 79
2025-04-27 12:44:18,457 [INFO] 循环学习率周期大小: 237 步
2025-04-27 12:45:04,250 [INFO] Epoch 1/15 - Policy Loss: 0.8973, Value Loss: 0.1475, Total Loss: 1.0448, LR: 0.001679
2025-04-27 12:45:46,220 [INFO] Epoch 2/15 - Policy Loss: 0.8924, Value Loss: 0.1452, Total Loss: 1.0376, LR: 0.003329
2025-04-27 12:46:37,795 [INFO] Epoch 3/15 - Policy Loss: 0.8908, Value Loss: 0.1450, Total Loss: 1.0357, LR: 0.004979
2025-04-27 12:47:14,326 [INFO] Epoch 4/15 - Policy Loss: 0.8893, Value Loss: 0.1447, Total Loss: 1.0340, LR: 0.003371
2025-04-27 12:48:04,825 [INFO] Epoch 5/15 - Policy Loss: 0.8867, Value Loss: 0.1441, Total Loss: 1.0308, LR: 0.001721
2025-04-27 12:48:45,639 [INFO] Epoch 6/15 - Policy Loss: 0.8847, Value Loss: 0.1434, Total Loss: 1.0281, LR: 0.000071
2025-04-27 12:49:37,148 [INFO] Epoch 7/15 - Policy Loss: 0.8829, Value Loss: 0.1427, Total Loss: 1.0256, LR: 0.001679
2025-04-27 12:50:24,445 [INFO] Epoch 8/15 - Policy Loss: 0.8814, Value Loss: 0.1422, Total Loss: 1.0236, LR: 0.003329
2025-04-27 12:51:19,394 [INFO] Epoch 9/15 - Policy Loss: 0.8799, Value Loss: 0.1416, Total Loss: 1.0215, LR: 0.004979
2025-04-27 12:52:16,041 [INFO] Epoch 10/15 - Policy Loss: 0.8791, Value Loss: 0.1415, Total Loss: 1.0207, LR: 0.003371
2025-04-27 12:52:59,991 [INFO] Epoch 11/15 - Policy Loss: 0.8783, Value Loss: 0.1413, Total Loss: 1.0195, LR: 0.001721
2025-04-27 12:53:49,512 [INFO] Epoch 12/15 - Policy Loss: 0.8770, Value Loss: 0.1408, Total Loss: 1.0178, LR: 0.000071
2025-04-27 12:54:37,024 [INFO] Epoch 13/15 - Policy Loss: 0.8756, Value Loss: 0.1405, Total Loss: 1.0160, LR: 0.001679
2025-04-27 12:55:19,687 [INFO] Epoch 14/15 - Policy Loss: 0.8744, Value Loss: 0.1401, Total Loss: 1.0145, LR: 0.003329
2025-04-27 12:55:59,052 [INFO] Epoch 15/15 - Policy Loss: 0.8739, Value Loss: 0.1400, Total Loss: 1.0139, LR: 0.004979
2025-04-27 12:55:59,086 [INFO] 训练完成，总损失: 1.0139
2025-04-27 12:55:59,086 [INFO] 保存迭代 239 的模型
2025-04-27 12:55:59,716 [INFO] Model saved to ./models/best.pt
2025-04-27 12:56:00,101 [INFO] Model saved to ./models/iteration_239.pt
2025-04-27 12:56:00,103 [INFO] 所有训练迭代完成
2025-04-27 12:56:00,103 [INFO] 开始迭代 240/300
2025-04-27 12:56:00,103 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 13:07:46,564 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 13:07:46,564 [INFO] 保存训练样本
2025-04-27 13:07:52,162 [INFO] 使用 162592 个样本训练神经网络
2025-04-27 13:07:52,163 [INFO] Training with 162592 examples
2025-04-27 13:07:52,164 [INFO] 总训练步数: 1185, 每轮次批次数: 79
2025-04-27 13:07:52,286 [INFO] 循环学习率周期大小: 237 步
2025-04-27 13:08:36,865 [INFO] Epoch 1/15 - Policy Loss: 0.8840, Value Loss: 0.1401, Total Loss: 1.0242, LR: 0.001679
2025-04-27 13:09:24,032 [INFO] Epoch 2/15 - Policy Loss: 0.8790, Value Loss: 0.1377, Total Loss: 1.0167, LR: 0.003329
2025-04-27 13:10:15,211 [INFO] Epoch 3/15 - Policy Loss: 0.8783, Value Loss: 0.1379, Total Loss: 1.0163, LR: 0.004979
2025-04-27 13:10:53,280 [INFO] Epoch 4/15 - Policy Loss: 0.8764, Value Loss: 0.1379, Total Loss: 1.0143, LR: 0.003371
2025-04-27 13:11:44,452 [INFO] Epoch 5/15 - Policy Loss: 0.8740, Value Loss: 0.1377, Total Loss: 1.0117, LR: 0.001721
2025-04-27 13:12:42,418 [INFO] Epoch 6/15 - Policy Loss: 0.8722, Value Loss: 0.1372, Total Loss: 1.0093, LR: 0.000071
2025-04-27 13:13:24,009 [INFO] Epoch 7/15 - Policy Loss: 0.8704, Value Loss: 0.1365, Total Loss: 1.0069, LR: 0.001679
2025-04-27 13:14:05,613 [INFO] Epoch 8/15 - Policy Loss: 0.8698, Value Loss: 0.1361, Total Loss: 1.0060, LR: 0.003329
2025-04-27 13:15:02,974 [INFO] Epoch 9/15 - Policy Loss: 0.8694, Value Loss: 0.1358, Total Loss: 1.0052, LR: 0.004979
2025-04-27 13:15:45,101 [INFO] Epoch 10/15 - Policy Loss: 0.8689, Value Loss: 0.1356, Total Loss: 1.0045, LR: 0.003371
2025-04-27 13:16:33,529 [INFO] Epoch 11/15 - Policy Loss: 0.8687, Value Loss: 0.1356, Total Loss: 1.0043, LR: 0.001721
2025-04-27 13:17:17,633 [INFO] Epoch 12/15 - Policy Loss: 0.8680, Value Loss: 0.1353, Total Loss: 1.0033, LR: 0.000071
2025-04-27 13:18:04,679 [INFO] Epoch 13/15 - Policy Loss: 0.8674, Value Loss: 0.1348, Total Loss: 1.0022, LR: 0.001679
2025-04-27 13:18:52,819 [INFO] Epoch 14/15 - Policy Loss: 0.8663, Value Loss: 0.1344, Total Loss: 1.0007, LR: 0.003329
2025-04-27 13:19:37,818 [INFO] Epoch 15/15 - Policy Loss: 0.8660, Value Loss: 0.1344, Total Loss: 1.0004, LR: 0.004979
2025-04-27 13:19:37,865 [INFO] 训练完成，总损失: 1.0004
2025-04-27 13:19:37,865 [INFO] 保存迭代 240 的模型
2025-04-27 13:19:38,720 [INFO] Model saved to ./models/best.pt
2025-04-27 13:19:39,278 [INFO] Model saved to ./models/iteration_240.pt
2025-04-27 13:19:39,279 [INFO] 所有训练迭代完成
2025-04-27 13:19:39,279 [INFO] 开始迭代 241/300
2025-04-27 13:19:39,279 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 13:31:47,383 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 13:31:47,383 [INFO] 保存训练样本
2025-04-27 13:31:52,925 [INFO] 使用 163088 个样本训练神经网络
2025-04-27 13:31:52,925 [INFO] Training with 163088 examples
2025-04-27 13:31:52,926 [INFO] 总训练步数: 1185, 每轮次批次数: 79
2025-04-27 13:31:53,715 [INFO] 循环学习率周期大小: 237 步
2025-04-27 13:32:35,031 [INFO] Epoch 1/15 - Policy Loss: 0.8817, Value Loss: 0.1385, Total Loss: 1.0201, LR: 0.001679
2025-04-27 13:33:25,591 [INFO] Epoch 2/15 - Policy Loss: 0.8768, Value Loss: 0.1388, Total Loss: 1.0157, LR: 0.003329
2025-04-27 13:34:12,919 [INFO] Epoch 3/15 - Policy Loss: 0.8772, Value Loss: 0.1391, Total Loss: 1.0163, LR: 0.004979
2025-04-27 13:34:51,080 [INFO] Epoch 4/15 - Policy Loss: 0.8755, Value Loss: 0.1381, Total Loss: 1.0137, LR: 0.003371
2025-04-27 13:35:41,007 [INFO] Epoch 5/15 - Policy Loss: 0.8728, Value Loss: 0.1370, Total Loss: 1.0098, LR: 0.001721
2025-04-27 13:36:28,601 [INFO] Epoch 6/15 - Policy Loss: 0.8707, Value Loss: 0.1360, Total Loss: 1.0067, LR: 0.000071
2025-04-27 13:37:05,300 [INFO] Epoch 7/15 - Policy Loss: 0.8688, Value Loss: 0.1354, Total Loss: 1.0042, LR: 0.001679
2025-04-27 13:37:53,957 [INFO] Epoch 8/15 - Policy Loss: 0.8676, Value Loss: 0.1347, Total Loss: 1.0023, LR: 0.003329
2025-04-27 13:38:40,191 [INFO] Epoch 9/15 - Policy Loss: 0.8670, Value Loss: 0.1343, Total Loss: 1.0013, LR: 0.004979
2025-04-27 13:39:31,169 [INFO] Epoch 10/15 - Policy Loss: 0.8668, Value Loss: 0.1339, Total Loss: 1.0007, LR: 0.003371
2025-04-27 13:40:18,314 [INFO] Epoch 11/15 - Policy Loss: 0.8661, Value Loss: 0.1336, Total Loss: 0.9996, LR: 0.001721
2025-04-27 13:41:01,050 [INFO] Epoch 12/15 - Policy Loss: 0.8653, Value Loss: 0.1331, Total Loss: 0.9984, LR: 0.000071
2025-04-27 13:41:47,794 [INFO] Epoch 13/15 - Policy Loss: 0.8643, Value Loss: 0.1326, Total Loss: 0.9970, LR: 0.001679
2025-04-27 13:42:29,490 [INFO] Epoch 14/15 - Policy Loss: 0.8637, Value Loss: 0.1321, Total Loss: 0.9958, LR: 0.003329
2025-04-27 13:43:18,293 [INFO] Epoch 15/15 - Policy Loss: 0.8631, Value Loss: 0.1319, Total Loss: 0.9951, LR: 0.004979
2025-04-27 13:43:18,340 [INFO] 训练完成，总损失: 0.9951
2025-04-27 13:43:18,341 [INFO] 保存迭代 241 的模型
2025-04-27 13:43:19,148 [INFO] Model saved to ./models/best.pt
2025-04-27 13:43:19,714 [INFO] Model saved to ./models/iteration_241.pt
2025-04-27 13:43:19,715 [INFO] 所有训练迭代完成
2025-04-27 13:43:19,715 [INFO] 开始迭代 242/300
2025-04-27 13:43:19,715 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 13:55:50,305 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 13:55:50,306 [INFO] 保存训练样本
2025-04-27 13:55:55,346 [INFO] 使用 163904 个样本训练神经网络
2025-04-27 13:55:55,346 [INFO] Training with 163904 examples
2025-04-27 13:55:55,347 [INFO] 总训练步数: 1200, 每轮次批次数: 80
2025-04-27 13:55:55,816 [INFO] 循环学习率周期大小: 240 步
2025-04-27 13:56:43,596 [INFO] Epoch 1/15 - Policy Loss: 0.8749, Value Loss: 0.1472, Total Loss: 1.0221, LR: 0.001679
2025-04-27 13:57:25,748 [INFO] Epoch 2/15 - Policy Loss: 0.8693, Value Loss: 0.1448, Total Loss: 1.0141, LR: 0.003329
2025-04-27 13:58:12,045 [INFO] Epoch 3/15 - Policy Loss: 0.8701, Value Loss: 0.1441, Total Loss: 1.0142, LR: 0.004979
2025-04-27 13:58:53,798 [INFO] Epoch 4/15 - Policy Loss: 0.8694, Value Loss: 0.1438, Total Loss: 1.0132, LR: 0.003371
2025-04-27 13:59:43,892 [INFO] Epoch 5/15 - Policy Loss: 0.8683, Value Loss: 0.1430, Total Loss: 1.0113, LR: 0.001721
2025-04-27 14:00:33,708 [INFO] Epoch 6/15 - Policy Loss: 0.8666, Value Loss: 0.1419, Total Loss: 1.0085, LR: 0.000071
2025-04-27 14:01:15,478 [INFO] Epoch 7/15 - Policy Loss: 0.8647, Value Loss: 0.1410, Total Loss: 1.0057, LR: 0.001679
2025-04-27 14:02:02,884 [INFO] Epoch 8/15 - Policy Loss: 0.8636, Value Loss: 0.1401, Total Loss: 1.0037, LR: 0.003329
2025-04-27 14:02:50,605 [INFO] Epoch 9/15 - Policy Loss: 0.8621, Value Loss: 0.1396, Total Loss: 1.0016, LR: 0.004979
2025-04-27 14:03:32,283 [INFO] Epoch 10/15 - Policy Loss: 0.8618, Value Loss: 0.1393, Total Loss: 1.0010, LR: 0.003371
2025-04-27 14:04:14,701 [INFO] Epoch 11/15 - Policy Loss: 0.8608, Value Loss: 0.1388, Total Loss: 0.9996, LR: 0.001721
2025-04-27 14:04:56,337 [INFO] Epoch 12/15 - Policy Loss: 0.8593, Value Loss: 0.1381, Total Loss: 0.9974, LR: 0.000071
2025-04-27 14:05:49,663 [INFO] Epoch 13/15 - Policy Loss: 0.8582, Value Loss: 0.1377, Total Loss: 0.9959, LR: 0.001679
2025-04-27 14:06:36,309 [INFO] Epoch 14/15 - Policy Loss: 0.8572, Value Loss: 0.1372, Total Loss: 0.9944, LR: 0.003329
2025-04-27 14:07:22,284 [INFO] Epoch 15/15 - Policy Loss: 0.8567, Value Loss: 0.1369, Total Loss: 0.9935, LR: 0.004979
2025-04-27 14:07:22,319 [INFO] 训练完成，总损失: 0.9935
2025-04-27 14:07:22,320 [INFO] 保存迭代 242 的模型
2025-04-27 14:07:22,860 [INFO] Model saved to ./models/best.pt
2025-04-27 14:07:23,243 [INFO] Model saved to ./models/iteration_242.pt
2025-04-27 14:07:23,244 [INFO] 所有训练迭代完成
2025-04-27 14:07:23,244 [INFO] 开始迭代 243/300
2025-04-27 14:07:23,244 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 14:18:52,416 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 14:18:52,418 [INFO] 保存训练样本
2025-04-27 14:18:59,844 [INFO] 使用 163360 个样本训练神经网络
2025-04-27 14:18:59,845 [INFO] Training with 163360 examples
2025-04-27 14:18:59,845 [INFO] 总训练步数: 1185, 每轮次批次数: 79
2025-04-27 14:18:59,942 [INFO] 循环学习率周期大小: 237 步
2025-04-27 14:19:48,740 [INFO] Epoch 1/15 - Policy Loss: 0.8658, Value Loss: 0.1377, Total Loss: 1.0035, LR: 0.001679
2025-04-27 14:20:33,761 [INFO] Epoch 2/15 - Policy Loss: 0.8625, Value Loss: 0.1380, Total Loss: 1.0004, LR: 0.003329
2025-04-27 14:21:12,161 [INFO] Epoch 3/15 - Policy Loss: 0.8617, Value Loss: 0.1380, Total Loss: 0.9996, LR: 0.004979
2025-04-27 14:21:55,916 [INFO] Epoch 4/15 - Policy Loss: 0.8614, Value Loss: 0.1381, Total Loss: 0.9994, LR: 0.003371
2025-04-27 14:22:43,641 [INFO] Epoch 5/15 - Policy Loss: 0.8600, Value Loss: 0.1374, Total Loss: 0.9974, LR: 0.001721
2025-04-27 14:23:30,218 [INFO] Epoch 6/15 - Policy Loss: 0.8584, Value Loss: 0.1366, Total Loss: 0.9950, LR: 0.000071
2025-04-27 14:24:08,930 [INFO] Epoch 7/15 - Policy Loss: 0.8575, Value Loss: 0.1358, Total Loss: 0.9933, LR: 0.001679
2025-04-27 14:27:19,315 [INFO] 设置多进程启动方法为: spawn
2025-04-27 14:27:19,435 [INFO] CUDA可用，使用GPU
2025-04-27 14:27:19,435 [INFO] 配置参数:
2025-04-27 14:27:19,435 [INFO] 训练参数:
2025-04-27 14:27:19,435 [INFO]   训练轮数: 15
2025-04-27 14:27:19,435 [INFO]   批量大小: 2048
2025-04-27 14:27:19,435 [INFO]   迭代次数: 300
2025-04-27 14:27:19,435 [INFO]   每次迭代的自我对弈次数: 50
2025-04-27 14:27:19,435 [INFO]   训练样本队列最大长度: 200000
2025-04-27 14:27:19,435 [INFO]   保留的历史迭代数: 20
2025-04-27 14:27:19,435 [INFO]   新模型胜率阈值: 0.55
2025-04-27 14:27:19,435 [INFO]   竞技场比赛次数: 40
2025-04-27 14:27:19,435 [INFO]   温度阈值: 5
2025-04-27 14:27:19,436 [INFO] 神经网络参数:
2025-04-27 14:27:19,436 [INFO]   通道数: 256
2025-04-27 14:27:19,436 [INFO]   Dropout率: 0.3
2025-04-27 14:27:19,436 [INFO]   学习率范围: 5e-05 - 0.005
2025-04-27 14:27:19,436 [INFO]   梯度裁剪: 1.0
2025-04-27 14:27:19,436 [INFO]   优化器: adam
2025-04-27 14:27:19,436 [INFO] MCTS参数:
2025-04-27 14:27:19,436 [INFO]   模拟次数: 800
2025-04-27 14:27:19,436 [INFO]   PUCT常数: 4.0
2025-04-27 14:27:19,436 [INFO]   Dirichlet噪声参数: 0.3
2025-04-27 14:27:19,436 [INFO]   Dirichlet噪声权重: 0.25
2025-04-27 14:27:19,436 [INFO] 游戏参数:
2025-04-27 14:27:19,436 [INFO]   棋盘大小: 15
2025-04-27 14:27:19,436 [INFO]   获胜所需的连续棋子数: 5
2025-04-27 14:27:19,436 [INFO] 系统参数:
2025-04-27 14:27:19,436 [INFO]   使用CUDA: True
2025-04-27 14:27:19,436 [INFO]   检查点目录: ./models
2025-04-27 14:27:19,436 [INFO]   数据目录: ./data
2025-04-27 14:27:19,437 [INFO]   加载模型: False
2025-04-27 14:27:19,437 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-27 14:27:19,437 [INFO]   工作线程数: 4
2025-04-27 14:27:19,437 [INFO]   使用Weights & Biases: False
2025-04-27 14:27:19,437 [INFO] GUI参数:
2025-04-27 14:27:19,437 [INFO]   窗口宽度: 800
2025-04-27 14:27:19,437 [INFO]   窗口高度: 850
2025-04-27 14:27:19,437 [INFO]   格子大小: 40
2025-04-27 14:27:19,437 [INFO]   边距: 40
2025-04-27 14:27:19,437 [INFO]   底部边距: 80
2025-04-27 14:27:19,437 [INFO]   帧率: 30
2025-04-27 14:27:20,390 [INFO] Using device: cuda
2025-04-27 14:27:22,656 [INFO] 设置循环学习率: 最小值=5e-05, 最大值=0.005
2025-04-27 14:27:22,657 [INFO] 设置并行进程数为: 8
2025-04-27 14:27:22,657 [INFO] 开始训练
2025-04-27 14:27:22,660 [INFO] 加载之前的训练样本
2025-04-27 14:27:24,583 [INFO] 加载了 20 组训练样本
2025-04-27 14:27:24,583 [INFO] 开始迭代 1/300
2025-04-27 14:27:24,583 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 14:32:47,409 [INFO] 设置多进程启动方法为: spawn
2025-04-27 14:32:47,479 [INFO] CUDA可用，使用GPU
2025-04-27 14:32:47,480 [INFO] 配置参数:
2025-04-27 14:32:47,480 [INFO] 训练参数:
2025-04-27 14:32:47,480 [INFO]   训练轮数: 15
2025-04-27 14:32:47,480 [INFO]   批量大小: 2048
2025-04-27 14:32:47,480 [INFO]   迭代次数: 300
2025-04-27 14:32:47,480 [INFO]   每次迭代的自我对弈次数: 50
2025-04-27 14:32:47,480 [INFO]   训练样本队列最大长度: 200000
2025-04-27 14:32:47,480 [INFO]   保留的历史迭代数: 20
2025-04-27 14:32:47,480 [INFO]   新模型胜率阈值: 0.55
2025-04-27 14:32:47,480 [INFO]   竞技场比赛次数: 40
2025-04-27 14:32:47,480 [INFO]   温度阈值: 5
2025-04-27 14:32:47,480 [INFO] 神经网络参数:
2025-04-27 14:32:47,480 [INFO]   通道数: 256
2025-04-27 14:32:47,480 [INFO]   Dropout率: 0.3
2025-04-27 14:32:47,480 [INFO]   学习率范围: 5e-05 - 0.005
2025-04-27 14:32:47,480 [INFO]   梯度裁剪: 1.0
2025-04-27 14:32:47,480 [INFO]   优化器: adam
2025-04-27 14:32:47,480 [INFO] MCTS参数:
2025-04-27 14:32:47,480 [INFO]   模拟次数: 800
2025-04-27 14:32:47,480 [INFO]   PUCT常数: 4.0
2025-04-27 14:32:47,480 [INFO]   Dirichlet噪声参数: 0.3
2025-04-27 14:32:47,480 [INFO]   Dirichlet噪声权重: 0.25
2025-04-27 14:32:47,480 [INFO] 游戏参数:
2025-04-27 14:32:47,480 [INFO]   棋盘大小: 15
2025-04-27 14:32:47,480 [INFO]   获胜所需的连续棋子数: 5
2025-04-27 14:32:47,480 [INFO] 系统参数:
2025-04-27 14:32:47,481 [INFO]   使用CUDA: True
2025-04-27 14:32:47,481 [INFO]   检查点目录: ./models
2025-04-27 14:32:47,481 [INFO]   数据目录: ./data
2025-04-27 14:32:47,481 [INFO]   加载模型: False
2025-04-27 14:32:47,481 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-04-27 14:32:47,481 [INFO]   工作线程数: 4
2025-04-27 14:32:47,481 [INFO]   使用Weights & Biases: False
2025-04-27 14:32:47,481 [INFO] GUI参数:
2025-04-27 14:32:47,481 [INFO]   窗口宽度: 800
2025-04-27 14:32:47,481 [INFO]   窗口高度: 850
2025-04-27 14:32:47,481 [INFO]   格子大小: 40
2025-04-27 14:32:47,481 [INFO]   边距: 40
2025-04-27 14:32:47,481 [INFO]   底部边距: 80
2025-04-27 14:32:47,481 [INFO]   帧率: 30
2025-04-27 14:32:47,987 [INFO] Using device: cuda
2025-04-27 14:32:49,669 [INFO] 设置循环学习率: 最小值=5e-05, 最大值=0.005
2025-04-27 14:32:49,669 [INFO] 设置并行进程数为: 8
2025-04-27 14:32:49,669 [INFO] 开始训练
2025-04-27 14:32:49,669 [INFO] 加载之前的训练样本
2025-04-27 14:32:51,633 [INFO] 加载了 20 组训练样本
2025-04-27 14:32:51,633 [INFO] 开始迭代 1/300
2025-04-27 14:32:51,633 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 15:35:48,283 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 15:35:48,292 [INFO] 保存训练样本
2025-04-27 15:35:56,153 [INFO] 使用 175504 个样本训练神经网络
2025-04-27 15:35:56,153 [INFO] Training with 175504 examples
2025-04-27 15:35:56,154 [INFO] 总训练步数: 1275, 每轮次批次数: 85
2025-04-27 15:35:56,302 [INFO] 循环学习率周期大小: 255 步
2025-04-27 15:37:03,281 [INFO] Epoch 1/15 - Policy Loss: 3.7944, Value Loss: 0.5269, Total Loss: 4.3213, LR: 0.001681
2025-04-27 15:38:10,735 [INFO] Epoch 2/15 - Policy Loss: 3.1143, Value Loss: 0.4451, Total Loss: 3.5594, LR: 0.003331
2025-04-27 15:39:18,516 [INFO] Epoch 3/15 - Policy Loss: 2.7751, Value Loss: 0.3997, Total Loss: 3.1747, LR: 0.004981
2025-04-27 15:40:20,207 [INFO] Epoch 4/15 - Policy Loss: 2.5522, Value Loss: 0.3620, Total Loss: 2.9142, LR: 0.003369
2025-04-27 15:41:23,000 [INFO] Epoch 5/15 - Policy Loss: 2.3852, Value Loss: 0.3297, Total Loss: 2.7149, LR: 0.001719
2025-04-27 15:42:35,808 [INFO] Epoch 6/15 - Policy Loss: 2.2560, Value Loss: 0.3023, Total Loss: 2.5583, LR: 0.000069
2025-04-27 15:43:44,447 [INFO] Epoch 7/15 - Policy Loss: 2.1575, Value Loss: 0.2814, Total Loss: 2.4389, LR: 0.001681
2025-04-27 15:44:49,664 [INFO] Epoch 8/15 - Policy Loss: 2.0888, Value Loss: 0.2675, Total Loss: 2.3563, LR: 0.003331
2025-04-27 15:45:52,610 [INFO] Epoch 9/15 - Policy Loss: 2.0423, Value Loss: 0.2587, Total Loss: 2.3010, LR: 0.004981
2025-04-27 15:46:54,983 [INFO] Epoch 10/15 - Policy Loss: 2.0040, Value Loss: 0.2506, Total Loss: 2.2546, LR: 0.003369
2025-04-27 15:48:01,488 [INFO] Epoch 11/15 - Policy Loss: 1.9624, Value Loss: 0.2409, Total Loss: 2.2033, LR: 0.001719
2025-04-27 15:49:09,257 [INFO] Epoch 12/15 - Policy Loss: 1.9217, Value Loss: 0.2313, Total Loss: 2.1530, LR: 0.000069
2025-04-27 15:50:23,055 [INFO] Epoch 13/15 - Policy Loss: 1.8857, Value Loss: 0.2228, Total Loss: 2.1085, LR: 0.001681
2025-04-27 15:51:29,215 [INFO] Epoch 14/15 - Policy Loss: 1.8564, Value Loss: 0.2161, Total Loss: 2.0725, LR: 0.003331
2025-04-27 15:52:40,155 [INFO] Epoch 15/15 - Policy Loss: 1.8357, Value Loss: 0.2113, Total Loss: 2.0469, LR: 0.004981
2025-04-27 15:52:40,200 [INFO] 训练完成，总损失: 2.0469
2025-04-27 15:52:40,200 [INFO] 保存迭代 1 的模型
2025-04-27 15:52:41,099 [INFO] Model saved to ./models/best.pt
2025-04-27 15:52:42,371 [INFO] Model saved to ./models/iteration_1.pt
2025-04-27 15:52:42,378 [INFO] 所有训练迭代完成
2025-04-27 15:52:42,378 [INFO] 开始迭代 2/300
2025-04-27 15:52:42,378 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 16:11:44,483 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 16:11:44,484 [INFO] 保存训练样本
2025-04-27 16:11:52,003 [INFO] 使用 176016 个样本训练神经网络
2025-04-27 16:11:52,003 [INFO] Training with 176016 examples
2025-04-27 16:11:52,004 [INFO] 总训练步数: 1275, 每轮次批次数: 85
2025-04-27 16:11:52,792 [INFO] 循环学习率周期大小: 255 步
2025-04-27 16:12:54,009 [INFO] Epoch 1/15 - Policy Loss: 1.5358, Value Loss: 0.1369, Total Loss: 1.6727, LR: 0.001681
2025-04-27 16:13:59,717 [INFO] Epoch 2/15 - Policy Loss: 1.5159, Value Loss: 0.1339, Total Loss: 1.6499, LR: 0.003331
2025-04-27 16:15:13,138 [INFO] Epoch 3/15 - Policy Loss: 1.5201, Value Loss: 0.1353, Total Loss: 1.6554, LR: 0.004981
2025-04-27 16:16:14,981 [INFO] Epoch 4/15 - Policy Loss: 1.5261, Value Loss: 0.1373, Total Loss: 1.6635, LR: 0.003369
2025-04-27 16:17:29,467 [INFO] Epoch 5/15 - Policy Loss: 1.5147, Value Loss: 0.1343, Total Loss: 1.6490, LR: 0.001719
2025-04-27 16:18:32,804 [INFO] Epoch 6/15 - Policy Loss: 1.5005, Value Loss: 0.1311, Total Loss: 1.6316, LR: 0.000069
2025-04-27 16:19:38,714 [INFO] Epoch 7/15 - Policy Loss: 1.4866, Value Loss: 0.1281, Total Loss: 1.6147, LR: 0.001681
2025-04-27 16:20:54,391 [INFO] Epoch 8/15 - Policy Loss: 1.4795, Value Loss: 0.1265, Total Loss: 1.6060, LR: 0.003331
2025-04-27 16:22:00,933 [INFO] Epoch 9/15 - Policy Loss: 1.4784, Value Loss: 0.1263, Total Loss: 1.6047, LR: 0.004981
2025-04-27 16:23:22,280 [INFO] Epoch 10/15 - Policy Loss: 1.4807, Value Loss: 0.1264, Total Loss: 1.6072, LR: 0.003369
2025-04-27 16:24:34,751 [INFO] Epoch 11/15 - Policy Loss: 1.4768, Value Loss: 0.1256, Total Loss: 1.6024, LR: 0.001719
2025-04-27 16:25:41,737 [INFO] Epoch 12/15 - Policy Loss: 1.4701, Value Loss: 0.1244, Total Loss: 1.5944, LR: 0.000069
2025-04-27 16:26:58,823 [INFO] Epoch 13/15 - Policy Loss: 1.4639, Value Loss: 0.1230, Total Loss: 1.5870, LR: 0.001681
2025-04-27 16:28:05,106 [INFO] Epoch 14/15 - Policy Loss: 1.4597, Value Loss: 0.1220, Total Loss: 1.5817, LR: 0.003331
2025-04-27 16:29:18,892 [INFO] Epoch 15/15 - Policy Loss: 1.4585, Value Loss: 0.1215, Total Loss: 1.5800, LR: 0.004981
2025-04-27 16:29:18,930 [INFO] 训练完成，总损失: 1.5800
2025-04-27 16:29:18,930 [INFO] 保存迭代 2 的模型
2025-04-27 16:29:20,537 [INFO] Model saved to ./models/best.pt
2025-04-27 16:29:21,717 [INFO] Model saved to ./models/iteration_2.pt
2025-04-27 16:29:21,717 [INFO] 所有训练迭代完成
2025-04-27 16:29:21,717 [INFO] 开始迭代 3/300
2025-04-27 16:29:21,717 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 16:49:27,012 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 16:49:27,012 [INFO] 保存训练样本
2025-04-27 16:49:32,737 [INFO] 使用 176168 个样本训练神经网络
2025-04-27 16:49:32,738 [INFO] Training with 176168 examples
2025-04-27 16:49:32,739 [INFO] 总训练步数: 1290, 每轮次批次数: 86
2025-04-27 16:49:33,399 [INFO] 循环学习率周期大小: 258 步
2025-04-27 16:50:48,869 [INFO] Epoch 1/15 - Policy Loss: 1.4718, Value Loss: 0.1137, Total Loss: 1.5855, LR: 0.001681
2025-04-27 16:51:56,149 [INFO] Epoch 2/15 - Policy Loss: 1.4587, Value Loss: 0.1099, Total Loss: 1.5687, LR: 0.003331
2025-04-27 16:52:59,572 [INFO] Epoch 3/15 - Policy Loss: 1.4616, Value Loss: 0.1103, Total Loss: 1.5720, LR: 0.004981
2025-04-27 16:54:01,375 [INFO] Epoch 4/15 - Policy Loss: 1.4686, Value Loss: 0.1136, Total Loss: 1.5822, LR: 0.003369
2025-04-27 16:55:03,861 [INFO] Epoch 5/15 - Policy Loss: 1.4635, Value Loss: 0.1123, Total Loss: 1.5757, LR: 0.001719
2025-04-27 16:56:12,116 [INFO] Epoch 6/15 - Policy Loss: 1.4531, Value Loss: 0.1103, Total Loss: 1.5634, LR: 0.000069
2025-04-27 16:57:13,989 [INFO] Epoch 7/15 - Policy Loss: 1.4425, Value Loss: 0.1084, Total Loss: 1.5509, LR: 0.001681
2025-04-27 16:58:24,707 [INFO] Epoch 8/15 - Policy Loss: 1.4356, Value Loss: 0.1074, Total Loss: 1.5429, LR: 0.003331
2025-04-27 16:59:32,148 [INFO] Epoch 9/15 - Policy Loss: 1.4349, Value Loss: 0.1070, Total Loss: 1.5419, LR: 0.004981
2025-04-27 17:00:36,081 [INFO] Epoch 10/15 - Policy Loss: 1.4377, Value Loss: 0.1074, Total Loss: 1.5451, LR: 0.003369
2025-04-27 17:01:42,639 [INFO] Epoch 11/15 - Policy Loss: 1.4359, Value Loss: 0.1071, Total Loss: 1.5430, LR: 0.001719
2025-04-27 17:02:46,570 [INFO] Epoch 12/15 - Policy Loss: 1.4317, Value Loss: 0.1065, Total Loss: 1.5382, LR: 0.000069
2025-04-27 17:04:02,557 [INFO] Epoch 13/15 - Policy Loss: 1.4268, Value Loss: 0.1057, Total Loss: 1.5326, LR: 0.001681
2025-04-27 17:05:16,884 [INFO] Epoch 14/15 - Policy Loss: 1.4239, Value Loss: 0.1053, Total Loss: 1.5291, LR: 0.003331
2025-04-27 17:06:17,599 [INFO] Epoch 15/15 - Policy Loss: 1.4236, Value Loss: 0.1052, Total Loss: 1.5288, LR: 0.004981
2025-04-27 17:06:17,643 [INFO] 训练完成，总损失: 1.5288
2025-04-27 17:06:17,643 [INFO] 保存迭代 3 的模型
2025-04-27 17:06:18,994 [INFO] Model saved to ./models/best.pt
2025-04-27 17:06:19,818 [INFO] Model saved to ./models/iteration_3.pt
2025-04-27 17:06:19,819 [INFO] 所有训练迭代完成
2025-04-27 17:06:19,819 [INFO] 开始迭代 4/300
2025-04-27 17:06:19,819 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 17:23:52,068 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 17:23:52,068 [INFO] 保存训练样本
2025-04-27 17:24:00,331 [INFO] 使用 175024 个样本训练神经网络
2025-04-27 17:24:00,331 [INFO] Training with 175024 examples
2025-04-27 17:24:00,331 [INFO] 总训练步数: 1275, 每轮次批次数: 85
2025-04-27 17:24:00,449 [INFO] 循环学习率周期大小: 255 步
2025-04-27 17:25:05,527 [INFO] Epoch 1/15 - Policy Loss: 1.4446, Value Loss: 0.1108, Total Loss: 1.5554, LR: 0.001681
2025-04-27 17:26:18,361 [INFO] Epoch 2/15 - Policy Loss: 1.4297, Value Loss: 0.1072, Total Loss: 1.5370, LR: 0.003331
2025-04-27 17:27:22,949 [INFO] Epoch 3/15 - Policy Loss: 1.4350, Value Loss: 0.1070, Total Loss: 1.5420, LR: 0.004981
2025-04-27 17:28:47,528 [INFO] Epoch 4/15 - Policy Loss: 1.4438, Value Loss: 0.1085, Total Loss: 1.5524, LR: 0.003369
2025-04-27 17:29:58,492 [INFO] Epoch 5/15 - Policy Loss: 1.4404, Value Loss: 0.1081, Total Loss: 1.5485, LR: 0.001719
2025-04-27 17:31:06,777 [INFO] Epoch 6/15 - Policy Loss: 1.4319, Value Loss: 0.1065, Total Loss: 1.5384, LR: 0.000069
2025-04-27 17:32:12,993 [INFO] Epoch 7/15 - Policy Loss: 1.4252, Value Loss: 0.1051, Total Loss: 1.5303, LR: 0.001681
2025-04-27 17:33:25,159 [INFO] Epoch 8/15 - Policy Loss: 1.4205, Value Loss: 0.1045, Total Loss: 1.5250, LR: 0.003331
2025-04-27 17:34:23,552 [INFO] Epoch 9/15 - Policy Loss: 1.4209, Value Loss: 0.1045, Total Loss: 1.5254, LR: 0.004981
2025-04-27 17:35:24,895 [INFO] Epoch 10/15 - Policy Loss: 1.4243, Value Loss: 0.1050, Total Loss: 1.5294, LR: 0.003369
2025-04-27 17:36:35,848 [INFO] Epoch 11/15 - Policy Loss: 1.4236, Value Loss: 0.1050, Total Loss: 1.5286, LR: 0.001719
2025-04-27 17:37:44,391 [INFO] Epoch 12/15 - Policy Loss: 1.4206, Value Loss: 0.1045, Total Loss: 1.5250, LR: 0.000069
2025-04-27 17:38:50,689 [INFO] Epoch 13/15 - Policy Loss: 1.4171, Value Loss: 0.1039, Total Loss: 1.5210, LR: 0.001681
2025-04-27 17:39:58,400 [INFO] Epoch 14/15 - Policy Loss: 1.4143, Value Loss: 0.1034, Total Loss: 1.5176, LR: 0.003331
2025-04-27 17:41:03,801 [INFO] Epoch 15/15 - Policy Loss: 1.4137, Value Loss: 0.1033, Total Loss: 1.5169, LR: 0.004981
2025-04-27 17:41:03,856 [INFO] 训练完成，总损失: 1.5169
2025-04-27 17:41:03,857 [INFO] 保存迭代 4 的模型
2025-04-27 17:41:05,045 [INFO] Model saved to ./models/best.pt
2025-04-27 17:41:05,764 [INFO] Model saved to ./models/iteration_4.pt
2025-04-27 17:41:05,764 [INFO] 所有训练迭代完成
2025-04-27 17:41:05,764 [INFO] 开始迭代 5/300
2025-04-27 17:41:05,764 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 17:57:41,145 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 17:57:41,145 [INFO] 保存训练样本
2025-04-27 17:57:47,965 [INFO] 使用 173864 个样本训练神经网络
2025-04-27 17:57:47,965 [INFO] Training with 173864 examples
2025-04-27 17:57:47,966 [INFO] 总训练步数: 1260, 每轮次批次数: 84
2025-04-27 17:57:48,662 [INFO] 循环学习率周期大小: 252 步
2025-04-27 17:58:53,835 [INFO] Epoch 1/15 - Policy Loss: 1.4234, Value Loss: 0.1065, Total Loss: 1.5298, LR: 0.001680
2025-04-27 18:00:01,457 [INFO] Epoch 2/15 - Policy Loss: 1.4127, Value Loss: 0.1058, Total Loss: 1.5185, LR: 0.003330
2025-04-27 18:01:16,484 [INFO] Epoch 3/15 - Policy Loss: 1.4169, Value Loss: 0.1062, Total Loss: 1.5231, LR: 0.004980
2025-04-27 18:02:18,078 [INFO] Epoch 4/15 - Policy Loss: 1.4241, Value Loss: 0.1073, Total Loss: 1.5314, LR: 0.003370
2025-04-27 18:03:24,415 [INFO] Epoch 5/15 - Policy Loss: 1.4223, Value Loss: 0.1068, Total Loss: 1.5291, LR: 0.001720
2025-04-27 18:04:29,808 [INFO] Epoch 6/15 - Policy Loss: 1.4148, Value Loss: 0.1054, Total Loss: 1.5202, LR: 0.000070
2025-04-27 18:05:31,055 [INFO] Epoch 7/15 - Policy Loss: 1.4084, Value Loss: 0.1042, Total Loss: 1.5126, LR: 0.001680
2025-04-27 18:06:33,704 [INFO] Epoch 8/15 - Policy Loss: 1.4044, Value Loss: 0.1036, Total Loss: 1.5079, LR: 0.003330
2025-04-27 18:07:39,172 [INFO] Epoch 9/15 - Policy Loss: 1.4046, Value Loss: 0.1034, Total Loss: 1.5080, LR: 0.004980
2025-04-27 18:08:50,364 [INFO] Epoch 10/15 - Policy Loss: 1.4071, Value Loss: 0.1037, Total Loss: 1.5108, LR: 0.003370
2025-04-27 18:09:56,575 [INFO] Epoch 11/15 - Policy Loss: 1.4057, Value Loss: 0.1033, Total Loss: 1.5091, LR: 0.001720
2025-04-27 18:11:01,939 [INFO] Epoch 12/15 - Policy Loss: 1.4033, Value Loss: 0.1028, Total Loss: 1.5061, LR: 0.000070
2025-04-27 18:12:09,585 [INFO] Epoch 13/15 - Policy Loss: 1.4009, Value Loss: 0.1023, Total Loss: 1.5032, LR: 0.001680
2025-04-27 18:13:11,515 [INFO] Epoch 14/15 - Policy Loss: 1.3993, Value Loss: 0.1019, Total Loss: 1.5012, LR: 0.003330
2025-04-27 18:14:18,058 [INFO] Epoch 15/15 - Policy Loss: 1.3997, Value Loss: 0.1018, Total Loss: 1.5016, LR: 0.004980
2025-04-27 18:14:18,088 [INFO] 训练完成，总损失: 1.5016
2025-04-27 18:14:18,088 [INFO] 保存迭代 5 的模型
2025-04-27 18:14:19,141 [INFO] Model saved to ./models/best.pt
2025-04-27 18:14:19,858 [INFO] Model saved to ./models/iteration_5.pt
2025-04-27 18:14:19,859 [INFO] 所有训练迭代完成
2025-04-27 18:14:19,859 [INFO] 开始迭代 6/300
2025-04-27 18:14:19,859 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 18:32:50,279 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 18:32:50,280 [INFO] 保存训练样本
2025-04-27 18:32:56,148 [INFO] 使用 174024 个样本训练神经网络
2025-04-27 18:32:56,148 [INFO] Training with 174024 examples
2025-04-27 18:32:56,148 [INFO] 总训练步数: 1260, 每轮次批次数: 84
2025-04-27 18:32:56,618 [INFO] 循环学习率周期大小: 252 步
2025-04-27 18:33:59,300 [INFO] Epoch 1/15 - Policy Loss: 1.4298, Value Loss: 0.1173, Total Loss: 1.5471, LR: 0.001680
2025-04-27 18:35:05,733 [INFO] Epoch 2/15 - Policy Loss: 1.4138, Value Loss: 0.1124, Total Loss: 1.5262, LR: 0.003330
2025-04-27 18:36:09,591 [INFO] Epoch 3/15 - Policy Loss: 1.4153, Value Loss: 0.1117, Total Loss: 1.5270, LR: 0.004980
2025-04-27 18:37:23,416 [INFO] Epoch 4/15 - Policy Loss: 1.4215, Value Loss: 0.1119, Total Loss: 1.5335, LR: 0.003370
2025-04-27 18:38:32,621 [INFO] Epoch 5/15 - Policy Loss: 1.4191, Value Loss: 0.1103, Total Loss: 1.5294, LR: 0.001720
2025-04-27 18:39:39,748 [INFO] Epoch 6/15 - Policy Loss: 1.4117, Value Loss: 0.1087, Total Loss: 1.5203, LR: 0.000070
2025-04-27 18:40:56,824 [INFO] Epoch 7/15 - Policy Loss: 1.4055, Value Loss: 0.1072, Total Loss: 1.5127, LR: 0.001680
2025-04-27 18:42:08,080 [INFO] Epoch 8/15 - Policy Loss: 1.4015, Value Loss: 0.1060, Total Loss: 1.5074, LR: 0.003330
2025-04-27 18:43:09,948 [INFO] Epoch 9/15 - Policy Loss: 1.4021, Value Loss: 0.1055, Total Loss: 1.5077, LR: 0.004980
2025-04-27 18:44:20,281 [INFO] Epoch 10/15 - Policy Loss: 1.4052, Value Loss: 0.1059, Total Loss: 1.5111, LR: 0.003370
2025-04-27 18:45:21,827 [INFO] Epoch 11/15 - Policy Loss: 1.4044, Value Loss: 0.1056, Total Loss: 1.5100, LR: 0.001720
2025-04-27 18:46:38,040 [INFO] Epoch 12/15 - Policy Loss: 1.4011, Value Loss: 0.1050, Total Loss: 1.5061, LR: 0.000070
2025-04-27 18:47:54,643 [INFO] Epoch 13/15 - Policy Loss: 1.3982, Value Loss: 0.1044, Total Loss: 1.5027, LR: 0.001680
2025-04-27 18:49:13,401 [INFO] Epoch 14/15 - Policy Loss: 1.3966, Value Loss: 0.1040, Total Loss: 1.5005, LR: 0.003330
2025-04-27 18:50:16,602 [INFO] Epoch 15/15 - Policy Loss: 1.3964, Value Loss: 0.1037, Total Loss: 1.5000, LR: 0.004980
2025-04-27 18:50:16,630 [INFO] 训练完成，总损失: 1.5000
2025-04-27 18:50:16,630 [INFO] 保存迭代 6 的模型
2025-04-27 18:50:18,139 [INFO] Model saved to ./models/best.pt
2025-04-27 18:50:19,080 [INFO] Model saved to ./models/iteration_6.pt
2025-04-27 18:50:19,080 [INFO] 所有训练迭代完成
2025-04-27 18:50:19,080 [INFO] 开始迭代 7/300
2025-04-27 18:50:19,080 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 19:09:12,801 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 19:09:12,803 [INFO] 保存训练样本
2025-04-27 19:09:21,112 [INFO] 使用 173312 个样本训练神经网络
2025-04-27 19:09:21,112 [INFO] Training with 173312 examples
2025-04-27 19:09:21,112 [INFO] 总训练步数: 1260, 每轮次批次数: 84
2025-04-27 19:09:21,870 [INFO] 循环学习率周期大小: 252 步
2025-04-27 19:10:28,051 [INFO] Epoch 1/15 - Policy Loss: 1.4310, Value Loss: 0.1127, Total Loss: 1.5437, LR: 0.001680
2025-04-27 19:11:39,648 [INFO] Epoch 2/15 - Policy Loss: 1.4159, Value Loss: 0.1083, Total Loss: 1.5241, LR: 0.003330
2025-04-27 19:12:49,701 [INFO] Epoch 3/15 - Policy Loss: 1.4152, Value Loss: 0.1074, Total Loss: 1.5225, LR: 0.004980
2025-04-27 19:13:46,628 [INFO] Epoch 4/15 - Policy Loss: 1.4206, Value Loss: 0.1075, Total Loss: 1.5281, LR: 0.003370
2025-04-27 19:14:53,568 [INFO] Epoch 5/15 - Policy Loss: 1.4178, Value Loss: 0.1065, Total Loss: 1.5243, LR: 0.001720
2025-04-27 19:16:03,975 [INFO] Epoch 6/15 - Policy Loss: 1.4112, Value Loss: 0.1048, Total Loss: 1.5160, LR: 0.000070
2025-04-27 19:17:11,744 [INFO] Epoch 7/15 - Policy Loss: 1.4055, Value Loss: 0.1034, Total Loss: 1.5090, LR: 0.001680
2025-04-27 19:18:19,464 [INFO] Epoch 8/15 - Policy Loss: 1.4019, Value Loss: 0.1023, Total Loss: 1.5043, LR: 0.003330
2025-04-27 19:19:33,676 [INFO] Epoch 9/15 - Policy Loss: 1.4012, Value Loss: 0.1019, Total Loss: 1.5031, LR: 0.004980
2025-04-27 19:20:39,842 [INFO] Epoch 10/15 - Policy Loss: 1.4034, Value Loss: 0.1019, Total Loss: 1.5053, LR: 0.003370
2025-04-27 19:21:45,322 [INFO] Epoch 11/15 - Policy Loss: 1.4029, Value Loss: 0.1014, Total Loss: 1.5043, LR: 0.001720
2025-04-27 19:22:53,136 [INFO] Epoch 12/15 - Policy Loss: 1.4004, Value Loss: 0.1010, Total Loss: 1.5014, LR: 0.000070
2025-04-27 19:23:55,857 [INFO] Epoch 13/15 - Policy Loss: 1.3983, Value Loss: 0.1006, Total Loss: 1.4988, LR: 0.001680
2025-04-27 19:25:04,356 [INFO] Epoch 14/15 - Policy Loss: 1.3961, Value Loss: 0.1001, Total Loss: 1.4962, LR: 0.003330
2025-04-27 19:26:11,133 [INFO] Epoch 15/15 - Policy Loss: 1.3960, Value Loss: 0.1000, Total Loss: 1.4960, LR: 0.004980
2025-04-27 19:26:11,181 [INFO] 训练完成，总损失: 1.4960
2025-04-27 19:26:11,181 [INFO] 保存迭代 7 的模型
2025-04-27 19:26:12,444 [INFO] Model saved to ./models/best.pt
2025-04-27 19:26:13,132 [INFO] Model saved to ./models/iteration_7.pt
2025-04-27 19:26:13,133 [INFO] 所有训练迭代完成
2025-04-27 19:26:13,133 [INFO] 开始迭代 8/300
2025-04-27 19:26:13,133 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 19:45:37,383 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 19:45:37,383 [INFO] 保存训练样本
2025-04-27 19:45:44,905 [INFO] 使用 172880 个样本训练神经网络
2025-04-27 19:45:44,905 [INFO] Training with 172880 examples
2025-04-27 19:45:44,906 [INFO] 总训练步数: 1260, 每轮次批次数: 84
2025-04-27 19:45:45,024 [INFO] 循环学习率周期大小: 252 步
2025-04-27 19:46:55,445 [INFO] Epoch 1/15 - Policy Loss: 1.4251, Value Loss: 0.1093, Total Loss: 1.5344, LR: 0.001680
2025-04-27 19:48:00,781 [INFO] Epoch 2/15 - Policy Loss: 1.4149, Value Loss: 0.1074, Total Loss: 1.5222, LR: 0.003330
2025-04-27 19:49:03,567 [INFO] Epoch 3/15 - Policy Loss: 1.4163, Value Loss: 0.1067, Total Loss: 1.5230, LR: 0.004980
2025-04-27 19:50:09,108 [INFO] Epoch 4/15 - Policy Loss: 1.4194, Value Loss: 0.1072, Total Loss: 1.5267, LR: 0.003370
2025-04-27 19:51:21,689 [INFO] Epoch 5/15 - Policy Loss: 1.4179, Value Loss: 0.1062, Total Loss: 1.5241, LR: 0.001720
2025-04-27 19:52:25,377 [INFO] Epoch 6/15 - Policy Loss: 1.4123, Value Loss: 0.1053, Total Loss: 1.5176, LR: 0.000070
2025-04-27 19:53:44,690 [INFO] Epoch 7/15 - Policy Loss: 1.4065, Value Loss: 0.1042, Total Loss: 1.5107, LR: 0.001680
2025-04-27 19:54:46,702 [INFO] Epoch 8/15 - Policy Loss: 1.4023, Value Loss: 0.1035, Total Loss: 1.5058, LR: 0.003330
2025-04-27 19:55:57,484 [INFO] Epoch 9/15 - Policy Loss: 1.4027, Value Loss: 0.1031, Total Loss: 1.5058, LR: 0.004980
2025-04-27 19:57:08,608 [INFO] Epoch 10/15 - Policy Loss: 1.4037, Value Loss: 0.1028, Total Loss: 1.5066, LR: 0.003370
2025-04-27 19:58:20,265 [INFO] Epoch 11/15 - Policy Loss: 1.4036, Value Loss: 0.1024, Total Loss: 1.5060, LR: 0.001720
2025-04-27 19:59:25,426 [INFO] Epoch 12/15 - Policy Loss: 1.4012, Value Loss: 0.1017, Total Loss: 1.5029, LR: 0.000070
2025-04-27 20:00:26,791 [INFO] Epoch 13/15 - Policy Loss: 1.3985, Value Loss: 0.1014, Total Loss: 1.4998, LR: 0.001680
2025-04-27 20:01:32,971 [INFO] Epoch 14/15 - Policy Loss: 1.3965, Value Loss: 0.1009, Total Loss: 1.4975, LR: 0.003330
2025-04-27 20:02:50,007 [INFO] Epoch 15/15 - Policy Loss: 1.3964, Value Loss: 0.1008, Total Loss: 1.4973, LR: 0.004980
2025-04-27 20:02:50,057 [INFO] 训练完成，总损失: 1.4973
2025-04-27 20:02:50,057 [INFO] 保存迭代 8 的模型
2025-04-27 20:02:51,661 [INFO] Model saved to ./models/best.pt
2025-04-27 20:02:52,645 [INFO] Model saved to ./models/iteration_8.pt
2025-04-27 20:02:52,645 [INFO] 所有训练迭代完成
2025-04-27 20:02:52,645 [INFO] 开始迭代 9/300
2025-04-27 20:02:52,645 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 20:21:56,005 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 20:21:56,006 [INFO] 保存训练样本
2025-04-27 20:22:01,813 [INFO] 使用 172072 个样本训练神经网络
2025-04-27 20:22:01,814 [INFO] Training with 172072 examples
2025-04-27 20:22:01,814 [INFO] 总训练步数: 1260, 每轮次批次数: 84
2025-04-27 20:22:02,536 [INFO] 循环学习率周期大小: 252 步
2025-04-27 20:23:11,220 [INFO] Epoch 1/15 - Policy Loss: 1.4206, Value Loss: 0.1001, Total Loss: 1.5207, LR: 0.001680
2025-04-27 20:24:16,510 [INFO] Epoch 2/15 - Policy Loss: 1.4174, Value Loss: 0.0987, Total Loss: 1.5160, LR: 0.003330
2025-04-27 20:25:17,453 [INFO] Epoch 3/15 - Policy Loss: 1.4162, Value Loss: 0.0987, Total Loss: 1.5149, LR: 0.004980
2025-04-27 20:26:20,761 [INFO] Epoch 4/15 - Policy Loss: 1.4214, Value Loss: 0.0997, Total Loss: 1.5211, LR: 0.003370
2025-04-27 20:27:36,036 [INFO] Epoch 5/15 - Policy Loss: 1.4192, Value Loss: 0.0994, Total Loss: 1.5186, LR: 0.001720
2025-04-27 20:28:37,196 [INFO] Epoch 6/15 - Policy Loss: 1.4126, Value Loss: 0.0985, Total Loss: 1.5111, LR: 0.000070
2025-04-27 20:29:34,523 [INFO] Epoch 7/15 - Policy Loss: 1.4076, Value Loss: 0.0977, Total Loss: 1.5054, LR: 0.001680
2025-04-27 20:30:44,364 [INFO] Epoch 8/15 - Policy Loss: 1.4041, Value Loss: 0.0971, Total Loss: 1.5013, LR: 0.003330
2025-04-27 20:31:55,931 [INFO] Epoch 9/15 - Policy Loss: 1.4031, Value Loss: 0.0969, Total Loss: 1.5000, LR: 0.004980
2025-04-27 20:33:01,093 [INFO] Epoch 10/15 - Policy Loss: 1.4052, Value Loss: 0.0974, Total Loss: 1.5026, LR: 0.003370
2025-04-27 20:34:03,560 [INFO] Epoch 11/15 - Policy Loss: 1.4044, Value Loss: 0.0973, Total Loss: 1.5017, LR: 0.001720
2025-04-27 20:35:05,505 [INFO] Epoch 12/15 - Policy Loss: 1.4015, Value Loss: 0.0970, Total Loss: 1.4985, LR: 0.000070
2025-04-27 20:36:17,240 [INFO] Epoch 13/15 - Policy Loss: 1.3997, Value Loss: 0.0965, Total Loss: 1.4962, LR: 0.001680
2025-04-27 20:37:18,097 [INFO] Epoch 14/15 - Policy Loss: 1.3980, Value Loss: 0.0962, Total Loss: 1.4942, LR: 0.003330
2025-04-27 20:38:19,740 [INFO] Epoch 15/15 - Policy Loss: 1.3977, Value Loss: 0.0961, Total Loss: 1.4938, LR: 0.004980
2025-04-27 20:38:19,781 [INFO] 训练完成，总损失: 1.4938
2025-04-27 20:38:19,781 [INFO] 保存迭代 9 的模型
2025-04-27 20:38:21,309 [INFO] Model saved to ./models/best.pt
2025-04-27 20:38:22,145 [INFO] Model saved to ./models/iteration_9.pt
2025-04-27 20:38:22,145 [INFO] 所有训练迭代完成
2025-04-27 20:38:22,145 [INFO] 开始迭代 10/300
2025-04-27 20:38:22,145 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 20:56:12,254 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 20:56:12,255 [INFO] 保存训练样本
2025-04-27 20:56:18,796 [INFO] 使用 171136 个样本训练神经网络
2025-04-27 20:56:18,797 [INFO] Training with 171136 examples
2025-04-27 20:56:18,799 [INFO] 总训练步数: 1245, 每轮次批次数: 83
2025-04-27 20:56:19,803 [INFO] 循环学习率周期大小: 249 步
2025-04-27 20:57:22,153 [INFO] Epoch 1/15 - Policy Loss: 1.4328, Value Loss: 0.1097, Total Loss: 1.5425, LR: 0.001680
2025-04-27 20:58:30,267 [INFO] Epoch 2/15 - Policy Loss: 1.4186, Value Loss: 0.1083, Total Loss: 1.5269, LR: 0.003330
2025-04-27 20:59:37,044 [INFO] Epoch 3/15 - Policy Loss: 1.4165, Value Loss: 0.1074, Total Loss: 1.5239, LR: 0.004980
2025-04-27 21:00:46,727 [INFO] Epoch 4/15 - Policy Loss: 1.4224, Value Loss: 0.1075, Total Loss: 1.5299, LR: 0.003370
2025-04-27 21:01:42,809 [INFO] Epoch 5/15 - Policy Loss: 1.4189, Value Loss: 0.1066, Total Loss: 1.5255, LR: 0.001720
2025-04-27 21:02:49,712 [INFO] Epoch 6/15 - Policy Loss: 1.4139, Value Loss: 0.1053, Total Loss: 1.5192, LR: 0.000070
2025-04-27 21:03:55,549 [INFO] Epoch 7/15 - Policy Loss: 1.4088, Value Loss: 0.1040, Total Loss: 1.5128, LR: 0.001680
2025-04-27 21:05:05,768 [INFO] Epoch 8/15 - Policy Loss: 1.4059, Value Loss: 0.1037, Total Loss: 1.5096, LR: 0.003330
2025-04-27 21:06:07,652 [INFO] Epoch 9/15 - Policy Loss: 1.4055, Value Loss: 0.1036, Total Loss: 1.5091, LR: 0.004980
2025-04-27 21:07:12,988 [INFO] Epoch 10/15 - Policy Loss: 1.4069, Value Loss: 0.1035, Total Loss: 1.5105, LR: 0.003370
2025-04-27 21:08:15,417 [INFO] Epoch 11/15 - Policy Loss: 1.4064, Value Loss: 0.1030, Total Loss: 1.5094, LR: 0.001720
2025-04-27 21:09:29,821 [INFO] Epoch 12/15 - Policy Loss: 1.4047, Value Loss: 0.1024, Total Loss: 1.5071, LR: 0.000070
2025-04-27 21:10:34,495 [INFO] Epoch 13/15 - Policy Loss: 1.4027, Value Loss: 0.1019, Total Loss: 1.5046, LR: 0.001680
2025-04-27 21:11:37,007 [INFO] Epoch 14/15 - Policy Loss: 1.4010, Value Loss: 0.1014, Total Loss: 1.5025, LR: 0.003330
2025-04-27 21:12:36,572 [INFO] Epoch 15/15 - Policy Loss: 1.4007, Value Loss: 0.1013, Total Loss: 1.5020, LR: 0.004980
2025-04-27 21:12:36,605 [INFO] 训练完成，总损失: 1.5020
2025-04-27 21:12:36,605 [INFO] 保存迭代 10 的模型
2025-04-27 21:12:38,230 [INFO] Model saved to ./models/best.pt
2025-04-27 21:12:39,062 [INFO] Model saved to ./models/iteration_10.pt
2025-04-27 21:12:39,062 [INFO] 所有训练迭代完成
2025-04-27 21:12:39,062 [INFO] 开始迭代 11/300
2025-04-27 21:12:39,062 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 21:31:21,985 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 21:31:21,987 [INFO] 保存训练样本
2025-04-27 21:31:29,125 [INFO] 使用 170672 个样本训练神经网络
2025-04-27 21:31:29,125 [INFO] Training with 170672 examples
2025-04-27 21:31:29,126 [INFO] 总训练步数: 1245, 每轮次批次数: 83
2025-04-27 21:31:29,744 [INFO] 循环学习率周期大小: 249 步
2025-04-27 21:32:43,227 [INFO] Epoch 1/15 - Policy Loss: 1.4364, Value Loss: 0.1049, Total Loss: 1.5414, LR: 0.001680
2025-04-27 21:33:50,967 [INFO] Epoch 2/15 - Policy Loss: 1.4270, Value Loss: 0.1026, Total Loss: 1.5295, LR: 0.003330
2025-04-27 21:34:57,896 [INFO] Epoch 3/15 - Policy Loss: 1.4260, Value Loss: 0.1027, Total Loss: 1.5287, LR: 0.004980
2025-04-27 21:36:06,667 [INFO] Epoch 4/15 - Policy Loss: 1.4245, Value Loss: 0.1029, Total Loss: 1.5274, LR: 0.003370
2025-04-27 21:37:03,504 [INFO] Epoch 5/15 - Policy Loss: 1.4215, Value Loss: 0.1023, Total Loss: 1.5239, LR: 0.001720
2025-04-27 21:38:08,368 [INFO] Epoch 6/15 - Policy Loss: 1.4165, Value Loss: 0.1013, Total Loss: 1.5178, LR: 0.000070
2025-04-27 21:39:28,585 [INFO] Epoch 7/15 - Policy Loss: 1.4121, Value Loss: 0.1007, Total Loss: 1.5128, LR: 0.001680
2025-04-27 21:40:32,832 [INFO] Epoch 8/15 - Policy Loss: 1.4095, Value Loss: 0.1003, Total Loss: 1.5098, LR: 0.003330
2025-04-27 21:41:39,820 [INFO] Epoch 9/15 - Policy Loss: 1.4091, Value Loss: 0.1004, Total Loss: 1.5095, LR: 0.004980
2025-04-27 21:42:42,594 [INFO] Epoch 10/15 - Policy Loss: 1.4102, Value Loss: 0.1003, Total Loss: 1.5106, LR: 0.003370
2025-04-27 21:43:52,175 [INFO] Epoch 11/15 - Policy Loss: 1.4094, Value Loss: 0.1004, Total Loss: 1.5098, LR: 0.001720
2025-04-27 21:45:09,129 [INFO] Epoch 12/15 - Policy Loss: 1.4067, Value Loss: 0.1001, Total Loss: 1.5068, LR: 0.000070
2025-04-27 21:46:14,005 [INFO] Epoch 13/15 - Policy Loss: 1.4052, Value Loss: 0.0998, Total Loss: 1.5050, LR: 0.001680
2025-04-27 21:47:23,763 [INFO] Epoch 14/15 - Policy Loss: 1.4035, Value Loss: 0.0996, Total Loss: 1.5031, LR: 0.003330
2025-04-27 21:48:26,259 [INFO] Epoch 15/15 - Policy Loss: 1.4028, Value Loss: 0.0995, Total Loss: 1.5023, LR: 0.004980
2025-04-27 21:48:26,334 [INFO] 训练完成，总损失: 1.5023
2025-04-27 21:48:26,335 [INFO] 保存迭代 11 的模型
2025-04-27 21:48:27,756 [INFO] Model saved to ./models/best.pt
2025-04-27 21:48:28,668 [INFO] Model saved to ./models/iteration_11.pt
2025-04-27 21:48:28,668 [INFO] 所有训练迭代完成
2025-04-27 21:48:28,668 [INFO] 开始迭代 12/300
2025-04-27 21:48:28,668 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 22:09:04,590 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 22:09:04,591 [INFO] 保存训练样本
2025-04-27 22:09:10,452 [INFO] 使用 169968 个样本训练神经网络
2025-04-27 22:09:10,452 [INFO] Training with 169968 examples
2025-04-27 22:09:10,452 [INFO] 总训练步数: 1230, 每轮次批次数: 82
2025-04-27 22:09:10,514 [INFO] 循环学习率周期大小: 246 步
2025-04-27 22:11:04,812 [INFO] Epoch 1/15 - Policy Loss: 1.4324, Value Loss: 0.1118, Total Loss: 1.5442, LR: 0.001680
2025-04-27 22:12:43,991 [INFO] Epoch 2/15 - Policy Loss: 1.4208, Value Loss: 0.1094, Total Loss: 1.5302, LR: 0.003330
2025-04-27 22:14:26,836 [INFO] Epoch 3/15 - Policy Loss: 1.4217, Value Loss: 0.1087, Total Loss: 1.5304, LR: 0.004980
2025-04-27 22:15:54,400 [INFO] Epoch 4/15 - Policy Loss: 1.4236, Value Loss: 0.1087, Total Loss: 1.5323, LR: 0.003370
2025-04-27 22:17:01,426 [INFO] Epoch 5/15 - Policy Loss: 1.4219, Value Loss: 0.1087, Total Loss: 1.5306, LR: 0.001720
2025-04-27 22:18:00,517 [INFO] Epoch 6/15 - Policy Loss: 1.4178, Value Loss: 0.1081, Total Loss: 1.5258, LR: 0.000070
2025-04-27 22:19:04,357 [INFO] Epoch 7/15 - Policy Loss: 1.4136, Value Loss: 0.1073, Total Loss: 1.5209, LR: 0.001680
2025-04-27 22:20:06,410 [INFO] Epoch 8/15 - Policy Loss: 1.4105, Value Loss: 0.1068, Total Loss: 1.5173, LR: 0.003330
2025-04-27 22:21:05,603 [INFO] Epoch 9/15 - Policy Loss: 1.4104, Value Loss: 0.1070, Total Loss: 1.5173, LR: 0.004980
2025-04-27 22:22:04,773 [INFO] Epoch 10/15 - Policy Loss: 1.4118, Value Loss: 0.1071, Total Loss: 1.5189, LR: 0.003370
2025-04-27 22:23:05,489 [INFO] Epoch 11/15 - Policy Loss: 1.4112, Value Loss: 0.1069, Total Loss: 1.5181, LR: 0.001720
2025-04-27 22:24:06,835 [INFO] Epoch 12/15 - Policy Loss: 1.4095, Value Loss: 0.1065, Total Loss: 1.5160, LR: 0.000070
2025-04-27 22:25:11,333 [INFO] Epoch 13/15 - Policy Loss: 1.4075, Value Loss: 0.1063, Total Loss: 1.5138, LR: 0.001680
2025-04-27 22:26:32,315 [INFO] Epoch 14/15 - Policy Loss: 1.4068, Value Loss: 0.1059, Total Loss: 1.5127, LR: 0.003330
2025-04-27 22:28:19,328 [INFO] Epoch 15/15 - Policy Loss: 1.4068, Value Loss: 0.1058, Total Loss: 1.5127, LR: 0.004980
2025-04-27 22:28:19,372 [INFO] 训练完成，总损失: 1.5127
2025-04-27 22:28:19,372 [INFO] 保存迭代 12 的模型
2025-04-27 22:28:20,683 [INFO] Model saved to ./models/best.pt
2025-04-27 22:28:21,584 [INFO] Model saved to ./models/iteration_12.pt
2025-04-27 22:28:21,585 [INFO] 所有训练迭代完成
2025-04-27 22:28:21,585 [INFO] 开始迭代 13/300
2025-04-27 22:28:21,585 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 22:53:48,882 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 22:53:48,883 [INFO] 保存训练样本
2025-04-27 22:53:55,260 [INFO] 使用 169888 个样本训练神经网络
2025-04-27 22:53:55,260 [INFO] Training with 169888 examples
2025-04-27 22:53:55,260 [INFO] 总训练步数: 1230, 每轮次批次数: 82
2025-04-27 22:53:55,779 [INFO] 循环学习率周期大小: 246 步
2025-04-27 22:55:44,331 [INFO] Epoch 1/15 - Policy Loss: 1.4552, Value Loss: 0.1157, Total Loss: 1.5709, LR: 0.001680
2025-04-27 22:57:49,674 [INFO] Epoch 2/15 - Policy Loss: 1.4406, Value Loss: 0.1136, Total Loss: 1.5542, LR: 0.003330
2025-04-27 22:59:46,174 [INFO] Epoch 3/15 - Policy Loss: 1.4376, Value Loss: 0.1123, Total Loss: 1.5499, LR: 0.004980
2025-04-27 23:01:39,518 [INFO] Epoch 4/15 - Policy Loss: 1.4387, Value Loss: 0.1118, Total Loss: 1.5505, LR: 0.003370
2025-04-27 23:03:43,719 [INFO] Epoch 5/15 - Policy Loss: 1.4353, Value Loss: 0.1112, Total Loss: 1.5465, LR: 0.001720
2025-04-27 23:05:19,659 [INFO] Epoch 6/15 - Policy Loss: 1.4319, Value Loss: 0.1099, Total Loss: 1.5417, LR: 0.000070
2025-04-27 23:06:37,004 [INFO] Epoch 7/15 - Policy Loss: 1.4275, Value Loss: 0.1088, Total Loss: 1.5363, LR: 0.001680
2025-04-27 23:07:57,245 [INFO] Epoch 8/15 - Policy Loss: 1.4241, Value Loss: 0.1080, Total Loss: 1.5320, LR: 0.003330
2025-04-27 23:09:20,501 [INFO] Epoch 9/15 - Policy Loss: 1.4223, Value Loss: 0.1071, Total Loss: 1.5294, LR: 0.004980
2025-04-27 23:10:36,036 [INFO] Epoch 10/15 - Policy Loss: 1.4220, Value Loss: 0.1068, Total Loss: 1.5288, LR: 0.003370
2025-04-27 23:12:00,797 [INFO] Epoch 11/15 - Policy Loss: 1.4210, Value Loss: 0.1063, Total Loss: 1.5273, LR: 0.001720
2025-04-27 23:13:14,310 [INFO] Epoch 12/15 - Policy Loss: 1.4190, Value Loss: 0.1059, Total Loss: 1.5249, LR: 0.000070
2025-04-27 23:14:40,821 [INFO] Epoch 13/15 - Policy Loss: 1.4169, Value Loss: 0.1055, Total Loss: 1.5224, LR: 0.001680
2025-04-27 23:16:02,648 [INFO] Epoch 14/15 - Policy Loss: 1.4155, Value Loss: 0.1050, Total Loss: 1.5205, LR: 0.003330
2025-04-27 23:17:29,369 [INFO] Epoch 15/15 - Policy Loss: 1.4148, Value Loss: 0.1048, Total Loss: 1.5196, LR: 0.004980
2025-04-27 23:17:29,409 [INFO] 训练完成，总损失: 1.5196
2025-04-27 23:17:29,410 [INFO] 保存迭代 13 的模型
2025-04-27 23:17:30,573 [INFO] Model saved to ./models/best.pt
2025-04-27 23:17:31,281 [INFO] Model saved to ./models/iteration_13.pt
2025-04-27 23:17:31,282 [INFO] 所有训练迭代完成
2025-04-27 23:17:31,282 [INFO] 开始迭代 14/300
2025-04-27 23:17:31,282 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-27 23:37:18,847 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-27 23:37:18,847 [INFO] 保存训练样本
2025-04-27 23:37:25,836 [INFO] 使用 169984 个样本训练神经网络
2025-04-27 23:37:25,836 [INFO] Training with 169984 examples
2025-04-27 23:37:25,836 [INFO] 总训练步数: 1245, 每轮次批次数: 83
2025-04-27 23:37:26,530 [INFO] 循环学习率周期大小: 249 步
2025-04-27 23:38:47,108 [INFO] Epoch 1/15 - Policy Loss: 1.4380, Value Loss: 0.1075, Total Loss: 1.5454, LR: 0.001680
2025-04-27 23:40:05,040 [INFO] Epoch 2/15 - Policy Loss: 1.4302, Value Loss: 0.1054, Total Loss: 1.5356, LR: 0.003330
2025-04-27 23:41:27,227 [INFO] Epoch 3/15 - Policy Loss: 1.4308, Value Loss: 0.1051, Total Loss: 1.5359, LR: 0.004980
2025-04-27 23:43:01,330 [INFO] Epoch 4/15 - Policy Loss: 1.4318, Value Loss: 0.1057, Total Loss: 1.5375, LR: 0.003370
2025-04-27 23:44:05,260 [INFO] Epoch 5/15 - Policy Loss: 1.4297, Value Loss: 0.1051, Total Loss: 1.5347, LR: 0.001720
2025-04-27 23:45:11,788 [INFO] Epoch 6/15 - Policy Loss: 1.4252, Value Loss: 0.1042, Total Loss: 1.5294, LR: 0.000070
2025-04-27 23:46:16,798 [INFO] Epoch 7/15 - Policy Loss: 1.4204, Value Loss: 0.1031, Total Loss: 1.5235, LR: 0.001680
2025-04-27 23:47:24,265 [INFO] Epoch 8/15 - Policy Loss: 1.4183, Value Loss: 0.1024, Total Loss: 1.5207, LR: 0.003330
2025-04-27 23:48:24,088 [INFO] Epoch 9/15 - Policy Loss: 1.4177, Value Loss: 0.1023, Total Loss: 1.5200, LR: 0.004980
2025-04-27 23:49:38,603 [INFO] Epoch 10/15 - Policy Loss: 1.4187, Value Loss: 0.1022, Total Loss: 1.5209, LR: 0.003370
2025-04-27 23:50:41,424 [INFO] Epoch 11/15 - Policy Loss: 1.4181, Value Loss: 0.1021, Total Loss: 1.5201, LR: 0.001720
2025-04-27 23:51:55,312 [INFO] Epoch 12/15 - Policy Loss: 1.4164, Value Loss: 0.1018, Total Loss: 1.5182, LR: 0.000070
2025-04-27 23:53:17,964 [INFO] Epoch 13/15 - Policy Loss: 1.4151, Value Loss: 0.1013, Total Loss: 1.5164, LR: 0.001680
2025-04-27 23:54:44,793 [INFO] Epoch 14/15 - Policy Loss: 1.4136, Value Loss: 0.1011, Total Loss: 1.5147, LR: 0.003330
2025-04-27 23:56:15,303 [INFO] Epoch 15/15 - Policy Loss: 1.4131, Value Loss: 0.1010, Total Loss: 1.5141, LR: 0.004980
2025-04-27 23:56:15,351 [INFO] 训练完成，总损失: 1.5141
2025-04-27 23:56:15,352 [INFO] 保存迭代 14 的模型
2025-04-27 23:56:16,521 [INFO] Model saved to ./models/best.pt
2025-04-27 23:56:17,367 [INFO] Model saved to ./models/iteration_14.pt
2025-04-27 23:56:17,367 [INFO] 所有训练迭代完成
2025-04-27 23:56:17,367 [INFO] 开始迭代 15/300
2025-04-27 23:56:17,367 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-28 00:15:36,663 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-28 00:15:36,664 [INFO] 保存训练样本
2025-04-28 00:15:42,548 [INFO] 使用 169056 个样本训练神经网络
2025-04-28 00:15:42,548 [INFO] Training with 169056 examples
2025-04-28 00:15:42,549 [INFO] 总训练步数: 1230, 每轮次批次数: 82
2025-04-28 00:15:43,090 [INFO] 循环学习率周期大小: 246 步
2025-04-28 00:17:11,868 [INFO] Epoch 1/15 - Policy Loss: 1.4399, Value Loss: 0.1078, Total Loss: 1.5477, LR: 0.001680
2025-04-28 00:18:30,432 [INFO] Epoch 2/15 - Policy Loss: 1.4303, Value Loss: 0.1056, Total Loss: 1.5359, LR: 0.003330
2025-04-28 00:19:39,492 [INFO] Epoch 3/15 - Policy Loss: 1.4301, Value Loss: 0.1048, Total Loss: 1.5350, LR: 0.004980
2025-04-28 00:20:46,572 [INFO] Epoch 4/15 - Policy Loss: 1.4327, Value Loss: 0.1050, Total Loss: 1.5377, LR: 0.003370
2025-04-28 00:22:00,508 [INFO] Epoch 5/15 - Policy Loss: 1.4324, Value Loss: 0.1049, Total Loss: 1.5373, LR: 0.001720
2025-04-28 00:23:12,275 [INFO] Epoch 6/15 - Policy Loss: 1.4286, Value Loss: 0.1036, Total Loss: 1.5322, LR: 0.000070
2025-04-28 00:24:30,968 [INFO] Epoch 7/15 - Policy Loss: 1.4260, Value Loss: 0.1028, Total Loss: 1.5288, LR: 0.001680
2025-04-28 00:25:42,768 [INFO] Epoch 8/15 - Policy Loss: 1.4240, Value Loss: 0.1020, Total Loss: 1.5260, LR: 0.003330
2025-04-28 00:27:07,316 [INFO] Epoch 9/15 - Policy Loss: 1.4238, Value Loss: 0.1016, Total Loss: 1.5253, LR: 0.004980
2025-04-28 00:28:17,865 [INFO] Epoch 10/15 - Policy Loss: 1.4240, Value Loss: 0.1013, Total Loss: 1.5254, LR: 0.003370
2025-04-28 00:29:29,617 [INFO] Epoch 11/15 - Policy Loss: 1.4230, Value Loss: 0.1009, Total Loss: 1.5239, LR: 0.001720
2025-04-28 00:30:43,800 [INFO] Epoch 12/15 - Policy Loss: 1.4215, Value Loss: 0.1008, Total Loss: 1.5222, LR: 0.000070
2025-04-28 00:32:06,458 [INFO] Epoch 13/15 - Policy Loss: 1.4198, Value Loss: 0.1004, Total Loss: 1.5202, LR: 0.001680
2025-04-28 00:33:19,544 [INFO] Epoch 14/15 - Policy Loss: 1.4182, Value Loss: 0.1001, Total Loss: 1.5184, LR: 0.003330
2025-04-28 00:34:28,190 [INFO] Epoch 15/15 - Policy Loss: 1.4178, Value Loss: 0.0999, Total Loss: 1.5178, LR: 0.004980
2025-04-28 00:34:28,236 [INFO] 训练完成，总损失: 1.5178
2025-04-28 00:34:28,236 [INFO] 保存迭代 15 的模型
2025-04-28 00:34:29,735 [INFO] Model saved to ./models/best.pt
2025-04-28 00:34:30,742 [INFO] Model saved to ./models/iteration_15.pt
2025-04-28 00:34:30,743 [INFO] 所有训练迭代完成
2025-04-28 00:34:30,743 [INFO] 开始迭代 16/300
2025-04-28 00:34:30,743 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-28 00:51:26,224 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-28 00:51:26,225 [INFO] 保存训练样本
2025-04-28 00:51:33,121 [INFO] 使用 168184 个样本训练神经网络
2025-04-28 00:51:33,121 [INFO] Training with 168184 examples
2025-04-28 00:51:33,123 [INFO] 总训练步数: 1230, 每轮次批次数: 82
2025-04-28 00:51:33,238 [INFO] 循环学习率周期大小: 246 步
2025-04-28 00:53:00,188 [INFO] Epoch 1/15 - Policy Loss: 1.4457, Value Loss: 0.1042, Total Loss: 1.5499, LR: 0.001680
2025-04-28 00:54:09,965 [INFO] Epoch 2/15 - Policy Loss: 1.4374, Value Loss: 0.1026, Total Loss: 1.5400, LR: 0.003330
2025-04-28 00:55:26,456 [INFO] Epoch 3/15 - Policy Loss: 1.4380, Value Loss: 0.1029, Total Loss: 1.5409, LR: 0.004980
2025-04-28 00:56:43,398 [INFO] Epoch 4/15 - Policy Loss: 1.4398, Value Loss: 0.1036, Total Loss: 1.5434, LR: 0.003370
2025-04-28 00:58:41,124 [INFO] Epoch 5/15 - Policy Loss: 1.4379, Value Loss: 0.1034, Total Loss: 1.5413, LR: 0.001720
2025-04-28 00:59:55,335 [INFO] Epoch 6/15 - Policy Loss: 1.4317, Value Loss: 0.1024, Total Loss: 1.5341, LR: 0.000070
2025-04-28 01:01:00,144 [INFO] Epoch 7/15 - Policy Loss: 1.4282, Value Loss: 0.1014, Total Loss: 1.5296, LR: 0.001680
2025-04-28 01:02:03,852 [INFO] Epoch 8/15 - Policy Loss: 1.4259, Value Loss: 0.1009, Total Loss: 1.5268, LR: 0.003330
2025-04-28 01:03:04,976 [INFO] Epoch 9/15 - Policy Loss: 1.4260, Value Loss: 0.1008, Total Loss: 1.5268, LR: 0.004980
2025-04-28 01:04:13,550 [INFO] Epoch 10/15 - Policy Loss: 1.4272, Value Loss: 0.1007, Total Loss: 1.5279, LR: 0.003370
2025-04-28 01:05:14,909 [INFO] Epoch 11/15 - Policy Loss: 1.4263, Value Loss: 0.1006, Total Loss: 1.5269, LR: 0.001720
2025-04-28 01:06:21,427 [INFO] Epoch 12/15 - Policy Loss: 1.4253, Value Loss: 0.1003, Total Loss: 1.5256, LR: 0.000070
2025-04-28 01:07:41,823 [INFO] Epoch 13/15 - Policy Loss: 1.4236, Value Loss: 0.1000, Total Loss: 1.5235, LR: 0.001680
2025-04-28 01:08:51,041 [INFO] Epoch 14/15 - Policy Loss: 1.4227, Value Loss: 0.0997, Total Loss: 1.5223, LR: 0.003330
2025-04-28 01:09:45,288 [INFO] Epoch 15/15 - Policy Loss: 1.4224, Value Loss: 0.0997, Total Loss: 1.5221, LR: 0.004980
2025-04-28 01:09:45,371 [INFO] 训练完成，总损失: 1.5221
2025-04-28 01:09:45,371 [INFO] 保存迭代 16 的模型
2025-04-28 01:09:48,202 [INFO] Model saved to ./models/best.pt
2025-04-28 01:09:50,408 [INFO] Model saved to ./models/iteration_16.pt
2025-04-28 01:09:50,408 [INFO] 所有训练迭代完成
2025-04-28 01:09:50,409 [INFO] 开始迭代 17/300
2025-04-28 01:09:50,409 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-28 01:29:15,197 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-28 01:29:15,198 [INFO] 保存训练样本
2025-04-28 01:29:24,810 [INFO] 使用 167872 个样本训练神经网络
2025-04-28 01:29:24,810 [INFO] Training with 167872 examples
2025-04-28 01:29:24,811 [INFO] 总训练步数: 1215, 每轮次批次数: 81
2025-04-28 01:29:24,930 [INFO] 循环学习率周期大小: 243 步
2025-04-28 01:30:22,089 [INFO] Epoch 1/15 - Policy Loss: 1.4487, Value Loss: 0.1126, Total Loss: 1.5613, LR: 0.001680
2025-04-28 01:31:13,452 [INFO] Epoch 2/15 - Policy Loss: 1.4401, Value Loss: 0.1090, Total Loss: 1.5491, LR: 0.003330
2025-04-28 01:32:10,050 [INFO] Epoch 3/15 - Policy Loss: 1.4413, Value Loss: 0.1078, Total Loss: 1.5491, LR: 0.004980
2025-04-28 01:33:01,814 [INFO] Epoch 4/15 - Policy Loss: 1.4459, Value Loss: 0.1085, Total Loss: 1.5545, LR: 0.003370
2025-04-28 01:33:56,412 [INFO] Epoch 5/15 - Policy Loss: 1.4442, Value Loss: 0.1077, Total Loss: 1.5520, LR: 0.001720
2025-04-28 01:34:51,876 [INFO] Epoch 6/15 - Policy Loss: 1.4409, Value Loss: 0.1069, Total Loss: 1.5477, LR: 0.000070
2025-04-28 01:35:45,559 [INFO] Epoch 7/15 - Policy Loss: 1.4384, Value Loss: 0.1059, Total Loss: 1.5442, LR: 0.001680
2025-04-28 01:36:37,401 [INFO] Epoch 8/15 - Policy Loss: 1.4356, Value Loss: 0.1052, Total Loss: 1.5408, LR: 0.003330
2025-04-28 01:37:34,103 [INFO] Epoch 9/15 - Policy Loss: 1.4353, Value Loss: 0.1049, Total Loss: 1.5402, LR: 0.004980
2025-04-28 01:38:26,967 [INFO] Epoch 10/15 - Policy Loss: 1.4355, Value Loss: 0.1045, Total Loss: 1.5400, LR: 0.003370
2025-04-28 01:39:23,775 [INFO] Epoch 11/15 - Policy Loss: 1.4355, Value Loss: 0.1043, Total Loss: 1.5398, LR: 0.001720
2025-04-28 01:40:15,671 [INFO] Epoch 12/15 - Policy Loss: 1.4335, Value Loss: 0.1038, Total Loss: 1.5373, LR: 0.000070
2025-04-28 01:41:11,887 [INFO] Epoch 13/15 - Policy Loss: 1.4320, Value Loss: 0.1033, Total Loss: 1.5353, LR: 0.001680
2025-04-28 01:42:05,237 [INFO] Epoch 14/15 - Policy Loss: 1.4308, Value Loss: 0.1031, Total Loss: 1.5338, LR: 0.003330
2025-04-28 01:42:58,639 [INFO] Epoch 15/15 - Policy Loss: 1.4306, Value Loss: 0.1030, Total Loss: 1.5336, LR: 0.004980
2025-04-28 01:42:58,692 [INFO] 训练完成，总损失: 1.5336
2025-04-28 01:42:58,692 [INFO] 保存迭代 17 的模型
2025-04-28 01:43:01,612 [INFO] Model saved to ./models/best.pt
2025-04-28 01:43:02,999 [INFO] Model saved to ./models/iteration_17.pt
2025-04-28 01:43:03,000 [INFO] 所有训练迭代完成
2025-04-28 01:43:03,000 [INFO] 开始迭代 18/300
2025-04-28 01:43:03,000 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-28 02:01:59,377 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-28 02:01:59,378 [INFO] 保存训练样本
2025-04-28 02:02:14,165 [INFO] 使用 167264 个样本训练神经网络
2025-04-28 02:02:14,165 [INFO] Training with 167264 examples
2025-04-28 02:02:14,166 [INFO] 总训练步数: 1215, 每轮次批次数: 81
2025-04-28 02:02:14,805 [INFO] 循环学习率周期大小: 243 步
2025-04-28 02:03:08,512 [INFO] Epoch 1/15 - Policy Loss: 1.4509, Value Loss: 0.1024, Total Loss: 1.5533, LR: 0.001680
2025-04-28 02:04:03,415 [INFO] Epoch 2/15 - Policy Loss: 1.4472, Value Loss: 0.1000, Total Loss: 1.5471, LR: 0.003330
2025-04-28 02:04:57,186 [INFO] Epoch 3/15 - Policy Loss: 1.4438, Value Loss: 0.1004, Total Loss: 1.5442, LR: 0.004980
2025-04-28 02:05:53,430 [INFO] Epoch 4/15 - Policy Loss: 1.4438, Value Loss: 0.1005, Total Loss: 1.5443, LR: 0.003370
2025-04-28 02:06:47,903 [INFO] Epoch 5/15 - Policy Loss: 1.4419, Value Loss: 0.1001, Total Loss: 1.5420, LR: 0.001720
2025-04-28 02:07:40,345 [INFO] Epoch 6/15 - Policy Loss: 1.4385, Value Loss: 0.0995, Total Loss: 1.5381, LR: 0.000070
2025-04-28 02:08:37,530 [INFO] Epoch 7/15 - Policy Loss: 1.4369, Value Loss: 0.0989, Total Loss: 1.5358, LR: 0.001680
2025-04-28 02:09:30,101 [INFO] Epoch 8/15 - Policy Loss: 1.4342, Value Loss: 0.0988, Total Loss: 1.5330, LR: 0.003330
2025-04-28 02:10:22,655 [INFO] Epoch 9/15 - Policy Loss: 1.4339, Value Loss: 0.0986, Total Loss: 1.5325, LR: 0.004980
2025-04-28 02:11:19,541 [INFO] Epoch 10/15 - Policy Loss: 1.4340, Value Loss: 0.0985, Total Loss: 1.5325, LR: 0.003370
2025-04-28 02:12:12,528 [INFO] Epoch 11/15 - Policy Loss: 1.4337, Value Loss: 0.0984, Total Loss: 1.5321, LR: 0.001720
2025-04-28 02:13:06,661 [INFO] Epoch 12/15 - Policy Loss: 1.4321, Value Loss: 0.0982, Total Loss: 1.5303, LR: 0.000070
2025-04-28 02:13:58,950 [INFO] Epoch 13/15 - Policy Loss: 1.4308, Value Loss: 0.0979, Total Loss: 1.5287, LR: 0.001680
2025-04-28 02:14:56,040 [INFO] Epoch 14/15 - Policy Loss: 1.4294, Value Loss: 0.0977, Total Loss: 1.5271, LR: 0.003330
2025-04-28 02:15:49,158 [INFO] Epoch 15/15 - Policy Loss: 1.4292, Value Loss: 0.0977, Total Loss: 1.5269, LR: 0.004980
2025-04-28 02:15:49,245 [INFO] 训练完成，总损失: 1.5269
2025-04-28 02:15:49,245 [INFO] 保存迭代 18 的模型
2025-04-28 02:15:52,181 [INFO] Model saved to ./models/best.pt
2025-04-28 02:15:53,709 [INFO] Model saved to ./models/iteration_18.pt
2025-04-28 02:15:53,710 [INFO] 所有训练迭代完成
2025-04-28 02:15:53,710 [INFO] 开始迭代 19/300
2025-04-28 02:15:53,710 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-28 02:36:12,052 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-28 02:36:12,052 [INFO] 保存训练样本
2025-04-28 02:36:22,812 [INFO] 使用 166824 个样本训练神经网络
2025-04-28 02:36:22,812 [INFO] Training with 166824 examples
2025-04-28 02:36:22,813 [INFO] 总训练步数: 1215, 每轮次批次数: 81
2025-04-28 02:36:23,382 [INFO] 循环学习率周期大小: 243 步
2025-04-28 02:37:16,553 [INFO] Epoch 1/15 - Policy Loss: 1.4649, Value Loss: 0.1215, Total Loss: 1.5864, LR: 0.001680
2025-04-28 02:38:08,132 [INFO] Epoch 2/15 - Policy Loss: 1.4583, Value Loss: 0.1167, Total Loss: 1.5750, LR: 0.003330
2025-04-28 02:39:04,951 [INFO] Epoch 3/15 - Policy Loss: 1.4564, Value Loss: 0.1148, Total Loss: 1.5711, LR: 0.004980
2025-04-28 02:39:57,229 [INFO] Epoch 4/15 - Policy Loss: 1.4578, Value Loss: 0.1148, Total Loss: 1.5726, LR: 0.003370
2025-04-28 02:40:53,102 [INFO] Epoch 5/15 - Policy Loss: 1.4559, Value Loss: 0.1139, Total Loss: 1.5698, LR: 0.001720
2025-04-28 02:41:45,701 [INFO] Epoch 6/15 - Policy Loss: 1.4529, Value Loss: 0.1122, Total Loss: 1.5651, LR: 0.000070
2025-04-28 02:42:43,470 [INFO] Epoch 7/15 - Policy Loss: 1.4491, Value Loss: 0.1112, Total Loss: 1.5603, LR: 0.001680
2025-04-28 02:43:35,416 [INFO] Epoch 8/15 - Policy Loss: 1.4465, Value Loss: 0.1100, Total Loss: 1.5565, LR: 0.003330
2025-04-28 02:44:28,244 [INFO] Epoch 9/15 - Policy Loss: 1.4459, Value Loss: 0.1094, Total Loss: 1.5554, LR: 0.004980
2025-04-28 02:45:25,277 [INFO] Epoch 10/15 - Policy Loss: 1.4459, Value Loss: 0.1093, Total Loss: 1.5552, LR: 0.003370
2025-04-28 02:46:17,929 [INFO] Epoch 11/15 - Policy Loss: 1.4450, Value Loss: 0.1086, Total Loss: 1.5536, LR: 0.001720
2025-04-28 02:47:09,192 [INFO] Epoch 12/15 - Policy Loss: 1.4432, Value Loss: 0.1080, Total Loss: 1.5512, LR: 0.000070
2025-04-28 02:48:05,556 [INFO] Epoch 13/15 - Policy Loss: 1.4417, Value Loss: 0.1076, Total Loss: 1.5493, LR: 0.001680
2025-04-28 02:49:02,293 [INFO] Epoch 14/15 - Policy Loss: 1.4399, Value Loss: 0.1072, Total Loss: 1.5471, LR: 0.003330
2025-04-28 02:49:54,873 [INFO] Epoch 15/15 - Policy Loss: 1.4402, Value Loss: 0.1070, Total Loss: 1.5472, LR: 0.004980
2025-04-28 02:49:54,947 [INFO] 训练完成，总损失: 1.5472
2025-04-28 02:49:54,947 [INFO] 保存迭代 19 的模型
2025-04-28 02:49:56,685 [INFO] Model saved to ./models/best.pt
2025-04-28 02:49:58,417 [INFO] Model saved to ./models/iteration_19.pt
2025-04-28 02:49:58,418 [INFO] 所有训练迭代完成
2025-04-28 02:49:58,418 [INFO] 开始迭代 20/300
2025-04-28 02:49:58,418 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-28 03:07:50,605 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-28 03:07:50,605 [INFO] 保存训练样本
2025-04-28 03:07:57,913 [INFO] 使用 166200 个样本训练神经网络
2025-04-28 03:07:57,913 [INFO] Training with 166200 examples
2025-04-28 03:07:57,914 [INFO] 总训练步数: 1215, 每轮次批次数: 81
2025-04-28 03:07:58,476 [INFO] 循环学习率周期大小: 243 步
2025-04-28 03:08:54,980 [INFO] Epoch 1/15 - Policy Loss: 1.4527, Value Loss: 0.1077, Total Loss: 1.5604, LR: 0.001680
2025-04-28 03:09:46,609 [INFO] Epoch 2/15 - Policy Loss: 1.4494, Value Loss: 0.1063, Total Loss: 1.5557, LR: 0.003330
2025-04-28 03:10:43,251 [INFO] Epoch 3/15 - Policy Loss: 1.4494, Value Loss: 0.1062, Total Loss: 1.5556, LR: 0.004980
2025-04-28 03:11:34,525 [INFO] Epoch 4/15 - Policy Loss: 1.4502, Value Loss: 0.1055, Total Loss: 1.5556, LR: 0.003370
2025-04-28 03:12:31,050 [INFO] Epoch 5/15 - Policy Loss: 1.4490, Value Loss: 0.1048, Total Loss: 1.5537, LR: 0.001720
2025-04-28 03:13:24,673 [INFO] Epoch 6/15 - Policy Loss: 1.4463, Value Loss: 0.1043, Total Loss: 1.5505, LR: 0.000070
2025-04-28 03:14:18,280 [INFO] Epoch 7/15 - Policy Loss: 1.4439, Value Loss: 0.1036, Total Loss: 1.5475, LR: 0.001680
2025-04-28 03:15:16,155 [INFO] Epoch 8/15 - Policy Loss: 1.4418, Value Loss: 0.1031, Total Loss: 1.5448, LR: 0.003330
2025-04-28 03:16:08,421 [INFO] Epoch 9/15 - Policy Loss: 1.4413, Value Loss: 0.1026, Total Loss: 1.5439, LR: 0.004980
2025-04-28 03:17:05,225 [INFO] Epoch 10/15 - Policy Loss: 1.4424, Value Loss: 0.1024, Total Loss: 1.5448, LR: 0.003370
2025-04-28 03:17:57,388 [INFO] Epoch 11/15 - Policy Loss: 1.4423, Value Loss: 0.1022, Total Loss: 1.5444, LR: 0.001720
2025-04-28 03:18:53,515 [INFO] Epoch 12/15 - Policy Loss: 1.4413, Value Loss: 0.1019, Total Loss: 1.5432, LR: 0.000070
2025-04-28 03:19:46,117 [INFO] Epoch 13/15 - Policy Loss: 1.4405, Value Loss: 0.1014, Total Loss: 1.5419, LR: 0.001680
2025-04-28 03:20:37,904 [INFO] Epoch 14/15 - Policy Loss: 1.4397, Value Loss: 0.1011, Total Loss: 1.5408, LR: 0.003330
2025-04-28 03:21:31,576 [INFO] Epoch 15/15 - Policy Loss: 1.4395, Value Loss: 0.1009, Total Loss: 1.5404, LR: 0.004980
2025-04-28 03:21:31,691 [INFO] 训练完成，总损失: 1.5404
2025-04-28 03:21:31,691 [INFO] 保存迭代 20 的模型
2025-04-28 03:21:33,368 [INFO] Model saved to ./models/best.pt
2025-04-28 03:21:34,331 [INFO] Model saved to ./models/iteration_20.pt
2025-04-28 03:21:34,332 [INFO] 所有训练迭代完成
2025-04-28 03:21:34,332 [INFO] 开始迭代 21/300
2025-04-28 03:21:34,332 [INFO] 使用 8 个进程进行并行自我对弈
2025-04-28 03:40:51,972 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-04-28 03:40:51,973 [INFO] 保存训练样本
2025-04-28 03:41:00,634 [INFO] 使用 154120 个样本训练神经网络
2025-04-28 03:41:00,635 [INFO] Training with 154120 examples
2025-04-28 03:41:00,635 [INFO] 总训练步数: 1125, 每轮次批次数: 75
2025-04-28 03:41:00,739 [INFO] 循环学习率周期大小: 225 步
2025-04-28 03:41:48,340 [INFO] Epoch 1/15 - Policy Loss: 1.0012, Value Loss: 0.1249, Total Loss: 1.1261, LR: 0.001678
2025-04-28 03:42:39,789 [INFO] Epoch 2/15 - Policy Loss: 0.9712, Value Loss: 0.1200, Total Loss: 1.0913, LR: 0.003328
2025-04-28 03:43:31,741 [INFO] Epoch 3/15 - Policy Loss: 0.9600, Value Loss: 0.1178, Total Loss: 1.0779, LR: 0.004978
2025-04-28 03:44:20,980 [INFO] Epoch 4/15 - Policy Loss: 0.9542, Value Loss: 0.1167, Total Loss: 1.0710, LR: 0.003372
2025-04-28 03:45:09,765 [INFO] Epoch 5/15 - Policy Loss: 0.9497, Value Loss: 0.1155, Total Loss: 1.0652, LR: 0.001722
2025-04-28 03:46:00,508 [INFO] Epoch 6/15 - Policy Loss: 0.9444, Value Loss: 0.1144, Total Loss: 1.0588, LR: 0.000072
2025-04-28 03:46:50,823 [INFO] Epoch 7/15 - Policy Loss: 0.9397, Value Loss: 0.1134, Total Loss: 1.0531, LR: 0.001678
2025-04-28 03:47:42,400 [INFO] Epoch 8/15 - Policy Loss: 0.9374, Value Loss: 0.1126, Total Loss: 1.0500, LR: 0.003328
2025-04-28 03:48:31,045 [INFO] Epoch 9/15 - Policy Loss: 0.9371, Value Loss: 0.1122, Total Loss: 1.0493, LR: 0.004978
2025-04-28 03:49:20,403 [INFO] Epoch 10/15 - Policy Loss: 0.9367, Value Loss: 0.1121, Total Loss: 1.0488, LR: 0.003372
2025-04-28 03:50:11,833 [INFO] Epoch 11/15 - Policy Loss: 0.9359, Value Loss: 0.1117, Total Loss: 1.0476, LR: 0.001722
2025-04-28 03:51:01,683 [INFO] Epoch 12/15 - Policy Loss: 0.9347, Value Loss: 0.1113, Total Loss: 1.0459, LR: 0.000072
2025-04-28 03:51:51,331 [INFO] Epoch 13/15 - Policy Loss: 0.9328, Value Loss: 0.1109, Total Loss: 1.0438, LR: 0.001678
2025-04-28 03:52:40,096 [INFO] Epoch 14/15 - Policy Loss: 0.9317, Value Loss: 0.1105, Total Loss: 1.0422, LR: 0.003328
2025-04-28 03:53:33,274 [INFO] Epoch 15/15 - Policy Loss: 0.9312, Value Loss: 0.1102, Total Loss: 1.0415, LR: 0.004978
2025-04-28 03:53:33,386 [INFO] 训练完成，总损失: 1.0415
2025-04-28 03:53:33,387 [INFO] 保存迭代 21 的模型
2025-04-28 03:53:34,943 [INFO] Model saved to ./models/best.pt
2025-04-28 03:53:35,802 [INFO] Model saved to ./models/iteration_21.pt
2025-04-28 03:53:35,803 [INFO] 所有训练迭代完成
2025-04-28 03:53:35,803 [INFO] 开始迭代 22/300
2025-04-28 03:53:35,803 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-10 23:04:08,506 [INFO] 设置多进程启动方法为: spawn
2025-05-10 23:04:08,743 [INFO] CUDA可用，使用GPU
2025-05-10 23:04:08,743 [INFO] 配置参数:
2025-05-10 23:04:08,743 [INFO] 训练参数:
2025-05-10 23:04:08,744 [INFO]   训练轮数: 15
2025-05-10 23:04:08,744 [INFO]   批量大小: 1024
2025-05-10 23:04:08,744 [INFO]   迭代次数: 300
2025-05-10 23:04:08,744 [INFO]   每次迭代的自我对弈次数: 50
2025-05-10 23:04:08,744 [INFO]   训练样本队列最大长度: 200000
2025-05-10 23:04:08,744 [INFO]   保留的历史迭代数: 20
2025-05-10 23:04:08,744 [INFO]   新模型胜率阈值: 0.55
2025-05-10 23:04:08,744 [INFO]   竞技场比赛次数: 40
2025-05-10 23:04:08,744 [INFO]   温度阈值: 5
2025-05-10 23:04:08,744 [INFO] 神经网络参数:
2025-05-10 23:04:08,744 [INFO]   通道数: 256
2025-05-10 23:04:08,744 [INFO]   Dropout率: 0.3
2025-05-10 23:04:08,744 [INFO]   学习率范围: 5e-05 - 0.005
2025-05-10 23:04:08,744 [INFO]   梯度裁剪: 1.0
2025-05-10 23:04:08,744 [INFO]   优化器: adam
2025-05-10 23:04:08,744 [INFO] MCTS参数:
2025-05-10 23:04:08,744 [INFO]   模拟次数: 800
2025-05-10 23:04:08,744 [INFO]   PUCT常数: 4.0
2025-05-10 23:04:08,744 [INFO]   Dirichlet噪声参数: 0.3
2025-05-10 23:04:08,744 [INFO]   Dirichlet噪声权重: 0.25
2025-05-10 23:04:08,744 [INFO] 游戏参数:
2025-05-10 23:04:08,745 [INFO]   棋盘大小: 15
2025-05-10 23:04:08,745 [INFO]   获胜所需的连续棋子数: 5
2025-05-10 23:04:08,745 [INFO] 系统参数:
2025-05-10 23:04:08,745 [INFO]   使用CUDA: True
2025-05-10 23:04:08,745 [INFO]   检查点目录: ./models
2025-05-10 23:04:08,745 [INFO]   数据目录: ./data
2025-05-10 23:04:08,745 [INFO]   加载模型: False
2025-05-10 23:04:08,745 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-05-10 23:04:08,745 [INFO]   工作线程数: 4
2025-05-10 23:04:08,745 [INFO]   使用Weights & Biases: False
2025-05-10 23:04:08,745 [INFO] GUI参数:
2025-05-10 23:04:08,745 [INFO]   窗口宽度: 800
2025-05-10 23:04:08,745 [INFO]   窗口高度: 850
2025-05-10 23:04:08,745 [INFO]   格子大小: 40
2025-05-10 23:04:08,745 [INFO]   边距: 40
2025-05-10 23:04:08,745 [INFO]   底部边距: 80
2025-05-10 23:04:08,745 [INFO]   帧率: 30
2025-05-10 23:04:09,210 [INFO] Using device: cuda
2025-05-10 23:04:11,356 [INFO] 设置循环学习率: 最小值=5e-05, 最大值=0.005
2025-05-10 23:04:11,356 [INFO] 设置并行进程数为: 8
2025-05-10 23:04:11,356 [INFO] 开始训练
2025-05-10 23:04:11,356 [INFO] 开始迭代 1/300
2025-05-10 23:04:11,356 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-10 23:05:35,993 [INFO] 设置多进程启动方法为: spawn
2025-05-10 23:05:36,237 [INFO] CUDA可用，使用GPU
2025-05-10 23:05:36,238 [INFO] 配置参数:
2025-05-10 23:05:36,238 [INFO] 训练参数:
2025-05-10 23:05:36,238 [INFO]   训练轮数: 15
2025-05-10 23:05:36,238 [INFO]   批量大小: 1024
2025-05-10 23:05:36,239 [INFO]   迭代次数: 300
2025-05-10 23:05:36,239 [INFO]   每次迭代的自我对弈次数: 50
2025-05-10 23:05:36,239 [INFO]   训练样本队列最大长度: 200000
2025-05-10 23:05:36,239 [INFO]   保留的历史迭代数: 20
2025-05-10 23:05:36,239 [INFO]   新模型胜率阈值: 0.55
2025-05-10 23:05:36,239 [INFO]   竞技场比赛次数: 40
2025-05-10 23:05:36,239 [INFO]   温度阈值: 5
2025-05-10 23:05:36,239 [INFO] 神经网络参数:
2025-05-10 23:05:36,239 [INFO]   通道数: 256
2025-05-10 23:05:36,239 [INFO]   Dropout率: 0.3
2025-05-10 23:05:36,239 [INFO]   学习率范围: 5e-05 - 0.005
2025-05-10 23:05:36,239 [INFO]   梯度裁剪: 1.0
2025-05-10 23:05:36,239 [INFO]   优化器: adam
2025-05-10 23:05:36,239 [INFO] MCTS参数:
2025-05-10 23:05:36,240 [INFO]   模拟次数: 800
2025-05-10 23:05:36,240 [INFO]   PUCT常数: 4.0
2025-05-10 23:05:36,240 [INFO]   Dirichlet噪声参数: 0.3
2025-05-10 23:05:36,240 [INFO]   Dirichlet噪声权重: 0.25
2025-05-10 23:05:36,240 [INFO] 游戏参数:
2025-05-10 23:05:36,240 [INFO]   棋盘大小: 15
2025-05-10 23:05:36,240 [INFO]   获胜所需的连续棋子数: 5
2025-05-10 23:05:36,240 [INFO] 系统参数:
2025-05-10 23:05:36,240 [INFO]   使用CUDA: True
2025-05-10 23:05:36,240 [INFO]   检查点目录: ./models
2025-05-10 23:05:36,240 [INFO]   数据目录: ./data
2025-05-10 23:05:36,240 [INFO]   加载模型: False
2025-05-10 23:05:36,240 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-05-10 23:05:36,240 [INFO]   工作线程数: 4
2025-05-10 23:05:36,240 [INFO]   使用Weights & Biases: False
2025-05-10 23:05:36,240 [INFO] GUI参数:
2025-05-10 23:05:36,240 [INFO]   窗口宽度: 800
2025-05-10 23:05:36,240 [INFO]   窗口高度: 850
2025-05-10 23:05:36,240 [INFO]   格子大小: 40
2025-05-10 23:05:36,240 [INFO]   边距: 40
2025-05-10 23:05:36,240 [INFO]   底部边距: 80
2025-05-10 23:05:36,240 [INFO]   帧率: 30
2025-05-10 23:05:36,734 [INFO] Using device: cuda
2025-05-10 23:05:38,279 [INFO] 设置循环学习率: 最小值=5e-05, 最大值=0.005
2025-05-10 23:05:38,279 [INFO] 设置并行进程数为: 8
2025-05-10 23:05:38,279 [INFO] 开始训练
2025-05-10 23:05:38,279 [INFO] 开始迭代 1/300
2025-05-10 23:05:38,279 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-10 23:56:16,469 [INFO] 保存训练样本
2025-05-10 23:56:17,146 [INFO] 使用 20144 个样本训练神经网络
2025-05-10 23:56:17,146 [INFO] Training with 20144 examples
2025-05-10 23:56:17,146 [INFO] 总训练步数: 285, 每轮次批次数: 19
2025-05-10 23:56:17,151 [INFO] 循环学习率周期大小: 57 步
2025-05-10 23:56:22,976 [INFO] Epoch 1/15 - Policy Loss: 5.4318, Value Loss: 0.9615, Total Loss: 6.3933, LR: 0.001613
2025-05-10 23:56:28,051 [INFO] Epoch 2/15 - Policy Loss: 5.4283, Value Loss: 0.7473, Total Loss: 6.1756, LR: 0.003263
2025-05-10 23:56:33,137 [INFO] Epoch 3/15 - Policy Loss: 5.4211, Value Loss: 0.6247, Total Loss: 6.0458, LR: 0.004913
2025-05-10 23:56:38,240 [INFO] Epoch 4/15 - Policy Loss: 5.4076, Value Loss: 0.5205, Total Loss: 5.9281, LR: 0.003437
2025-05-10 23:56:43,313 [INFO] Epoch 5/15 - Policy Loss: 5.3962, Value Loss: 0.4417, Total Loss: 5.8379, LR: 0.001787
2025-05-10 23:56:48,374 [INFO] Epoch 6/15 - Policy Loss: 5.3849, Value Loss: 0.3814, Total Loss: 5.7663, LR: 0.000137
2025-05-10 23:56:53,435 [INFO] Epoch 7/15 - Policy Loss: 5.3748, Value Loss: 0.3363, Total Loss: 5.7111, LR: 0.001613
2025-05-10 23:56:58,497 [INFO] Epoch 8/15 - Policy Loss: 5.3664, Value Loss: 0.3033, Total Loss: 5.6697, LR: 0.003263
2025-05-10 23:57:03,582 [INFO] Epoch 9/15 - Policy Loss: 5.3611, Value Loss: 0.2792, Total Loss: 5.6403, LR: 0.004913
2025-05-10 23:57:08,757 [INFO] Epoch 10/15 - Policy Loss: 5.3555, Value Loss: 0.2618, Total Loss: 5.6174, LR: 0.003437
2025-05-10 23:57:13,831 [INFO] Epoch 11/15 - Policy Loss: 5.3494, Value Loss: 0.2447, Total Loss: 5.5941, LR: 0.001787
2025-05-10 23:57:18,908 [INFO] Epoch 12/15 - Policy Loss: 5.3439, Value Loss: 0.2294, Total Loss: 5.5733, LR: 0.000137
2025-05-10 23:57:23,977 [INFO] Epoch 13/15 - Policy Loss: 5.3380, Value Loss: 0.2158, Total Loss: 5.5537, LR: 0.001613
2025-05-10 23:57:29,061 [INFO] Epoch 14/15 - Policy Loss: 5.3331, Value Loss: 0.2064, Total Loss: 5.5395, LR: 0.003263
2025-05-10 23:57:34,134 [INFO] Epoch 15/15 - Policy Loss: 5.3295, Value Loss: 0.2012, Total Loss: 5.5307, LR: 0.004913
2025-05-10 23:57:34,137 [INFO] 训练完成，总损失: 5.5307
2025-05-10 23:57:34,137 [INFO] 保存迭代 1 的模型
2025-05-10 23:57:34,990 [INFO] Model saved to ./models/best.pt
2025-05-10 23:57:35,817 [INFO] Model saved to ./models/iteration_1.pt
2025-05-10 23:57:35,817 [INFO] 所有训练迭代完成
2025-05-10 23:57:35,817 [INFO] 开始迭代 2/300
2025-05-10 23:57:35,817 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 00:50:30,608 [INFO] 保存训练样本
2025-05-11 00:50:32,080 [INFO] 使用 42496 个样本训练神经网络
2025-05-11 00:50:32,081 [INFO] Training with 42496 examples
2025-05-11 00:50:32,081 [INFO] 总训练步数: 615, 每轮次批次数: 41
2025-05-11 00:50:32,094 [INFO] 循环学习率周期大小: 123 步
2025-05-11 00:50:43,061 [INFO] Epoch 1/15 - Policy Loss: 5.1581, Value Loss: 0.6028, Total Loss: 5.7609, LR: 0.001660
2025-05-11 00:50:53,994 [INFO] Epoch 2/15 - Policy Loss: 4.9531, Value Loss: 0.4280, Total Loss: 5.3811, LR: 0.003310
2025-05-11 00:51:05,118 [INFO] Epoch 3/15 - Policy Loss: 4.8165, Value Loss: 0.3515, Total Loss: 5.1680, LR: 0.004960
2025-05-11 00:51:16,102 [INFO] Epoch 4/15 - Policy Loss: 4.6996, Value Loss: 0.3094, Total Loss: 5.0090, LR: 0.003390
2025-05-11 00:51:27,136 [INFO] Epoch 5/15 - Policy Loss: 4.5771, Value Loss: 0.2732, Total Loss: 4.8503, LR: 0.001740
2025-05-11 00:51:38,124 [INFO] Epoch 6/15 - Policy Loss: 4.4641, Value Loss: 0.2437, Total Loss: 4.7078, LR: 0.000090
2025-05-11 00:51:49,112 [INFO] Epoch 7/15 - Policy Loss: 4.3648, Value Loss: 0.2201, Total Loss: 4.5849, LR: 0.001660
2025-05-11 00:52:00,064 [INFO] Epoch 8/15 - Policy Loss: 4.2918, Value Loss: 0.2051, Total Loss: 4.4970, LR: 0.003310
2025-05-11 00:52:11,049 [INFO] Epoch 9/15 - Policy Loss: 4.2429, Value Loss: 0.1990, Total Loss: 4.4420, LR: 0.004960
2025-05-11 00:52:21,939 [INFO] Epoch 10/15 - Policy Loss: 4.2021, Value Loss: 0.1954, Total Loss: 4.3975, LR: 0.003390
2025-05-11 00:52:32,842 [INFO] Epoch 11/15 - Policy Loss: 4.1511, Value Loss: 0.1893, Total Loss: 4.3404, LR: 0.001740
2025-05-11 00:52:43,741 [INFO] Epoch 12/15 - Policy Loss: 4.0951, Value Loss: 0.1808, Total Loss: 4.2759, LR: 0.000090
2025-05-11 00:52:54,637 [INFO] Epoch 13/15 - Policy Loss: 4.0403, Value Loss: 0.1726, Total Loss: 4.2130, LR: 0.001660
2025-05-11 00:53:05,574 [INFO] Epoch 14/15 - Policy Loss: 3.9941, Value Loss: 0.1660, Total Loss: 4.1601, LR: 0.003310
2025-05-11 00:53:16,513 [INFO] Epoch 15/15 - Policy Loss: 3.9607, Value Loss: 0.1606, Total Loss: 4.1213, LR: 0.004960
2025-05-11 00:53:16,519 [INFO] 训练完成，总损失: 4.1213
2025-05-11 00:53:16,519 [INFO] 保存迭代 2 的模型
2025-05-11 00:53:17,971 [INFO] Model saved to ./models/best.pt
2025-05-11 00:53:18,627 [INFO] Model saved to ./models/iteration_2.pt
2025-05-11 00:53:18,627 [INFO] 所有训练迭代完成
2025-05-11 00:53:18,627 [INFO] 开始迭代 3/300
2025-05-11 00:53:18,627 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 01:46:13,848 [INFO] 保存训练样本
2025-05-11 01:46:15,865 [INFO] 使用 63712 个样本训练神经网络
2025-05-11 01:46:15,865 [INFO] Training with 63712 examples
2025-05-11 01:46:15,866 [INFO] 总训练步数: 930, 每轮次批次数: 62
2025-05-11 01:46:16,047 [INFO] 循环学习率周期大小: 186 步
2025-05-11 01:46:32,549 [INFO] Epoch 1/15 - Policy Loss: 4.0637, Value Loss: 0.5029, Total Loss: 4.5667, LR: 0.001673
2025-05-11 01:46:49,119 [INFO] Epoch 2/15 - Policy Loss: 3.8925, Value Loss: 0.3516, Total Loss: 4.2441, LR: 0.003323
2025-05-11 01:47:05,624 [INFO] Epoch 3/15 - Policy Loss: 3.7801, Value Loss: 0.2856, Total Loss: 4.0658, LR: 0.004973
2025-05-11 01:47:22,176 [INFO] Epoch 4/15 - Policy Loss: 3.6954, Value Loss: 0.2470, Total Loss: 3.9424, LR: 0.003377
2025-05-11 01:47:38,845 [INFO] Epoch 5/15 - Policy Loss: 3.6095, Value Loss: 0.2188, Total Loss: 3.8283, LR: 0.001727
2025-05-11 01:47:55,424 [INFO] Epoch 6/15 - Policy Loss: 3.5278, Value Loss: 0.1970, Total Loss: 3.7248, LR: 0.000077
2025-05-11 01:48:12,002 [INFO] Epoch 7/15 - Policy Loss: 3.4632, Value Loss: 0.1802, Total Loss: 3.6434, LR: 0.001673
2025-05-11 01:48:28,585 [INFO] Epoch 8/15 - Policy Loss: 3.4127, Value Loss: 0.1677, Total Loss: 3.5804, LR: 0.003323
2025-05-11 01:48:45,215 [INFO] Epoch 9/15 - Policy Loss: 3.3811, Value Loss: 0.1587, Total Loss: 3.5398, LR: 0.004973
2025-05-11 01:49:01,795 [INFO] Epoch 10/15 - Policy Loss: 3.3611, Value Loss: 0.1525, Total Loss: 3.5135, LR: 0.003377
2025-05-11 01:49:18,369 [INFO] Epoch 11/15 - Policy Loss: 3.3324, Value Loss: 0.1462, Total Loss: 3.4786, LR: 0.001727
2025-05-11 01:49:35,049 [INFO] Epoch 12/15 - Policy Loss: 3.2997, Value Loss: 0.1401, Total Loss: 3.4398, LR: 0.000077
2025-05-11 01:49:51,608 [INFO] Epoch 13/15 - Policy Loss: 3.2675, Value Loss: 0.1347, Total Loss: 3.4022, LR: 0.001673
2025-05-11 01:50:08,161 [INFO] Epoch 14/15 - Policy Loss: 3.2391, Value Loss: 0.1299, Total Loss: 3.3690, LR: 0.003323
2025-05-11 01:50:24,678 [INFO] Epoch 15/15 - Policy Loss: 3.2192, Value Loss: 0.1265, Total Loss: 3.3457, LR: 0.004973
2025-05-11 01:50:24,688 [INFO] 训练完成，总损失: 3.3457
2025-05-11 01:50:24,688 [INFO] 保存迭代 3 的模型
2025-05-11 01:50:25,995 [INFO] Model saved to ./models/best.pt
2025-05-11 01:50:26,980 [INFO] Model saved to ./models/iteration_3.pt
2025-05-11 01:50:26,981 [INFO] 所有训练迭代完成
2025-05-11 01:50:26,981 [INFO] 开始迭代 4/300
2025-05-11 01:50:26,981 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 02:47:36,935 [INFO] 保存训练样本
2025-05-11 02:47:39,722 [INFO] 使用 86552 个样本训练神经网络
2025-05-11 02:47:39,722 [INFO] Training with 86552 examples
2025-05-11 02:47:39,723 [INFO] 总训练步数: 1260, 每轮次批次数: 84
2025-05-11 02:47:39,749 [INFO] 循环学习率周期大小: 252 步
2025-05-11 02:48:01,984 [INFO] Epoch 1/15 - Policy Loss: 3.5361, Value Loss: 0.3213, Total Loss: 3.8574, LR: 0.001680
2025-05-11 02:48:24,241 [INFO] Epoch 2/15 - Policy Loss: 3.4161, Value Loss: 0.2215, Total Loss: 3.6377, LR: 0.003330
2025-05-11 02:48:46,387 [INFO] Epoch 3/15 - Policy Loss: 3.3503, Value Loss: 0.1838, Total Loss: 3.5341, LR: 0.004980
2025-05-11 02:49:08,700 [INFO] Epoch 4/15 - Policy Loss: 3.3075, Value Loss: 0.1644, Total Loss: 3.4719, LR: 0.003370
2025-05-11 02:49:30,865 [INFO] Epoch 5/15 - Policy Loss: 3.2519, Value Loss: 0.1477, Total Loss: 3.3996, LR: 0.001720
2025-05-11 02:49:53,297 [INFO] Epoch 6/15 - Policy Loss: 3.1944, Value Loss: 0.1346, Total Loss: 3.3291, LR: 0.000070
2025-05-11 02:50:15,718 [INFO] Epoch 7/15 - Policy Loss: 3.1451, Value Loss: 0.1250, Total Loss: 3.2701, LR: 0.001680
2025-05-11 02:50:38,074 [INFO] Epoch 8/15 - Policy Loss: 3.1088, Value Loss: 0.1184, Total Loss: 3.2271, LR: 0.003330
2025-05-11 02:51:00,455 [INFO] Epoch 9/15 - Policy Loss: 3.0874, Value Loss: 0.1133, Total Loss: 3.2007, LR: 0.004980
2025-05-11 02:51:22,766 [INFO] Epoch 10/15 - Policy Loss: 3.0745, Value Loss: 0.1099, Total Loss: 3.1844, LR: 0.003370
2025-05-11 02:51:45,200 [INFO] Epoch 11/15 - Policy Loss: 3.0549, Value Loss: 0.1066, Total Loss: 3.1615, LR: 0.001720
2025-05-11 02:52:07,504 [INFO] Epoch 12/15 - Policy Loss: 3.0295, Value Loss: 0.1034, Total Loss: 3.1329, LR: 0.000070
2025-05-11 02:52:29,773 [INFO] Epoch 13/15 - Policy Loss: 3.0043, Value Loss: 0.1003, Total Loss: 3.1045, LR: 0.001680
2025-05-11 02:52:52,208 [INFO] Epoch 14/15 - Policy Loss: 2.9842, Value Loss: 0.0979, Total Loss: 3.0821, LR: 0.003330
2025-05-11 02:53:14,576 [INFO] Epoch 15/15 - Policy Loss: 2.9721, Value Loss: 0.0962, Total Loss: 3.0683, LR: 0.004980
2025-05-11 02:53:14,588 [INFO] 训练完成，总损失: 3.0683
2025-05-11 02:53:14,588 [INFO] 保存迭代 4 的模型
2025-05-11 02:53:15,641 [INFO] Model saved to ./models/best.pt
2025-05-11 02:53:16,311 [INFO] Model saved to ./models/iteration_4.pt
2025-05-11 02:53:16,311 [INFO] 所有训练迭代完成
2025-05-11 02:53:16,311 [INFO] 开始迭代 5/300
2025-05-11 02:53:16,311 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 03:40:01,204 [INFO] 保存训练样本
2025-05-11 03:40:04,727 [INFO] 使用 105240 个样本训练神经网络
2025-05-11 03:40:04,727 [INFO] Training with 105240 examples
2025-05-11 03:40:04,727 [INFO] 总训练步数: 1530, 每轮次批次数: 102
2025-05-11 03:40:05,030 [INFO] 循环学习率周期大小: 306 步
2025-05-11 03:40:32,014 [INFO] Epoch 1/15 - Policy Loss: 3.2646, Value Loss: 0.2002, Total Loss: 3.4648, LR: 0.001684
2025-05-11 03:40:59,118 [INFO] Epoch 2/15 - Policy Loss: 3.1655, Value Loss: 0.1455, Total Loss: 3.3110, LR: 0.003334
2025-05-11 03:41:26,202 [INFO] Epoch 3/15 - Policy Loss: 3.1230, Value Loss: 0.1266, Total Loss: 3.2496, LR: 0.004984
2025-05-11 03:41:53,384 [INFO] Epoch 4/15 - Policy Loss: 3.0996, Value Loss: 0.1166, Total Loss: 3.2161, LR: 0.003366
2025-05-11 03:42:20,380 [INFO] Epoch 5/15 - Policy Loss: 3.0551, Value Loss: 0.1075, Total Loss: 3.1627, LR: 0.001716
2025-05-11 03:42:47,417 [INFO] Epoch 6/15 - Policy Loss: 3.0048, Value Loss: 0.1003, Total Loss: 3.1051, LR: 0.000066
2025-05-11 03:43:14,448 [INFO] Epoch 7/15 - Policy Loss: 2.9623, Value Loss: 0.0950, Total Loss: 3.0573, LR: 0.001684
2025-05-11 03:43:41,559 [INFO] Epoch 8/15 - Policy Loss: 2.9301, Value Loss: 0.0909, Total Loss: 3.0210, LR: 0.003334
2025-05-11 03:44:08,783 [INFO] Epoch 9/15 - Policy Loss: 2.9148, Value Loss: 0.0888, Total Loss: 3.0036, LR: 0.004984
2025-05-11 03:44:35,902 [INFO] Epoch 10/15 - Policy Loss: 2.9102, Value Loss: 0.0888, Total Loss: 2.9990, LR: 0.003366
2025-05-11 03:45:03,074 [INFO] Epoch 11/15 - Policy Loss: 2.8953, Value Loss: 0.0874, Total Loss: 2.9827, LR: 0.001716
2025-05-11 03:45:30,304 [INFO] Epoch 12/15 - Policy Loss: 2.8733, Value Loss: 0.0853, Total Loss: 2.9587, LR: 0.000066
2025-05-11 03:45:57,671 [INFO] Epoch 13/15 - Policy Loss: 2.8523, Value Loss: 0.0834, Total Loss: 2.9357, LR: 0.001684
2025-05-11 03:46:24,916 [INFO] Epoch 14/15 - Policy Loss: 2.8342, Value Loss: 0.0818, Total Loss: 2.9160, LR: 0.003334
2025-05-11 03:46:52,252 [INFO] Epoch 15/15 - Policy Loss: 2.8227, Value Loss: 0.0806, Total Loss: 2.9032, LR: 0.004984
2025-05-11 03:46:52,269 [INFO] 训练完成，总损失: 2.9032
2025-05-11 03:46:52,270 [INFO] 保存迭代 5 的模型
2025-05-11 03:46:53,574 [INFO] Model saved to ./models/best.pt
2025-05-11 03:46:54,256 [INFO] Model saved to ./models/iteration_5.pt
2025-05-11 03:46:54,256 [INFO] 所有训练迭代完成
2025-05-11 03:46:54,256 [INFO] 开始迭代 6/300
2025-05-11 03:46:54,256 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 04:34:33,208 [INFO] 保存训练样本
2025-05-11 04:34:37,363 [INFO] 使用 123968 个样本训练神经网络
2025-05-11 04:34:37,363 [INFO] Training with 123968 examples
2025-05-11 04:34:37,364 [INFO] 总训练步数: 1815, 每轮次批次数: 121
2025-05-11 04:34:37,408 [INFO] 循环学习率周期大小: 363 步
2025-05-11 04:35:09,189 [INFO] Epoch 1/15 - Policy Loss: 3.0277, Value Loss: 0.1909, Total Loss: 3.2186, LR: 0.001686
2025-05-11 04:35:41,169 [INFO] Epoch 2/15 - Policy Loss: 2.9414, Value Loss: 0.1394, Total Loss: 3.0808, LR: 0.003336
2025-05-11 04:36:13,117 [INFO] Epoch 3/15 - Policy Loss: 2.9069, Value Loss: 0.1204, Total Loss: 3.0273, LR: 0.004986
2025-05-11 04:36:44,956 [INFO] Epoch 4/15 - Policy Loss: 2.8951, Value Loss: 0.1124, Total Loss: 3.0075, LR: 0.003364
2025-05-11 04:37:16,898 [INFO] Epoch 5/15 - Policy Loss: 2.8572, Value Loss: 0.1045, Total Loss: 2.9618, LR: 0.001714
2025-05-11 04:37:48,930 [INFO] Epoch 6/15 - Policy Loss: 2.8132, Value Loss: 0.0977, Total Loss: 2.9109, LR: 0.000064
2025-05-11 04:38:21,340 [INFO] Epoch 7/15 - Policy Loss: 2.7758, Value Loss: 0.0928, Total Loss: 2.8686, LR: 0.001686
2025-05-11 04:38:53,478 [INFO] Epoch 8/15 - Policy Loss: 2.7475, Value Loss: 0.0889, Total Loss: 2.8364, LR: 0.003336
2025-05-11 04:39:25,693 [INFO] Epoch 9/15 - Policy Loss: 2.7338, Value Loss: 0.0864, Total Loss: 2.8201, LR: 0.004986
2025-05-11 04:39:57,966 [INFO] Epoch 10/15 - Policy Loss: 2.7276, Value Loss: 0.0849, Total Loss: 2.8125, LR: 0.003364
2025-05-11 04:40:30,037 [INFO] Epoch 11/15 - Policy Loss: 2.7126, Value Loss: 0.0830, Total Loss: 2.7957, LR: 0.001714
2025-05-11 04:41:02,234 [INFO] Epoch 12/15 - Policy Loss: 2.6929, Value Loss: 0.0811, Total Loss: 2.7740, LR: 0.000064
2025-05-11 04:41:34,411 [INFO] Epoch 13/15 - Policy Loss: 2.6739, Value Loss: 0.0793, Total Loss: 2.7532, LR: 0.001686
2025-05-11 04:42:06,825 [INFO] Epoch 14/15 - Policy Loss: 2.6583, Value Loss: 0.0779, Total Loss: 2.7361, LR: 0.003336
2025-05-11 04:42:39,159 [INFO] Epoch 15/15 - Policy Loss: 2.6491, Value Loss: 0.0768, Total Loss: 2.7259, LR: 0.004986
2025-05-11 04:42:39,179 [INFO] 训练完成，总损失: 2.7259
2025-05-11 04:42:39,179 [INFO] 保存迭代 6 的模型
2025-05-11 04:42:40,539 [INFO] Model saved to ./models/best.pt
2025-05-11 04:42:41,399 [INFO] Model saved to ./models/iteration_6.pt
2025-05-11 04:42:41,399 [INFO] 所有训练迭代完成
2025-05-11 04:42:41,399 [INFO] 开始迭代 7/300
2025-05-11 04:42:41,399 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 05:27:54,565 [INFO] 保存训练样本
2025-05-11 05:27:58,527 [INFO] 使用 142408 个样本训练神经网络
2025-05-11 05:27:58,527 [INFO] Training with 142408 examples
2025-05-11 05:27:58,527 [INFO] 总训练步数: 2085, 每轮次批次数: 139
2025-05-11 05:27:58,852 [INFO] 循环学习率周期大小: 417 步
2025-05-11 05:28:35,343 [INFO] Epoch 1/15 - Policy Loss: 2.8686, Value Loss: 0.1834, Total Loss: 3.0520, LR: 0.001688
2025-05-11 05:29:11,850 [INFO] Epoch 2/15 - Policy Loss: 2.7911, Value Loss: 0.1353, Total Loss: 2.9264, LR: 0.003338
2025-05-11 05:29:48,359 [INFO] Epoch 3/15 - Policy Loss: 2.7705, Value Loss: 0.1202, Total Loss: 2.8907, LR: 0.004988
2025-05-11 05:30:25,059 [INFO] Epoch 4/15 - Policy Loss: 2.7632, Value Loss: 0.1109, Total Loss: 2.8742, LR: 0.003362
2025-05-11 05:31:01,695 [INFO] Epoch 5/15 - Policy Loss: 2.7248, Value Loss: 0.1022, Total Loss: 2.8270, LR: 0.001712
2025-05-11 05:31:38,287 [INFO] Epoch 6/15 - Policy Loss: 2.6821, Value Loss: 0.0954, Total Loss: 2.7775, LR: 0.000062
2025-05-11 05:32:15,127 [INFO] Epoch 7/15 - Policy Loss: 2.6460, Value Loss: 0.0905, Total Loss: 2.7365, LR: 0.001688
2025-05-11 05:32:51,744 [INFO] Epoch 8/15 - Policy Loss: 2.6182, Value Loss: 0.0868, Total Loss: 2.7049, LR: 0.003338
2025-05-11 05:33:28,341 [INFO] Epoch 9/15 - Policy Loss: 2.6043, Value Loss: 0.0843, Total Loss: 2.6886, LR: 0.004988
2025-05-11 05:34:05,277 [INFO] Epoch 10/15 - Policy Loss: 2.5995, Value Loss: 0.0826, Total Loss: 2.6821, LR: 0.003362
2025-05-11 05:34:42,045 [INFO] Epoch 11/15 - Policy Loss: 2.5864, Value Loss: 0.0808, Total Loss: 2.6672, LR: 0.001712
2025-05-11 05:35:19,026 [INFO] Epoch 12/15 - Policy Loss: 2.5688, Value Loss: 0.0790, Total Loss: 2.6478, LR: 0.000062
2025-05-11 05:35:56,102 [INFO] Epoch 13/15 - Policy Loss: 2.5513, Value Loss: 0.0775, Total Loss: 2.6288, LR: 0.001688
2025-05-11 05:36:33,216 [INFO] Epoch 14/15 - Policy Loss: 2.5365, Value Loss: 0.0761, Total Loss: 2.6126, LR: 0.003338
2025-05-11 05:37:10,276 [INFO] Epoch 15/15 - Policy Loss: 2.5283, Value Loss: 0.0751, Total Loss: 2.6035, LR: 0.004988
2025-05-11 05:37:10,300 [INFO] 训练完成，总损失: 2.6035
2025-05-11 05:37:10,300 [INFO] 保存迭代 7 的模型
2025-05-11 05:37:11,658 [INFO] Model saved to ./models/best.pt
2025-05-11 05:37:12,482 [INFO] Model saved to ./models/iteration_7.pt
2025-05-11 05:37:12,482 [INFO] 所有训练迭代完成
2025-05-11 05:37:12,482 [INFO] 开始迭代 8/300
2025-05-11 05:37:12,482 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 06:23:33,514 [INFO] 保存训练样本
2025-05-11 06:23:39,063 [INFO] 使用 161096 个样本训练神经网络
2025-05-11 06:23:39,063 [INFO] Training with 161096 examples
2025-05-11 06:23:39,063 [INFO] 总训练步数: 2355, 每轮次批次数: 157
2025-05-11 06:23:39,122 [INFO] 循环学习率周期大小: 471 步
2025-05-11 06:24:20,331 [INFO] Epoch 1/15 - Policy Loss: 2.7262, Value Loss: 0.1711, Total Loss: 2.8972, LR: 0.001689
2025-05-11 06:25:01,516 [INFO] Epoch 2/15 - Policy Loss: 2.6592, Value Loss: 0.1301, Total Loss: 2.7893, LR: 0.003339
2025-05-11 06:25:42,698 [INFO] Epoch 3/15 - Policy Loss: 2.6329, Value Loss: 0.1135, Total Loss: 2.7463, LR: 0.004989
2025-05-11 06:26:23,929 [INFO] Epoch 4/15 - Policy Loss: 2.6275, Value Loss: 0.1053, Total Loss: 2.7329, LR: 0.003361
2025-05-11 06:27:05,712 [INFO] Epoch 5/15 - Policy Loss: 2.5954, Value Loss: 0.0979, Total Loss: 2.6934, LR: 0.001711
2025-05-11 06:27:47,370 [INFO] Epoch 6/15 - Policy Loss: 2.5571, Value Loss: 0.0923, Total Loss: 2.6494, LR: 0.000061
2025-05-11 06:28:29,131 [INFO] Epoch 7/15 - Policy Loss: 2.5258, Value Loss: 0.0879, Total Loss: 2.6137, LR: 0.001689
2025-05-11 06:29:10,789 [INFO] Epoch 8/15 - Policy Loss: 2.5013, Value Loss: 0.0848, Total Loss: 2.5861, LR: 0.003339
2025-05-11 06:29:52,333 [INFO] Epoch 9/15 - Policy Loss: 2.4897, Value Loss: 0.0826, Total Loss: 2.5724, LR: 0.004989
2025-05-11 06:30:34,025 [INFO] Epoch 10/15 - Policy Loss: 2.4889, Value Loss: 0.0818, Total Loss: 2.5707, LR: 0.003361
2025-05-11 06:31:15,619 [INFO] Epoch 11/15 - Policy Loss: 2.4792, Value Loss: 0.0803, Total Loss: 2.5595, LR: 0.001711
2025-05-11 06:31:57,288 [INFO] Epoch 12/15 - Policy Loss: 2.4639, Value Loss: 0.0788, Total Loss: 2.5427, LR: 0.000061
2025-05-11 06:32:39,102 [INFO] Epoch 13/15 - Policy Loss: 2.4496, Value Loss: 0.0773, Total Loss: 2.5270, LR: 0.001689
2025-05-11 06:33:20,773 [INFO] Epoch 14/15 - Policy Loss: 2.4366, Value Loss: 0.0762, Total Loss: 2.5127, LR: 0.003339
2025-05-11 06:34:02,386 [INFO] Epoch 15/15 - Policy Loss: 2.4307, Value Loss: 0.0755, Total Loss: 2.5062, LR: 0.004989
2025-05-11 06:34:02,410 [INFO] 训练完成，总损失: 2.5062
2025-05-11 06:34:02,411 [INFO] 保存迭代 8 的模型
2025-05-11 06:34:03,520 [INFO] Model saved to ./models/best.pt
2025-05-11 06:34:04,185 [INFO] Model saved to ./models/iteration_8.pt
2025-05-11 06:34:04,185 [INFO] 所有训练迭代完成
2025-05-11 06:34:04,185 [INFO] 开始迭代 9/300
2025-05-11 06:34:04,185 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 07:19:52,183 [INFO] 保存训练样本
2025-05-11 07:19:58,452 [INFO] 使用 179568 个样本训练神经网络
2025-05-11 07:19:58,452 [INFO] Training with 179568 examples
2025-05-11 07:19:58,452 [INFO] 总训练步数: 2625, 每轮次批次数: 175
2025-05-11 07:19:58,900 [INFO] 循环学习率周期大小: 525 步
2025-05-11 07:20:45,151 [INFO] Epoch 1/15 - Policy Loss: 2.6377, Value Loss: 0.1691, Total Loss: 2.8068, LR: 0.001691
2025-05-11 07:21:31,201 [INFO] Epoch 2/15 - Policy Loss: 2.5703, Value Loss: 0.1314, Total Loss: 2.7016, LR: 0.003341
2025-05-11 07:22:17,156 [INFO] Epoch 3/15 - Policy Loss: 2.5442, Value Loss: 0.1157, Total Loss: 2.6598, LR: 0.004991
2025-05-11 07:23:03,079 [INFO] Epoch 4/15 - Policy Loss: 2.5333, Value Loss: 0.1072, Total Loss: 2.6404, LR: 0.003359
2025-05-11 07:23:49,225 [INFO] Epoch 5/15 - Policy Loss: 2.5024, Value Loss: 0.1005, Total Loss: 2.6029, LR: 0.001709
2025-05-11 07:24:35,515 [INFO] Epoch 6/15 - Policy Loss: 2.4662, Value Loss: 0.0955, Total Loss: 2.5617, LR: 0.000059
2025-05-11 07:25:21,581 [INFO] Epoch 7/15 - Policy Loss: 2.4369, Value Loss: 0.0916, Total Loss: 2.5284, LR: 0.001691
2025-05-11 07:26:07,856 [INFO] Epoch 8/15 - Policy Loss: 2.4152, Value Loss: 0.0885, Total Loss: 2.5037, LR: 0.003341
2025-05-11 07:26:54,257 [INFO] Epoch 9/15 - Policy Loss: 2.4050, Value Loss: 0.0865, Total Loss: 2.4915, LR: 0.004991
2025-05-11 07:27:40,768 [INFO] Epoch 10/15 - Policy Loss: 2.4053, Value Loss: 0.0858, Total Loss: 2.4911, LR: 0.003359
2025-05-11 07:28:27,393 [INFO] Epoch 11/15 - Policy Loss: 2.3966, Value Loss: 0.0845, Total Loss: 2.4811, LR: 0.001709
2025-05-11 07:29:14,015 [INFO] Epoch 12/15 - Policy Loss: 2.3828, Value Loss: 0.0831, Total Loss: 2.4659, LR: 0.000059
2025-05-11 07:30:00,695 [INFO] Epoch 13/15 - Policy Loss: 2.3688, Value Loss: 0.0818, Total Loss: 2.4507, LR: 0.001691
2025-05-11 07:30:47,648 [INFO] Epoch 14/15 - Policy Loss: 2.3572, Value Loss: 0.0808, Total Loss: 2.4379, LR: 0.003341
2025-05-11 07:31:34,148 [INFO] Epoch 15/15 - Policy Loss: 2.3514, Value Loss: 0.0802, Total Loss: 2.4316, LR: 0.004991
2025-05-11 07:31:34,178 [INFO] 训练完成，总损失: 2.4316
2025-05-11 07:31:34,178 [INFO] 保存迭代 9 的模型
2025-05-11 07:31:35,487 [INFO] Model saved to ./models/best.pt
2025-05-11 07:31:36,329 [INFO] Model saved to ./models/iteration_9.pt
2025-05-11 07:31:36,329 [INFO] 所有训练迭代完成
2025-05-11 07:31:36,329 [INFO] 开始迭代 10/300
2025-05-11 07:31:36,329 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 08:10:49,401 [INFO] 保存训练样本
2025-05-11 08:10:55,947 [INFO] 使用 195560 个样本训练神经网络
2025-05-11 08:10:55,947 [INFO] Training with 195560 examples
2025-05-11 08:10:55,948 [INFO] 总训练步数: 2850, 每轮次批次数: 190
2025-05-11 08:10:56,431 [INFO] 循环学习率周期大小: 570 步
2025-05-11 08:11:46,541 [INFO] Epoch 1/15 - Policy Loss: 2.4831, Value Loss: 0.1465, Total Loss: 2.6296, LR: 0.001691
2025-05-11 08:12:36,754 [INFO] Epoch 2/15 - Policy Loss: 2.4269, Value Loss: 0.1205, Total Loss: 2.5474, LR: 0.003341
2025-05-11 08:13:26,954 [INFO] Epoch 3/15 - Policy Loss: 2.4106, Value Loss: 0.1091, Total Loss: 2.5197, LR: 0.004991
2025-05-11 08:14:17,250 [INFO] Epoch 4/15 - Policy Loss: 2.4078, Value Loss: 0.1048, Total Loss: 2.5126, LR: 0.003359
2025-05-11 08:15:07,408 [INFO] Epoch 5/15 - Policy Loss: 2.3854, Value Loss: 0.0995, Total Loss: 2.4849, LR: 0.001709
2025-05-11 08:15:57,658 [INFO] Epoch 6/15 - Policy Loss: 2.3567, Value Loss: 0.0956, Total Loss: 2.4523, LR: 0.000059
2025-05-11 08:16:48,522 [INFO] Epoch 7/15 - Policy Loss: 2.3329, Value Loss: 0.0925, Total Loss: 2.4253, LR: 0.001691
2025-05-11 08:17:38,866 [INFO] Epoch 8/15 - Policy Loss: 2.3154, Value Loss: 0.0905, Total Loss: 2.4058, LR: 0.003341
2025-05-11 08:18:29,070 [INFO] Epoch 9/15 - Policy Loss: 2.3077, Value Loss: 0.0892, Total Loss: 2.3969, LR: 0.004991
2025-05-11 08:19:19,441 [INFO] Epoch 10/15 - Policy Loss: 2.3072, Value Loss: 0.0884, Total Loss: 2.3956, LR: 0.003359
2025-05-11 08:20:09,929 [INFO] Epoch 11/15 - Policy Loss: 2.2993, Value Loss: 0.0874, Total Loss: 2.3867, LR: 0.001709
2025-05-11 08:21:00,413 [INFO] Epoch 12/15 - Policy Loss: 2.2875, Value Loss: 0.0863, Total Loss: 2.3738, LR: 0.000059
2025-05-11 08:21:51,029 [INFO] Epoch 13/15 - Policy Loss: 2.2759, Value Loss: 0.0853, Total Loss: 2.3612, LR: 0.001691
2025-05-11 08:22:41,708 [INFO] Epoch 14/15 - Policy Loss: 2.2666, Value Loss: 0.0845, Total Loss: 2.3511, LR: 0.003341
2025-05-11 08:23:32,140 [INFO] Epoch 15/15 - Policy Loss: 2.2626, Value Loss: 0.0839, Total Loss: 2.3465, LR: 0.004991
2025-05-11 08:23:32,168 [INFO] 训练完成，总损失: 2.3465
2025-05-11 08:23:32,168 [INFO] 保存迭代 10 的模型
2025-05-11 08:23:33,232 [INFO] Model saved to ./models/best.pt
2025-05-11 08:23:33,890 [INFO] Model saved to ./models/iteration_10.pt
2025-05-11 08:23:33,890 [INFO] 所有训练迭代完成
2025-05-11 08:23:33,890 [INFO] 开始迭代 11/300
2025-05-11 08:23:33,891 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 09:04:48,829 [INFO] 保存训练样本
2025-05-11 09:04:55,511 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 09:04:56,189 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 09:04:56,190 [INFO] Training with 200000 examples
2025-05-11 09:04:56,191 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 09:04:56,824 [INFO] 循环学习率周期大小: 585 步
2025-05-11 09:05:48,566 [INFO] Epoch 1/15 - Policy Loss: 2.4132, Value Loss: 0.1556, Total Loss: 2.5689, LR: 0.001692
2025-05-11 09:06:40,562 [INFO] Epoch 2/15 - Policy Loss: 2.3616, Value Loss: 0.1306, Total Loss: 2.4922, LR: 0.003342
2025-05-11 09:07:32,773 [INFO] Epoch 3/15 - Policy Loss: 2.3423, Value Loss: 0.1196, Total Loss: 2.4620, LR: 0.004992
2025-05-11 09:08:24,867 [INFO] Epoch 4/15 - Policy Loss: 2.3423, Value Loss: 0.1146, Total Loss: 2.4569, LR: 0.003358
2025-05-11 09:09:17,005 [INFO] Epoch 5/15 - Policy Loss: 2.3210, Value Loss: 0.1096, Total Loss: 2.4305, LR: 0.001708
2025-05-11 09:10:09,403 [INFO] Epoch 6/15 - Policy Loss: 2.2945, Value Loss: 0.1052, Total Loss: 2.3997, LR: 0.000058
2025-05-11 09:11:01,693 [INFO] Epoch 7/15 - Policy Loss: 2.2719, Value Loss: 0.1015, Total Loss: 2.3734, LR: 0.001692
2025-05-11 09:11:53,793 [INFO] Epoch 8/15 - Policy Loss: 2.2543, Value Loss: 0.0988, Total Loss: 2.3531, LR: 0.003342
2025-05-11 09:12:46,261 [INFO] Epoch 9/15 - Policy Loss: 2.2463, Value Loss: 0.0971, Total Loss: 2.3433, LR: 0.004992
2025-05-11 09:13:38,578 [INFO] Epoch 10/15 - Policy Loss: 2.2456, Value Loss: 0.0962, Total Loss: 2.3418, LR: 0.003358
2025-05-11 09:14:30,999 [INFO] Epoch 11/15 - Policy Loss: 2.2383, Value Loss: 0.0949, Total Loss: 2.3332, LR: 0.001708
2025-05-11 09:15:23,423 [INFO] Epoch 12/15 - Policy Loss: 2.2271, Value Loss: 0.0936, Total Loss: 2.3207, LR: 0.000058
2025-05-11 09:16:15,745 [INFO] Epoch 13/15 - Policy Loss: 2.2167, Value Loss: 0.0924, Total Loss: 2.3091, LR: 0.001692
2025-05-11 09:17:08,191 [INFO] Epoch 14/15 - Policy Loss: 2.2077, Value Loss: 0.0914, Total Loss: 2.2991, LR: 0.003342
2025-05-11 09:18:00,476 [INFO] Epoch 15/15 - Policy Loss: 2.2038, Value Loss: 0.0907, Total Loss: 2.2944, LR: 0.004992
2025-05-11 09:18:00,511 [INFO] 训练完成，总损失: 2.2944
2025-05-11 09:18:00,511 [INFO] 保存迭代 11 的模型
2025-05-11 09:18:02,037 [INFO] Model saved to ./models/best.pt
2025-05-11 09:18:02,973 [INFO] Model saved to ./models/iteration_11.pt
2025-05-11 09:18:02,974 [INFO] 所有训练迭代完成
2025-05-11 09:18:02,974 [INFO] 开始迭代 12/300
2025-05-11 09:18:02,974 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 09:58:48,027 [INFO] 保存训练样本
2025-05-11 09:58:55,884 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 09:58:56,104 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 09:58:56,104 [INFO] Training with 200000 examples
2025-05-11 09:58:56,104 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 09:58:56,788 [INFO] 循环学习率周期大小: 585 步
2025-05-11 09:59:48,870 [INFO] Epoch 1/15 - Policy Loss: 2.3885, Value Loss: 0.1605, Total Loss: 2.5490, LR: 0.001692
2025-05-11 10:00:40,968 [INFO] Epoch 2/15 - Policy Loss: 2.3302, Value Loss: 0.1315, Total Loss: 2.4617, LR: 0.003342
2025-05-11 10:01:33,230 [INFO] Epoch 3/15 - Policy Loss: 2.3089, Value Loss: 0.1188, Total Loss: 2.4277, LR: 0.004992
2025-05-11 10:02:25,226 [INFO] Epoch 4/15 - Policy Loss: 2.2986, Value Loss: 0.1119, Total Loss: 2.4105, LR: 0.003358
2025-05-11 10:03:17,313 [INFO] Epoch 5/15 - Policy Loss: 2.2753, Value Loss: 0.1065, Total Loss: 2.3817, LR: 0.001708
2025-05-11 10:04:09,422 [INFO] Epoch 6/15 - Policy Loss: 2.2478, Value Loss: 0.1020, Total Loss: 2.3498, LR: 0.000058
2025-05-11 10:05:01,757 [INFO] Epoch 7/15 - Policy Loss: 2.2253, Value Loss: 0.0987, Total Loss: 2.3240, LR: 0.001692
2025-05-11 10:05:54,139 [INFO] Epoch 8/15 - Policy Loss: 2.2084, Value Loss: 0.0964, Total Loss: 2.3048, LR: 0.003342
2025-05-11 10:06:47,085 [INFO] Epoch 9/15 - Policy Loss: 2.2012, Value Loss: 0.0949, Total Loss: 2.2961, LR: 0.004992
2025-05-11 10:07:39,522 [INFO] Epoch 10/15 - Policy Loss: 2.2012, Value Loss: 0.0943, Total Loss: 2.2956, LR: 0.003358
2025-05-11 10:08:31,632 [INFO] Epoch 11/15 - Policy Loss: 2.1949, Value Loss: 0.0933, Total Loss: 2.2882, LR: 0.001708
2025-05-11 10:09:24,068 [INFO] Epoch 12/15 - Policy Loss: 2.1838, Value Loss: 0.0921, Total Loss: 2.2759, LR: 0.000058
2025-05-11 10:10:16,496 [INFO] Epoch 13/15 - Policy Loss: 2.1736, Value Loss: 0.0911, Total Loss: 2.2647, LR: 0.001692
2025-05-11 10:11:09,061 [INFO] Epoch 14/15 - Policy Loss: 2.1648, Value Loss: 0.0902, Total Loss: 2.2550, LR: 0.003342
2025-05-11 10:12:01,473 [INFO] Epoch 15/15 - Policy Loss: 2.1606, Value Loss: 0.0896, Total Loss: 2.2502, LR: 0.004992
2025-05-11 10:12:01,509 [INFO] 训练完成，总损失: 2.2502
2025-05-11 10:12:01,509 [INFO] 保存迭代 12 的模型
2025-05-11 10:12:02,958 [INFO] Model saved to ./models/best.pt
2025-05-11 10:12:03,841 [INFO] Model saved to ./models/iteration_12.pt
2025-05-11 10:12:03,841 [INFO] 所有训练迭代完成
2025-05-11 10:12:03,841 [INFO] 开始迭代 13/300
2025-05-11 10:12:03,841 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 10:54:39,451 [INFO] 保存训练样本
2025-05-11 10:54:45,585 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 10:54:46,200 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 10:54:46,200 [INFO] Training with 200000 examples
2025-05-11 10:54:46,201 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 10:54:46,265 [INFO] 循环学习率周期大小: 585 步
2025-05-11 10:55:37,525 [INFO] Epoch 1/15 - Policy Loss: 2.3552, Value Loss: 0.1516, Total Loss: 2.5068, LR: 0.001692
2025-05-11 10:56:28,949 [INFO] Epoch 2/15 - Policy Loss: 2.3064, Value Loss: 0.1284, Total Loss: 2.4348, LR: 0.003342
2025-05-11 10:57:20,713 [INFO] Epoch 3/15 - Policy Loss: 2.2857, Value Loss: 0.1175, Total Loss: 2.4033, LR: 0.004992
2025-05-11 10:58:12,017 [INFO] Epoch 4/15 - Policy Loss: 2.2756, Value Loss: 0.1119, Total Loss: 2.3875, LR: 0.003358
2025-05-11 10:59:03,539 [INFO] Epoch 5/15 - Policy Loss: 2.2512, Value Loss: 0.1068, Total Loss: 2.3581, LR: 0.001708
2025-05-11 10:59:55,179 [INFO] Epoch 6/15 - Policy Loss: 2.2234, Value Loss: 0.1028, Total Loss: 2.3262, LR: 0.000058
2025-05-11 11:00:46,888 [INFO] Epoch 7/15 - Policy Loss: 2.2007, Value Loss: 0.0997, Total Loss: 2.3004, LR: 0.001692
2025-05-11 11:01:38,768 [INFO] Epoch 8/15 - Policy Loss: 2.1838, Value Loss: 0.0972, Total Loss: 2.2810, LR: 0.003342
2025-05-11 11:02:30,412 [INFO] Epoch 9/15 - Policy Loss: 2.1745, Value Loss: 0.0958, Total Loss: 2.2703, LR: 0.004992
2025-05-11 11:03:22,249 [INFO] Epoch 10/15 - Policy Loss: 2.1707, Value Loss: 0.0950, Total Loss: 2.2657, LR: 0.003358
2025-05-11 11:04:14,032 [INFO] Epoch 11/15 - Policy Loss: 2.1623, Value Loss: 0.0940, Total Loss: 2.2563, LR: 0.001708
2025-05-11 11:05:06,055 [INFO] Epoch 12/15 - Policy Loss: 2.1510, Value Loss: 0.0928, Total Loss: 2.2438, LR: 0.000058
2025-05-11 11:05:58,011 [INFO] Epoch 13/15 - Policy Loss: 2.1408, Value Loss: 0.0917, Total Loss: 2.2325, LR: 0.001692
2025-05-11 11:06:49,681 [INFO] Epoch 14/15 - Policy Loss: 2.1317, Value Loss: 0.0906, Total Loss: 2.2223, LR: 0.003342
2025-05-11 11:07:41,646 [INFO] Epoch 15/15 - Policy Loss: 2.1270, Value Loss: 0.0901, Total Loss: 2.2171, LR: 0.004992
2025-05-11 11:07:41,676 [INFO] 训练完成，总损失: 2.2171
2025-05-11 11:07:41,676 [INFO] 保存迭代 13 的模型
2025-05-11 11:07:42,776 [INFO] Model saved to ./models/best.pt
2025-05-11 11:07:43,448 [INFO] Model saved to ./models/iteration_13.pt
2025-05-11 11:07:43,448 [INFO] 所有训练迭代完成
2025-05-11 11:07:43,448 [INFO] 开始迭代 14/300
2025-05-11 11:07:43,449 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 11:42:59,720 [INFO] 保存训练样本
2025-05-11 11:43:07,401 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 11:43:08,062 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 11:43:08,062 [INFO] Training with 200000 examples
2025-05-11 11:43:08,062 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 11:43:08,983 [INFO] 循环学习率周期大小: 585 步
2025-05-11 11:44:00,570 [INFO] Epoch 1/15 - Policy Loss: 2.3254, Value Loss: 0.1459, Total Loss: 2.4713, LR: 0.001692
2025-05-11 11:44:52,114 [INFO] Epoch 2/15 - Policy Loss: 2.2799, Value Loss: 0.1265, Total Loss: 2.4064, LR: 0.003342
2025-05-11 11:45:43,973 [INFO] Epoch 3/15 - Policy Loss: 2.2560, Value Loss: 0.1175, Total Loss: 2.3734, LR: 0.004992
2025-05-11 11:46:35,492 [INFO] Epoch 4/15 - Policy Loss: 2.2439, Value Loss: 0.1125, Total Loss: 2.3564, LR: 0.003358
2025-05-11 11:47:27,492 [INFO] Epoch 5/15 - Policy Loss: 2.2194, Value Loss: 0.1077, Total Loss: 2.3272, LR: 0.001708
2025-05-11 11:48:19,392 [INFO] Epoch 6/15 - Policy Loss: 2.1940, Value Loss: 0.1039, Total Loss: 2.2979, LR: 0.000058
2025-05-11 11:49:11,312 [INFO] Epoch 7/15 - Policy Loss: 2.1731, Value Loss: 0.1010, Total Loss: 2.2741, LR: 0.001692
2025-05-11 11:50:03,084 [INFO] Epoch 8/15 - Policy Loss: 2.1568, Value Loss: 0.0986, Total Loss: 2.2554, LR: 0.003342
2025-05-11 11:50:54,906 [INFO] Epoch 9/15 - Policy Loss: 2.1483, Value Loss: 0.0973, Total Loss: 2.2456, LR: 0.004992
2025-05-11 11:51:46,776 [INFO] Epoch 10/15 - Policy Loss: 2.1445, Value Loss: 0.0964, Total Loss: 2.2410, LR: 0.003358
2025-05-11 11:52:38,620 [INFO] Epoch 11/15 - Policy Loss: 2.1366, Value Loss: 0.0954, Total Loss: 2.2320, LR: 0.001708
2025-05-11 11:53:30,740 [INFO] Epoch 12/15 - Policy Loss: 2.1255, Value Loss: 0.0942, Total Loss: 2.2197, LR: 0.000058
2025-05-11 11:54:22,874 [INFO] Epoch 13/15 - Policy Loss: 2.1152, Value Loss: 0.0931, Total Loss: 2.2084, LR: 0.001692
2025-05-11 11:55:15,083 [INFO] Epoch 14/15 - Policy Loss: 2.1063, Value Loss: 0.0923, Total Loss: 2.1986, LR: 0.003342
2025-05-11 11:56:07,112 [INFO] Epoch 15/15 - Policy Loss: 2.1026, Value Loss: 0.0917, Total Loss: 2.1943, LR: 0.004992
2025-05-11 11:56:07,145 [INFO] 训练完成，总损失: 2.1943
2025-05-11 11:56:07,145 [INFO] 保存迭代 14 的模型
2025-05-11 11:56:08,475 [INFO] Model saved to ./models/best.pt
2025-05-11 11:56:09,296 [INFO] Model saved to ./models/iteration_14.pt
2025-05-11 11:56:09,297 [INFO] 所有训练迭代完成
2025-05-11 11:56:09,297 [INFO] 开始迭代 15/300
2025-05-11 11:56:09,297 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 12:31:26,689 [INFO] 保存训练样本
2025-05-11 12:31:34,901 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 12:31:35,084 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 12:31:35,085 [INFO] Training with 200000 examples
2025-05-11 12:31:35,085 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 12:31:35,700 [INFO] 循环学习率周期大小: 585 步
2025-05-11 12:32:27,153 [INFO] Epoch 1/15 - Policy Loss: 2.3219, Value Loss: 0.1470, Total Loss: 2.4690, LR: 0.001692
2025-05-11 12:33:18,800 [INFO] Epoch 2/15 - Policy Loss: 2.2781, Value Loss: 0.1300, Total Loss: 2.4081, LR: 0.003342
2025-05-11 12:34:10,455 [INFO] Epoch 3/15 - Policy Loss: 2.2547, Value Loss: 0.1208, Total Loss: 2.3755, LR: 0.004992
2025-05-11 12:35:02,063 [INFO] Epoch 4/15 - Policy Loss: 2.2389, Value Loss: 0.1149, Total Loss: 2.3538, LR: 0.003358
2025-05-11 12:35:53,789 [INFO] Epoch 5/15 - Policy Loss: 2.2125, Value Loss: 0.1099, Total Loss: 2.3224, LR: 0.001708
2025-05-11 12:36:45,617 [INFO] Epoch 6/15 - Policy Loss: 2.1850, Value Loss: 0.1058, Total Loss: 2.2908, LR: 0.000058
2025-05-11 12:37:37,322 [INFO] Epoch 7/15 - Policy Loss: 2.1626, Value Loss: 0.1025, Total Loss: 2.2651, LR: 0.001692
2025-05-11 12:38:29,275 [INFO] Epoch 8/15 - Policy Loss: 2.1444, Value Loss: 0.0999, Total Loss: 2.2443, LR: 0.003342
2025-05-11 12:39:21,321 [INFO] Epoch 9/15 - Policy Loss: 2.1357, Value Loss: 0.0983, Total Loss: 2.2339, LR: 0.004992
2025-05-11 12:40:13,154 [INFO] Epoch 10/15 - Policy Loss: 2.1321, Value Loss: 0.0972, Total Loss: 2.2293, LR: 0.003358
2025-05-11 12:41:05,204 [INFO] Epoch 11/15 - Policy Loss: 2.1234, Value Loss: 0.0959, Total Loss: 2.2194, LR: 0.001708
2025-05-11 12:41:57,440 [INFO] Epoch 12/15 - Policy Loss: 2.1122, Value Loss: 0.0945, Total Loss: 2.2068, LR: 0.000058
2025-05-11 12:42:49,514 [INFO] Epoch 13/15 - Policy Loss: 2.1021, Value Loss: 0.0933, Total Loss: 2.1954, LR: 0.001692
2025-05-11 12:43:41,495 [INFO] Epoch 14/15 - Policy Loss: 2.0928, Value Loss: 0.0923, Total Loss: 2.1851, LR: 0.003342
2025-05-11 12:44:33,626 [INFO] Epoch 15/15 - Policy Loss: 2.0879, Value Loss: 0.0917, Total Loss: 2.1796, LR: 0.004992
2025-05-11 12:44:33,657 [INFO] 训练完成，总损失: 2.1796
2025-05-11 12:44:33,657 [INFO] 保存迭代 15 的模型
2025-05-11 12:44:34,760 [INFO] Model saved to ./models/best.pt
2025-05-11 12:44:35,415 [INFO] Model saved to ./models/iteration_15.pt
2025-05-11 12:44:35,416 [INFO] 所有训练迭代完成
2025-05-11 12:44:35,416 [INFO] 开始迭代 16/300
2025-05-11 12:44:35,416 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 13:20:26,038 [INFO] 保存训练样本
2025-05-11 13:20:33,319 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 13:20:33,507 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 13:20:33,507 [INFO] Training with 200000 examples
2025-05-11 13:20:33,507 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 13:20:34,220 [INFO] 循环学习率周期大小: 585 步
2025-05-11 13:21:25,754 [INFO] Epoch 1/15 - Policy Loss: 2.3183, Value Loss: 0.1470, Total Loss: 2.4653, LR: 0.001692
2025-05-11 13:22:17,282 [INFO] Epoch 2/15 - Policy Loss: 2.2727, Value Loss: 0.1295, Total Loss: 2.4022, LR: 0.003342
2025-05-11 13:23:08,756 [INFO] Epoch 3/15 - Policy Loss: 2.2451, Value Loss: 0.1197, Total Loss: 2.3648, LR: 0.004992
2025-05-11 13:24:00,296 [INFO] Epoch 4/15 - Policy Loss: 2.2260, Value Loss: 0.1140, Total Loss: 2.3400, LR: 0.003358
2025-05-11 13:24:51,948 [INFO] Epoch 5/15 - Policy Loss: 2.1992, Value Loss: 0.1090, Total Loss: 2.3082, LR: 0.001708
2025-05-11 13:25:43,853 [INFO] Epoch 6/15 - Policy Loss: 2.1728, Value Loss: 0.1052, Total Loss: 2.2780, LR: 0.000058
2025-05-11 13:26:35,707 [INFO] Epoch 7/15 - Policy Loss: 2.1501, Value Loss: 0.1020, Total Loss: 2.2521, LR: 0.001692
2025-05-11 13:27:27,572 [INFO] Epoch 8/15 - Policy Loss: 2.1331, Value Loss: 0.0995, Total Loss: 2.2327, LR: 0.003342
2025-05-11 13:28:19,605 [INFO] Epoch 9/15 - Policy Loss: 2.1225, Value Loss: 0.0978, Total Loss: 2.2202, LR: 0.004992
2025-05-11 13:29:11,597 [INFO] Epoch 10/15 - Policy Loss: 2.1170, Value Loss: 0.0966, Total Loss: 2.2136, LR: 0.003358
2025-05-11 13:30:03,661 [INFO] Epoch 11/15 - Policy Loss: 2.1077, Value Loss: 0.0953, Total Loss: 2.2030, LR: 0.001708
2025-05-11 13:30:55,681 [INFO] Epoch 12/15 - Policy Loss: 2.0966, Value Loss: 0.0943, Total Loss: 2.1909, LR: 0.000058
2025-05-11 13:31:47,842 [INFO] Epoch 13/15 - Policy Loss: 2.0858, Value Loss: 0.0930, Total Loss: 2.1788, LR: 0.001692
2025-05-11 13:32:39,632 [INFO] Epoch 14/15 - Policy Loss: 2.0773, Value Loss: 0.0921, Total Loss: 2.1694, LR: 0.003342
2025-05-11 13:33:31,491 [INFO] Epoch 15/15 - Policy Loss: 2.0721, Value Loss: 0.0915, Total Loss: 2.1637, LR: 0.004992
2025-05-11 13:33:31,522 [INFO] 训练完成，总损失: 2.1637
2025-05-11 13:33:31,522 [INFO] 保存迭代 16 的模型
2025-05-11 13:33:32,644 [INFO] Model saved to ./models/best.pt
2025-05-11 13:33:33,324 [INFO] Model saved to ./models/iteration_16.pt
2025-05-11 13:33:33,324 [INFO] 所有训练迭代完成
2025-05-11 13:33:33,324 [INFO] 开始迭代 17/300
2025-05-11 13:33:33,324 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 14:03:40,147 [INFO] 保存训练样本
2025-05-11 14:03:49,191 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 14:03:49,379 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 14:03:49,379 [INFO] Training with 200000 examples
2025-05-11 14:03:49,379 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 14:03:50,063 [INFO] 循环学习率周期大小: 585 步
2025-05-11 14:04:41,599 [INFO] Epoch 1/15 - Policy Loss: 2.2960, Value Loss: 0.1334, Total Loss: 2.4294, LR: 0.001692
2025-05-11 14:05:33,083 [INFO] Epoch 2/15 - Policy Loss: 2.2468, Value Loss: 0.1218, Total Loss: 2.3686, LR: 0.003342
2025-05-11 14:06:24,886 [INFO] Epoch 3/15 - Policy Loss: 2.2196, Value Loss: 0.1152, Total Loss: 2.3348, LR: 0.004992
2025-05-11 14:07:16,449 [INFO] Epoch 4/15 - Policy Loss: 2.2048, Value Loss: 0.1113, Total Loss: 2.3160, LR: 0.003358
2025-05-11 14:08:08,165 [INFO] Epoch 5/15 - Policy Loss: 2.1775, Value Loss: 0.1071, Total Loss: 2.2846, LR: 0.001708
2025-05-11 14:08:59,906 [INFO] Epoch 6/15 - Policy Loss: 2.1515, Value Loss: 0.1036, Total Loss: 2.2552, LR: 0.000058
2025-05-11 14:09:51,873 [INFO] Epoch 7/15 - Policy Loss: 2.1302, Value Loss: 0.1008, Total Loss: 2.2310, LR: 0.001692
2025-05-11 14:10:43,590 [INFO] Epoch 8/15 - Policy Loss: 2.1131, Value Loss: 0.0986, Total Loss: 2.2117, LR: 0.003342
2025-05-11 14:11:35,437 [INFO] Epoch 9/15 - Policy Loss: 2.1026, Value Loss: 0.0973, Total Loss: 2.1999, LR: 0.004992
2025-05-11 14:12:27,340 [INFO] Epoch 10/15 - Policy Loss: 2.0971, Value Loss: 0.0965, Total Loss: 2.1935, LR: 0.003358
2025-05-11 14:13:19,363 [INFO] Epoch 11/15 - Policy Loss: 2.0882, Value Loss: 0.0954, Total Loss: 2.1836, LR: 0.001708
2025-05-11 14:14:11,438 [INFO] Epoch 12/15 - Policy Loss: 2.0775, Value Loss: 0.0944, Total Loss: 2.1718, LR: 0.000058
2025-05-11 14:15:03,147 [INFO] Epoch 13/15 - Policy Loss: 2.0669, Value Loss: 0.0933, Total Loss: 2.1602, LR: 0.001692
2025-05-11 14:15:55,088 [INFO] Epoch 14/15 - Policy Loss: 2.0582, Value Loss: 0.0926, Total Loss: 2.1508, LR: 0.003342
2025-05-11 14:16:46,904 [INFO] Epoch 15/15 - Policy Loss: 2.0529, Value Loss: 0.0920, Total Loss: 2.1449, LR: 0.004992
2025-05-11 14:16:46,934 [INFO] 训练完成，总损失: 2.1449
2025-05-11 14:16:46,934 [INFO] 保存迭代 17 的模型
2025-05-11 14:16:47,874 [INFO] Model saved to ./models/best.pt
2025-05-11 14:16:48,497 [INFO] Model saved to ./models/iteration_17.pt
2025-05-11 14:16:48,497 [INFO] 所有训练迭代完成
2025-05-11 14:16:48,497 [INFO] 开始迭代 18/300
2025-05-11 14:16:48,497 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 14:48:12,471 [INFO] 保存训练样本
2025-05-11 14:48:22,407 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 14:48:22,596 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 14:48:22,597 [INFO] Training with 200000 examples
2025-05-11 14:48:22,597 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 14:48:22,670 [INFO] 循环学习率周期大小: 585 步
2025-05-11 14:49:14,825 [INFO] Epoch 1/15 - Policy Loss: 2.2720, Value Loss: 0.1443, Total Loss: 2.4163, LR: 0.001692
2025-05-11 14:50:06,554 [INFO] Epoch 2/15 - Policy Loss: 2.2275, Value Loss: 0.1306, Total Loss: 2.3581, LR: 0.003342
2025-05-11 14:50:58,284 [INFO] Epoch 3/15 - Policy Loss: 2.2025, Value Loss: 0.1237, Total Loss: 2.3262, LR: 0.004992
2025-05-11 14:51:50,098 [INFO] Epoch 4/15 - Policy Loss: 2.1873, Value Loss: 0.1189, Total Loss: 2.3061, LR: 0.003358
2025-05-11 14:52:41,971 [INFO] Epoch 5/15 - Policy Loss: 2.1607, Value Loss: 0.1140, Total Loss: 2.2747, LR: 0.001708
2025-05-11 14:53:33,828 [INFO] Epoch 6/15 - Policy Loss: 2.1350, Value Loss: 0.1104, Total Loss: 2.2454, LR: 0.000058
2025-05-11 14:54:25,695 [INFO] Epoch 7/15 - Policy Loss: 2.1127, Value Loss: 0.1074, Total Loss: 2.2202, LR: 0.001692
2025-05-11 14:55:17,591 [INFO] Epoch 8/15 - Policy Loss: 2.0962, Value Loss: 0.1052, Total Loss: 2.2014, LR: 0.003342
2025-05-11 14:56:09,546 [INFO] Epoch 9/15 - Policy Loss: 2.0857, Value Loss: 0.1035, Total Loss: 2.1891, LR: 0.004992
2025-05-11 14:57:01,723 [INFO] Epoch 10/15 - Policy Loss: 2.0803, Value Loss: 0.1025, Total Loss: 2.1829, LR: 0.003358
2025-05-11 14:57:53,839 [INFO] Epoch 11/15 - Policy Loss: 2.0717, Value Loss: 0.1013, Total Loss: 2.1731, LR: 0.001708
2025-05-11 14:58:45,991 [INFO] Epoch 12/15 - Policy Loss: 2.0611, Value Loss: 0.1000, Total Loss: 2.1611, LR: 0.000058
2025-05-11 14:59:38,246 [INFO] Epoch 13/15 - Policy Loss: 2.0510, Value Loss: 0.0989, Total Loss: 2.1499, LR: 0.001692
2025-05-11 15:00:30,307 [INFO] Epoch 14/15 - Policy Loss: 2.0430, Value Loss: 0.0979, Total Loss: 2.1410, LR: 0.003342
2025-05-11 15:01:22,479 [INFO] Epoch 15/15 - Policy Loss: 2.0378, Value Loss: 0.0973, Total Loss: 2.1351, LR: 0.004992
2025-05-11 15:01:22,513 [INFO] 训练完成，总损失: 2.1351
2025-05-11 15:01:22,513 [INFO] 保存迭代 18 的模型
2025-05-11 15:01:23,648 [INFO] Model saved to ./models/best.pt
2025-05-11 15:01:24,445 [INFO] Model saved to ./models/iteration_18.pt
2025-05-11 15:01:24,445 [INFO] 所有训练迭代完成
2025-05-11 15:01:24,445 [INFO] 开始迭代 19/300
2025-05-11 15:01:24,445 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 15:30:30,793 [INFO] 保存训练样本
2025-05-11 15:30:40,291 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 15:30:41,098 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 15:30:41,099 [INFO] Training with 200000 examples
2025-05-11 15:30:41,099 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 15:30:41,166 [INFO] 循环学习率周期大小: 585 步
2025-05-11 15:31:32,237 [INFO] Epoch 1/15 - Policy Loss: 2.2609, Value Loss: 0.1346, Total Loss: 2.3955, LR: 0.001692
2025-05-11 15:32:23,685 [INFO] Epoch 2/15 - Policy Loss: 2.2120, Value Loss: 0.1238, Total Loss: 2.3358, LR: 0.003342
2025-05-11 15:33:15,155 [INFO] Epoch 3/15 - Policy Loss: 2.1861, Value Loss: 0.1176, Total Loss: 2.3037, LR: 0.004992
2025-05-11 15:34:07,386 [INFO] Epoch 4/15 - Policy Loss: 2.1689, Value Loss: 0.1141, Total Loss: 2.2830, LR: 0.003358
2025-05-11 15:34:59,052 [INFO] Epoch 5/15 - Policy Loss: 2.1426, Value Loss: 0.1102, Total Loss: 2.2528, LR: 0.001708
2025-05-11 15:35:50,840 [INFO] Epoch 6/15 - Policy Loss: 2.1163, Value Loss: 0.1068, Total Loss: 2.2231, LR: 0.000058
2025-05-11 15:36:42,235 [INFO] Epoch 7/15 - Policy Loss: 2.0956, Value Loss: 0.1041, Total Loss: 2.1997, LR: 0.001692
2025-05-11 15:37:33,791 [INFO] Epoch 8/15 - Policy Loss: 2.0785, Value Loss: 0.1022, Total Loss: 2.1807, LR: 0.003342
2025-05-11 15:38:25,392 [INFO] Epoch 9/15 - Policy Loss: 2.0687, Value Loss: 0.1008, Total Loss: 2.1695, LR: 0.004992
2025-05-11 15:39:17,124 [INFO] Epoch 10/15 - Policy Loss: 2.0636, Value Loss: 0.1000, Total Loss: 2.1637, LR: 0.003358
2025-05-11 15:40:08,809 [INFO] Epoch 11/15 - Policy Loss: 2.0556, Value Loss: 0.0990, Total Loss: 2.1546, LR: 0.001708
2025-05-11 15:41:00,776 [INFO] Epoch 12/15 - Policy Loss: 2.0457, Value Loss: 0.0979, Total Loss: 2.1436, LR: 0.000058
2025-05-11 15:41:52,977 [INFO] Epoch 13/15 - Policy Loss: 2.0356, Value Loss: 0.0970, Total Loss: 2.1326, LR: 0.001692
2025-05-11 15:42:45,044 [INFO] Epoch 14/15 - Policy Loss: 2.0274, Value Loss: 0.0962, Total Loss: 2.1237, LR: 0.003342
2025-05-11 15:43:37,085 [INFO] Epoch 15/15 - Policy Loss: 2.0223, Value Loss: 0.0955, Total Loss: 2.1179, LR: 0.004992
2025-05-11 15:43:37,120 [INFO] 训练完成，总损失: 2.1179
2025-05-11 15:43:37,120 [INFO] 保存迭代 19 的模型
2025-05-11 15:43:38,441 [INFO] Model saved to ./models/best.pt
2025-05-11 15:43:39,314 [INFO] Model saved to ./models/iteration_19.pt
2025-05-11 15:43:39,314 [INFO] 所有训练迭代完成
2025-05-11 15:43:39,314 [INFO] 开始迭代 20/300
2025-05-11 15:43:39,314 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 16:07:44,447 [INFO] 设置多进程启动方法为: spawn
2025-05-11 16:07:44,655 [INFO] CUDA可用，使用GPU
2025-05-11 16:07:44,655 [INFO] 配置参数:
2025-05-11 16:07:44,655 [INFO] 训练参数:
2025-05-11 16:07:44,655 [INFO]   训练轮数: 15
2025-05-11 16:07:44,655 [INFO]   批量大小: 1024
2025-05-11 16:07:44,656 [INFO]   迭代次数: 300
2025-05-11 16:07:44,656 [INFO]   每次迭代的自我对弈次数: 50
2025-05-11 16:07:44,656 [INFO]   训练样本队列最大长度: 200000
2025-05-11 16:07:44,656 [INFO]   保留的历史迭代数: 20
2025-05-11 16:07:44,656 [INFO]   新模型胜率阈值: 0.55
2025-05-11 16:07:44,656 [INFO]   竞技场比赛次数: 40
2025-05-11 16:07:44,656 [INFO]   温度阈值: 5
2025-05-11 16:07:44,656 [INFO] 神经网络参数:
2025-05-11 16:07:44,656 [INFO]   通道数: 256
2025-05-11 16:07:44,656 [INFO]   Dropout率: 0.3
2025-05-11 16:07:44,656 [INFO]   学习率范围: 5e-05 - 0.005
2025-05-11 16:07:44,656 [INFO]   梯度裁剪: 1.0
2025-05-11 16:07:44,656 [INFO]   优化器: adam
2025-05-11 16:07:44,656 [INFO] MCTS参数:
2025-05-11 16:07:44,656 [INFO]   模拟次数: 800
2025-05-11 16:07:44,656 [INFO]   PUCT常数: 4.0
2025-05-11 16:07:44,656 [INFO]   Dirichlet噪声参数: 0.3
2025-05-11 16:07:44,656 [INFO]   Dirichlet噪声权重: 0.25
2025-05-11 16:07:44,656 [INFO] 游戏参数:
2025-05-11 16:07:44,656 [INFO]   棋盘大小: 15
2025-05-11 16:07:44,656 [INFO]   获胜所需的连续棋子数: 5
2025-05-11 16:07:44,656 [INFO] 系统参数:
2025-05-11 16:07:44,656 [INFO]   使用CUDA: True
2025-05-11 16:07:44,657 [INFO]   检查点目录: ./models
2025-05-11 16:07:44,657 [INFO]   数据目录: ./data
2025-05-11 16:07:44,657 [INFO]   加载模型: False
2025-05-11 16:07:44,657 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-05-11 16:07:44,657 [INFO]   工作线程数: 4
2025-05-11 16:07:44,657 [INFO]   使用Weights & Biases: False
2025-05-11 16:07:44,657 [INFO] GUI参数:
2025-05-11 16:07:44,657 [INFO]   窗口宽度: 800
2025-05-11 16:07:44,657 [INFO]   窗口高度: 850
2025-05-11 16:07:44,657 [INFO]   格子大小: 40
2025-05-11 16:07:44,657 [INFO]   边距: 40
2025-05-11 16:07:44,657 [INFO]   底部边距: 80
2025-05-11 16:07:44,657 [INFO]   帧率: 30
2025-05-11 16:07:45,063 [INFO] Using device: cuda
2025-05-11 16:07:46,454 [INFO] 设置循环学习率: 最小值=5e-05, 最大值=0.005
2025-05-11 16:07:46,454 [INFO] 设置并行进程数为: 8
2025-05-11 16:07:46,454 [INFO] 开始训练
2025-05-11 16:07:46,455 [INFO] 加载之前的训练样本
2025-05-11 16:07:49,965 [INFO] 加载了 19 组训练样本
2025-05-11 16:07:49,965 [INFO] 开始迭代 1/300
2025-05-11 16:07:49,965 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 17:00:51,554 [INFO] 保存训练样本
2025-05-11 17:01:03,527 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 17:01:03,689 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 17:01:03,690 [INFO] Training with 200000 examples
2025-05-11 17:01:03,690 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 17:01:04,652 [INFO] 循环学习率周期大小: 585 步
2025-05-11 17:01:58,658 [INFO] Epoch 1/15 - Policy Loss: 4.9645, Value Loss: 0.9586, Total Loss: 5.9231, LR: 0.001692
2025-05-11 17:02:51,434 [INFO] Epoch 2/15 - Policy Loss: 4.7449, Value Loss: 0.8634, Total Loss: 5.6083, LR: 0.003342
2025-05-11 17:03:43,663 [INFO] Epoch 3/15 - Policy Loss: 4.6085, Value Loss: 0.7622, Total Loss: 5.3707, LR: 0.004992
2025-05-11 17:04:36,060 [INFO] Epoch 4/15 - Policy Loss: 4.4887, Value Loss: 0.6681, Total Loss: 5.1567, LR: 0.003358
2025-05-11 17:05:28,872 [INFO] Epoch 5/15 - Policy Loss: 4.3682, Value Loss: 0.5865, Total Loss: 4.9548, LR: 0.001708
2025-05-11 17:06:21,356 [INFO] Epoch 6/15 - Policy Loss: 4.2529, Value Loss: 0.5211, Total Loss: 4.7740, LR: 0.000058
2025-05-11 17:07:13,914 [INFO] Epoch 7/15 - Policy Loss: 4.1558, Value Loss: 0.4710, Total Loss: 4.6268, LR: 0.001692
2025-05-11 17:08:06,493 [INFO] Epoch 8/15 - Policy Loss: 4.0840, Value Loss: 0.4377, Total Loss: 4.5217, LR: 0.003342
2025-05-11 17:08:59,449 [INFO] Epoch 9/15 - Policy Loss: 4.0309, Value Loss: 0.4163, Total Loss: 4.4472, LR: 0.004992
2025-05-11 17:09:51,795 [INFO] Epoch 10/15 - Policy Loss: 3.9793, Value Loss: 0.3960, Total Loss: 4.3753, LR: 0.003358
2025-05-11 17:10:44,582 [INFO] Epoch 11/15 - Policy Loss: 3.9180, Value Loss: 0.3744, Total Loss: 4.2923, LR: 0.001708
2025-05-11 17:11:38,034 [INFO] Epoch 12/15 - Policy Loss: 3.8511, Value Loss: 0.3537, Total Loss: 4.2048, LR: 0.000058
2025-05-11 17:12:30,662 [INFO] Epoch 13/15 - Policy Loss: 3.7875, Value Loss: 0.3354, Total Loss: 4.1229, LR: 0.001692
2025-05-11 17:13:23,482 [INFO] Epoch 14/15 - Policy Loss: 3.7355, Value Loss: 0.3207, Total Loss: 4.0562, LR: 0.003342
2025-05-11 17:14:16,310 [INFO] Epoch 15/15 - Policy Loss: 3.7006, Value Loss: 0.3114, Total Loss: 4.0120, LR: 0.004992
2025-05-11 17:14:16,351 [INFO] 训练完成，总损失: 4.0120
2025-05-11 17:14:16,351 [INFO] 保存迭代 1 的模型
2025-05-11 17:14:17,595 [INFO] Model saved to ./models/best.pt
2025-05-11 17:14:18,392 [INFO] Model saved to ./models/iteration_1.pt
2025-05-11 17:14:18,393 [INFO] 所有训练迭代完成
2025-05-11 17:14:18,393 [INFO] 开始迭代 2/300
2025-05-11 17:14:18,393 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 17:41:34,521 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 17:41:34,544 [INFO] 保存训练样本
2025-05-11 17:41:46,132 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 17:41:46,391 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 17:41:46,391 [INFO] Training with 200000 examples
2025-05-11 17:41:46,392 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 17:41:47,448 [INFO] 循环学习率周期大小: 585 步
2025-05-11 17:42:39,361 [INFO] Epoch 1/15 - Policy Loss: 3.6337, Value Loss: 0.2248, Total Loss: 3.8585, LR: 0.001692
2025-05-11 17:43:31,464 [INFO] Epoch 2/15 - Policy Loss: 3.5185, Value Loss: 0.2012, Total Loss: 3.7197, LR: 0.003342
2025-05-11 17:44:23,988 [INFO] Epoch 3/15 - Policy Loss: 3.4460, Value Loss: 0.1964, Total Loss: 3.6424, LR: 0.004992
2025-05-11 17:45:16,605 [INFO] Epoch 4/15 - Policy Loss: 3.3802, Value Loss: 0.1909, Total Loss: 3.5711, LR: 0.003358
2025-05-11 17:46:08,639 [INFO] Epoch 5/15 - Policy Loss: 3.2908, Value Loss: 0.1795, Total Loss: 3.4703, LR: 0.001708
2025-05-11 17:47:01,307 [INFO] Epoch 6/15 - Policy Loss: 3.1953, Value Loss: 0.1682, Total Loss: 3.3634, LR: 0.000058
2025-05-11 17:47:53,736 [INFO] Epoch 7/15 - Policy Loss: 3.1157, Value Loss: 0.1593, Total Loss: 3.2749, LR: 0.001692
2025-05-11 17:48:46,217 [INFO] Epoch 8/15 - Policy Loss: 3.0558, Value Loss: 0.1533, Total Loss: 3.2092, LR: 0.003342
2025-05-11 17:49:39,455 [INFO] Epoch 9/15 - Policy Loss: 3.0259, Value Loss: 0.1521, Total Loss: 3.1780, LR: 0.004992
2025-05-11 17:50:32,135 [INFO] Epoch 10/15 - Policy Loss: 3.0021, Value Loss: 0.1519, Total Loss: 3.1540, LR: 0.003358
2025-05-11 17:51:24,643 [INFO] Epoch 11/15 - Policy Loss: 2.9623, Value Loss: 0.1486, Total Loss: 3.1109, LR: 0.001708
2025-05-11 17:52:17,267 [INFO] Epoch 12/15 - Policy Loss: 2.9152, Value Loss: 0.1444, Total Loss: 3.0597, LR: 0.000058
2025-05-11 17:53:09,628 [INFO] Epoch 13/15 - Policy Loss: 2.8703, Value Loss: 0.1406, Total Loss: 3.0108, LR: 0.001692
2025-05-11 17:54:02,624 [INFO] Epoch 14/15 - Policy Loss: 2.8329, Value Loss: 0.1374, Total Loss: 2.9703, LR: 0.003342
2025-05-11 17:54:54,823 [INFO] Epoch 15/15 - Policy Loss: 2.8100, Value Loss: 0.1363, Total Loss: 2.9463, LR: 0.004992
2025-05-11 17:54:54,865 [INFO] 训练完成，总损失: 2.9463
2025-05-11 17:54:54,865 [INFO] 保存迭代 2 的模型
2025-05-11 17:54:56,149 [INFO] Model saved to ./models/best.pt
2025-05-11 17:54:56,985 [INFO] Model saved to ./models/iteration_2.pt
2025-05-11 17:54:56,985 [INFO] 所有训练迭代完成
2025-05-11 17:54:56,985 [INFO] 开始迭代 3/300
2025-05-11 17:54:56,985 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 18:26:44,268 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 18:26:44,292 [INFO] 保存训练样本
2025-05-11 18:26:53,746 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 18:26:54,749 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 18:26:54,750 [INFO] Training with 200000 examples
2025-05-11 18:26:54,750 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 18:26:54,825 [INFO] 循环学习率周期大小: 585 步
2025-05-11 18:27:48,039 [INFO] Epoch 1/15 - Policy Loss: 3.2760, Value Loss: 0.1926, Total Loss: 3.4686, LR: 0.001692
2025-05-11 18:28:40,185 [INFO] Epoch 2/15 - Policy Loss: 3.1488, Value Loss: 0.1716, Total Loss: 3.3203, LR: 0.003342
2025-05-11 18:29:32,713 [INFO] Epoch 3/15 - Policy Loss: 3.0734, Value Loss: 0.1643, Total Loss: 3.2377, LR: 0.004992
2025-05-11 18:30:25,159 [INFO] Epoch 4/15 - Policy Loss: 3.0174, Value Loss: 0.1596, Total Loss: 3.1770, LR: 0.003358
2025-05-11 18:31:17,866 [INFO] Epoch 5/15 - Policy Loss: 2.9380, Value Loss: 0.1511, Total Loss: 3.0891, LR: 0.001708
2025-05-11 18:32:10,546 [INFO] Epoch 6/15 - Policy Loss: 2.8591, Value Loss: 0.1430, Total Loss: 3.0022, LR: 0.000058
2025-05-11 18:33:02,887 [INFO] Epoch 7/15 - Policy Loss: 2.7959, Value Loss: 0.1367, Total Loss: 2.9326, LR: 0.001692
2025-05-11 18:33:55,426 [INFO] Epoch 8/15 - Policy Loss: 2.7468, Value Loss: 0.1320, Total Loss: 2.8787, LR: 0.003342
2025-05-11 18:34:47,955 [INFO] Epoch 9/15 - Policy Loss: 2.7195, Value Loss: 0.1301, Total Loss: 2.8496, LR: 0.004992
2025-05-11 18:35:40,873 [INFO] Epoch 10/15 - Policy Loss: 2.7057, Value Loss: 0.1304, Total Loss: 2.8361, LR: 0.003358
2025-05-11 18:36:34,577 [INFO] Epoch 11/15 - Policy Loss: 2.6786, Value Loss: 0.1286, Total Loss: 2.8072, LR: 0.001708
2025-05-11 18:37:27,086 [INFO] Epoch 12/15 - Policy Loss: 2.6456, Value Loss: 0.1258, Total Loss: 2.7714, LR: 0.000058
2025-05-11 18:38:19,595 [INFO] Epoch 13/15 - Policy Loss: 2.6144, Value Loss: 0.1233, Total Loss: 2.7376, LR: 0.001692
2025-05-11 18:39:12,148 [INFO] Epoch 14/15 - Policy Loss: 2.5887, Value Loss: 0.1212, Total Loss: 2.7099, LR: 0.003342
2025-05-11 18:40:05,173 [INFO] Epoch 15/15 - Policy Loss: 2.5738, Value Loss: 0.1205, Total Loss: 2.6943, LR: 0.004992
2025-05-11 18:40:05,213 [INFO] 训练完成，总损失: 2.6943
2025-05-11 18:40:05,213 [INFO] 保存迭代 3 的模型
2025-05-11 18:40:06,440 [INFO] Model saved to ./models/best.pt
2025-05-11 18:40:07,254 [INFO] Model saved to ./models/iteration_3.pt
2025-05-11 18:40:07,255 [INFO] 所有训练迭代完成
2025-05-11 18:40:07,255 [INFO] 开始迭代 4/300
2025-05-11 18:40:07,255 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 19:04:08,365 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 19:04:08,387 [INFO] 保存训练样本
2025-05-11 19:04:23,945 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 19:04:26,120 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 19:04:26,121 [INFO] Training with 200000 examples
2025-05-11 19:04:26,121 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 19:04:26,308 [INFO] 循环学习率周期大小: 585 步
2025-05-11 19:05:18,077 [INFO] Epoch 1/15 - Policy Loss: 2.9626, Value Loss: 0.1661, Total Loss: 3.1287, LR: 0.001692
2025-05-11 19:06:10,030 [INFO] Epoch 2/15 - Policy Loss: 2.8543, Value Loss: 0.1502, Total Loss: 3.0045, LR: 0.003342
2025-05-11 19:07:02,678 [INFO] Epoch 3/15 - Policy Loss: 2.7957, Value Loss: 0.1450, Total Loss: 2.9407, LR: 0.004992
2025-05-11 19:07:55,964 [INFO] Epoch 4/15 - Policy Loss: 2.7907, Value Loss: 0.1479, Total Loss: 2.9386, LR: 0.003358
2025-05-11 19:08:48,628 [INFO] Epoch 5/15 - Policy Loss: 2.7314, Value Loss: 0.1415, Total Loss: 2.8730, LR: 0.001708
2025-05-11 19:09:40,986 [INFO] Epoch 6/15 - Policy Loss: 2.6690, Value Loss: 0.1347, Total Loss: 2.8037, LR: 0.000058
2025-05-11 19:10:33,062 [INFO] Epoch 7/15 - Policy Loss: 2.6165, Value Loss: 0.1291, Total Loss: 2.7456, LR: 0.001692
2025-05-11 19:11:25,585 [INFO] Epoch 8/15 - Policy Loss: 2.5760, Value Loss: 0.1253, Total Loss: 2.7014, LR: 0.003342
2025-05-11 19:12:18,401 [INFO] Epoch 9/15 - Policy Loss: 2.5524, Value Loss: 0.1234, Total Loss: 2.6759, LR: 0.004992
2025-05-11 19:13:11,131 [INFO] Epoch 10/15 - Policy Loss: 2.5396, Value Loss: 0.1232, Total Loss: 2.6628, LR: 0.003358
2025-05-11 19:14:03,537 [INFO] Epoch 11/15 - Policy Loss: 2.5165, Value Loss: 0.1214, Total Loss: 2.6379, LR: 0.001708
2025-05-11 19:14:56,403 [INFO] Epoch 12/15 - Policy Loss: 2.4896, Value Loss: 0.1190, Total Loss: 2.6087, LR: 0.000058
2025-05-11 19:15:49,824 [INFO] Epoch 13/15 - Policy Loss: 2.4641, Value Loss: 0.1169, Total Loss: 2.5810, LR: 0.001692
2025-05-11 19:16:42,499 [INFO] Epoch 14/15 - Policy Loss: 2.4430, Value Loss: 0.1151, Total Loss: 2.5581, LR: 0.003342
2025-05-11 19:17:34,833 [INFO] Epoch 15/15 - Policy Loss: 2.4300, Value Loss: 0.1142, Total Loss: 2.5442, LR: 0.004992
2025-05-11 19:17:34,872 [INFO] 训练完成，总损失: 2.5442
2025-05-11 19:17:34,872 [INFO] 保存迭代 4 的模型
2025-05-11 19:17:36,125 [INFO] Model saved to ./models/best.pt
2025-05-11 19:17:36,982 [INFO] Model saved to ./models/iteration_4.pt
2025-05-11 19:17:36,983 [INFO] 所有训练迭代完成
2025-05-11 19:17:36,984 [INFO] 开始迭代 5/300
2025-05-11 19:17:36,984 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 19:40:25,429 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 19:40:25,467 [INFO] 保存训练样本
2025-05-11 19:40:35,474 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 19:40:36,443 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 19:40:36,444 [INFO] Training with 200000 examples
2025-05-11 19:40:36,444 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 19:40:36,527 [INFO] 循环学习率周期大小: 585 步
2025-05-11 19:41:28,817 [INFO] Epoch 1/15 - Policy Loss: 2.7428, Value Loss: 0.1613, Total Loss: 2.9041, LR: 0.001692
2025-05-11 19:42:20,827 [INFO] Epoch 2/15 - Policy Loss: 2.6449, Value Loss: 0.1469, Total Loss: 2.7918, LR: 0.003342
2025-05-11 19:43:13,281 [INFO] Epoch 3/15 - Policy Loss: 2.5953, Value Loss: 0.1417, Total Loss: 2.7370, LR: 0.004992
2025-05-11 19:44:05,383 [INFO] Epoch 4/15 - Policy Loss: 2.5649, Value Loss: 0.1383, Total Loss: 2.7031, LR: 0.003358
2025-05-11 19:44:58,489 [INFO] Epoch 5/15 - Policy Loss: 2.5153, Value Loss: 0.1326, Total Loss: 2.6479, LR: 0.001708
2025-05-11 19:45:50,993 [INFO] Epoch 6/15 - Policy Loss: 2.4641, Value Loss: 0.1273, Total Loss: 2.5914, LR: 0.000058
2025-05-11 19:46:44,827 [INFO] Epoch 7/15 - Policy Loss: 2.4225, Value Loss: 0.1231, Total Loss: 2.5456, LR: 0.001692
2025-05-11 19:47:37,702 [INFO] Epoch 8/15 - Policy Loss: 2.3912, Value Loss: 0.1202, Total Loss: 2.5114, LR: 0.003342
2025-05-11 19:48:30,506 [INFO] Epoch 9/15 - Policy Loss: 2.3747, Value Loss: 0.1187, Total Loss: 2.4934, LR: 0.004992
2025-05-11 19:49:23,558 [INFO] Epoch 10/15 - Policy Loss: 2.3685, Value Loss: 0.1186, Total Loss: 2.4870, LR: 0.003358
2025-05-11 19:50:17,107 [INFO] Epoch 11/15 - Policy Loss: 2.3529, Value Loss: 0.1173, Total Loss: 2.4702, LR: 0.001708
2025-05-11 19:51:09,994 [INFO] Epoch 12/15 - Policy Loss: 2.3327, Value Loss: 0.1155, Total Loss: 2.4482, LR: 0.000058
2025-05-11 19:52:03,360 [INFO] Epoch 13/15 - Policy Loss: 2.3132, Value Loss: 0.1139, Total Loss: 2.4271, LR: 0.001692
2025-05-11 19:52:56,433 [INFO] Epoch 14/15 - Policy Loss: 2.2975, Value Loss: 0.1125, Total Loss: 2.4100, LR: 0.003342
2025-05-11 19:53:49,128 [INFO] Epoch 15/15 - Policy Loss: 2.2876, Value Loss: 0.1118, Total Loss: 2.3994, LR: 0.004992
2025-05-11 19:53:49,184 [INFO] 训练完成，总损失: 2.3994
2025-05-11 19:53:49,185 [INFO] 保存迭代 5 的模型
2025-05-11 19:53:50,937 [INFO] Model saved to ./models/best.pt
2025-05-11 19:53:51,865 [INFO] Model saved to ./models/iteration_5.pt
2025-05-11 19:53:51,865 [INFO] 所有训练迭代完成
2025-05-11 19:53:51,865 [INFO] 开始迭代 6/300
2025-05-11 19:53:51,865 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 20:17:25,602 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 20:17:25,621 [INFO] 保存训练样本
2025-05-11 20:17:33,840 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 20:17:34,942 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 20:17:34,943 [INFO] Training with 200000 examples
2025-05-11 20:17:34,943 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 20:17:35,041 [INFO] 循环学习率周期大小: 585 步
2025-05-11 20:18:27,494 [INFO] Epoch 1/15 - Policy Loss: 2.5724, Value Loss: 0.1550, Total Loss: 2.7273, LR: 0.001692
2025-05-11 20:19:19,482 [INFO] Epoch 2/15 - Policy Loss: 2.4899, Value Loss: 0.1441, Total Loss: 2.6340, LR: 0.003342
2025-05-11 20:20:11,525 [INFO] Epoch 3/15 - Policy Loss: 2.4593, Value Loss: 0.1399, Total Loss: 2.5992, LR: 0.004992
2025-05-11 20:21:03,619 [INFO] Epoch 4/15 - Policy Loss: 2.4349, Value Loss: 0.1364, Total Loss: 2.5714, LR: 0.003358
2025-05-11 20:21:55,975 [INFO] Epoch 5/15 - Policy Loss: 2.3920, Value Loss: 0.1314, Total Loss: 2.5234, LR: 0.001708
2025-05-11 20:22:48,253 [INFO] Epoch 6/15 - Policy Loss: 2.3478, Value Loss: 0.1266, Total Loss: 2.4744, LR: 0.000058
2025-05-11 20:23:40,684 [INFO] Epoch 7/15 - Policy Loss: 2.3122, Value Loss: 0.1230, Total Loss: 2.4351, LR: 0.001692
2025-05-11 20:24:32,939 [INFO] Epoch 8/15 - Policy Loss: 2.2856, Value Loss: 0.1202, Total Loss: 2.4058, LR: 0.003342
2025-05-11 20:25:25,286 [INFO] Epoch 9/15 - Policy Loss: 2.2705, Value Loss: 0.1189, Total Loss: 2.3893, LR: 0.004992
2025-05-11 20:26:18,250 [INFO] Epoch 10/15 - Policy Loss: 2.2665, Value Loss: 0.1187, Total Loss: 2.3852, LR: 0.003358
2025-05-11 20:27:11,941 [INFO] Epoch 11/15 - Policy Loss: 2.2542, Value Loss: 0.1176, Total Loss: 2.3718, LR: 0.001708
2025-05-11 20:28:04,272 [INFO] Epoch 12/15 - Policy Loss: 2.2370, Value Loss: 0.1159, Total Loss: 2.3530, LR: 0.000058
2025-05-11 20:28:57,428 [INFO] Epoch 13/15 - Policy Loss: 2.2203, Value Loss: 0.1144, Total Loss: 2.3347, LR: 0.001692
2025-05-11 20:29:50,432 [INFO] Epoch 14/15 - Policy Loss: 2.2060, Value Loss: 0.1130, Total Loss: 2.3190, LR: 0.003342
2025-05-11 20:30:43,245 [INFO] Epoch 15/15 - Policy Loss: 2.1984, Value Loss: 0.1124, Total Loss: 2.3108, LR: 0.004992
2025-05-11 20:30:43,285 [INFO] 训练完成，总损失: 2.3108
2025-05-11 20:30:43,285 [INFO] 保存迭代 6 的模型
2025-05-11 20:30:44,504 [INFO] Model saved to ./models/best.pt
2025-05-11 20:30:45,329 [INFO] Model saved to ./models/iteration_6.pt
2025-05-11 20:30:45,330 [INFO] 所有训练迭代完成
2025-05-11 20:30:45,330 [INFO] 开始迭代 7/300
2025-05-11 20:30:45,330 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 20:47:17,352 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 20:47:17,371 [INFO] 保存训练样本
2025-05-11 20:47:26,553 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 20:47:26,801 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 20:47:26,801 [INFO] Training with 200000 examples
2025-05-11 20:47:26,801 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 20:47:27,677 [INFO] 循环学习率周期大小: 585 步
2025-05-11 20:48:20,154 [INFO] Epoch 1/15 - Policy Loss: 2.4328, Value Loss: 0.1439, Total Loss: 2.5766, LR: 0.001692
2025-05-11 20:49:12,960 [INFO] Epoch 2/15 - Policy Loss: 2.3636, Value Loss: 0.1348, Total Loss: 2.4985, LR: 0.003342
2025-05-11 20:50:04,568 [INFO] Epoch 3/15 - Policy Loss: 2.3323, Value Loss: 0.1311, Total Loss: 2.4634, LR: 0.004992
2025-05-11 20:50:57,061 [INFO] Epoch 4/15 - Policy Loss: 2.3130, Value Loss: 0.1293, Total Loss: 2.4423, LR: 0.003358
2025-05-11 20:51:49,100 [INFO] Epoch 5/15 - Policy Loss: 2.2808, Value Loss: 0.1257, Total Loss: 2.4065, LR: 0.001708
2025-05-11 20:52:43,169 [INFO] Epoch 6/15 - Policy Loss: 2.2465, Value Loss: 0.1227, Total Loss: 2.3693, LR: 0.000058
2025-05-11 20:53:35,700 [INFO] Epoch 7/15 - Policy Loss: 2.2183, Value Loss: 0.1199, Total Loss: 2.3381, LR: 0.001692
2025-05-11 20:54:28,959 [INFO] Epoch 8/15 - Policy Loss: 2.1970, Value Loss: 0.1178, Total Loss: 2.3147, LR: 0.003342
2025-05-11 20:55:21,762 [INFO] Epoch 9/15 - Policy Loss: 2.1864, Value Loss: 0.1168, Total Loss: 2.3032, LR: 0.004992
2025-05-11 20:56:14,070 [INFO] Epoch 10/15 - Policy Loss: 2.1843, Value Loss: 0.1167, Total Loss: 2.3010, LR: 0.003358
2025-05-11 20:57:07,028 [INFO] Epoch 11/15 - Policy Loss: 2.1744, Value Loss: 0.1157, Total Loss: 2.2902, LR: 0.001708
2025-05-11 20:57:59,461 [INFO] Epoch 12/15 - Policy Loss: 2.1610, Value Loss: 0.1147, Total Loss: 2.2757, LR: 0.000058
2025-05-11 20:58:51,907 [INFO] Epoch 13/15 - Policy Loss: 2.1475, Value Loss: 0.1136, Total Loss: 2.2611, LR: 0.001692
2025-05-11 20:59:46,884 [INFO] Epoch 14/15 - Policy Loss: 2.1367, Value Loss: 0.1127, Total Loss: 2.2494, LR: 0.003342
2025-05-11 21:00:39,524 [INFO] Epoch 15/15 - Policy Loss: 2.1308, Value Loss: 0.1123, Total Loss: 2.2431, LR: 0.004992
2025-05-11 21:00:39,566 [INFO] 训练完成，总损失: 2.2431
2025-05-11 21:00:39,566 [INFO] 保存迭代 7 的模型
2025-05-11 21:00:40,781 [INFO] Model saved to ./models/best.pt
2025-05-11 21:00:41,625 [INFO] Model saved to ./models/iteration_7.pt
2025-05-11 21:00:41,625 [INFO] 所有训练迭代完成
2025-05-11 21:00:41,625 [INFO] 开始迭代 8/300
2025-05-11 21:00:41,625 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 21:19:00,919 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 21:19:00,936 [INFO] 保存训练样本
2025-05-11 21:19:15,340 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 21:19:15,580 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 21:19:15,580 [INFO] Training with 200000 examples
2025-05-11 21:19:15,581 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 21:19:16,506 [INFO] 循环学习率周期大小: 585 步
2025-05-11 21:20:08,401 [INFO] Epoch 1/15 - Policy Loss: 2.3355, Value Loss: 0.1488, Total Loss: 2.4843, LR: 0.001692
2025-05-11 21:21:01,221 [INFO] Epoch 2/15 - Policy Loss: 2.2811, Value Loss: 0.1399, Total Loss: 2.4210, LR: 0.003342
2025-05-11 21:21:53,832 [INFO] Epoch 3/15 - Policy Loss: 2.2586, Value Loss: 0.1365, Total Loss: 2.3951, LR: 0.004992
2025-05-11 21:22:46,301 [INFO] Epoch 4/15 - Policy Loss: 2.2459, Value Loss: 0.1343, Total Loss: 2.3802, LR: 0.003358
2025-05-11 21:23:39,096 [INFO] Epoch 5/15 - Policy Loss: 2.2194, Value Loss: 0.1305, Total Loss: 2.3500, LR: 0.001708
2025-05-11 21:24:31,043 [INFO] Epoch 6/15 - Policy Loss: 2.1887, Value Loss: 0.1270, Total Loss: 2.3157, LR: 0.000058
2025-05-11 21:25:24,002 [INFO] Epoch 7/15 - Policy Loss: 2.1644, Value Loss: 0.1244, Total Loss: 2.2888, LR: 0.001692
2025-05-11 21:26:16,241 [INFO] Epoch 8/15 - Policy Loss: 2.1464, Value Loss: 0.1223, Total Loss: 2.2687, LR: 0.003342
2025-05-11 21:27:10,139 [INFO] Epoch 9/15 - Policy Loss: 2.1377, Value Loss: 0.1210, Total Loss: 2.2586, LR: 0.004992
2025-05-11 21:28:02,380 [INFO] Epoch 10/15 - Policy Loss: 2.1369, Value Loss: 0.1208, Total Loss: 2.2577, LR: 0.003358
2025-05-11 21:28:54,966 [INFO] Epoch 11/15 - Policy Loss: 2.1293, Value Loss: 0.1202, Total Loss: 2.2495, LR: 0.001708
2025-05-11 21:29:47,346 [INFO] Epoch 12/15 - Policy Loss: 2.1178, Value Loss: 0.1192, Total Loss: 2.2370, LR: 0.000058
2025-05-11 21:30:39,868 [INFO] Epoch 13/15 - Policy Loss: 2.1063, Value Loss: 0.1180, Total Loss: 2.2243, LR: 0.001692
2025-05-11 21:31:32,028 [INFO] Epoch 14/15 - Policy Loss: 2.0966, Value Loss: 0.1170, Total Loss: 2.2136, LR: 0.003342
2025-05-11 21:32:24,405 [INFO] Epoch 15/15 - Policy Loss: 2.0920, Value Loss: 0.1165, Total Loss: 2.2084, LR: 0.004992
2025-05-11 21:32:24,445 [INFO] 训练完成，总损失: 2.2084
2025-05-11 21:32:24,445 [INFO] 保存迭代 8 的模型
2025-05-11 21:32:25,747 [INFO] Model saved to ./models/best.pt
2025-05-11 21:32:26,607 [INFO] Model saved to ./models/iteration_8.pt
2025-05-11 21:32:26,607 [INFO] 所有训练迭代完成
2025-05-11 21:32:26,607 [INFO] 开始迭代 9/300
2025-05-11 21:32:26,607 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 21:47:54,871 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 21:47:54,883 [INFO] 保存训练样本
2025-05-11 21:48:03,698 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 21:48:03,946 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 21:48:03,947 [INFO] Training with 200000 examples
2025-05-11 21:48:03,947 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 21:48:04,837 [INFO] 循环学习率周期大小: 585 步
2025-05-11 21:48:57,330 [INFO] Epoch 1/15 - Policy Loss: 2.2545, Value Loss: 0.1405, Total Loss: 2.3950, LR: 0.001692
2025-05-11 21:49:50,451 [INFO] Epoch 2/15 - Policy Loss: 2.2041, Value Loss: 0.1339, Total Loss: 2.3379, LR: 0.003342
2025-05-11 21:50:43,048 [INFO] Epoch 3/15 - Policy Loss: 2.1895, Value Loss: 0.1320, Total Loss: 2.3215, LR: 0.004992
2025-05-11 21:51:36,298 [INFO] Epoch 4/15 - Policy Loss: 2.1860, Value Loss: 0.1308, Total Loss: 2.3169, LR: 0.003358
2025-05-11 21:52:29,950 [INFO] Epoch 5/15 - Policy Loss: 2.1682, Value Loss: 0.1285, Total Loss: 2.2967, LR: 0.001708
2025-05-11 21:53:22,680 [INFO] Epoch 6/15 - Policy Loss: 2.1439, Value Loss: 0.1258, Total Loss: 2.2697, LR: 0.000058
2025-05-11 21:54:16,032 [INFO] Epoch 7/15 - Policy Loss: 2.1232, Value Loss: 0.1239, Total Loss: 2.2470, LR: 0.001692
2025-05-11 21:55:08,986 [INFO] Epoch 8/15 - Policy Loss: 2.1084, Value Loss: 0.1223, Total Loss: 2.2307, LR: 0.003342
2025-05-11 21:56:02,679 [INFO] Epoch 9/15 - Policy Loss: 2.1021, Value Loss: 0.1217, Total Loss: 2.2238, LR: 0.004992
2025-05-11 21:56:55,631 [INFO] Epoch 10/15 - Policy Loss: 2.1037, Value Loss: 0.1219, Total Loss: 2.2256, LR: 0.003358
2025-05-11 21:57:48,748 [INFO] Epoch 11/15 - Policy Loss: 2.0986, Value Loss: 0.1213, Total Loss: 2.2199, LR: 0.001708
2025-05-11 21:58:41,435 [INFO] Epoch 12/15 - Policy Loss: 2.0897, Value Loss: 0.1206, Total Loss: 2.2102, LR: 0.000058
2025-05-11 21:59:35,643 [INFO] Epoch 13/15 - Policy Loss: 2.0808, Value Loss: 0.1197, Total Loss: 2.2005, LR: 0.001692
2025-05-11 22:00:29,276 [INFO] Epoch 14/15 - Policy Loss: 2.0724, Value Loss: 0.1189, Total Loss: 2.1913, LR: 0.003342
2025-05-11 22:01:23,377 [INFO] Epoch 15/15 - Policy Loss: 2.0688, Value Loss: 0.1184, Total Loss: 2.1872, LR: 0.004992
2025-05-11 22:01:23,417 [INFO] 训练完成，总损失: 2.1872
2025-05-11 22:01:23,417 [INFO] 保存迭代 9 的模型
2025-05-11 22:01:25,006 [INFO] Model saved to ./models/best.pt
2025-05-11 22:01:25,868 [INFO] Model saved to ./models/iteration_9.pt
2025-05-11 22:01:25,868 [INFO] 所有训练迭代完成
2025-05-11 22:01:25,868 [INFO] 开始迭代 10/300
2025-05-11 22:01:25,868 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 22:15:18,151 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 22:15:18,164 [INFO] 保存训练样本
2025-05-11 22:15:26,270 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 22:15:26,499 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 22:15:26,499 [INFO] Training with 200000 examples
2025-05-11 22:15:26,499 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 22:15:27,275 [INFO] 循环学习率周期大小: 585 步
2025-05-11 22:16:20,055 [INFO] Epoch 1/15 - Policy Loss: 2.1951, Value Loss: 0.1453, Total Loss: 2.3403, LR: 0.001692
2025-05-11 22:17:14,430 [INFO] Epoch 2/15 - Policy Loss: 2.1566, Value Loss: 0.1387, Total Loss: 2.2953, LR: 0.003342
2025-05-11 22:18:07,659 [INFO] Epoch 3/15 - Policy Loss: 2.1454, Value Loss: 0.1351, Total Loss: 2.2805, LR: 0.004992
2025-05-11 22:18:59,877 [INFO] Epoch 4/15 - Policy Loss: 2.1483, Value Loss: 0.1341, Total Loss: 2.2824, LR: 0.003358
2025-05-11 22:19:53,439 [INFO] Epoch 5/15 - Policy Loss: 2.1327, Value Loss: 0.1312, Total Loss: 2.2638, LR: 0.001708
2025-05-11 22:20:46,944 [INFO] Epoch 6/15 - Policy Loss: 2.1116, Value Loss: 0.1278, Total Loss: 2.2394, LR: 0.000058
2025-05-11 22:21:39,410 [INFO] Epoch 7/15 - Policy Loss: 2.0936, Value Loss: 0.1258, Total Loss: 2.2194, LR: 0.001692
2025-05-11 22:22:31,966 [INFO] Epoch 8/15 - Policy Loss: 2.0814, Value Loss: 0.1240, Total Loss: 2.2055, LR: 0.003342
2025-05-11 22:23:24,702 [INFO] Epoch 9/15 - Policy Loss: 2.0763, Value Loss: 0.1232, Total Loss: 2.1995, LR: 0.004992
2025-05-11 22:24:17,699 [INFO] Epoch 10/15 - Policy Loss: 2.0767, Value Loss: 0.1233, Total Loss: 2.2000, LR: 0.003358
2025-05-11 22:25:11,149 [INFO] Epoch 11/15 - Policy Loss: 2.0716, Value Loss: 0.1225, Total Loss: 2.1940, LR: 0.001708
2025-05-11 22:26:04,398 [INFO] Epoch 12/15 - Policy Loss: 2.0634, Value Loss: 0.1217, Total Loss: 2.1851, LR: 0.000058
2025-05-11 22:26:56,937 [INFO] Epoch 13/15 - Policy Loss: 2.0556, Value Loss: 0.1210, Total Loss: 2.1766, LR: 0.001692
2025-05-11 22:27:49,978 [INFO] Epoch 14/15 - Policy Loss: 2.0485, Value Loss: 0.1205, Total Loss: 2.1690, LR: 0.003342
2025-05-11 22:28:43,149 [INFO] Epoch 15/15 - Policy Loss: 2.0456, Value Loss: 0.1201, Total Loss: 2.1658, LR: 0.004992
2025-05-11 22:28:43,193 [INFO] 训练完成，总损失: 2.1658
2025-05-11 22:28:43,193 [INFO] 保存迭代 10 的模型
2025-05-11 22:28:44,616 [INFO] Model saved to ./models/best.pt
2025-05-11 22:28:45,575 [INFO] Model saved to ./models/iteration_10.pt
2025-05-11 22:28:45,576 [INFO] 所有训练迭代完成
2025-05-11 22:28:45,576 [INFO] 开始迭代 11/300
2025-05-11 22:28:45,576 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 22:42:15,917 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 22:42:15,928 [INFO] 保存训练样本
2025-05-11 22:42:24,431 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 22:42:24,679 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 22:42:24,679 [INFO] Training with 200000 examples
2025-05-11 22:42:24,679 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 22:42:25,463 [INFO] 循环学习率周期大小: 585 步
2025-05-11 22:43:17,853 [INFO] Epoch 1/15 - Policy Loss: 2.1694, Value Loss: 0.1377, Total Loss: 2.3071, LR: 0.001692
2025-05-11 22:44:10,271 [INFO] Epoch 2/15 - Policy Loss: 2.1365, Value Loss: 0.1329, Total Loss: 2.2694, LR: 0.003342
2025-05-11 22:45:03,094 [INFO] Epoch 3/15 - Policy Loss: 2.1226, Value Loss: 0.1308, Total Loss: 2.2534, LR: 0.004992
2025-05-11 22:45:55,670 [INFO] Epoch 4/15 - Policy Loss: 2.1227, Value Loss: 0.1298, Total Loss: 2.2525, LR: 0.003358
2025-05-11 22:46:48,120 [INFO] Epoch 5/15 - Policy Loss: 2.1089, Value Loss: 0.1281, Total Loss: 2.2370, LR: 0.001708
2025-05-11 22:47:40,954 [INFO] Epoch 6/15 - Policy Loss: 2.0918, Value Loss: 0.1261, Total Loss: 2.2179, LR: 0.000058
2025-05-11 22:48:34,047 [INFO] Epoch 7/15 - Policy Loss: 2.0774, Value Loss: 0.1242, Total Loss: 2.2016, LR: 0.001692
2025-05-11 22:49:26,562 [INFO] Epoch 8/15 - Policy Loss: 2.0670, Value Loss: 0.1228, Total Loss: 2.1898, LR: 0.003342
2025-05-11 22:50:18,820 [INFO] Epoch 9/15 - Policy Loss: 2.0624, Value Loss: 0.1219, Total Loss: 2.1843, LR: 0.004992
2025-05-11 22:51:12,123 [INFO] Epoch 10/15 - Policy Loss: 2.0627, Value Loss: 0.1214, Total Loss: 2.1841, LR: 0.003358
2025-05-11 22:52:04,943 [INFO] Epoch 11/15 - Policy Loss: 2.0578, Value Loss: 0.1208, Total Loss: 2.1786, LR: 0.001708
2025-05-11 22:52:58,919 [INFO] Epoch 12/15 - Policy Loss: 2.0511, Value Loss: 0.1202, Total Loss: 2.1712, LR: 0.000058
2025-05-11 22:53:52,252 [INFO] Epoch 13/15 - Policy Loss: 2.0438, Value Loss: 0.1195, Total Loss: 2.1632, LR: 0.001692
2025-05-11 22:54:46,073 [INFO] Epoch 14/15 - Policy Loss: 2.0379, Value Loss: 0.1188, Total Loss: 2.1567, LR: 0.003342
2025-05-11 22:55:38,743 [INFO] Epoch 15/15 - Policy Loss: 2.0357, Value Loss: 0.1185, Total Loss: 2.1542, LR: 0.004992
2025-05-11 22:55:38,837 [INFO] 训练完成，总损失: 2.1542
2025-05-11 22:55:38,838 [INFO] 保存迭代 11 的模型
2025-05-11 22:55:42,674 [INFO] Model saved to ./models/best.pt
2025-05-11 22:55:44,620 [INFO] Model saved to ./models/iteration_11.pt
2025-05-11 22:55:44,621 [INFO] 所有训练迭代完成
2025-05-11 22:55:44,621 [INFO] 开始迭代 12/300
2025-05-11 22:55:44,621 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 23:09:10,945 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 23:09:10,961 [INFO] 保存训练样本
2025-05-11 23:09:20,596 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 23:09:20,825 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 23:09:20,825 [INFO] Training with 200000 examples
2025-05-11 23:09:20,826 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 23:09:21,475 [INFO] 循环学习率周期大小: 585 步
2025-05-11 23:10:13,508 [INFO] Epoch 1/15 - Policy Loss: 2.1275, Value Loss: 0.1362, Total Loss: 2.2637, LR: 0.001692
2025-05-11 23:11:06,064 [INFO] Epoch 2/15 - Policy Loss: 2.0998, Value Loss: 0.1312, Total Loss: 2.2310, LR: 0.003342
2025-05-11 23:11:58,063 [INFO] Epoch 3/15 - Policy Loss: 2.0958, Value Loss: 0.1296, Total Loss: 2.2254, LR: 0.004992
2025-05-11 23:12:50,892 [INFO] Epoch 4/15 - Policy Loss: 2.1015, Value Loss: 0.1295, Total Loss: 2.2309, LR: 0.003358
2025-05-11 23:13:43,674 [INFO] Epoch 5/15 - Policy Loss: 2.0919, Value Loss: 0.1281, Total Loss: 2.2200, LR: 0.001708
2025-05-11 23:14:35,526 [INFO] Epoch 6/15 - Policy Loss: 2.0775, Value Loss: 0.1263, Total Loss: 2.2038, LR: 0.000058
2025-05-11 23:15:27,418 [INFO] Epoch 7/15 - Policy Loss: 2.0659, Value Loss: 0.1248, Total Loss: 2.1907, LR: 0.001692
2025-05-11 23:16:19,387 [INFO] Epoch 8/15 - Policy Loss: 2.0581, Value Loss: 0.1236, Total Loss: 2.1817, LR: 0.003342
2025-05-11 23:17:11,593 [INFO] Epoch 9/15 - Policy Loss: 2.0543, Value Loss: 0.1228, Total Loss: 2.1771, LR: 0.004992
2025-05-11 23:18:03,960 [INFO] Epoch 10/15 - Policy Loss: 2.0545, Value Loss: 0.1223, Total Loss: 2.1768, LR: 0.003358
2025-05-11 23:18:56,646 [INFO] Epoch 11/15 - Policy Loss: 2.0505, Value Loss: 0.1215, Total Loss: 2.1720, LR: 0.001708
2025-05-11 23:19:48,540 [INFO] Epoch 12/15 - Policy Loss: 2.0442, Value Loss: 0.1205, Total Loss: 2.1647, LR: 0.000058
2025-05-11 23:20:40,523 [INFO] Epoch 13/15 - Policy Loss: 2.0375, Value Loss: 0.1196, Total Loss: 2.1571, LR: 0.001692
2025-05-11 23:21:32,535 [INFO] Epoch 14/15 - Policy Loss: 2.0319, Value Loss: 0.1189, Total Loss: 2.1508, LR: 0.003342
2025-05-11 23:22:25,036 [INFO] Epoch 15/15 - Policy Loss: 2.0297, Value Loss: 0.1185, Total Loss: 2.1482, LR: 0.004992
2025-05-11 23:22:25,075 [INFO] 训练完成，总损失: 2.1482
2025-05-11 23:22:25,076 [INFO] 保存迭代 12 的模型
2025-05-11 23:22:26,864 [INFO] Model saved to ./models/best.pt
2025-05-11 23:22:27,932 [INFO] Model saved to ./models/iteration_12.pt
2025-05-11 23:22:27,933 [INFO] 所有训练迭代完成
2025-05-11 23:22:27,933 [INFO] 开始迭代 13/300
2025-05-11 23:22:27,933 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 23:32:04,381 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 23:32:04,389 [INFO] 保存训练样本
2025-05-11 23:32:11,082 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 23:32:11,315 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 23:32:11,315 [INFO] Training with 200000 examples
2025-05-11 23:32:11,316 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 23:32:11,919 [INFO] 循环学习率周期大小: 585 步
2025-05-11 23:33:03,474 [INFO] Epoch 1/15 - Policy Loss: 2.0964, Value Loss: 0.1295, Total Loss: 2.2259, LR: 0.001692
2025-05-11 23:33:54,873 [INFO] Epoch 2/15 - Policy Loss: 2.0709, Value Loss: 0.1246, Total Loss: 2.1955, LR: 0.003342
2025-05-11 23:34:46,477 [INFO] Epoch 3/15 - Policy Loss: 2.0730, Value Loss: 0.1247, Total Loss: 2.1977, LR: 0.004992
2025-05-11 23:35:38,000 [INFO] Epoch 4/15 - Policy Loss: 2.0814, Value Loss: 0.1256, Total Loss: 2.2070, LR: 0.003358
2025-05-11 23:36:29,482 [INFO] Epoch 5/15 - Policy Loss: 2.0755, Value Loss: 0.1244, Total Loss: 2.1999, LR: 0.001708
2025-05-11 23:37:21,180 [INFO] Epoch 6/15 - Policy Loss: 2.0654, Value Loss: 0.1233, Total Loss: 2.1887, LR: 0.000058
2025-05-11 23:38:12,935 [INFO] Epoch 7/15 - Policy Loss: 2.0556, Value Loss: 0.1220, Total Loss: 2.1776, LR: 0.001692
2025-05-11 23:39:05,407 [INFO] Epoch 8/15 - Policy Loss: 2.0476, Value Loss: 0.1210, Total Loss: 2.1686, LR: 0.003342
2025-05-11 23:39:57,112 [INFO] Epoch 9/15 - Policy Loss: 2.0460, Value Loss: 0.1204, Total Loss: 2.1664, LR: 0.004992
2025-05-11 23:40:49,042 [INFO] Epoch 10/15 - Policy Loss: 2.0492, Value Loss: 0.1206, Total Loss: 2.1698, LR: 0.003358
2025-05-11 23:41:41,214 [INFO] Epoch 11/15 - Policy Loss: 2.0475, Value Loss: 0.1203, Total Loss: 2.1679, LR: 0.001708
2025-05-11 23:42:33,352 [INFO] Epoch 12/15 - Policy Loss: 2.0432, Value Loss: 0.1199, Total Loss: 2.1631, LR: 0.000058
2025-05-11 23:43:25,435 [INFO] Epoch 13/15 - Policy Loss: 2.0383, Value Loss: 0.1194, Total Loss: 2.1577, LR: 0.001692
2025-05-11 23:44:17,518 [INFO] Epoch 14/15 - Policy Loss: 2.0344, Value Loss: 0.1189, Total Loss: 2.1533, LR: 0.003342
2025-05-11 23:45:09,533 [INFO] Epoch 15/15 - Policy Loss: 2.0332, Value Loss: 0.1186, Total Loss: 2.1517, LR: 0.004992
2025-05-11 23:45:09,572 [INFO] 训练完成，总损失: 2.1517
2025-05-11 23:45:09,572 [INFO] 保存迭代 13 的模型
2025-05-11 23:45:11,207 [INFO] Model saved to ./models/best.pt
2025-05-11 23:45:12,118 [INFO] Model saved to ./models/iteration_13.pt
2025-05-11 23:45:12,119 [INFO] 所有训练迭代完成
2025-05-11 23:45:12,119 [INFO] 开始迭代 14/300
2025-05-11 23:45:12,119 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-11 23:58:34,808 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-11 23:58:34,814 [INFO] 保存训练样本
2025-05-11 23:58:40,459 [INFO] 截断训练样本，保持长度为 200000
2025-05-11 23:58:41,274 [INFO] 使用 200000 个样本训练神经网络
2025-05-11 23:58:41,274 [INFO] Training with 200000 examples
2025-05-11 23:58:41,275 [INFO] 总训练步数: 2925, 每轮次批次数: 195
2025-05-11 23:58:41,359 [INFO] 循环学习率周期大小: 585 步
2025-05-11 23:59:33,160 [INFO] Epoch 1/15 - Policy Loss: 2.1188, Value Loss: 0.1415, Total Loss: 2.2602, LR: 0.001692
2025-05-12 00:00:25,146 [INFO] Epoch 2/15 - Policy Loss: 2.0955, Value Loss: 0.1370, Total Loss: 2.2325, LR: 0.003342
2025-05-12 00:01:17,770 [INFO] Epoch 3/15 - Policy Loss: 2.0918, Value Loss: 0.1358, Total Loss: 2.2276, LR: 0.004992
2025-05-12 00:02:09,799 [INFO] Epoch 4/15 - Policy Loss: 2.0947, Value Loss: 0.1353, Total Loss: 2.2300, LR: 0.003358
2025-05-12 00:03:02,075 [INFO] Epoch 5/15 - Policy Loss: 2.0894, Value Loss: 0.1341, Total Loss: 2.2235, LR: 0.001708
2025-05-12 00:03:54,289 [INFO] Epoch 6/15 - Policy Loss: 2.0793, Value Loss: 0.1323, Total Loss: 2.2116, LR: 0.000058
2025-05-12 00:04:46,441 [INFO] Epoch 7/15 - Policy Loss: 2.0698, Value Loss: 0.1309, Total Loss: 2.2007, LR: 0.001692
2025-05-12 00:05:38,692 [INFO] Epoch 8/15 - Policy Loss: 2.0627, Value Loss: 0.1298, Total Loss: 2.1925, LR: 0.003342
2025-05-12 00:06:30,995 [INFO] Epoch 9/15 - Policy Loss: 2.0608, Value Loss: 0.1291, Total Loss: 2.1899, LR: 0.004992
2025-05-12 00:07:23,368 [INFO] Epoch 10/15 - Policy Loss: 2.0628, Value Loss: 0.1290, Total Loss: 2.1918, LR: 0.003358
2025-05-12 00:08:15,723 [INFO] Epoch 11/15 - Policy Loss: 2.0602, Value Loss: 0.1284, Total Loss: 2.1886, LR: 0.001708
2025-05-12 00:09:08,333 [INFO] Epoch 12/15 - Policy Loss: 2.0557, Value Loss: 0.1278, Total Loss: 2.1834, LR: 0.000058
2025-05-12 00:10:00,943 [INFO] Epoch 13/15 - Policy Loss: 2.0508, Value Loss: 0.1272, Total Loss: 2.1780, LR: 0.001692
2025-05-12 00:10:53,588 [INFO] Epoch 14/15 - Policy Loss: 2.0466, Value Loss: 0.1267, Total Loss: 2.1733, LR: 0.003342
2025-05-12 00:11:46,356 [INFO] Epoch 15/15 - Policy Loss: 2.0453, Value Loss: 0.1264, Total Loss: 2.1717, LR: 0.004992
2025-05-12 00:11:46,396 [INFO] 训练完成，总损失: 2.1717
2025-05-12 00:11:46,396 [INFO] 保存迭代 14 的模型
2025-05-12 00:11:47,733 [INFO] Model saved to ./models/best.pt
2025-05-12 00:11:48,574 [INFO] Model saved to ./models/iteration_14.pt
2025-05-12 00:11:48,574 [INFO] 所有训练迭代完成
2025-05-12 00:11:48,574 [INFO] 开始迭代 15/300
2025-05-12 00:11:48,574 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 00:26:41,487 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 00:26:41,490 [INFO] 保存训练样本
2025-05-12 00:26:48,418 [INFO] 使用 197048 个样本训练神经网络
2025-05-12 00:26:48,418 [INFO] Training with 197048 examples
2025-05-12 00:26:48,419 [INFO] 总训练步数: 2880, 每轮次批次数: 192
2025-05-12 00:26:49,220 [INFO] 循环学习率周期大小: 576 步
2025-05-12 00:27:40,321 [INFO] Epoch 1/15 - Policy Loss: 2.1275, Value Loss: 0.1575, Total Loss: 2.2850, LR: 0.001691
2025-05-12 00:28:31,506 [INFO] Epoch 2/15 - Policy Loss: 2.1063, Value Loss: 0.1494, Total Loss: 2.2557, LR: 0.003341
2025-05-12 00:29:22,818 [INFO] Epoch 3/15 - Policy Loss: 2.1026, Value Loss: 0.1450, Total Loss: 2.2476, LR: 0.004991
2025-05-12 00:30:14,256 [INFO] Epoch 4/15 - Policy Loss: 2.1047, Value Loss: 0.1431, Total Loss: 2.2478, LR: 0.003359
2025-05-12 00:31:05,574 [INFO] Epoch 5/15 - Policy Loss: 2.0974, Value Loss: 0.1409, Total Loss: 2.2383, LR: 0.001709
2025-05-12 00:31:56,981 [INFO] Epoch 6/15 - Policy Loss: 2.0868, Value Loss: 0.1390, Total Loss: 2.2258, LR: 0.000059
2025-05-12 00:32:48,469 [INFO] Epoch 7/15 - Policy Loss: 2.0777, Value Loss: 0.1375, Total Loss: 2.2152, LR: 0.001691
2025-05-12 00:33:40,101 [INFO] Epoch 8/15 - Policy Loss: 2.0715, Value Loss: 0.1362, Total Loss: 2.2078, LR: 0.003341
2025-05-12 00:34:31,629 [INFO] Epoch 9/15 - Policy Loss: 2.0689, Value Loss: 0.1354, Total Loss: 2.2043, LR: 0.004991
2025-05-12 00:35:23,409 [INFO] Epoch 10/15 - Policy Loss: 2.0701, Value Loss: 0.1350, Total Loss: 2.2052, LR: 0.003359
2025-05-12 00:36:15,240 [INFO] Epoch 11/15 - Policy Loss: 2.0677, Value Loss: 0.1343, Total Loss: 2.2020, LR: 0.001709
2025-05-12 00:37:07,038 [INFO] Epoch 12/15 - Policy Loss: 2.0637, Value Loss: 0.1337, Total Loss: 2.1974, LR: 0.000059
2025-05-12 00:37:59,409 [INFO] Epoch 13/15 - Policy Loss: 2.0587, Value Loss: 0.1330, Total Loss: 2.1918, LR: 0.001691
2025-05-12 00:38:50,921 [INFO] Epoch 14/15 - Policy Loss: 2.0549, Value Loss: 0.1325, Total Loss: 2.1873, LR: 0.003341
2025-05-12 00:39:42,603 [INFO] Epoch 15/15 - Policy Loss: 2.0530, Value Loss: 0.1320, Total Loss: 2.1850, LR: 0.004991
2025-05-12 00:39:42,643 [INFO] 训练完成，总损失: 2.1850
2025-05-12 00:39:42,643 [INFO] 保存迭代 15 的模型
2025-05-12 00:39:43,904 [INFO] Model saved to ./models/best.pt
2025-05-12 00:39:44,750 [INFO] Model saved to ./models/iteration_15.pt
2025-05-12 00:39:44,751 [INFO] 所有训练迭代完成
2025-05-12 00:39:44,751 [INFO] 开始迭代 16/300
2025-05-12 00:39:44,751 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 00:52:33,122 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 00:52:33,123 [INFO] 保存训练样本
2025-05-12 00:52:39,336 [INFO] 使用 188576 个样本训练神经网络
2025-05-12 00:52:39,336 [INFO] Training with 188576 examples
2025-05-12 00:52:39,337 [INFO] 总训练步数: 2760, 每轮次批次数: 184
2025-05-12 00:52:40,148 [INFO] 循环学习率周期大小: 552 步
2025-05-12 00:53:31,142 [INFO] Epoch 1/15 - Policy Loss: 2.1228, Value Loss: 0.1527, Total Loss: 2.2755, LR: 0.001691
2025-05-12 00:54:21,362 [INFO] Epoch 2/15 - Policy Loss: 2.0982, Value Loss: 0.1471, Total Loss: 2.2452, LR: 0.003341
2025-05-12 00:55:10,618 [INFO] Epoch 3/15 - Policy Loss: 2.0965, Value Loss: 0.1454, Total Loss: 2.2418, LR: 0.004991
2025-05-12 00:56:01,389 [INFO] Epoch 4/15 - Policy Loss: 2.1021, Value Loss: 0.1449, Total Loss: 2.2470, LR: 0.003359
2025-05-12 00:56:50,111 [INFO] Epoch 5/15 - Policy Loss: 2.0962, Value Loss: 0.1440, Total Loss: 2.2402, LR: 0.001709
2025-05-12 00:57:42,580 [INFO] Epoch 6/15 - Policy Loss: 2.0865, Value Loss: 0.1425, Total Loss: 2.2290, LR: 0.000059
2025-05-12 00:58:32,654 [INFO] Epoch 7/15 - Policy Loss: 2.0788, Value Loss: 0.1411, Total Loss: 2.2199, LR: 0.001691
2025-05-12 00:59:22,201 [INFO] Epoch 8/15 - Policy Loss: 2.0724, Value Loss: 0.1401, Total Loss: 2.2124, LR: 0.003341
2025-05-12 01:00:13,881 [INFO] Epoch 9/15 - Policy Loss: 2.0704, Value Loss: 0.1397, Total Loss: 2.2101, LR: 0.004991
2025-05-12 01:01:03,387 [INFO] Epoch 10/15 - Policy Loss: 2.0724, Value Loss: 0.1396, Total Loss: 2.2121, LR: 0.003359
2025-05-12 01:01:53,982 [INFO] Epoch 11/15 - Policy Loss: 2.0711, Value Loss: 0.1393, Total Loss: 2.2104, LR: 0.001709
2025-05-12 01:02:43,652 [INFO] Epoch 12/15 - Policy Loss: 2.0674, Value Loss: 0.1389, Total Loss: 2.2063, LR: 0.000059
2025-05-12 01:03:34,399 [INFO] Epoch 13/15 - Policy Loss: 2.0639, Value Loss: 0.1383, Total Loss: 2.2023, LR: 0.001691
2025-05-12 01:04:24,099 [INFO] Epoch 14/15 - Policy Loss: 2.0602, Value Loss: 0.1379, Total Loss: 2.1981, LR: 0.003341
2025-05-12 01:05:13,075 [INFO] Epoch 15/15 - Policy Loss: 2.0590, Value Loss: 0.1376, Total Loss: 2.1966, LR: 0.004991
2025-05-12 01:05:13,110 [INFO] 训练完成，总损失: 2.1966
2025-05-12 01:05:13,111 [INFO] 保存迭代 16 的模型
2025-05-12 01:05:15,029 [INFO] Model saved to ./models/best.pt
2025-05-12 01:05:16,193 [INFO] Model saved to ./models/iteration_16.pt
2025-05-12 01:05:16,193 [INFO] 所有训练迭代完成
2025-05-12 01:05:16,193 [INFO] 开始迭代 17/300
2025-05-12 01:05:16,193 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 01:18:10,824 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 01:18:10,825 [INFO] 保存训练样本
2025-05-12 01:18:21,416 [INFO] 使用 180056 个样本训练神经网络
2025-05-12 01:18:21,417 [INFO] Training with 180056 examples
2025-05-12 01:18:21,418 [INFO] 总训练步数: 2625, 每轮次批次数: 175
2025-05-12 01:18:21,562 [INFO] 循环学习率周期大小: 525 步
2025-05-12 01:19:09,242 [INFO] Epoch 1/15 - Policy Loss: 2.1291, Value Loss: 0.1643, Total Loss: 2.2934, LR: 0.001691
2025-05-12 01:19:57,884 [INFO] Epoch 2/15 - Policy Loss: 2.1100, Value Loss: 0.1575, Total Loss: 2.2675, LR: 0.003341
2025-05-12 01:20:45,405 [INFO] Epoch 3/15 - Policy Loss: 2.1052, Value Loss: 0.1546, Total Loss: 2.2598, LR: 0.004991
2025-05-12 01:21:34,502 [INFO] Epoch 4/15 - Policy Loss: 2.1088, Value Loss: 0.1539, Total Loss: 2.2626, LR: 0.003359
2025-05-12 01:22:22,382 [INFO] Epoch 5/15 - Policy Loss: 2.1034, Value Loss: 0.1519, Total Loss: 2.2553, LR: 0.001709
2025-05-12 01:23:10,251 [INFO] Epoch 6/15 - Policy Loss: 2.0951, Value Loss: 0.1502, Total Loss: 2.2453, LR: 0.000059
2025-05-12 01:23:57,389 [INFO] Epoch 7/15 - Policy Loss: 2.0866, Value Loss: 0.1488, Total Loss: 2.2354, LR: 0.001691
2025-05-12 01:24:46,310 [INFO] Epoch 8/15 - Policy Loss: 2.0809, Value Loss: 0.1477, Total Loss: 2.2286, LR: 0.003341
2025-05-12 01:25:33,312 [INFO] Epoch 9/15 - Policy Loss: 2.0789, Value Loss: 0.1474, Total Loss: 2.2263, LR: 0.004991
2025-05-12 01:26:21,976 [INFO] Epoch 10/15 - Policy Loss: 2.0798, Value Loss: 0.1471, Total Loss: 2.2269, LR: 0.003359
2025-05-12 01:27:09,548 [INFO] Epoch 11/15 - Policy Loss: 2.0777, Value Loss: 0.1466, Total Loss: 2.2243, LR: 0.001709
2025-05-12 01:27:56,837 [INFO] Epoch 12/15 - Policy Loss: 2.0742, Value Loss: 0.1460, Total Loss: 2.2202, LR: 0.000059
2025-05-12 01:28:45,716 [INFO] Epoch 13/15 - Policy Loss: 2.0709, Value Loss: 0.1454, Total Loss: 2.2162, LR: 0.001691
2025-05-12 01:29:33,033 [INFO] Epoch 14/15 - Policy Loss: 2.0677, Value Loss: 0.1447, Total Loss: 2.2124, LR: 0.003341
2025-05-12 01:30:21,650 [INFO] Epoch 15/15 - Policy Loss: 2.0663, Value Loss: 0.1443, Total Loss: 2.2106, LR: 0.004991
2025-05-12 01:30:21,781 [INFO] 训练完成，总损失: 2.2106
2025-05-12 01:30:21,782 [INFO] 保存迭代 17 的模型
2025-05-12 01:30:25,156 [INFO] Model saved to ./models/best.pt
2025-05-12 01:30:26,947 [INFO] Model saved to ./models/iteration_17.pt
2025-05-12 01:30:26,948 [INFO] 所有训练迭代完成
2025-05-12 01:30:26,949 [INFO] 开始迭代 18/300
2025-05-12 01:30:26,949 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 01:43:45,470 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 01:43:45,472 [INFO] 保存训练样本
2025-05-12 01:43:58,477 [INFO] 使用 173152 个样本训练神经网络
2025-05-12 01:43:58,477 [INFO] Training with 173152 examples
2025-05-12 01:43:58,478 [INFO] 总训练步数: 2535, 每轮次批次数: 169
2025-05-12 01:43:59,892 [INFO] 循环学习率周期大小: 507 步
2025-05-12 01:44:45,199 [INFO] Epoch 1/15 - Policy Loss: 2.1224, Value Loss: 0.1593, Total Loss: 2.2817, LR: 0.001690
2025-05-12 01:45:31,908 [INFO] Epoch 2/15 - Policy Loss: 2.1094, Value Loss: 0.1565, Total Loss: 2.2659, LR: 0.003340
2025-05-12 01:46:18,835 [INFO] Epoch 3/15 - Policy Loss: 2.1081, Value Loss: 0.1549, Total Loss: 2.2630, LR: 0.004990
2025-05-12 01:47:04,201 [INFO] Epoch 4/15 - Policy Loss: 2.1109, Value Loss: 0.1542, Total Loss: 2.2651, LR: 0.003360
2025-05-12 01:47:52,162 [INFO] Epoch 5/15 - Policy Loss: 2.1057, Value Loss: 0.1529, Total Loss: 2.2585, LR: 0.001710
2025-05-12 01:48:37,721 [INFO] Epoch 6/15 - Policy Loss: 2.0991, Value Loss: 0.1517, Total Loss: 2.2507, LR: 0.000060
2025-05-12 01:49:25,404 [INFO] Epoch 7/15 - Policy Loss: 2.0921, Value Loss: 0.1507, Total Loss: 2.2428, LR: 0.001690
2025-05-12 01:50:11,296 [INFO] Epoch 8/15 - Policy Loss: 2.0868, Value Loss: 0.1498, Total Loss: 2.2366, LR: 0.003340
2025-05-12 01:50:58,644 [INFO] Epoch 9/15 - Policy Loss: 2.0846, Value Loss: 0.1491, Total Loss: 2.2337, LR: 0.004990
2025-05-12 01:51:45,106 [INFO] Epoch 10/15 - Policy Loss: 2.0848, Value Loss: 0.1489, Total Loss: 2.2337, LR: 0.003360
2025-05-12 01:52:31,457 [INFO] Epoch 11/15 - Policy Loss: 2.0835, Value Loss: 0.1486, Total Loss: 2.2321, LR: 0.001710
2025-05-12 01:53:16,813 [INFO] Epoch 12/15 - Policy Loss: 2.0801, Value Loss: 0.1481, Total Loss: 2.2282, LR: 0.000060
2025-05-12 01:54:02,433 [INFO] Epoch 13/15 - Policy Loss: 2.0770, Value Loss: 0.1477, Total Loss: 2.2247, LR: 0.001690
2025-05-12 01:54:49,155 [INFO] Epoch 14/15 - Policy Loss: 2.0740, Value Loss: 0.1473, Total Loss: 2.2213, LR: 0.003340
2025-05-12 01:55:34,764 [INFO] Epoch 15/15 - Policy Loss: 2.0731, Value Loss: 0.1473, Total Loss: 2.2203, LR: 0.004990
2025-05-12 01:55:34,798 [INFO] 训练完成，总损失: 2.2203
2025-05-12 01:55:34,798 [INFO] 保存迭代 18 的模型
2025-05-12 01:55:36,209 [INFO] Model saved to ./models/best.pt
2025-05-12 01:55:37,122 [INFO] Model saved to ./models/iteration_18.pt
2025-05-12 01:55:37,123 [INFO] 所有训练迭代完成
2025-05-12 01:55:37,123 [INFO] 开始迭代 19/300
2025-05-12 01:55:37,123 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 02:09:22,617 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 02:09:22,618 [INFO] 保存训练样本
2025-05-12 02:09:28,273 [INFO] 使用 167024 个样本训练神经网络
2025-05-12 02:09:28,274 [INFO] Training with 167024 examples
2025-05-12 02:09:28,274 [INFO] 总训练步数: 2445, 每轮次批次数: 163
2025-05-12 02:09:28,870 [INFO] 循环学习率周期大小: 489 步
2025-05-12 02:10:13,706 [INFO] Epoch 1/15 - Policy Loss: 2.1512, Value Loss: 0.1818, Total Loss: 2.3329, LR: 0.001690
2025-05-12 02:10:58,329 [INFO] Epoch 2/15 - Policy Loss: 2.1332, Value Loss: 0.1759, Total Loss: 2.3092, LR: 0.003340
2025-05-12 02:11:41,881 [INFO] Epoch 3/15 - Policy Loss: 2.1295, Value Loss: 0.1719, Total Loss: 2.3014, LR: 0.004990
2025-05-12 02:12:25,484 [INFO] Epoch 4/15 - Policy Loss: 2.1295, Value Loss: 0.1700, Total Loss: 2.2995, LR: 0.003360
2025-05-12 02:13:11,209 [INFO] Epoch 5/15 - Policy Loss: 2.1248, Value Loss: 0.1674, Total Loss: 2.2921, LR: 0.001710
2025-05-12 02:13:57,025 [INFO] Epoch 6/15 - Policy Loss: 2.1174, Value Loss: 0.1650, Total Loss: 2.2824, LR: 0.000060
2025-05-12 02:14:41,564 [INFO] Epoch 7/15 - Policy Loss: 2.1100, Value Loss: 0.1631, Total Loss: 2.2731, LR: 0.001690
2025-05-12 02:15:25,327 [INFO] Epoch 8/15 - Policy Loss: 2.1044, Value Loss: 0.1617, Total Loss: 2.2662, LR: 0.003340
2025-05-12 02:16:10,050 [INFO] Epoch 9/15 - Policy Loss: 2.1019, Value Loss: 0.1609, Total Loss: 2.2628, LR: 0.004990
2025-05-12 02:16:54,475 [INFO] Epoch 10/15 - Policy Loss: 2.1017, Value Loss: 0.1604, Total Loss: 2.2622, LR: 0.003360
2025-05-12 02:17:38,115 [INFO] Epoch 11/15 - Policy Loss: 2.1001, Value Loss: 0.1597, Total Loss: 2.2599, LR: 0.001710
2025-05-12 02:18:25,056 [INFO] Epoch 12/15 - Policy Loss: 2.0963, Value Loss: 0.1589, Total Loss: 2.2552, LR: 0.000060
2025-05-12 02:19:10,971 [INFO] Epoch 13/15 - Policy Loss: 2.0920, Value Loss: 0.1581, Total Loss: 2.2501, LR: 0.001690
2025-05-12 02:19:56,734 [INFO] Epoch 14/15 - Policy Loss: 2.0884, Value Loss: 0.1576, Total Loss: 2.2460, LR: 0.003340
2025-05-12 02:20:40,714 [INFO] Epoch 15/15 - Policy Loss: 2.0869, Value Loss: 0.1572, Total Loss: 2.2441, LR: 0.004990
2025-05-12 02:20:40,746 [INFO] 训练完成，总损失: 2.2441
2025-05-12 02:20:40,746 [INFO] 保存迭代 19 的模型
2025-05-12 02:20:42,300 [INFO] Model saved to ./models/best.pt
2025-05-12 02:20:43,208 [INFO] Model saved to ./models/iteration_19.pt
2025-05-12 02:20:43,209 [INFO] 所有训练迭代完成
2025-05-12 02:20:43,209 [INFO] 开始迭代 20/300
2025-05-12 02:20:43,209 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 02:34:14,750 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 02:34:14,751 [INFO] 保存训练样本
2025-05-12 02:34:19,640 [INFO] 使用 160984 个样本训练神经网络
2025-05-12 02:34:19,640 [INFO] Training with 160984 examples
2025-05-12 02:34:19,640 [INFO] 总训练步数: 2355, 每轮次批次数: 157
2025-05-12 02:34:20,229 [INFO] 循环学习率周期大小: 471 步
2025-05-12 02:35:02,084 [INFO] Epoch 1/15 - Policy Loss: 2.1564, Value Loss: 0.1825, Total Loss: 2.3389, LR: 0.001689
2025-05-12 02:35:45,121 [INFO] Epoch 2/15 - Policy Loss: 2.1356, Value Loss: 0.1756, Total Loss: 2.3111, LR: 0.003339
2025-05-12 02:36:26,792 [INFO] Epoch 3/15 - Policy Loss: 2.1289, Value Loss: 0.1725, Total Loss: 2.3014, LR: 0.004989
2025-05-12 02:37:10,294 [INFO] Epoch 4/15 - Policy Loss: 2.1306, Value Loss: 0.1719, Total Loss: 2.3026, LR: 0.003361
2025-05-12 02:37:52,416 [INFO] Epoch 5/15 - Policy Loss: 2.1257, Value Loss: 0.1704, Total Loss: 2.2962, LR: 0.001711
2025-05-12 02:38:34,461 [INFO] Epoch 6/15 - Policy Loss: 2.1181, Value Loss: 0.1687, Total Loss: 2.2868, LR: 0.000061
2025-05-12 02:39:16,610 [INFO] Epoch 7/15 - Policy Loss: 2.1131, Value Loss: 0.1673, Total Loss: 2.2804, LR: 0.001689
2025-05-12 02:39:58,587 [INFO] Epoch 8/15 - Policy Loss: 2.1090, Value Loss: 0.1665, Total Loss: 2.2754, LR: 0.003339
2025-05-12 02:40:41,240 [INFO] Epoch 9/15 - Policy Loss: 2.1062, Value Loss: 0.1658, Total Loss: 2.2720, LR: 0.004989
2025-05-12 02:41:23,691 [INFO] Epoch 10/15 - Policy Loss: 2.1074, Value Loss: 0.1655, Total Loss: 2.2729, LR: 0.003361
2025-05-12 02:42:06,367 [INFO] Epoch 11/15 - Policy Loss: 2.1059, Value Loss: 0.1648, Total Loss: 2.2707, LR: 0.001711
2025-05-12 02:42:49,433 [INFO] Epoch 12/15 - Policy Loss: 2.1022, Value Loss: 0.1644, Total Loss: 2.2666, LR: 0.000061
2025-05-12 02:43:31,687 [INFO] Epoch 13/15 - Policy Loss: 2.0992, Value Loss: 0.1638, Total Loss: 2.2630, LR: 0.001689
2025-05-12 02:44:15,034 [INFO] Epoch 14/15 - Policy Loss: 2.0963, Value Loss: 0.1633, Total Loss: 2.2596, LR: 0.003339
2025-05-12 02:44:57,187 [INFO] Epoch 15/15 - Policy Loss: 2.0955, Value Loss: 0.1630, Total Loss: 2.2585, LR: 0.004989
2025-05-12 02:44:57,214 [INFO] 训练完成，总损失: 2.2585
2025-05-12 02:44:57,214 [INFO] 保存迭代 20 的模型
2025-05-12 02:44:58,396 [INFO] Model saved to ./models/best.pt
2025-05-12 02:44:59,100 [INFO] Model saved to ./models/iteration_20.pt
2025-05-12 02:44:59,100 [INFO] 所有训练迭代完成
2025-05-12 02:44:59,100 [INFO] 开始迭代 21/300
2025-05-12 02:44:59,100 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 02:58:34,897 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 02:58:34,899 [INFO] 保存训练样本
2025-05-12 02:58:42,696 [INFO] 使用 146744 个样本训练神经网络
2025-05-12 02:58:42,697 [INFO] Training with 146744 examples
2025-05-12 02:58:42,698 [INFO] 总训练步数: 2145, 每轮次批次数: 143
2025-05-12 02:58:43,546 [INFO] 循环学习率周期大小: 429 步
2025-05-12 02:59:21,718 [INFO] Epoch 1/15 - Policy Loss: 1.7152, Value Loss: 0.2129, Total Loss: 1.9281, LR: 0.001688
2025-05-12 03:00:00,330 [INFO] Epoch 2/15 - Policy Loss: 1.6797, Value Loss: 0.2057, Total Loss: 1.8855, LR: 0.003338
2025-05-12 03:00:39,562 [INFO] Epoch 3/15 - Policy Loss: 1.6692, Value Loss: 0.2025, Total Loss: 1.8717, LR: 0.004988
2025-05-12 03:01:17,793 [INFO] Epoch 4/15 - Policy Loss: 1.6656, Value Loss: 0.1999, Total Loss: 1.8655, LR: 0.003362
2025-05-12 03:01:56,812 [INFO] Epoch 5/15 - Policy Loss: 1.6571, Value Loss: 0.1968, Total Loss: 1.8539, LR: 0.001712
2025-05-12 03:02:35,340 [INFO] Epoch 6/15 - Policy Loss: 1.6486, Value Loss: 0.1943, Total Loss: 1.8429, LR: 0.000062
2025-05-12 03:03:15,271 [INFO] Epoch 7/15 - Policy Loss: 1.6409, Value Loss: 0.1924, Total Loss: 1.8333, LR: 0.001688
2025-05-12 03:03:53,624 [INFO] Epoch 8/15 - Policy Loss: 1.6342, Value Loss: 0.1909, Total Loss: 1.8251, LR: 0.003338
2025-05-12 03:04:33,915 [INFO] Epoch 9/15 - Policy Loss: 1.6313, Value Loss: 0.1899, Total Loss: 1.8212, LR: 0.004988
2025-05-12 03:05:12,772 [INFO] Epoch 10/15 - Policy Loss: 1.6307, Value Loss: 0.1893, Total Loss: 1.8200, LR: 0.003362
2025-05-12 03:05:52,626 [INFO] Epoch 11/15 - Policy Loss: 1.6285, Value Loss: 0.1887, Total Loss: 1.8171, LR: 0.001712
2025-05-12 03:06:30,959 [INFO] Epoch 12/15 - Policy Loss: 1.6248, Value Loss: 0.1879, Total Loss: 1.8127, LR: 0.000062
2025-05-12 03:07:09,344 [INFO] Epoch 13/15 - Policy Loss: 1.6206, Value Loss: 0.1869, Total Loss: 1.8076, LR: 0.001688
2025-05-12 03:07:50,571 [INFO] Epoch 14/15 - Policy Loss: 1.6174, Value Loss: 0.1863, Total Loss: 1.8037, LR: 0.003338
2025-05-12 03:08:29,024 [INFO] Epoch 15/15 - Policy Loss: 1.6156, Value Loss: 0.1857, Total Loss: 1.8014, LR: 0.004988
2025-05-12 03:08:29,051 [INFO] 训练完成，总损失: 1.8014
2025-05-12 03:08:29,051 [INFO] 保存迭代 21 的模型
2025-05-12 03:08:30,367 [INFO] Model saved to ./models/best.pt
2025-05-12 03:08:31,260 [INFO] Model saved to ./models/iteration_21.pt
2025-05-12 03:08:31,261 [INFO] 所有训练迭代完成
2025-05-12 03:08:31,261 [INFO] 开始迭代 22/300
2025-05-12 03:08:31,261 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 03:20:24,988 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 03:20:24,989 [INFO] 保存训练样本
2025-05-12 03:20:29,761 [INFO] 使用 141760 个样本训练神经网络
2025-05-12 03:20:29,761 [INFO] Training with 141760 examples
2025-05-12 03:20:29,761 [INFO] 总训练步数: 2070, 每轮次批次数: 138
2025-05-12 03:20:29,827 [INFO] 循环学习率周期大小: 414 步
2025-05-12 03:21:06,588 [INFO] Epoch 1/15 - Policy Loss: 1.6412, Value Loss: 0.2091, Total Loss: 1.8503, LR: 0.001688
2025-05-12 03:21:45,053 [INFO] Epoch 2/15 - Policy Loss: 1.6200, Value Loss: 0.2020, Total Loss: 1.8220, LR: 0.003338
2025-05-12 03:22:21,856 [INFO] Epoch 3/15 - Policy Loss: 1.6147, Value Loss: 0.1989, Total Loss: 1.8136, LR: 0.004988
2025-05-12 03:22:59,101 [INFO] Epoch 4/15 - Policy Loss: 1.6152, Value Loss: 0.1971, Total Loss: 1.8122, LR: 0.003362
2025-05-12 03:23:38,826 [INFO] Epoch 5/15 - Policy Loss: 1.6112, Value Loss: 0.1954, Total Loss: 1.8065, LR: 0.001712
2025-05-12 03:24:15,861 [INFO] Epoch 6/15 - Policy Loss: 1.6039, Value Loss: 0.1939, Total Loss: 1.7978, LR: 0.000062
2025-05-12 03:24:54,665 [INFO] Epoch 7/15 - Policy Loss: 1.5969, Value Loss: 0.1924, Total Loss: 1.7893, LR: 0.001688
2025-05-12 03:25:32,908 [INFO] Epoch 8/15 - Policy Loss: 1.5926, Value Loss: 0.1913, Total Loss: 1.7839, LR: 0.003338
2025-05-12 03:26:09,864 [INFO] Epoch 9/15 - Policy Loss: 1.5912, Value Loss: 0.1907, Total Loss: 1.7819, LR: 0.004988
2025-05-12 03:26:47,607 [INFO] Epoch 10/15 - Policy Loss: 1.5912, Value Loss: 0.1903, Total Loss: 1.7815, LR: 0.003362
2025-05-12 03:27:25,243 [INFO] Epoch 11/15 - Policy Loss: 1.5899, Value Loss: 0.1897, Total Loss: 1.7797, LR: 0.001712
2025-05-12 03:28:03,116 [INFO] Epoch 12/15 - Policy Loss: 1.5863, Value Loss: 0.1888, Total Loss: 1.7752, LR: 0.000062
2025-05-12 03:28:40,349 [INFO] Epoch 13/15 - Policy Loss: 1.5827, Value Loss: 0.1883, Total Loss: 1.7710, LR: 0.001688
2025-05-12 03:29:17,628 [INFO] Epoch 14/15 - Policy Loss: 1.5804, Value Loss: 0.1878, Total Loss: 1.7682, LR: 0.003338
2025-05-12 03:29:56,715 [INFO] Epoch 15/15 - Policy Loss: 1.5797, Value Loss: 0.1874, Total Loss: 1.7671, LR: 0.004988
2025-05-12 03:29:56,741 [INFO] 训练完成，总损失: 1.7671
2025-05-12 03:29:56,741 [INFO] 保存迭代 22 的模型
2025-05-12 03:29:57,992 [INFO] Model saved to ./models/best.pt
2025-05-12 03:29:59,035 [INFO] Model saved to ./models/iteration_22.pt
2025-05-12 03:29:59,035 [INFO] 所有训练迭代完成
2025-05-12 03:29:59,035 [INFO] 开始迭代 23/300
2025-05-12 03:29:59,035 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 03:43:19,616 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 03:43:19,617 [INFO] 保存训练样本
2025-05-12 03:43:23,542 [INFO] 使用 134968 个样本训练神经网络
2025-05-12 03:43:23,542 [INFO] Training with 134968 examples
2025-05-12 03:43:23,543 [INFO] 总训练步数: 1965, 每轮次批次数: 131
2025-05-12 03:43:23,607 [INFO] 循环学习率周期大小: 393 步
2025-05-12 03:43:58,351 [INFO] Epoch 1/15 - Policy Loss: 1.6259, Value Loss: 0.2263, Total Loss: 1.8521, LR: 0.001687
2025-05-12 03:44:34,489 [INFO] Epoch 2/15 - Policy Loss: 1.6040, Value Loss: 0.2190, Total Loss: 1.8230, LR: 0.003337
2025-05-12 03:45:10,155 [INFO] Epoch 3/15 - Policy Loss: 1.5991, Value Loss: 0.2152, Total Loss: 1.8143, LR: 0.004987
2025-05-12 03:45:47,817 [INFO] Epoch 4/15 - Policy Loss: 1.5977, Value Loss: 0.2124, Total Loss: 1.8101, LR: 0.003363
2025-05-12 03:46:22,948 [INFO] Epoch 5/15 - Policy Loss: 1.5907, Value Loss: 0.2098, Total Loss: 1.8004, LR: 0.001713
2025-05-12 03:46:59,621 [INFO] Epoch 6/15 - Policy Loss: 1.5839, Value Loss: 0.2082, Total Loss: 1.7921, LR: 0.000063
2025-05-12 03:47:34,528 [INFO] Epoch 7/15 - Policy Loss: 1.5775, Value Loss: 0.2067, Total Loss: 1.7842, LR: 0.001687
2025-05-12 03:48:10,428 [INFO] Epoch 8/15 - Policy Loss: 1.5721, Value Loss: 0.2055, Total Loss: 1.7776, LR: 0.003337
2025-05-12 03:48:46,329 [INFO] Epoch 9/15 - Policy Loss: 1.5700, Value Loss: 0.2046, Total Loss: 1.7746, LR: 0.004987
2025-05-12 03:49:22,876 [INFO] Epoch 10/15 - Policy Loss: 1.5697, Value Loss: 0.2042, Total Loss: 1.7740, LR: 0.003363
2025-05-12 03:49:58,135 [INFO] Epoch 11/15 - Policy Loss: 1.5675, Value Loss: 0.2037, Total Loss: 1.7712, LR: 0.001713
2025-05-12 03:50:33,391 [INFO] Epoch 12/15 - Policy Loss: 1.5644, Value Loss: 0.2032, Total Loss: 1.7676, LR: 0.000063
2025-05-12 03:51:10,783 [INFO] Epoch 13/15 - Policy Loss: 1.5613, Value Loss: 0.2025, Total Loss: 1.7638, LR: 0.001687
2025-05-12 03:51:47,590 [INFO] Epoch 14/15 - Policy Loss: 1.5586, Value Loss: 0.2018, Total Loss: 1.7604, LR: 0.003337
2025-05-12 03:52:22,939 [INFO] Epoch 15/15 - Policy Loss: 1.5574, Value Loss: 0.2013, Total Loss: 1.7587, LR: 0.004987
2025-05-12 03:52:22,980 [INFO] 训练完成，总损失: 1.7587
2025-05-12 03:52:22,981 [INFO] 保存迭代 23 的模型
2025-05-12 03:52:25,026 [INFO] Model saved to ./models/best.pt
2025-05-12 03:52:26,400 [INFO] Model saved to ./models/iteration_23.pt
2025-05-12 03:52:26,400 [INFO] 所有训练迭代完成
2025-05-12 03:52:26,401 [INFO] 开始迭代 24/300
2025-05-12 03:52:26,401 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 04:06:21,613 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 04:06:21,614 [INFO] 保存训练样本
2025-05-12 04:06:31,768 [INFO] 使用 131968 个样本训练神经网络
2025-05-12 04:06:31,768 [INFO] Training with 131968 examples
2025-05-12 04:06:31,769 [INFO] 总训练步数: 1920, 每轮次批次数: 128
2025-05-12 04:06:32,792 [INFO] 循环学习率周期大小: 384 步
2025-05-12 04:07:07,084 [INFO] Epoch 1/15 - Policy Loss: 1.6113, Value Loss: 0.2481, Total Loss: 1.8593, LR: 0.001687
2025-05-12 04:07:41,259 [INFO] Epoch 2/15 - Policy Loss: 1.5914, Value Loss: 0.2369, Total Loss: 1.8283, LR: 0.003337
2025-05-12 04:08:15,571 [INFO] Epoch 3/15 - Policy Loss: 1.5848, Value Loss: 0.2319, Total Loss: 1.8167, LR: 0.004987
2025-05-12 04:08:50,185 [INFO] Epoch 4/15 - Policy Loss: 1.5832, Value Loss: 0.2285, Total Loss: 1.8117, LR: 0.003363
2025-05-12 04:09:24,439 [INFO] Epoch 5/15 - Policy Loss: 1.5760, Value Loss: 0.2257, Total Loss: 1.8017, LR: 0.001713
2025-05-12 04:10:00,212 [INFO] Epoch 6/15 - Policy Loss: 1.5660, Value Loss: 0.2234, Total Loss: 1.7893, LR: 0.000063
2025-05-12 04:10:35,268 [INFO] Epoch 7/15 - Policy Loss: 1.5582, Value Loss: 0.2212, Total Loss: 1.7794, LR: 0.001687
2025-05-12 04:11:09,950 [INFO] Epoch 8/15 - Policy Loss: 1.5522, Value Loss: 0.2196, Total Loss: 1.7718, LR: 0.003337
2025-05-12 04:11:44,263 [INFO] Epoch 9/15 - Policy Loss: 1.5497, Value Loss: 0.2183, Total Loss: 1.7680, LR: 0.004987
2025-05-12 04:12:19,832 [INFO] Epoch 10/15 - Policy Loss: 1.5492, Value Loss: 0.2174, Total Loss: 1.7665, LR: 0.003363
2025-05-12 04:12:55,565 [INFO] Epoch 11/15 - Policy Loss: 1.5464, Value Loss: 0.2166, Total Loss: 1.7630, LR: 0.001713
2025-05-12 04:13:30,142 [INFO] Epoch 12/15 - Policy Loss: 1.5430, Value Loss: 0.2157, Total Loss: 1.7586, LR: 0.000063
2025-05-12 04:14:05,453 [INFO] Epoch 13/15 - Policy Loss: 1.5397, Value Loss: 0.2149, Total Loss: 1.7546, LR: 0.001687
2025-05-12 04:14:40,133 [INFO] Epoch 14/15 - Policy Loss: 1.5372, Value Loss: 0.2142, Total Loss: 1.7514, LR: 0.003337
2025-05-12 04:15:14,567 [INFO] Epoch 15/15 - Policy Loss: 1.5365, Value Loss: 0.2138, Total Loss: 1.7503, LR: 0.004987
2025-05-12 04:15:14,592 [INFO] 训练完成，总损失: 1.7503
2025-05-12 04:15:14,592 [INFO] 保存迭代 24 的模型
2025-05-12 04:15:15,950 [INFO] Model saved to ./models/best.pt
2025-05-12 04:15:16,869 [INFO] Model saved to ./models/iteration_24.pt
2025-05-12 04:15:16,869 [INFO] 所有训练迭代完成
2025-05-12 04:15:16,869 [INFO] 开始迭代 25/300
2025-05-12 04:15:16,869 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 04:29:52,952 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 04:29:52,953 [INFO] 保存训练样本
2025-05-12 04:29:57,576 [INFO] 使用 129400 个样本训练神经网络
2025-05-12 04:29:57,577 [INFO] Training with 129400 examples
2025-05-12 04:29:57,577 [INFO] 总训练步数: 1890, 每轮次批次数: 126
2025-05-12 04:29:58,011 [INFO] 循环学习率周期大小: 378 步
2025-05-12 04:30:31,526 [INFO] Epoch 1/15 - Policy Loss: 1.5986, Value Loss: 0.2597, Total Loss: 1.8583, LR: 0.001687
2025-05-12 04:31:07,058 [INFO] Epoch 2/15 - Policy Loss: 1.5788, Value Loss: 0.2486, Total Loss: 1.8274, LR: 0.003337
2025-05-12 04:31:40,716 [INFO] Epoch 3/15 - Policy Loss: 1.5716, Value Loss: 0.2426, Total Loss: 1.8143, LR: 0.004987
2025-05-12 04:32:15,531 [INFO] Epoch 4/15 - Policy Loss: 1.5678, Value Loss: 0.2401, Total Loss: 1.8079, LR: 0.003363
2025-05-12 04:32:49,258 [INFO] Epoch 5/15 - Policy Loss: 1.5603, Value Loss: 0.2371, Total Loss: 1.7973, LR: 0.001713
2025-05-12 04:33:23,994 [INFO] Epoch 6/15 - Policy Loss: 1.5514, Value Loss: 0.2344, Total Loss: 1.7858, LR: 0.000063
2025-05-12 04:33:57,663 [INFO] Epoch 7/15 - Policy Loss: 1.5433, Value Loss: 0.2326, Total Loss: 1.7758, LR: 0.001687
2025-05-12 04:34:32,194 [INFO] Epoch 8/15 - Policy Loss: 1.5373, Value Loss: 0.2311, Total Loss: 1.7684, LR: 0.003337
2025-05-12 04:35:05,938 [INFO] Epoch 9/15 - Policy Loss: 1.5339, Value Loss: 0.2299, Total Loss: 1.7639, LR: 0.004987
2025-05-12 04:35:40,477 [INFO] Epoch 10/15 - Policy Loss: 1.5325, Value Loss: 0.2291, Total Loss: 1.7616, LR: 0.003363
2025-05-12 04:36:14,460 [INFO] Epoch 11/15 - Policy Loss: 1.5293, Value Loss: 0.2281, Total Loss: 1.7573, LR: 0.001713
2025-05-12 04:36:49,093 [INFO] Epoch 12/15 - Policy Loss: 1.5259, Value Loss: 0.2275, Total Loss: 1.7534, LR: 0.000063
2025-05-12 04:37:23,588 [INFO] Epoch 13/15 - Policy Loss: 1.5230, Value Loss: 0.2268, Total Loss: 1.7498, LR: 0.001687
2025-05-12 04:37:58,985 [INFO] Epoch 14/15 - Policy Loss: 1.5202, Value Loss: 0.2261, Total Loss: 1.7462, LR: 0.003337
2025-05-12 04:38:33,038 [INFO] Epoch 15/15 - Policy Loss: 1.5187, Value Loss: 0.2255, Total Loss: 1.7442, LR: 0.004987
2025-05-12 04:38:33,062 [INFO] 训练完成，总损失: 1.7442
2025-05-12 04:38:33,062 [INFO] 保存迭代 25 的模型
2025-05-12 04:38:34,419 [INFO] Model saved to ./models/best.pt
2025-05-12 04:38:35,290 [INFO] Model saved to ./models/iteration_25.pt
2025-05-12 04:38:35,291 [INFO] 所有训练迭代完成
2025-05-12 04:38:35,291 [INFO] 开始迭代 26/300
2025-05-12 04:38:35,291 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 04:52:35,728 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 04:52:35,728 [INFO] 保存训练样本
2025-05-12 04:52:39,376 [INFO] 使用 126176 个样本训练神经网络
2025-05-12 04:52:39,377 [INFO] Training with 126176 examples
2025-05-12 04:52:39,377 [INFO] 总训练步数: 1845, 每轮次批次数: 123
2025-05-12 04:52:39,876 [INFO] 循环学习率周期大小: 369 步
2025-05-12 04:53:12,630 [INFO] Epoch 1/15 - Policy Loss: 1.5671, Value Loss: 0.2519, Total Loss: 1.8190, LR: 0.001687
2025-05-12 04:53:47,365 [INFO] Epoch 2/15 - Policy Loss: 1.5515, Value Loss: 0.2443, Total Loss: 1.7958, LR: 0.003337
2025-05-12 04:54:20,352 [INFO] Epoch 3/15 - Policy Loss: 1.5441, Value Loss: 0.2405, Total Loss: 1.7846, LR: 0.004987
2025-05-12 04:54:53,740 [INFO] Epoch 4/15 - Policy Loss: 1.5424, Value Loss: 0.2392, Total Loss: 1.7816, LR: 0.003363
2025-05-12 04:55:26,471 [INFO] Epoch 5/15 - Policy Loss: 1.5346, Value Loss: 0.2370, Total Loss: 1.7715, LR: 0.001713
2025-05-12 04:55:59,977 [INFO] Epoch 6/15 - Policy Loss: 1.5258, Value Loss: 0.2354, Total Loss: 1.7612, LR: 0.000063
2025-05-12 04:56:35,247 [INFO] Epoch 7/15 - Policy Loss: 1.5188, Value Loss: 0.2339, Total Loss: 1.7528, LR: 0.001687
2025-05-12 04:57:07,973 [INFO] Epoch 8/15 - Policy Loss: 1.5143, Value Loss: 0.2327, Total Loss: 1.7470, LR: 0.003337
2025-05-12 04:57:40,692 [INFO] Epoch 9/15 - Policy Loss: 1.5109, Value Loss: 0.2315, Total Loss: 1.7424, LR: 0.004987
2025-05-12 04:58:13,645 [INFO] Epoch 10/15 - Policy Loss: 1.5101, Value Loss: 0.2310, Total Loss: 1.7411, LR: 0.003363
2025-05-12 04:58:48,317 [INFO] Epoch 11/15 - Policy Loss: 1.5075, Value Loss: 0.2306, Total Loss: 1.7381, LR: 0.001713
2025-05-12 04:59:21,730 [INFO] Epoch 12/15 - Policy Loss: 1.5041, Value Loss: 0.2301, Total Loss: 1.7342, LR: 0.000063
2025-05-12 04:59:56,099 [INFO] Epoch 13/15 - Policy Loss: 1.5009, Value Loss: 0.2296, Total Loss: 1.7305, LR: 0.001687
2025-05-12 05:00:29,882 [INFO] Epoch 14/15 - Policy Loss: 1.4986, Value Loss: 0.2293, Total Loss: 1.7279, LR: 0.003337
2025-05-12 05:01:02,969 [INFO] Epoch 15/15 - Policy Loss: 1.4975, Value Loss: 0.2289, Total Loss: 1.7263, LR: 0.004987
2025-05-12 05:01:02,991 [INFO] 训练完成，总损失: 1.7263
2025-05-12 05:01:02,992 [INFO] 保存迭代 26 的模型
2025-05-12 05:01:04,160 [INFO] Model saved to ./models/best.pt
2025-05-12 05:01:04,998 [INFO] Model saved to ./models/iteration_26.pt
2025-05-12 05:01:04,999 [INFO] 所有训练迭代完成
2025-05-12 05:01:04,999 [INFO] 开始迭代 27/300
2025-05-12 05:01:04,999 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 05:14:00,847 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 05:14:00,847 [INFO] 保存训练样本
2025-05-12 05:14:04,288 [INFO] 使用 124840 个样本训练神经网络
2025-05-12 05:14:04,288 [INFO] Training with 124840 examples
2025-05-12 05:14:04,289 [INFO] 总训练步数: 1815, 每轮次批次数: 121
2025-05-12 05:14:04,332 [INFO] 循环学习率周期大小: 363 步
2025-05-12 05:14:36,268 [INFO] Epoch 1/15 - Policy Loss: 1.5267, Value Loss: 0.2590, Total Loss: 1.7857, LR: 0.001686
2025-05-12 05:15:10,405 [INFO] Epoch 2/15 - Policy Loss: 1.5134, Value Loss: 0.2538, Total Loss: 1.7672, LR: 0.003336
2025-05-12 05:15:42,499 [INFO] Epoch 3/15 - Policy Loss: 1.5084, Value Loss: 0.2507, Total Loss: 1.7591, LR: 0.004986
2025-05-12 05:16:15,759 [INFO] Epoch 4/15 - Policy Loss: 1.5049, Value Loss: 0.2484, Total Loss: 1.7533, LR: 0.003364
2025-05-12 05:16:47,980 [INFO] Epoch 5/15 - Policy Loss: 1.4998, Value Loss: 0.2462, Total Loss: 1.7460, LR: 0.001714
2025-05-12 05:17:20,943 [INFO] Epoch 6/15 - Policy Loss: 1.4935, Value Loss: 0.2443, Total Loss: 1.7378, LR: 0.000064
2025-05-12 05:17:54,816 [INFO] Epoch 7/15 - Policy Loss: 1.4876, Value Loss: 0.2425, Total Loss: 1.7301, LR: 0.001686
2025-05-12 05:18:27,643 [INFO] Epoch 8/15 - Policy Loss: 1.4831, Value Loss: 0.2412, Total Loss: 1.7243, LR: 0.003336
2025-05-12 05:18:59,816 [INFO] Epoch 9/15 - Policy Loss: 1.4804, Value Loss: 0.2400, Total Loss: 1.7204, LR: 0.004986
2025-05-12 05:19:33,262 [INFO] Epoch 10/15 - Policy Loss: 1.4801, Value Loss: 0.2394, Total Loss: 1.7196, LR: 0.003364
2025-05-12 05:20:07,826 [INFO] Epoch 11/15 - Policy Loss: 1.4786, Value Loss: 0.2386, Total Loss: 1.7172, LR: 0.001714
2025-05-12 05:20:40,781 [INFO] Epoch 12/15 - Policy Loss: 1.4760, Value Loss: 0.2377, Total Loss: 1.7138, LR: 0.000064
2025-05-12 05:21:13,257 [INFO] Epoch 13/15 - Policy Loss: 1.4732, Value Loss: 0.2370, Total Loss: 1.7102, LR: 0.001686
2025-05-12 05:21:48,416 [INFO] Epoch 14/15 - Policy Loss: 1.4705, Value Loss: 0.2365, Total Loss: 1.7070, LR: 0.003336
2025-05-12 05:22:21,079 [INFO] Epoch 15/15 - Policy Loss: 1.4693, Value Loss: 0.2359, Total Loss: 1.7052, LR: 0.004986
2025-05-12 05:22:21,099 [INFO] 训练完成，总损失: 1.7052
2025-05-12 05:22:21,099 [INFO] 保存迭代 27 的模型
2025-05-12 05:22:22,156 [INFO] Model saved to ./models/best.pt
2025-05-12 05:22:23,059 [INFO] Model saved to ./models/iteration_27.pt
2025-05-12 05:22:23,059 [INFO] 所有训练迭代完成
2025-05-12 05:22:23,060 [INFO] 开始迭代 28/300
2025-05-12 05:22:23,060 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 05:36:21,002 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 05:36:21,003 [INFO] 保存训练样本
2025-05-12 05:36:25,265 [INFO] 使用 124056 个样本训练神经网络
2025-05-12 05:36:25,265 [INFO] Training with 124056 examples
2025-05-12 05:36:25,266 [INFO] 总训练步数: 1815, 每轮次批次数: 121
2025-05-12 05:36:25,318 [INFO] 循环学习率周期大小: 363 步
2025-05-12 05:36:57,434 [INFO] Epoch 1/15 - Policy Loss: 1.5172, Value Loss: 0.2542, Total Loss: 1.7714, LR: 0.001686
2025-05-12 05:37:31,412 [INFO] Epoch 2/15 - Policy Loss: 1.4991, Value Loss: 0.2491, Total Loss: 1.7482, LR: 0.003336
2025-05-12 05:38:04,621 [INFO] Epoch 3/15 - Policy Loss: 1.4893, Value Loss: 0.2450, Total Loss: 1.7344, LR: 0.004986
2025-05-12 05:38:37,510 [INFO] Epoch 4/15 - Policy Loss: 1.4873, Value Loss: 0.2451, Total Loss: 1.7324, LR: 0.003364
2025-05-12 05:39:10,929 [INFO] Epoch 5/15 - Policy Loss: 1.4806, Value Loss: 0.2430, Total Loss: 1.7236, LR: 0.001714
2025-05-12 05:39:43,757 [INFO] Epoch 6/15 - Policy Loss: 1.4730, Value Loss: 0.2408, Total Loss: 1.7138, LR: 0.000064
2025-05-12 05:40:16,643 [INFO] Epoch 7/15 - Policy Loss: 1.4670, Value Loss: 0.2399, Total Loss: 1.7069, LR: 0.001686
2025-05-12 05:40:48,954 [INFO] Epoch 8/15 - Policy Loss: 1.4611, Value Loss: 0.2383, Total Loss: 1.6994, LR: 0.003336
2025-05-12 05:41:22,448 [INFO] Epoch 9/15 - Policy Loss: 1.4589, Value Loss: 0.2378, Total Loss: 1.6967, LR: 0.004986
2025-05-12 05:41:54,801 [INFO] Epoch 10/15 - Policy Loss: 1.4582, Value Loss: 0.2376, Total Loss: 1.6958, LR: 0.003364
2025-05-12 05:42:28,566 [INFO] Epoch 11/15 - Policy Loss: 1.4559, Value Loss: 0.2369, Total Loss: 1.6928, LR: 0.001714
2025-05-12 05:43:02,091 [INFO] Epoch 12/15 - Policy Loss: 1.4530, Value Loss: 0.2364, Total Loss: 1.6895, LR: 0.000064
2025-05-12 05:43:34,585 [INFO] Epoch 13/15 - Policy Loss: 1.4500, Value Loss: 0.2358, Total Loss: 1.6857, LR: 0.001686
2025-05-12 05:44:08,531 [INFO] Epoch 14/15 - Policy Loss: 1.4475, Value Loss: 0.2354, Total Loss: 1.6829, LR: 0.003336
2025-05-12 05:44:40,957 [INFO] Epoch 15/15 - Policy Loss: 1.4466, Value Loss: 0.2351, Total Loss: 1.6816, LR: 0.004986
2025-05-12 05:44:40,976 [INFO] 训练完成，总损失: 1.6816
2025-05-12 05:44:40,977 [INFO] 保存迭代 28 的模型
2025-05-12 05:44:41,941 [INFO] Model saved to ./models/best.pt
2025-05-12 05:44:42,607 [INFO] Model saved to ./models/iteration_28.pt
2025-05-12 05:44:42,607 [INFO] 所有训练迭代完成
2025-05-12 05:44:42,607 [INFO] 开始迭代 29/300
2025-05-12 05:44:42,607 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 05:55:46,250 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 05:55:46,251 [INFO] 保存训练样本
2025-05-12 05:55:50,465 [INFO] 使用 123168 个样本训练神经网络
2025-05-12 05:55:50,465 [INFO] Training with 123168 examples
2025-05-12 05:55:50,466 [INFO] 总训练步数: 1800, 每轮次批次数: 120
2025-05-12 05:55:50,515 [INFO] 循环学习率周期大小: 360 步
2025-05-12 05:56:22,903 [INFO] Epoch 1/15 - Policy Loss: 1.4579, Value Loss: 0.2509, Total Loss: 1.7088, LR: 0.001686
2025-05-12 05:56:55,002 [INFO] Epoch 2/15 - Policy Loss: 1.4444, Value Loss: 0.2460, Total Loss: 1.6904, LR: 0.003336
2025-05-12 05:57:27,190 [INFO] Epoch 3/15 - Policy Loss: 1.4400, Value Loss: 0.2437, Total Loss: 1.6837, LR: 0.004986
2025-05-12 05:58:01,864 [INFO] Epoch 4/15 - Policy Loss: 1.4397, Value Loss: 0.2430, Total Loss: 1.6828, LR: 0.003364
2025-05-12 05:58:33,959 [INFO] Epoch 5/15 - Policy Loss: 1.4361, Value Loss: 0.2421, Total Loss: 1.6781, LR: 0.001714
2025-05-12 05:59:06,430 [INFO] Epoch 6/15 - Policy Loss: 1.4301, Value Loss: 0.2408, Total Loss: 1.6709, LR: 0.000064
2025-05-12 05:59:38,392 [INFO] Epoch 7/15 - Policy Loss: 1.4260, Value Loss: 0.2394, Total Loss: 1.6654, LR: 0.001686
2025-05-12 06:00:10,373 [INFO] Epoch 8/15 - Policy Loss: 1.4218, Value Loss: 0.2383, Total Loss: 1.6601, LR: 0.003336
2025-05-12 06:00:42,553 [INFO] Epoch 9/15 - Policy Loss: 1.4204, Value Loss: 0.2379, Total Loss: 1.6583, LR: 0.004986
2025-05-12 06:01:16,402 [INFO] Epoch 10/15 - Policy Loss: 1.4208, Value Loss: 0.2378, Total Loss: 1.6586, LR: 0.003364
2025-05-12 06:01:48,524 [INFO] Epoch 11/15 - Policy Loss: 1.4195, Value Loss: 0.2376, Total Loss: 1.6570, LR: 0.001714
2025-05-12 06:02:22,005 [INFO] Epoch 12/15 - Policy Loss: 1.4170, Value Loss: 0.2372, Total Loss: 1.6542, LR: 0.000064
2025-05-12 06:02:54,285 [INFO] Epoch 13/15 - Policy Loss: 1.4150, Value Loss: 0.2367, Total Loss: 1.6517, LR: 0.001686
2025-05-12 06:03:26,442 [INFO] Epoch 14/15 - Policy Loss: 1.4131, Value Loss: 0.2363, Total Loss: 1.6495, LR: 0.003336
2025-05-12 06:03:58,813 [INFO] Epoch 15/15 - Policy Loss: 1.4122, Value Loss: 0.2361, Total Loss: 1.6483, LR: 0.004986
2025-05-12 06:03:58,869 [INFO] 训练完成，总损失: 1.6483
2025-05-12 06:03:58,870 [INFO] 保存迭代 29 的模型
2025-05-12 06:04:00,758 [INFO] Model saved to ./models/best.pt
2025-05-12 06:04:01,900 [INFO] Model saved to ./models/iteration_29.pt
2025-05-12 06:04:01,900 [INFO] 所有训练迭代完成
2025-05-12 06:04:01,901 [INFO] 开始迭代 30/300
2025-05-12 06:04:01,901 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 06:17:09,475 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 06:17:09,476 [INFO] 保存训练样本
2025-05-12 06:17:13,520 [INFO] 使用 123352 个样本训练神经网络
2025-05-12 06:17:13,520 [INFO] Training with 123352 examples
2025-05-12 06:17:13,522 [INFO] 总训练步数: 1800, 每轮次批次数: 120
2025-05-12 06:17:14,016 [INFO] 循环学习率周期大小: 360 步
2025-05-12 06:17:46,021 [INFO] Epoch 1/15 - Policy Loss: 1.4572, Value Loss: 0.2628, Total Loss: 1.7201, LR: 0.001686
2025-05-12 06:18:19,734 [INFO] Epoch 2/15 - Policy Loss: 1.4384, Value Loss: 0.2570, Total Loss: 1.6954, LR: 0.003336
2025-05-12 06:18:53,903 [INFO] Epoch 3/15 - Policy Loss: 1.4311, Value Loss: 0.2549, Total Loss: 1.6860, LR: 0.004986
2025-05-12 06:19:25,883 [INFO] Epoch 4/15 - Policy Loss: 1.4273, Value Loss: 0.2536, Total Loss: 1.6809, LR: 0.003364
2025-05-12 06:19:58,397 [INFO] Epoch 5/15 - Policy Loss: 1.4207, Value Loss: 0.2518, Total Loss: 1.6725, LR: 0.001714
2025-05-12 06:20:33,079 [INFO] Epoch 6/15 - Policy Loss: 1.4137, Value Loss: 0.2508, Total Loss: 1.6645, LR: 0.000064
2025-05-12 06:21:05,267 [INFO] Epoch 7/15 - Policy Loss: 1.4075, Value Loss: 0.2494, Total Loss: 1.6569, LR: 0.001686
2025-05-12 06:21:37,893 [INFO] Epoch 8/15 - Policy Loss: 1.4021, Value Loss: 0.2480, Total Loss: 1.6502, LR: 0.003336
2025-05-12 06:22:11,379 [INFO] Epoch 9/15 - Policy Loss: 1.3995, Value Loss: 0.2469, Total Loss: 1.6465, LR: 0.004986
2025-05-12 06:22:43,811 [INFO] Epoch 10/15 - Policy Loss: 1.3983, Value Loss: 0.2464, Total Loss: 1.6447, LR: 0.003364
2025-05-12 06:23:16,236 [INFO] Epoch 11/15 - Policy Loss: 1.3964, Value Loss: 0.2456, Total Loss: 1.6420, LR: 0.001714
2025-05-12 06:23:48,480 [INFO] Epoch 12/15 - Policy Loss: 1.3935, Value Loss: 0.2451, Total Loss: 1.6386, LR: 0.000064
2025-05-12 06:24:20,541 [INFO] Epoch 13/15 - Policy Loss: 1.3905, Value Loss: 0.2446, Total Loss: 1.6351, LR: 0.001686
2025-05-12 06:24:52,863 [INFO] Epoch 14/15 - Policy Loss: 1.3883, Value Loss: 0.2442, Total Loss: 1.6325, LR: 0.003336
2025-05-12 06:25:27,794 [INFO] Epoch 15/15 - Policy Loss: 1.3872, Value Loss: 0.2438, Total Loss: 1.6310, LR: 0.004986
2025-05-12 06:25:27,857 [INFO] 训练完成，总损失: 1.6310
2025-05-12 06:25:27,858 [INFO] 保存迭代 30 的模型
2025-05-12 06:25:29,747 [INFO] Model saved to ./models/best.pt
2025-05-12 06:25:30,967 [INFO] Model saved to ./models/iteration_30.pt
2025-05-12 06:25:30,967 [INFO] 所有训练迭代完成
2025-05-12 06:25:30,967 [INFO] 开始迭代 31/300
2025-05-12 06:25:30,968 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 06:37:01,505 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 06:37:01,506 [INFO] 保存训练样本
2025-05-12 06:37:05,353 [INFO] 使用 122904 个样本训练神经网络
2025-05-12 06:37:05,353 [INFO] Training with 122904 examples
2025-05-12 06:37:05,354 [INFO] 总训练步数: 1800, 每轮次批次数: 120
2025-05-12 06:37:05,799 [INFO] 循环学习率周期大小: 360 步
2025-05-12 06:37:37,980 [INFO] Epoch 1/15 - Policy Loss: 1.4020, Value Loss: 0.2667, Total Loss: 1.6687, LR: 0.001686
2025-05-12 06:38:10,277 [INFO] Epoch 2/15 - Policy Loss: 1.3901, Value Loss: 0.2610, Total Loss: 1.6512, LR: 0.003336
2025-05-12 06:38:42,238 [INFO] Epoch 3/15 - Policy Loss: 1.3865, Value Loss: 0.2583, Total Loss: 1.6448, LR: 0.004986
2025-05-12 06:39:16,165 [INFO] Epoch 4/15 - Policy Loss: 1.3878, Value Loss: 0.2579, Total Loss: 1.6457, LR: 0.003364
2025-05-12 06:39:48,126 [INFO] Epoch 5/15 - Policy Loss: 1.3821, Value Loss: 0.2561, Total Loss: 1.6382, LR: 0.001714
2025-05-12 06:40:21,042 [INFO] Epoch 6/15 - Policy Loss: 1.3782, Value Loss: 0.2542, Total Loss: 1.6323, LR: 0.000064
2025-05-12 06:40:53,259 [INFO] Epoch 7/15 - Policy Loss: 1.3729, Value Loss: 0.2532, Total Loss: 1.6260, LR: 0.001686
2025-05-12 06:41:25,508 [INFO] Epoch 8/15 - Policy Loss: 1.3696, Value Loss: 0.2525, Total Loss: 1.6221, LR: 0.003336
2025-05-12 06:41:59,449 [INFO] Epoch 9/15 - Policy Loss: 1.3684, Value Loss: 0.2523, Total Loss: 1.6207, LR: 0.004986
2025-05-12 06:42:31,529 [INFO] Epoch 10/15 - Policy Loss: 1.3683, Value Loss: 0.2521, Total Loss: 1.6203, LR: 0.003364
2025-05-12 06:43:06,863 [INFO] Epoch 11/15 - Policy Loss: 1.3673, Value Loss: 0.2517, Total Loss: 1.6190, LR: 0.001714
2025-05-12 06:43:38,896 [INFO] Epoch 12/15 - Policy Loss: 1.3654, Value Loss: 0.2510, Total Loss: 1.6165, LR: 0.000064
2025-05-12 06:44:12,248 [INFO] Epoch 13/15 - Policy Loss: 1.3633, Value Loss: 0.2506, Total Loss: 1.6139, LR: 0.001686
2025-05-12 06:44:45,979 [INFO] Epoch 14/15 - Policy Loss: 1.3614, Value Loss: 0.2503, Total Loss: 1.6116, LR: 0.003336
2025-05-12 06:45:18,077 [INFO] Epoch 15/15 - Policy Loss: 1.3604, Value Loss: 0.2498, Total Loss: 1.6102, LR: 0.004986
2025-05-12 06:45:18,098 [INFO] 训练完成，总损失: 1.6102
2025-05-12 06:45:18,098 [INFO] 保存迭代 31 的模型
2025-05-12 06:45:19,269 [INFO] Model saved to ./models/best.pt
2025-05-12 06:45:19,908 [INFO] Model saved to ./models/iteration_31.pt
2025-05-12 06:45:19,908 [INFO] 所有训练迭代完成
2025-05-12 06:45:19,908 [INFO] 开始迭代 32/300
2025-05-12 06:45:19,908 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 06:55:45,523 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 06:55:45,524 [INFO] 保存训练样本
2025-05-12 06:55:49,139 [INFO] 使用 122296 个样本训练神经网络
2025-05-12 06:55:49,139 [INFO] Training with 122296 examples
2025-05-12 06:55:49,140 [INFO] 总训练步数: 1785, 每轮次批次数: 119
2025-05-12 06:55:49,499 [INFO] 循环学习率周期大小: 357 步
2025-05-12 06:56:21,023 [INFO] Epoch 1/15 - Policy Loss: 1.3748, Value Loss: 0.2710, Total Loss: 1.6457, LR: 0.001686
2025-05-12 06:56:53,517 [INFO] Epoch 2/15 - Policy Loss: 1.3676, Value Loss: 0.2677, Total Loss: 1.6353, LR: 0.003336
2025-05-12 06:57:25,274 [INFO] Epoch 3/15 - Policy Loss: 1.3629, Value Loss: 0.2636, Total Loss: 1.6265, LR: 0.004986
2025-05-12 06:57:56,902 [INFO] Epoch 4/15 - Policy Loss: 1.3647, Value Loss: 0.2624, Total Loss: 1.6271, LR: 0.003364
2025-05-12 06:58:29,685 [INFO] Epoch 5/15 - Policy Loss: 1.3602, Value Loss: 0.2604, Total Loss: 1.6206, LR: 0.001714
2025-05-12 06:59:02,408 [INFO] Epoch 6/15 - Policy Loss: 1.3555, Value Loss: 0.2590, Total Loss: 1.6145, LR: 0.000064
2025-05-12 06:59:34,221 [INFO] Epoch 7/15 - Policy Loss: 1.3519, Value Loss: 0.2577, Total Loss: 1.6096, LR: 0.001686
2025-05-12 07:00:07,067 [INFO] Epoch 8/15 - Policy Loss: 1.3482, Value Loss: 0.2567, Total Loss: 1.6049, LR: 0.003336
2025-05-12 07:00:38,778 [INFO] Epoch 9/15 - Policy Loss: 1.3471, Value Loss: 0.2557, Total Loss: 1.6028, LR: 0.004986
2025-05-12 07:01:13,551 [INFO] Epoch 10/15 - Policy Loss: 1.3475, Value Loss: 0.2556, Total Loss: 1.6030, LR: 0.003364
2025-05-12 07:01:45,381 [INFO] Epoch 11/15 - Policy Loss: 1.3465, Value Loss: 0.2550, Total Loss: 1.6015, LR: 0.001714
2025-05-12 07:02:17,681 [INFO] Epoch 12/15 - Policy Loss: 1.3448, Value Loss: 0.2543, Total Loss: 1.5990, LR: 0.000064
2025-05-12 07:02:49,719 [INFO] Epoch 13/15 - Policy Loss: 1.3428, Value Loss: 0.2539, Total Loss: 1.5967, LR: 0.001686
2025-05-12 07:03:21,588 [INFO] Epoch 14/15 - Policy Loss: 1.3414, Value Loss: 0.2534, Total Loss: 1.5948, LR: 0.003336
2025-05-12 07:03:54,185 [INFO] Epoch 15/15 - Policy Loss: 1.3402, Value Loss: 0.2532, Total Loss: 1.5935, LR: 0.004986
2025-05-12 07:03:54,243 [INFO] 训练完成，总损失: 1.5935
2025-05-12 07:03:54,244 [INFO] 保存迭代 32 的模型
2025-05-12 07:03:57,388 [INFO] Model saved to ./models/best.pt
2025-05-12 07:03:58,956 [INFO] Model saved to ./models/iteration_32.pt
2025-05-12 07:03:58,957 [INFO] 所有训练迭代完成
2025-05-12 07:03:58,957 [INFO] 开始迭代 33/300
2025-05-12 07:03:58,957 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 07:14:53,470 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 07:14:53,471 [INFO] 保存训练样本
2025-05-12 07:14:57,482 [INFO] 使用 122856 个样本训练神经网络
2025-05-12 07:14:57,483 [INFO] Training with 122856 examples
2025-05-12 07:14:57,483 [INFO] 总训练步数: 1785, 每轮次批次数: 119
2025-05-12 07:14:57,531 [INFO] 循环学习率周期大小: 357 步
2025-05-12 07:15:29,107 [INFO] Epoch 1/15 - Policy Loss: 1.3622, Value Loss: 0.2631, Total Loss: 1.6253, LR: 0.001686
2025-05-12 07:16:02,049 [INFO] Epoch 2/15 - Policy Loss: 1.3524, Value Loss: 0.2615, Total Loss: 1.6139, LR: 0.003336
2025-05-12 07:16:35,172 [INFO] Epoch 3/15 - Policy Loss: 1.3495, Value Loss: 0.2611, Total Loss: 1.6105, LR: 0.004986
2025-05-12 07:17:06,948 [INFO] Epoch 4/15 - Policy Loss: 1.3492, Value Loss: 0.2605, Total Loss: 1.6097, LR: 0.003364
2025-05-12 07:17:40,457 [INFO] Epoch 5/15 - Policy Loss: 1.3453, Value Loss: 0.2591, Total Loss: 1.6044, LR: 0.001714
2025-05-12 07:18:13,156 [INFO] Epoch 6/15 - Policy Loss: 1.3418, Value Loss: 0.2588, Total Loss: 1.6005, LR: 0.000064
2025-05-12 07:18:45,482 [INFO] Epoch 7/15 - Policy Loss: 1.3369, Value Loss: 0.2579, Total Loss: 1.5947, LR: 0.001686
2025-05-12 07:19:17,488 [INFO] Epoch 8/15 - Policy Loss: 1.3338, Value Loss: 0.2575, Total Loss: 1.5913, LR: 0.003336
2025-05-12 07:19:49,416 [INFO] Epoch 9/15 - Policy Loss: 1.3329, Value Loss: 0.2569, Total Loss: 1.5898, LR: 0.004986
2025-05-12 07:20:24,074 [INFO] Epoch 10/15 - Policy Loss: 1.3332, Value Loss: 0.2567, Total Loss: 1.5899, LR: 0.003364
2025-05-12 07:20:55,948 [INFO] Epoch 11/15 - Policy Loss: 1.3318, Value Loss: 0.2565, Total Loss: 1.5883, LR: 0.001714
2025-05-12 07:21:28,739 [INFO] Epoch 12/15 - Policy Loss: 1.3296, Value Loss: 0.2562, Total Loss: 1.5858, LR: 0.000064
2025-05-12 07:22:00,758 [INFO] Epoch 13/15 - Policy Loss: 1.3273, Value Loss: 0.2558, Total Loss: 1.5831, LR: 0.001686
2025-05-12 07:22:32,752 [INFO] Epoch 14/15 - Policy Loss: 1.3254, Value Loss: 0.2553, Total Loss: 1.5807, LR: 0.003336
2025-05-12 07:23:07,170 [INFO] Epoch 15/15 - Policy Loss: 1.3246, Value Loss: 0.2550, Total Loss: 1.5796, LR: 0.004986
2025-05-12 07:23:07,206 [INFO] 训练完成，总损失: 1.5796
2025-05-12 07:23:07,207 [INFO] 保存迭代 33 的模型
2025-05-12 07:23:08,539 [INFO] Model saved to ./models/best.pt
2025-05-12 07:23:09,381 [INFO] Model saved to ./models/iteration_33.pt
2025-05-12 07:23:09,382 [INFO] 所有训练迭代完成
2025-05-12 07:23:09,382 [INFO] 开始迭代 34/300
2025-05-12 07:23:09,382 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 07:34:39,375 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 07:34:39,375 [INFO] 保存训练样本
2025-05-12 07:34:42,860 [INFO] 使用 122640 个样本训练神经网络
2025-05-12 07:34:42,860 [INFO] Training with 122640 examples
2025-05-12 07:34:42,861 [INFO] 总训练步数: 1785, 每轮次批次数: 119
2025-05-12 07:34:42,907 [INFO] 循环学习率周期大小: 357 步
2025-05-12 07:35:16,066 [INFO] Epoch 1/15 - Policy Loss: 1.3581, Value Loss: 0.2690, Total Loss: 1.6271, LR: 0.001686
2025-05-12 07:35:48,169 [INFO] Epoch 2/15 - Policy Loss: 1.3428, Value Loss: 0.2635, Total Loss: 1.6063, LR: 0.003336
2025-05-12 07:36:20,997 [INFO] Epoch 3/15 - Policy Loss: 1.3401, Value Loss: 0.2616, Total Loss: 1.6017, LR: 0.004986
2025-05-12 07:36:52,722 [INFO] Epoch 4/15 - Policy Loss: 1.3393, Value Loss: 0.2611, Total Loss: 1.6004, LR: 0.003364
2025-05-12 07:37:26,698 [INFO] Epoch 5/15 - Policy Loss: 1.3351, Value Loss: 0.2598, Total Loss: 1.5949, LR: 0.001714
2025-05-12 07:37:58,650 [INFO] Epoch 6/15 - Policy Loss: 1.3298, Value Loss: 0.2584, Total Loss: 1.5882, LR: 0.000064
2025-05-12 07:38:31,121 [INFO] Epoch 7/15 - Policy Loss: 1.3255, Value Loss: 0.2572, Total Loss: 1.5827, LR: 0.001686
2025-05-12 07:39:04,303 [INFO] Epoch 8/15 - Policy Loss: 1.3218, Value Loss: 0.2563, Total Loss: 1.5780, LR: 0.003336
2025-05-12 07:39:36,017 [INFO] Epoch 9/15 - Policy Loss: 1.3203, Value Loss: 0.2557, Total Loss: 1.5760, LR: 0.004986
2025-05-12 07:40:07,855 [INFO] Epoch 10/15 - Policy Loss: 1.3198, Value Loss: 0.2555, Total Loss: 1.5752, LR: 0.003364
2025-05-12 07:40:41,768 [INFO] Epoch 11/15 - Policy Loss: 1.3180, Value Loss: 0.2548, Total Loss: 1.5728, LR: 0.001714
2025-05-12 07:41:13,871 [INFO] Epoch 12/15 - Policy Loss: 1.3157, Value Loss: 0.2544, Total Loss: 1.5700, LR: 0.000064
2025-05-12 07:41:46,400 [INFO] Epoch 13/15 - Policy Loss: 1.3132, Value Loss: 0.2539, Total Loss: 1.5671, LR: 0.001686
2025-05-12 07:42:18,430 [INFO] Epoch 14/15 - Policy Loss: 1.3116, Value Loss: 0.2535, Total Loss: 1.5651, LR: 0.003336
2025-05-12 07:42:50,490 [INFO] Epoch 15/15 - Policy Loss: 1.3112, Value Loss: 0.2533, Total Loss: 1.5645, LR: 0.004986
2025-05-12 07:42:50,511 [INFO] 训练完成，总损失: 1.5645
2025-05-12 07:42:50,511 [INFO] 保存迭代 34 的模型
2025-05-12 07:42:51,793 [INFO] Model saved to ./models/best.pt
2025-05-12 07:42:52,642 [INFO] Model saved to ./models/iteration_34.pt
2025-05-12 07:42:52,642 [INFO] 所有训练迭代完成
2025-05-12 07:42:52,642 [INFO] 开始迭代 35/300
2025-05-12 07:42:52,642 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 07:53:34,687 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 07:53:34,688 [INFO] 保存训练样本
2025-05-12 07:53:38,669 [INFO] 使用 121320 个样本训练神经网络
2025-05-12 07:53:38,669 [INFO] Training with 121320 examples
2025-05-12 07:53:38,670 [INFO] 总训练步数: 1770, 每轮次批次数: 118
2025-05-12 07:53:39,206 [INFO] 循环学习率周期大小: 354 步
2025-05-12 07:54:11,256 [INFO] Epoch 1/15 - Policy Loss: 1.3284, Value Loss: 0.2642, Total Loss: 1.5926, LR: 0.001686
2025-05-12 07:54:42,918 [INFO] Epoch 2/15 - Policy Loss: 1.3158, Value Loss: 0.2614, Total Loss: 1.5772, LR: 0.003336
2025-05-12 07:55:15,877 [INFO] Epoch 3/15 - Policy Loss: 1.3131, Value Loss: 0.2587, Total Loss: 1.5717, LR: 0.004986
2025-05-12 07:55:47,253 [INFO] Epoch 4/15 - Policy Loss: 1.3094, Value Loss: 0.2569, Total Loss: 1.5663, LR: 0.003364
2025-05-12 07:56:19,390 [INFO] Epoch 5/15 - Policy Loss: 1.3055, Value Loss: 0.2554, Total Loss: 1.5609, LR: 0.001714
2025-05-12 07:56:51,637 [INFO] Epoch 6/15 - Policy Loss: 1.3010, Value Loss: 0.2541, Total Loss: 1.5550, LR: 0.000064
2025-05-12 07:57:23,422 [INFO] Epoch 7/15 - Policy Loss: 1.2966, Value Loss: 0.2532, Total Loss: 1.5498, LR: 0.001686
2025-05-12 07:57:56,482 [INFO] Epoch 8/15 - Policy Loss: 1.2930, Value Loss: 0.2523, Total Loss: 1.5453, LR: 0.003336
2025-05-12 07:58:28,032 [INFO] Epoch 9/15 - Policy Loss: 1.2920, Value Loss: 0.2521, Total Loss: 1.5441, LR: 0.004986
2025-05-12 07:59:01,048 [INFO] Epoch 10/15 - Policy Loss: 1.2924, Value Loss: 0.2517, Total Loss: 1.5441, LR: 0.003364
2025-05-12 07:59:32,817 [INFO] Epoch 11/15 - Policy Loss: 1.2918, Value Loss: 0.2512, Total Loss: 1.5430, LR: 0.001714
2025-05-12 08:00:05,154 [INFO] Epoch 12/15 - Policy Loss: 1.2901, Value Loss: 0.2508, Total Loss: 1.5409, LR: 0.000064
2025-05-12 08:00:36,736 [INFO] Epoch 13/15 - Policy Loss: 1.2880, Value Loss: 0.2501, Total Loss: 1.5381, LR: 0.001686
2025-05-12 08:01:10,635 [INFO] Epoch 14/15 - Policy Loss: 1.2859, Value Loss: 0.2497, Total Loss: 1.5355, LR: 0.003336
2025-05-12 08:01:42,589 [INFO] Epoch 15/15 - Policy Loss: 1.2856, Value Loss: 0.2494, Total Loss: 1.5349, LR: 0.004986
2025-05-12 08:01:42,607 [INFO] 训练完成，总损失: 1.5349
2025-05-12 08:01:42,607 [INFO] 保存迭代 35 的模型
2025-05-12 08:01:43,616 [INFO] Model saved to ./models/best.pt
2025-05-12 08:01:44,275 [INFO] Model saved to ./models/iteration_35.pt
2025-05-12 08:01:44,276 [INFO] 所有训练迭代完成
2025-05-12 08:01:44,276 [INFO] 开始迭代 36/300
2025-05-12 08:01:44,276 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 08:11:36,894 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 08:11:36,894 [INFO] 保存训练样本
2025-05-12 08:11:40,667 [INFO] 使用 120416 个样本训练神经网络
2025-05-12 08:11:40,668 [INFO] Training with 120416 examples
2025-05-12 08:11:40,668 [INFO] 总训练步数: 1755, 每轮次批次数: 117
2025-05-12 08:11:41,158 [INFO] 循环学习率周期大小: 351 步
2025-05-12 08:12:12,093 [INFO] Epoch 1/15 - Policy Loss: 1.2916, Value Loss: 0.2563, Total Loss: 1.5479, LR: 0.001686
2025-05-12 08:12:43,320 [INFO] Epoch 2/15 - Policy Loss: 1.2816, Value Loss: 0.2521, Total Loss: 1.5337, LR: 0.003336
2025-05-12 08:13:14,473 [INFO] Epoch 3/15 - Policy Loss: 1.2814, Value Loss: 0.2523, Total Loss: 1.5336, LR: 0.004986
2025-05-12 08:13:46,448 [INFO] Epoch 4/15 - Policy Loss: 1.2812, Value Loss: 0.2521, Total Loss: 1.5333, LR: 0.003364
2025-05-12 08:14:18,897 [INFO] Epoch 5/15 - Policy Loss: 1.2783, Value Loss: 0.2506, Total Loss: 1.5289, LR: 0.001714
2025-05-12 08:14:50,200 [INFO] Epoch 6/15 - Policy Loss: 1.2742, Value Loss: 0.2497, Total Loss: 1.5239, LR: 0.000064
2025-05-12 08:15:22,587 [INFO] Epoch 7/15 - Policy Loss: 1.2700, Value Loss: 0.2490, Total Loss: 1.5190, LR: 0.001686
2025-05-12 08:15:55,690 [INFO] Epoch 8/15 - Policy Loss: 1.2680, Value Loss: 0.2481, Total Loss: 1.5161, LR: 0.003336
2025-05-12 08:16:27,653 [INFO] Epoch 9/15 - Policy Loss: 1.2674, Value Loss: 0.2477, Total Loss: 1.5151, LR: 0.004986
2025-05-12 08:16:59,467 [INFO] Epoch 10/15 - Policy Loss: 1.2683, Value Loss: 0.2475, Total Loss: 1.5158, LR: 0.003364
2025-05-12 08:17:30,782 [INFO] Epoch 11/15 - Policy Loss: 1.2681, Value Loss: 0.2472, Total Loss: 1.5153, LR: 0.001714
2025-05-12 08:18:03,033 [INFO] Epoch 12/15 - Policy Loss: 1.2670, Value Loss: 0.2470, Total Loss: 1.5140, LR: 0.000064
2025-05-12 08:18:34,388 [INFO] Epoch 13/15 - Policy Loss: 1.2655, Value Loss: 0.2469, Total Loss: 1.5125, LR: 0.001686
2025-05-12 08:19:07,211 [INFO] Epoch 14/15 - Policy Loss: 1.2643, Value Loss: 0.2463, Total Loss: 1.5106, LR: 0.003336
2025-05-12 08:19:38,723 [INFO] Epoch 15/15 - Policy Loss: 1.2640, Value Loss: 0.2461, Total Loss: 1.5101, LR: 0.004986
2025-05-12 08:19:38,744 [INFO] 训练完成，总损失: 1.5101
2025-05-12 08:19:38,744 [INFO] 保存迭代 36 的模型
2025-05-12 08:19:39,984 [INFO] Model saved to ./models/best.pt
2025-05-12 08:19:40,902 [INFO] Model saved to ./models/iteration_36.pt
2025-05-12 08:19:40,903 [INFO] 所有训练迭代完成
2025-05-12 08:19:40,903 [INFO] 开始迭代 37/300
2025-05-12 08:19:40,903 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 08:30:31,794 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 08:30:31,795 [INFO] 保存训练样本
2025-05-12 08:30:35,652 [INFO] 使用 120064 个样本训练神经网络
2025-05-12 08:30:35,653 [INFO] Training with 120064 examples
2025-05-12 08:30:35,653 [INFO] 总训练步数: 1755, 每轮次批次数: 117
2025-05-12 08:30:36,091 [INFO] 循环学习率周期大小: 351 步
2025-05-12 08:31:08,844 [INFO] Epoch 1/15 - Policy Loss: 1.2925, Value Loss: 0.2654, Total Loss: 1.5579, LR: 0.001686
2025-05-12 08:31:40,117 [INFO] Epoch 2/15 - Policy Loss: 1.2832, Value Loss: 0.2613, Total Loss: 1.5445, LR: 0.003336
2025-05-12 08:32:13,165 [INFO] Epoch 3/15 - Policy Loss: 1.2788, Value Loss: 0.2593, Total Loss: 1.5381, LR: 0.004986
2025-05-12 08:32:44,394 [INFO] Epoch 4/15 - Policy Loss: 1.2784, Value Loss: 0.2577, Total Loss: 1.5361, LR: 0.003364
2025-05-12 08:33:15,670 [INFO] Epoch 5/15 - Policy Loss: 1.2748, Value Loss: 0.2565, Total Loss: 1.5314, LR: 0.001714
2025-05-12 08:33:48,154 [INFO] Epoch 6/15 - Policy Loss: 1.2696, Value Loss: 0.2551, Total Loss: 1.5247, LR: 0.000064
2025-05-12 08:34:21,516 [INFO] Epoch 7/15 - Policy Loss: 1.2660, Value Loss: 0.2543, Total Loss: 1.5203, LR: 0.001686
2025-05-12 08:34:52,912 [INFO] Epoch 8/15 - Policy Loss: 1.2634, Value Loss: 0.2533, Total Loss: 1.5167, LR: 0.003336
2025-05-12 08:35:24,211 [INFO] Epoch 9/15 - Policy Loss: 1.2622, Value Loss: 0.2527, Total Loss: 1.5150, LR: 0.004986
2025-05-12 08:35:55,505 [INFO] Epoch 10/15 - Policy Loss: 1.2618, Value Loss: 0.2525, Total Loss: 1.5143, LR: 0.003364
2025-05-12 08:36:26,926 [INFO] Epoch 11/15 - Policy Loss: 1.2607, Value Loss: 0.2519, Total Loss: 1.5126, LR: 0.001714
2025-05-12 08:37:00,800 [INFO] Epoch 12/15 - Policy Loss: 1.2589, Value Loss: 0.2516, Total Loss: 1.5105, LR: 0.000064
2025-05-12 08:37:32,259 [INFO] Epoch 13/15 - Policy Loss: 1.2566, Value Loss: 0.2512, Total Loss: 1.5078, LR: 0.001686
2025-05-12 08:38:04,610 [INFO] Epoch 14/15 - Policy Loss: 1.2550, Value Loss: 0.2506, Total Loss: 1.5056, LR: 0.003336
2025-05-12 08:38:36,923 [INFO] Epoch 15/15 - Policy Loss: 1.2546, Value Loss: 0.2504, Total Loss: 1.5050, LR: 0.004986
2025-05-12 08:38:36,943 [INFO] 训练完成，总损失: 1.5050
2025-05-12 08:38:36,943 [INFO] 保存迭代 37 的模型
2025-05-12 08:38:38,183 [INFO] Model saved to ./models/best.pt
2025-05-12 08:38:38,837 [INFO] Model saved to ./models/iteration_37.pt
2025-05-12 08:38:38,837 [INFO] 所有训练迭代完成
2025-05-12 08:38:38,837 [INFO] 开始迭代 38/300
2025-05-12 08:38:38,837 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 08:50:39,835 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 08:50:39,836 [INFO] 保存训练样本
2025-05-12 08:50:45,265 [INFO] 使用 120296 个样本训练神经网络
2025-05-12 08:50:45,266 [INFO] Training with 120296 examples
2025-05-12 08:50:45,267 [INFO] 总训练步数: 1755, 每轮次批次数: 117
2025-05-12 08:50:46,047 [INFO] 循环学习率周期大小: 351 步
2025-05-12 08:51:17,461 [INFO] Epoch 1/15 - Policy Loss: 1.2953, Value Loss: 0.2626, Total Loss: 1.5580, LR: 0.001686
2025-05-12 08:51:50,152 [INFO] Epoch 2/15 - Policy Loss: 1.2818, Value Loss: 0.2573, Total Loss: 1.5391, LR: 0.003336
2025-05-12 08:52:21,204 [INFO] Epoch 3/15 - Policy Loss: 1.2747, Value Loss: 0.2548, Total Loss: 1.5295, LR: 0.004986
2025-05-12 08:52:53,463 [INFO] Epoch 4/15 - Policy Loss: 1.2735, Value Loss: 0.2533, Total Loss: 1.5268, LR: 0.003364
2025-05-12 08:53:25,061 [INFO] Epoch 5/15 - Policy Loss: 1.2683, Value Loss: 0.2517, Total Loss: 1.5200, LR: 0.001714
2025-05-12 08:53:56,619 [INFO] Epoch 6/15 - Policy Loss: 1.2630, Value Loss: 0.2503, Total Loss: 1.5133, LR: 0.000064
2025-05-12 08:54:27,897 [INFO] Epoch 7/15 - Policy Loss: 1.2581, Value Loss: 0.2498, Total Loss: 1.5079, LR: 0.001686
2025-05-12 08:54:59,143 [INFO] Epoch 8/15 - Policy Loss: 1.2551, Value Loss: 0.2487, Total Loss: 1.5039, LR: 0.003336
2025-05-12 08:55:31,140 [INFO] Epoch 9/15 - Policy Loss: 1.2538, Value Loss: 0.2484, Total Loss: 1.5022, LR: 0.004986
2025-05-12 08:56:03,897 [INFO] Epoch 10/15 - Policy Loss: 1.2536, Value Loss: 0.2480, Total Loss: 1.5017, LR: 0.003364
2025-05-12 08:56:35,261 [INFO] Epoch 11/15 - Policy Loss: 1.2513, Value Loss: 0.2473, Total Loss: 1.4986, LR: 0.001714
2025-05-12 08:57:08,544 [INFO] Epoch 12/15 - Policy Loss: 1.2487, Value Loss: 0.2469, Total Loss: 1.4956, LR: 0.000064
2025-05-12 08:57:40,219 [INFO] Epoch 13/15 - Policy Loss: 1.2463, Value Loss: 0.2463, Total Loss: 1.4926, LR: 0.001686
2025-05-12 08:58:11,708 [INFO] Epoch 14/15 - Policy Loss: 1.2446, Value Loss: 0.2459, Total Loss: 1.4905, LR: 0.003336
2025-05-12 08:58:43,712 [INFO] Epoch 15/15 - Policy Loss: 1.2439, Value Loss: 0.2457, Total Loss: 1.4896, LR: 0.004986
2025-05-12 08:58:43,780 [INFO] 训练完成，总损失: 1.4896
2025-05-12 08:58:43,781 [INFO] 保存迭代 38 的模型
2025-05-12 08:58:46,581 [INFO] Model saved to ./models/best.pt
2025-05-12 08:58:47,737 [INFO] Model saved to ./models/iteration_38.pt
2025-05-12 08:58:47,738 [INFO] 所有训练迭代完成
2025-05-12 08:58:47,738 [INFO] 开始迭代 39/300
2025-05-12 08:58:47,738 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 09:09:56,536 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 09:09:56,537 [INFO] 保存训练样本
2025-05-12 09:10:00,003 [INFO] 使用 119496 个样本训练神经网络
2025-05-12 09:10:00,003 [INFO] Training with 119496 examples
2025-05-12 09:10:00,004 [INFO] 总训练步数: 1740, 每轮次批次数: 116
2025-05-12 09:10:00,460 [INFO] 循环学习率周期大小: 348 步
2025-05-12 09:10:32,052 [INFO] Epoch 1/15 - Policy Loss: 1.2659, Value Loss: 0.2638, Total Loss: 1.5297, LR: 0.001686
2025-05-12 09:11:05,852 [INFO] Epoch 2/15 - Policy Loss: 1.2535, Value Loss: 0.2591, Total Loss: 1.5126, LR: 0.003336
2025-05-12 09:11:36,633 [INFO] Epoch 3/15 - Policy Loss: 1.2514, Value Loss: 0.2566, Total Loss: 1.5080, LR: 0.004986
2025-05-12 09:12:07,499 [INFO] Epoch 4/15 - Policy Loss: 1.2500, Value Loss: 0.2546, Total Loss: 1.5046, LR: 0.003364
2025-05-12 09:12:40,661 [INFO] Epoch 5/15 - Policy Loss: 1.2469, Value Loss: 0.2531, Total Loss: 1.5001, LR: 0.001714
2025-05-12 09:13:12,011 [INFO] Epoch 6/15 - Policy Loss: 1.2429, Value Loss: 0.2514, Total Loss: 1.4944, LR: 0.000064
2025-05-12 09:13:44,691 [INFO] Epoch 7/15 - Policy Loss: 1.2387, Value Loss: 0.2500, Total Loss: 1.4887, LR: 0.001686
2025-05-12 09:14:15,821 [INFO] Epoch 8/15 - Policy Loss: 1.2351, Value Loss: 0.2489, Total Loss: 1.4840, LR: 0.003336
2025-05-12 09:14:47,190 [INFO] Epoch 9/15 - Policy Loss: 1.2340, Value Loss: 0.2481, Total Loss: 1.4820, LR: 0.004986
2025-05-12 09:15:18,864 [INFO] Epoch 10/15 - Policy Loss: 1.2347, Value Loss: 0.2477, Total Loss: 1.4824, LR: 0.003364
2025-05-12 09:15:51,483 [INFO] Epoch 11/15 - Policy Loss: 1.2331, Value Loss: 0.2469, Total Loss: 1.4800, LR: 0.001714
2025-05-12 09:16:22,507 [INFO] Epoch 12/15 - Policy Loss: 1.2315, Value Loss: 0.2462, Total Loss: 1.4777, LR: 0.000064
2025-05-12 09:16:53,497 [INFO] Epoch 13/15 - Policy Loss: 1.2295, Value Loss: 0.2457, Total Loss: 1.4752, LR: 0.001686
2025-05-12 09:17:26,679 [INFO] Epoch 14/15 - Policy Loss: 1.2276, Value Loss: 0.2450, Total Loss: 1.4726, LR: 0.003336
2025-05-12 09:17:58,192 [INFO] Epoch 15/15 - Policy Loss: 1.2263, Value Loss: 0.2445, Total Loss: 1.4707, LR: 0.004986
2025-05-12 09:17:58,225 [INFO] 训练完成，总损失: 1.4707
2025-05-12 09:17:58,225 [INFO] 保存迭代 39 的模型
2025-05-12 09:17:59,339 [INFO] Model saved to ./models/best.pt
2025-05-12 09:18:00,377 [INFO] Model saved to ./models/iteration_39.pt
2025-05-12 09:18:00,378 [INFO] 所有训练迭代完成
2025-05-12 09:18:00,378 [INFO] 开始迭代 40/300
2025-05-12 09:18:00,378 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 09:28:21,158 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 09:28:21,159 [INFO] 保存训练样本
2025-05-12 09:28:25,181 [INFO] 使用 119168 个样本训练神经网络
2025-05-12 09:28:25,181 [INFO] Training with 119168 examples
2025-05-12 09:28:25,182 [INFO] 总训练步数: 1740, 每轮次批次数: 116
2025-05-12 09:28:25,233 [INFO] 循环学习率周期大小: 348 步
2025-05-12 09:28:56,036 [INFO] Epoch 1/15 - Policy Loss: 1.2334, Value Loss: 0.2497, Total Loss: 1.4831, LR: 0.001686
2025-05-12 09:29:26,915 [INFO] Epoch 2/15 - Policy Loss: 1.2240, Value Loss: 0.2463, Total Loss: 1.4703, LR: 0.003336
2025-05-12 09:29:57,897 [INFO] Epoch 3/15 - Policy Loss: 1.2236, Value Loss: 0.2450, Total Loss: 1.4686, LR: 0.004986
2025-05-12 09:30:30,813 [INFO] Epoch 4/15 - Policy Loss: 1.2244, Value Loss: 0.2454, Total Loss: 1.4698, LR: 0.003364
2025-05-12 09:31:03,329 [INFO] Epoch 5/15 - Policy Loss: 1.2218, Value Loss: 0.2450, Total Loss: 1.4668, LR: 0.001714
2025-05-12 09:31:34,451 [INFO] Epoch 6/15 - Policy Loss: 1.2176, Value Loss: 0.2442, Total Loss: 1.4617, LR: 0.000064
2025-05-12 09:32:05,539 [INFO] Epoch 7/15 - Policy Loss: 1.2145, Value Loss: 0.2431, Total Loss: 1.4576, LR: 0.001686
2025-05-12 09:32:39,452 [INFO] Epoch 8/15 - Policy Loss: 1.2117, Value Loss: 0.2424, Total Loss: 1.4542, LR: 0.003336
2025-05-12 09:33:10,598 [INFO] Epoch 9/15 - Policy Loss: 1.2112, Value Loss: 0.2421, Total Loss: 1.4533, LR: 0.004986
2025-05-12 09:33:41,804 [INFO] Epoch 10/15 - Policy Loss: 1.2115, Value Loss: 0.2420, Total Loss: 1.4535, LR: 0.003364
2025-05-12 09:34:14,658 [INFO] Epoch 11/15 - Policy Loss: 1.2107, Value Loss: 0.2417, Total Loss: 1.4524, LR: 0.001714
2025-05-12 09:34:45,811 [INFO] Epoch 12/15 - Policy Loss: 1.2090, Value Loss: 0.2412, Total Loss: 1.4502, LR: 0.000064
2025-05-12 09:35:18,126 [INFO] Epoch 13/15 - Policy Loss: 1.2075, Value Loss: 0.2407, Total Loss: 1.4482, LR: 0.001686
2025-05-12 09:35:49,688 [INFO] Epoch 14/15 - Policy Loss: 1.2060, Value Loss: 0.2405, Total Loss: 1.4464, LR: 0.003336
2025-05-12 09:36:20,807 [INFO] Epoch 15/15 - Policy Loss: 1.2059, Value Loss: 0.2405, Total Loss: 1.4463, LR: 0.004986
2025-05-12 09:36:20,825 [INFO] 训练完成，总损失: 1.4463
2025-05-12 09:36:20,825 [INFO] 保存迭代 40 的模型
2025-05-12 09:36:21,767 [INFO] Model saved to ./models/best.pt
2025-05-12 09:36:22,413 [INFO] Model saved to ./models/iteration_40.pt
2025-05-12 09:36:22,413 [INFO] 所有训练迭代完成
2025-05-12 09:36:22,413 [INFO] 开始迭代 41/300
2025-05-12 09:36:22,413 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 09:47:38,413 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 09:47:38,413 [INFO] 保存训练样本
2025-05-12 09:47:42,500 [INFO] 使用 118616 个样本训练神经网络
2025-05-12 09:47:42,500 [INFO] Training with 118616 examples
2025-05-12 09:47:42,501 [INFO] 总训练步数: 1725, 每轮次批次数: 115
2025-05-12 09:47:42,556 [INFO] 循环学习率周期大小: 345 步
2025-05-12 09:48:15,324 [INFO] Epoch 1/15 - Policy Loss: 1.2305, Value Loss: 0.2567, Total Loss: 1.4872, LR: 0.001686
2025-05-12 09:48:47,484 [INFO] Epoch 2/15 - Policy Loss: 1.2227, Value Loss: 0.2533, Total Loss: 1.4759, LR: 0.003336
2025-05-12 09:49:18,169 [INFO] Epoch 3/15 - Policy Loss: 1.2180, Value Loss: 0.2511, Total Loss: 1.4691, LR: 0.004986
2025-05-12 09:49:49,874 [INFO] Epoch 4/15 - Policy Loss: 1.2192, Value Loss: 0.2493, Total Loss: 1.4685, LR: 0.003364
2025-05-12 09:50:22,223 [INFO] Epoch 5/15 - Policy Loss: 1.2156, Value Loss: 0.2483, Total Loss: 1.4639, LR: 0.001714
2025-05-12 09:50:53,053 [INFO] Epoch 6/15 - Policy Loss: 1.2108, Value Loss: 0.2469, Total Loss: 1.4577, LR: 0.000064
2025-05-12 09:51:25,882 [INFO] Epoch 7/15 - Policy Loss: 1.2070, Value Loss: 0.2457, Total Loss: 1.4527, LR: 0.001686
2025-05-12 09:51:56,864 [INFO] Epoch 8/15 - Policy Loss: 1.2044, Value Loss: 0.2445, Total Loss: 1.4489, LR: 0.003336
2025-05-12 09:52:27,853 [INFO] Epoch 9/15 - Policy Loss: 1.2041, Value Loss: 0.2441, Total Loss: 1.4482, LR: 0.004986
2025-05-12 09:52:58,582 [INFO] Epoch 10/15 - Policy Loss: 1.2042, Value Loss: 0.2436, Total Loss: 1.4478, LR: 0.003364
2025-05-12 09:53:29,571 [INFO] Epoch 11/15 - Policy Loss: 1.2034, Value Loss: 0.2432, Total Loss: 1.4466, LR: 0.001714
2025-05-12 09:54:01,529 [INFO] Epoch 12/15 - Policy Loss: 1.2019, Value Loss: 0.2425, Total Loss: 1.4444, LR: 0.000064
2025-05-12 09:54:32,371 [INFO] Epoch 13/15 - Policy Loss: 1.2006, Value Loss: 0.2420, Total Loss: 1.4426, LR: 0.001686
2025-05-12 09:55:03,266 [INFO] Epoch 14/15 - Policy Loss: 1.1989, Value Loss: 0.2415, Total Loss: 1.4405, LR: 0.003336
2025-05-12 09:55:36,124 [INFO] Epoch 15/15 - Policy Loss: 1.1988, Value Loss: 0.2413, Total Loss: 1.4401, LR: 0.004986
2025-05-12 09:55:36,142 [INFO] 训练完成，总损失: 1.4401
2025-05-12 09:55:36,142 [INFO] 保存迭代 41 的模型
2025-05-12 09:55:37,213 [INFO] Model saved to ./models/best.pt
2025-05-12 09:55:38,118 [INFO] Model saved to ./models/iteration_41.pt
2025-05-12 09:55:38,119 [INFO] 所有训练迭代完成
2025-05-12 09:55:38,119 [INFO] 开始迭代 42/300
2025-05-12 09:55:38,119 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 10:06:31,848 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 10:06:31,849 [INFO] 保存训练样本
2025-05-12 10:06:35,738 [INFO] 使用 118520 个样本训练神经网络
2025-05-12 10:06:35,739 [INFO] Training with 118520 examples
2025-05-12 10:06:35,739 [INFO] 总训练步数: 1725, 每轮次批次数: 115
2025-05-12 10:06:35,789 [INFO] 循环学习率周期大小: 345 步
2025-05-12 10:07:09,010 [INFO] Epoch 1/15 - Policy Loss: 1.2329, Value Loss: 0.2566, Total Loss: 1.4895, LR: 0.001686
2025-05-12 10:07:41,260 [INFO] Epoch 2/15 - Policy Loss: 1.2170, Value Loss: 0.2512, Total Loss: 1.4682, LR: 0.003336
2025-05-12 10:08:12,076 [INFO] Epoch 3/15 - Policy Loss: 1.2106, Value Loss: 0.2491, Total Loss: 1.4597, LR: 0.004986
2025-05-12 10:08:44,417 [INFO] Epoch 4/15 - Policy Loss: 1.2097, Value Loss: 0.2486, Total Loss: 1.4582, LR: 0.003364
2025-05-12 10:09:15,148 [INFO] Epoch 5/15 - Policy Loss: 1.2058, Value Loss: 0.2475, Total Loss: 1.4533, LR: 0.001714
2025-05-12 10:09:46,045 [INFO] Epoch 6/15 - Policy Loss: 1.2007, Value Loss: 0.2465, Total Loss: 1.4472, LR: 0.000064
2025-05-12 10:10:18,239 [INFO] Epoch 7/15 - Policy Loss: 1.1970, Value Loss: 0.2455, Total Loss: 1.4424, LR: 0.001686
2025-05-12 10:10:49,095 [INFO] Epoch 8/15 - Policy Loss: 1.1943, Value Loss: 0.2449, Total Loss: 1.4392, LR: 0.003336
2025-05-12 10:11:20,077 [INFO] Epoch 9/15 - Policy Loss: 1.1930, Value Loss: 0.2444, Total Loss: 1.4373, LR: 0.004986
2025-05-12 10:11:53,240 [INFO] Epoch 10/15 - Policy Loss: 1.1932, Value Loss: 0.2442, Total Loss: 1.4374, LR: 0.003364
2025-05-12 10:12:24,124 [INFO] Epoch 11/15 - Policy Loss: 1.1917, Value Loss: 0.2440, Total Loss: 1.4357, LR: 0.001714
2025-05-12 10:12:55,044 [INFO] Epoch 12/15 - Policy Loss: 1.1898, Value Loss: 0.2434, Total Loss: 1.4332, LR: 0.000064
2025-05-12 10:13:27,928 [INFO] Epoch 13/15 - Policy Loss: 1.1877, Value Loss: 0.2429, Total Loss: 1.4306, LR: 0.001686
2025-05-12 10:13:58,905 [INFO] Epoch 14/15 - Policy Loss: 1.1863, Value Loss: 0.2424, Total Loss: 1.4286, LR: 0.003336
2025-05-12 10:14:31,745 [INFO] Epoch 15/15 - Policy Loss: 1.1859, Value Loss: 0.2422, Total Loss: 1.4281, LR: 0.004986
2025-05-12 10:14:31,765 [INFO] 训练完成，总损失: 1.4281
2025-05-12 10:14:31,765 [INFO] 保存迭代 42 的模型
2025-05-12 10:14:33,167 [INFO] Model saved to ./models/best.pt
2025-05-12 10:14:34,053 [INFO] Model saved to ./models/iteration_42.pt
2025-05-12 10:14:34,054 [INFO] 所有训练迭代完成
2025-05-12 10:14:34,054 [INFO] 开始迭代 43/300
2025-05-12 10:14:34,054 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 10:23:27,413 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 10:23:27,414 [INFO] 保存训练样本
2025-05-12 10:23:31,477 [INFO] 使用 117368 个样本训练神经网络
2025-05-12 10:23:31,477 [INFO] Training with 117368 examples
2025-05-12 10:23:31,477 [INFO] 总训练步数: 1710, 每轮次批次数: 114
2025-05-12 10:23:31,522 [INFO] 循环学习率周期大小: 342 步
2025-05-12 10:24:02,619 [INFO] Epoch 1/15 - Policy Loss: 1.1904, Value Loss: 0.2470, Total Loss: 1.4373, LR: 0.001686
2025-05-12 10:24:34,489 [INFO] Epoch 2/15 - Policy Loss: 1.1844, Value Loss: 0.2437, Total Loss: 1.4281, LR: 0.003336
2025-05-12 10:25:04,933 [INFO] Epoch 3/15 - Policy Loss: 1.1808, Value Loss: 0.2428, Total Loss: 1.4237, LR: 0.004986
2025-05-12 10:25:35,889 [INFO] Epoch 4/15 - Policy Loss: 1.1800, Value Loss: 0.2431, Total Loss: 1.4230, LR: 0.003364
2025-05-12 10:26:07,561 [INFO] Epoch 5/15 - Policy Loss: 1.1792, Value Loss: 0.2427, Total Loss: 1.4219, LR: 0.001714
2025-05-12 10:26:38,462 [INFO] Epoch 6/15 - Policy Loss: 1.1762, Value Loss: 0.2420, Total Loss: 1.4182, LR: 0.000064
2025-05-12 10:27:09,108 [INFO] Epoch 7/15 - Policy Loss: 1.1728, Value Loss: 0.2408, Total Loss: 1.4136, LR: 0.001686
2025-05-12 10:27:39,632 [INFO] Epoch 8/15 - Policy Loss: 1.1703, Value Loss: 0.2399, Total Loss: 1.4102, LR: 0.003336
2025-05-12 10:28:10,588 [INFO] Epoch 9/15 - Policy Loss: 1.1692, Value Loss: 0.2394, Total Loss: 1.4086, LR: 0.004986
2025-05-12 10:28:41,220 [INFO] Epoch 10/15 - Policy Loss: 1.1695, Value Loss: 0.2394, Total Loss: 1.4089, LR: 0.003364
2025-05-12 10:29:11,775 [INFO] Epoch 11/15 - Policy Loss: 1.1683, Value Loss: 0.2390, Total Loss: 1.4073, LR: 0.001714
2025-05-12 10:29:43,781 [INFO] Epoch 12/15 - Policy Loss: 1.1671, Value Loss: 0.2386, Total Loss: 1.4057, LR: 0.000064
2025-05-12 10:30:15,084 [INFO] Epoch 13/15 - Policy Loss: 1.1660, Value Loss: 0.2384, Total Loss: 1.4044, LR: 0.001686
2025-05-12 10:30:45,724 [INFO] Epoch 14/15 - Policy Loss: 1.1647, Value Loss: 0.2380, Total Loss: 1.4028, LR: 0.003336
2025-05-12 10:31:16,309 [INFO] Epoch 15/15 - Policy Loss: 1.1644, Value Loss: 0.2379, Total Loss: 1.4023, LR: 0.004986
2025-05-12 10:31:16,328 [INFO] 训练完成，总损失: 1.4023
2025-05-12 10:31:16,329 [INFO] 保存迭代 43 的模型
2025-05-12 10:31:17,793 [INFO] Model saved to ./models/best.pt
2025-05-12 10:31:18,629 [INFO] Model saved to ./models/iteration_43.pt
2025-05-12 10:31:18,629 [INFO] 所有训练迭代完成
2025-05-12 10:31:18,629 [INFO] 开始迭代 44/300
2025-05-12 10:31:18,630 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 10:43:37,758 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 10:43:37,759 [INFO] 保存训练样本
2025-05-12 10:43:42,086 [INFO] 使用 116400 个样本训练神经网络
2025-05-12 10:43:42,086 [INFO] Training with 116400 examples
2025-05-12 10:43:42,087 [INFO] 总训练步数: 1695, 每轮次批次数: 113
2025-05-12 10:43:42,533 [INFO] 循环学习率周期大小: 339 步
2025-05-12 10:44:12,782 [INFO] Epoch 1/15 - Policy Loss: 1.1937, Value Loss: 0.2556, Total Loss: 1.4493, LR: 0.001685
2025-05-12 10:44:44,173 [INFO] Epoch 2/15 - Policy Loss: 1.1831, Value Loss: 0.2493, Total Loss: 1.4324, LR: 0.003335
2025-05-12 10:45:15,141 [INFO] Epoch 3/15 - Policy Loss: 1.1820, Value Loss: 0.2463, Total Loss: 1.4283, LR: 0.004985
2025-05-12 10:45:46,272 [INFO] Epoch 4/15 - Policy Loss: 1.1809, Value Loss: 0.2453, Total Loss: 1.4261, LR: 0.003365
2025-05-12 10:46:16,616 [INFO] Epoch 5/15 - Policy Loss: 1.1779, Value Loss: 0.2437, Total Loss: 1.4216, LR: 0.001715
2025-05-12 10:46:48,174 [INFO] Epoch 6/15 - Policy Loss: 1.1731, Value Loss: 0.2423, Total Loss: 1.4153, LR: 0.000065
2025-05-12 10:47:18,534 [INFO] Epoch 7/15 - Policy Loss: 1.1695, Value Loss: 0.2406, Total Loss: 1.4101, LR: 0.001685
2025-05-12 10:47:50,604 [INFO] Epoch 8/15 - Policy Loss: 1.1670, Value Loss: 0.2398, Total Loss: 1.4068, LR: 0.003335
2025-05-12 10:48:21,039 [INFO] Epoch 9/15 - Policy Loss: 1.1656, Value Loss: 0.2392, Total Loss: 1.4048, LR: 0.004985
2025-05-12 10:48:51,317 [INFO] Epoch 10/15 - Policy Loss: 1.1651, Value Loss: 0.2389, Total Loss: 1.4041, LR: 0.003365
2025-05-12 10:49:22,173 [INFO] Epoch 11/15 - Policy Loss: 1.1643, Value Loss: 0.2387, Total Loss: 1.4030, LR: 0.001715
2025-05-12 10:49:54,357 [INFO] Epoch 12/15 - Policy Loss: 1.1627, Value Loss: 0.2379, Total Loss: 1.4006, LR: 0.000065
2025-05-12 10:50:24,787 [INFO] Epoch 13/15 - Policy Loss: 1.1609, Value Loss: 0.2374, Total Loss: 1.3983, LR: 0.001685
2025-05-12 10:50:55,240 [INFO] Epoch 14/15 - Policy Loss: 1.1592, Value Loss: 0.2369, Total Loss: 1.3961, LR: 0.003335
2025-05-12 10:51:27,512 [INFO] Epoch 15/15 - Policy Loss: 1.1591, Value Loss: 0.2367, Total Loss: 1.3957, LR: 0.004985
2025-05-12 10:51:27,554 [INFO] 训练完成，总损失: 1.3957
2025-05-12 10:51:27,555 [INFO] 保存迭代 44 的模型
2025-05-12 10:51:30,253 [INFO] Model saved to ./models/best.pt
2025-05-12 10:51:32,044 [INFO] Model saved to ./models/iteration_44.pt
2025-05-12 10:51:32,045 [INFO] 所有训练迭代完成
2025-05-12 10:51:32,045 [INFO] 开始迭代 45/300
2025-05-12 10:51:32,045 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 11:04:33,509 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 11:04:33,509 [INFO] 保存训练样本
2025-05-12 11:04:36,869 [INFO] 使用 115768 个样本训练神经网络
2025-05-12 11:04:36,870 [INFO] Training with 115768 examples
2025-05-12 11:04:36,870 [INFO] 总训练步数: 1695, 每轮次批次数: 113
2025-05-12 11:04:37,325 [INFO] 循环学习率周期大小: 339 步
2025-05-12 11:05:07,825 [INFO] Epoch 1/15 - Policy Loss: 1.1935, Value Loss: 0.2451, Total Loss: 1.4386, LR: 0.001685
2025-05-12 11:05:38,008 [INFO] Epoch 2/15 - Policy Loss: 1.1843, Value Loss: 0.2430, Total Loss: 1.4273, LR: 0.003335
2025-05-12 11:06:08,992 [INFO] Epoch 3/15 - Policy Loss: 1.1795, Value Loss: 0.2424, Total Loss: 1.4219, LR: 0.004985
2025-05-12 11:06:39,827 [INFO] Epoch 4/15 - Policy Loss: 1.1779, Value Loss: 0.2432, Total Loss: 1.4211, LR: 0.003365
2025-05-12 11:07:10,169 [INFO] Epoch 5/15 - Policy Loss: 1.1740, Value Loss: 0.2421, Total Loss: 1.4161, LR: 0.001715
2025-05-12 11:07:42,162 [INFO] Epoch 6/15 - Policy Loss: 1.1686, Value Loss: 0.2407, Total Loss: 1.4093, LR: 0.000065
2025-05-12 11:08:12,247 [INFO] Epoch 7/15 - Policy Loss: 1.1642, Value Loss: 0.2399, Total Loss: 1.4042, LR: 0.001685
2025-05-12 11:08:42,432 [INFO] Epoch 8/15 - Policy Loss: 1.1616, Value Loss: 0.2394, Total Loss: 1.4010, LR: 0.003335
2025-05-12 11:09:15,378 [INFO] Epoch 9/15 - Policy Loss: 1.1594, Value Loss: 0.2389, Total Loss: 1.3983, LR: 0.004985
2025-05-12 11:09:46,143 [INFO] Epoch 10/15 - Policy Loss: 1.1584, Value Loss: 0.2387, Total Loss: 1.3971, LR: 0.003365
2025-05-12 11:10:16,501 [INFO] Epoch 11/15 - Policy Loss: 1.1569, Value Loss: 0.2380, Total Loss: 1.3949, LR: 0.001715
2025-05-12 11:10:46,968 [INFO] Epoch 12/15 - Policy Loss: 1.1545, Value Loss: 0.2373, Total Loss: 1.3918, LR: 0.000065
2025-05-12 11:11:17,221 [INFO] Epoch 13/15 - Policy Loss: 1.1526, Value Loss: 0.2367, Total Loss: 1.3892, LR: 0.001685
2025-05-12 11:11:47,749 [INFO] Epoch 14/15 - Policy Loss: 1.1506, Value Loss: 0.2359, Total Loss: 1.3866, LR: 0.003335
2025-05-12 11:12:18,166 [INFO] Epoch 15/15 - Policy Loss: 1.1495, Value Loss: 0.2356, Total Loss: 1.3851, LR: 0.004985
2025-05-12 11:12:18,186 [INFO] 训练完成，总损失: 1.3851
2025-05-12 11:12:18,186 [INFO] 保存迭代 45 的模型
2025-05-12 11:12:19,482 [INFO] Model saved to ./models/best.pt
2025-05-12 11:12:20,341 [INFO] Model saved to ./models/iteration_45.pt
2025-05-12 11:12:20,341 [INFO] 所有训练迭代完成
2025-05-12 11:12:20,341 [INFO] 开始迭代 46/300
2025-05-12 11:12:20,341 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 11:24:40,821 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 11:24:40,822 [INFO] 保存训练样本
2025-05-12 11:24:44,429 [INFO] 使用 115360 个样本训练神经网络
2025-05-12 11:24:44,429 [INFO] Training with 115360 examples
2025-05-12 11:24:44,430 [INFO] 总训练步数: 1680, 每轮次批次数: 112
2025-05-12 11:24:44,895 [INFO] 循环学习率周期大小: 336 步
2025-05-12 11:25:14,689 [INFO] Epoch 1/15 - Policy Loss: 1.1697, Value Loss: 0.2489, Total Loss: 1.4185, LR: 0.001685
2025-05-12 11:25:46,197 [INFO] Epoch 2/15 - Policy Loss: 1.1587, Value Loss: 0.2433, Total Loss: 1.4020, LR: 0.003335
2025-05-12 11:26:16,920 [INFO] Epoch 3/15 - Policy Loss: 1.1558, Value Loss: 0.2430, Total Loss: 1.3988, LR: 0.004985
2025-05-12 11:26:46,748 [INFO] Epoch 4/15 - Policy Loss: 1.1538, Value Loss: 0.2427, Total Loss: 1.3965, LR: 0.003365
2025-05-12 11:27:17,377 [INFO] Epoch 5/15 - Policy Loss: 1.1499, Value Loss: 0.2411, Total Loss: 1.3911, LR: 0.001715
2025-05-12 11:27:47,553 [INFO] Epoch 6/15 - Policy Loss: 1.1459, Value Loss: 0.2398, Total Loss: 1.3857, LR: 0.000065
2025-05-12 11:28:17,485 [INFO] Epoch 7/15 - Policy Loss: 1.1420, Value Loss: 0.2385, Total Loss: 1.3805, LR: 0.001685
2025-05-12 11:28:47,542 [INFO] Epoch 8/15 - Policy Loss: 1.1394, Value Loss: 0.2379, Total Loss: 1.3773, LR: 0.003335
2025-05-12 11:29:18,480 [INFO] Epoch 9/15 - Policy Loss: 1.1388, Value Loss: 0.2372, Total Loss: 1.3760, LR: 0.004985
2025-05-12 11:29:49,325 [INFO] Epoch 10/15 - Policy Loss: 1.1382, Value Loss: 0.2369, Total Loss: 1.3751, LR: 0.003365
2025-05-12 11:30:20,863 [INFO] Epoch 11/15 - Policy Loss: 1.1369, Value Loss: 0.2365, Total Loss: 1.3734, LR: 0.001715
2025-05-12 11:30:50,898 [INFO] Epoch 12/15 - Policy Loss: 1.1354, Value Loss: 0.2363, Total Loss: 1.3716, LR: 0.000065
2025-05-12 11:31:20,922 [INFO] Epoch 13/15 - Policy Loss: 1.1337, Value Loss: 0.2358, Total Loss: 1.3695, LR: 0.001685
2025-05-12 11:31:53,677 [INFO] Epoch 14/15 - Policy Loss: 1.1325, Value Loss: 0.2355, Total Loss: 1.3680, LR: 0.003335
2025-05-12 11:32:23,824 [INFO] Epoch 15/15 - Policy Loss: 1.1318, Value Loss: 0.2352, Total Loss: 1.3670, LR: 0.004985
2025-05-12 11:32:23,844 [INFO] 训练完成，总损失: 1.3670
2025-05-12 11:32:23,844 [INFO] 保存迭代 46 的模型
2025-05-12 11:32:25,522 [INFO] Model saved to ./models/best.pt
2025-05-12 11:32:26,482 [INFO] Model saved to ./models/iteration_46.pt
2025-05-12 11:32:26,482 [INFO] 所有训练迭代完成
2025-05-12 11:32:26,483 [INFO] 开始迭代 47/300
2025-05-12 11:32:26,483 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 11:43:17,793 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 11:43:17,794 [INFO] 保存训练样本
2025-05-12 11:43:21,439 [INFO] 使用 114656 个样本训练神经网络
2025-05-12 11:43:21,440 [INFO] Training with 114656 examples
2025-05-12 11:43:21,441 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 11:43:21,890 [INFO] 循环学习率周期大小: 333 步
2025-05-12 11:43:51,551 [INFO] Epoch 1/15 - Policy Loss: 1.1554, Value Loss: 0.2535, Total Loss: 1.4089, LR: 0.001685
2025-05-12 11:44:20,863 [INFO] Epoch 2/15 - Policy Loss: 1.1475, Value Loss: 0.2493, Total Loss: 1.3968, LR: 0.003335
2025-05-12 11:44:50,331 [INFO] Epoch 3/15 - Policy Loss: 1.1436, Value Loss: 0.2474, Total Loss: 1.3910, LR: 0.004985
2025-05-12 11:45:21,819 [INFO] Epoch 4/15 - Policy Loss: 1.1418, Value Loss: 0.2464, Total Loss: 1.3882, LR: 0.003365
2025-05-12 11:45:51,625 [INFO] Epoch 5/15 - Policy Loss: 1.1399, Value Loss: 0.2445, Total Loss: 1.3845, LR: 0.001715
2025-05-12 11:46:21,268 [INFO] Epoch 6/15 - Policy Loss: 1.1353, Value Loss: 0.2433, Total Loss: 1.3786, LR: 0.000065
2025-05-12 11:46:51,878 [INFO] Epoch 7/15 - Policy Loss: 1.1321, Value Loss: 0.2425, Total Loss: 1.3747, LR: 0.001685
2025-05-12 11:47:21,836 [INFO] Epoch 8/15 - Policy Loss: 1.1295, Value Loss: 0.2416, Total Loss: 1.3711, LR: 0.003335
2025-05-12 11:47:51,711 [INFO] Epoch 9/15 - Policy Loss: 1.1291, Value Loss: 0.2414, Total Loss: 1.3705, LR: 0.004985
2025-05-12 11:48:21,386 [INFO] Epoch 10/15 - Policy Loss: 1.1292, Value Loss: 0.2412, Total Loss: 1.3705, LR: 0.003365
2025-05-12 11:48:51,132 [INFO] Epoch 11/15 - Policy Loss: 1.1288, Value Loss: 0.2412, Total Loss: 1.3699, LR: 0.001715
2025-05-12 11:49:22,841 [INFO] Epoch 12/15 - Policy Loss: 1.1274, Value Loss: 0.2407, Total Loss: 1.3680, LR: 0.000065
2025-05-12 11:49:54,338 [INFO] Epoch 13/15 - Policy Loss: 1.1259, Value Loss: 0.2401, Total Loss: 1.3659, LR: 0.001685
2025-05-12 11:50:24,102 [INFO] Epoch 14/15 - Policy Loss: 1.1247, Value Loss: 0.2396, Total Loss: 1.3643, LR: 0.003335
2025-05-12 11:50:53,698 [INFO] Epoch 15/15 - Policy Loss: 1.1239, Value Loss: 0.2395, Total Loss: 1.3634, LR: 0.004985
2025-05-12 11:50:53,717 [INFO] 训练完成，总损失: 1.3634
2025-05-12 11:50:53,717 [INFO] 保存迭代 47 的模型
2025-05-12 11:50:54,897 [INFO] Model saved to ./models/best.pt
2025-05-12 11:50:55,722 [INFO] Model saved to ./models/iteration_47.pt
2025-05-12 11:50:55,723 [INFO] 所有训练迭代完成
2025-05-12 11:50:55,723 [INFO] 开始迭代 48/300
2025-05-12 11:50:55,723 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 12:02:07,198 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 12:02:07,199 [INFO] 保存训练样本
2025-05-12 12:02:11,000 [INFO] 使用 113840 个样本训练神经网络
2025-05-12 12:02:11,000 [INFO] Training with 113840 examples
2025-05-12 12:02:11,001 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 12:02:11,385 [INFO] 循环学习率周期大小: 333 步
2025-05-12 12:02:41,503 [INFO] Epoch 1/15 - Policy Loss: 1.1475, Value Loss: 0.2635, Total Loss: 1.4111, LR: 0.001685
2025-05-12 12:03:12,199 [INFO] Epoch 2/15 - Policy Loss: 1.1423, Value Loss: 0.2597, Total Loss: 1.4020, LR: 0.003335
2025-05-12 12:03:42,453 [INFO] Epoch 3/15 - Policy Loss: 1.1397, Value Loss: 0.2588, Total Loss: 1.3984, LR: 0.004985
2025-05-12 12:04:12,351 [INFO] Epoch 4/15 - Policy Loss: 1.1375, Value Loss: 0.2574, Total Loss: 1.3949, LR: 0.003365
2025-05-12 12:04:42,900 [INFO] Epoch 5/15 - Policy Loss: 1.1331, Value Loss: 0.2552, Total Loss: 1.3883, LR: 0.001715
2025-05-12 12:05:12,723 [INFO] Epoch 6/15 - Policy Loss: 1.1284, Value Loss: 0.2539, Total Loss: 1.3823, LR: 0.000065
2025-05-12 12:05:43,693 [INFO] Epoch 7/15 - Policy Loss: 1.1249, Value Loss: 0.2524, Total Loss: 1.3773, LR: 0.001685
2025-05-12 12:06:13,946 [INFO] Epoch 8/15 - Policy Loss: 1.1222, Value Loss: 0.2514, Total Loss: 1.3736, LR: 0.003335
2025-05-12 12:06:44,696 [INFO] Epoch 9/15 - Policy Loss: 1.1209, Value Loss: 0.2509, Total Loss: 1.3718, LR: 0.004985
2025-05-12 12:07:14,334 [INFO] Epoch 10/15 - Policy Loss: 1.1200, Value Loss: 0.2505, Total Loss: 1.3705, LR: 0.003365
2025-05-12 12:07:44,108 [INFO] Epoch 11/15 - Policy Loss: 1.1190, Value Loss: 0.2502, Total Loss: 1.3692, LR: 0.001715
2025-05-12 12:08:13,757 [INFO] Epoch 12/15 - Policy Loss: 1.1168, Value Loss: 0.2493, Total Loss: 1.3662, LR: 0.000065
2025-05-12 12:08:43,575 [INFO] Epoch 13/15 - Policy Loss: 1.1150, Value Loss: 0.2485, Total Loss: 1.3635, LR: 0.001685
2025-05-12 12:09:13,275 [INFO] Epoch 14/15 - Policy Loss: 1.1136, Value Loss: 0.2479, Total Loss: 1.3616, LR: 0.003335
2025-05-12 12:09:43,704 [INFO] Epoch 15/15 - Policy Loss: 1.1125, Value Loss: 0.2475, Total Loss: 1.3601, LR: 0.004985
2025-05-12 12:09:43,721 [INFO] 训练完成，总损失: 1.3601
2025-05-12 12:09:43,722 [INFO] 保存迭代 48 的模型
2025-05-12 12:09:44,660 [INFO] Model saved to ./models/best.pt
2025-05-12 12:09:45,294 [INFO] Model saved to ./models/iteration_48.pt
2025-05-12 12:09:45,294 [INFO] 所有训练迭代完成
2025-05-12 12:09:45,294 [INFO] 开始迭代 49/300
2025-05-12 12:09:45,294 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 12:21:24,101 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 12:21:24,101 [INFO] 保存训练样本
2025-05-12 12:21:27,347 [INFO] 使用 114032 个样本训练神经网络
2025-05-12 12:21:27,347 [INFO] Training with 114032 examples
2025-05-12 12:21:27,348 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 12:21:27,801 [INFO] 循环学习率周期大小: 333 步
2025-05-12 12:21:57,355 [INFO] Epoch 1/15 - Policy Loss: 1.1503, Value Loss: 0.2581, Total Loss: 1.4084, LR: 0.001685
2025-05-12 12:22:26,895 [INFO] Epoch 2/15 - Policy Loss: 1.1385, Value Loss: 0.2536, Total Loss: 1.3921, LR: 0.003335
2025-05-12 12:22:56,589 [INFO] Epoch 3/15 - Policy Loss: 1.1342, Value Loss: 0.2517, Total Loss: 1.3859, LR: 0.004985
2025-05-12 12:23:28,214 [INFO] Epoch 4/15 - Policy Loss: 1.1313, Value Loss: 0.2500, Total Loss: 1.3812, LR: 0.003365
2025-05-12 12:23:57,852 [INFO] Epoch 5/15 - Policy Loss: 1.1276, Value Loss: 0.2486, Total Loss: 1.3762, LR: 0.001715
2025-05-12 12:24:27,464 [INFO] Epoch 6/15 - Policy Loss: 1.1226, Value Loss: 0.2479, Total Loss: 1.3705, LR: 0.000065
2025-05-12 12:24:59,061 [INFO] Epoch 7/15 - Policy Loss: 1.1194, Value Loss: 0.2466, Total Loss: 1.3660, LR: 0.001685
2025-05-12 12:25:28,713 [INFO] Epoch 8/15 - Policy Loss: 1.1167, Value Loss: 0.2452, Total Loss: 1.3619, LR: 0.003335
2025-05-12 12:25:58,424 [INFO] Epoch 9/15 - Policy Loss: 1.1161, Value Loss: 0.2449, Total Loss: 1.3609, LR: 0.004985
2025-05-12 12:26:28,025 [INFO] Epoch 10/15 - Policy Loss: 1.1156, Value Loss: 0.2444, Total Loss: 1.3600, LR: 0.003365
2025-05-12 12:26:57,833 [INFO] Epoch 11/15 - Policy Loss: 1.1143, Value Loss: 0.2438, Total Loss: 1.3581, LR: 0.001715
2025-05-12 12:27:28,371 [INFO] Epoch 12/15 - Policy Loss: 1.1127, Value Loss: 0.2431, Total Loss: 1.3558, LR: 0.000065
2025-05-12 12:27:58,209 [INFO] Epoch 13/15 - Policy Loss: 1.1107, Value Loss: 0.2427, Total Loss: 1.3533, LR: 0.001685
2025-05-12 12:28:28,450 [INFO] Epoch 14/15 - Policy Loss: 1.1092, Value Loss: 0.2421, Total Loss: 1.3513, LR: 0.003335
2025-05-12 12:28:58,863 [INFO] Epoch 15/15 - Policy Loss: 1.1089, Value Loss: 0.2418, Total Loss: 1.3508, LR: 0.004985
2025-05-12 12:28:58,910 [INFO] 训练完成，总损失: 1.3508
2025-05-12 12:28:58,911 [INFO] 保存迭代 49 的模型
2025-05-12 12:29:01,672 [INFO] Model saved to ./models/best.pt
2025-05-12 12:29:03,538 [INFO] Model saved to ./models/iteration_49.pt
2025-05-12 12:29:03,539 [INFO] 所有训练迭代完成
2025-05-12 12:29:03,539 [INFO] 开始迭代 50/300
2025-05-12 12:29:03,539 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 12:39:51,998 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 12:39:51,998 [INFO] 保存训练样本
2025-05-12 12:39:55,133 [INFO] 使用 113088 个样本训练神经网络
2025-05-12 12:39:55,133 [INFO] Training with 113088 examples
2025-05-12 12:39:55,134 [INFO] 总训练步数: 1650, 每轮次批次数: 110
2025-05-12 12:39:55,527 [INFO] 循环学习率周期大小: 330 步
2025-05-12 12:40:24,981 [INFO] Epoch 1/15 - Policy Loss: 1.1360, Value Loss: 0.2558, Total Loss: 1.3918, LR: 0.001685
2025-05-12 12:40:55,367 [INFO] Epoch 2/15 - Policy Loss: 1.1292, Value Loss: 0.2510, Total Loss: 1.3803, LR: 0.003335
2025-05-12 12:41:24,521 [INFO] Epoch 3/15 - Policy Loss: 1.1271, Value Loss: 0.2485, Total Loss: 1.3757, LR: 0.004985
2025-05-12 12:41:55,047 [INFO] Epoch 4/15 - Policy Loss: 1.1262, Value Loss: 0.2480, Total Loss: 1.3742, LR: 0.003365
2025-05-12 12:42:24,446 [INFO] Epoch 5/15 - Policy Loss: 1.1231, Value Loss: 0.2466, Total Loss: 1.3698, LR: 0.001715
2025-05-12 12:42:53,801 [INFO] Epoch 6/15 - Policy Loss: 1.1192, Value Loss: 0.2448, Total Loss: 1.3641, LR: 0.000065
2025-05-12 12:43:24,396 [INFO] Epoch 7/15 - Policy Loss: 1.1163, Value Loss: 0.2431, Total Loss: 1.3594, LR: 0.001685
2025-05-12 12:43:53,756 [INFO] Epoch 8/15 - Policy Loss: 1.1136, Value Loss: 0.2423, Total Loss: 1.3560, LR: 0.003335
2025-05-12 12:44:22,947 [INFO] Epoch 9/15 - Policy Loss: 1.1123, Value Loss: 0.2418, Total Loss: 1.3540, LR: 0.004985
2025-05-12 12:44:54,718 [INFO] Epoch 10/15 - Policy Loss: 1.1118, Value Loss: 0.2414, Total Loss: 1.3532, LR: 0.003365
2025-05-12 12:45:24,983 [INFO] Epoch 11/15 - Policy Loss: 1.1111, Value Loss: 0.2411, Total Loss: 1.3522, LR: 0.001715
2025-05-12 12:45:55,068 [INFO] Epoch 12/15 - Policy Loss: 1.1091, Value Loss: 0.2406, Total Loss: 1.3497, LR: 0.000065
2025-05-12 12:46:24,675 [INFO] Epoch 13/15 - Policy Loss: 1.1078, Value Loss: 0.2404, Total Loss: 1.3482, LR: 0.001685
2025-05-12 12:46:54,229 [INFO] Epoch 14/15 - Policy Loss: 1.1065, Value Loss: 0.2400, Total Loss: 1.3465, LR: 0.003335
2025-05-12 12:47:24,742 [INFO] Epoch 15/15 - Policy Loss: 1.1062, Value Loss: 0.2397, Total Loss: 1.3459, LR: 0.004985
2025-05-12 12:47:24,760 [INFO] 训练完成，总损失: 1.3459
2025-05-12 12:47:24,761 [INFO] 保存迭代 50 的模型
2025-05-12 12:47:26,033 [INFO] Model saved to ./models/best.pt
2025-05-12 12:47:26,874 [INFO] Model saved to ./models/iteration_50.pt
2025-05-12 12:47:26,875 [INFO] 所有训练迭代完成
2025-05-12 12:47:26,875 [INFO] 开始迭代 51/300
2025-05-12 12:47:26,875 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 13:00:04,717 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 13:00:04,717 [INFO] 保存训练样本
2025-05-12 13:00:08,514 [INFO] 使用 113616 个样本训练神经网络
2025-05-12 13:00:08,514 [INFO] Training with 113616 examples
2025-05-12 13:00:08,514 [INFO] 总训练步数: 1650, 每轮次批次数: 110
2025-05-12 13:00:08,551 [INFO] 循环学习率周期大小: 330 步
2025-05-12 13:00:38,536 [INFO] Epoch 1/15 - Policy Loss: 1.1342, Value Loss: 0.2651, Total Loss: 1.3993, LR: 0.001685
2025-05-12 13:01:07,835 [INFO] Epoch 2/15 - Policy Loss: 1.1251, Value Loss: 0.2601, Total Loss: 1.3851, LR: 0.003335
2025-05-12 13:01:37,768 [INFO] Epoch 3/15 - Policy Loss: 1.1221, Value Loss: 0.2569, Total Loss: 1.3790, LR: 0.004985
2025-05-12 13:02:07,255 [INFO] Epoch 4/15 - Policy Loss: 1.1205, Value Loss: 0.2549, Total Loss: 1.3754, LR: 0.003365
2025-05-12 13:02:37,540 [INFO] Epoch 5/15 - Policy Loss: 1.1178, Value Loss: 0.2530, Total Loss: 1.3707, LR: 0.001715
2025-05-12 13:03:06,856 [INFO] Epoch 6/15 - Policy Loss: 1.1138, Value Loss: 0.2512, Total Loss: 1.3650, LR: 0.000065
2025-05-12 13:03:36,967 [INFO] Epoch 7/15 - Policy Loss: 1.1100, Value Loss: 0.2498, Total Loss: 1.3599, LR: 0.001685
2025-05-12 13:04:06,884 [INFO] Epoch 8/15 - Policy Loss: 1.1070, Value Loss: 0.2486, Total Loss: 1.3556, LR: 0.003335
2025-05-12 13:04:38,044 [INFO] Epoch 9/15 - Policy Loss: 1.1052, Value Loss: 0.2478, Total Loss: 1.3530, LR: 0.004985
2025-05-12 13:05:08,169 [INFO] Epoch 10/15 - Policy Loss: 1.1047, Value Loss: 0.2471, Total Loss: 1.3518, LR: 0.003365
2025-05-12 13:05:37,604 [INFO] Epoch 11/15 - Policy Loss: 1.1043, Value Loss: 0.2462, Total Loss: 1.3505, LR: 0.001715
2025-05-12 13:06:07,296 [INFO] Epoch 12/15 - Policy Loss: 1.1026, Value Loss: 0.2455, Total Loss: 1.3480, LR: 0.000065
2025-05-12 13:06:36,773 [INFO] Epoch 13/15 - Policy Loss: 1.1009, Value Loss: 0.2448, Total Loss: 1.3457, LR: 0.001685
2025-05-12 13:07:06,050 [INFO] Epoch 14/15 - Policy Loss: 1.1001, Value Loss: 0.2444, Total Loss: 1.3445, LR: 0.003335
2025-05-12 13:07:36,920 [INFO] Epoch 15/15 - Policy Loss: 1.0991, Value Loss: 0.2441, Total Loss: 1.3432, LR: 0.004985
2025-05-12 13:07:36,964 [INFO] 训练完成，总损失: 1.3432
2025-05-12 13:07:36,965 [INFO] 保存迭代 51 的模型
2025-05-12 13:07:40,638 [INFO] Model saved to ./models/best.pt
2025-05-12 13:07:42,443 [INFO] Model saved to ./models/iteration_51.pt
2025-05-12 13:07:42,444 [INFO] 所有训练迭代完成
2025-05-12 13:07:42,444 [INFO] 开始迭代 52/300
2025-05-12 13:07:42,444 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 13:18:37,192 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 13:18:37,192 [INFO] 保存训练样本
2025-05-12 13:18:40,911 [INFO] 使用 114000 个样本训练神经网络
2025-05-12 13:18:40,911 [INFO] Training with 114000 examples
2025-05-12 13:18:40,912 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 13:18:40,956 [INFO] 循环学习率周期大小: 333 步
2025-05-12 13:19:10,388 [INFO] Epoch 1/15 - Policy Loss: 1.1302, Value Loss: 0.2572, Total Loss: 1.3874, LR: 0.001685
2025-05-12 13:19:41,828 [INFO] Epoch 2/15 - Policy Loss: 1.1225, Value Loss: 0.2532, Total Loss: 1.3757, LR: 0.003335
2025-05-12 13:20:11,204 [INFO] Epoch 3/15 - Policy Loss: 1.1166, Value Loss: 0.2516, Total Loss: 1.3682, LR: 0.004985
2025-05-12 13:20:41,079 [INFO] Epoch 4/15 - Policy Loss: 1.1146, Value Loss: 0.2500, Total Loss: 1.3646, LR: 0.003365
2025-05-12 13:21:11,277 [INFO] Epoch 5/15 - Policy Loss: 1.1112, Value Loss: 0.2486, Total Loss: 1.3597, LR: 0.001715
2025-05-12 13:21:41,699 [INFO] Epoch 6/15 - Policy Loss: 1.1078, Value Loss: 0.2467, Total Loss: 1.3545, LR: 0.000065
2025-05-12 13:22:11,254 [INFO] Epoch 7/15 - Policy Loss: 1.1048, Value Loss: 0.2453, Total Loss: 1.3501, LR: 0.001685
2025-05-12 13:22:40,688 [INFO] Epoch 8/15 - Policy Loss: 1.1027, Value Loss: 0.2444, Total Loss: 1.3472, LR: 0.003335
2025-05-12 13:23:10,905 [INFO] Epoch 9/15 - Policy Loss: 1.1016, Value Loss: 0.2437, Total Loss: 1.3453, LR: 0.004985
2025-05-12 13:23:41,564 [INFO] Epoch 10/15 - Policy Loss: 1.1004, Value Loss: 0.2430, Total Loss: 1.3434, LR: 0.003365
2025-05-12 13:24:11,612 [INFO] Epoch 11/15 - Policy Loss: 1.0995, Value Loss: 0.2423, Total Loss: 1.3418, LR: 0.001715
2025-05-12 13:24:41,835 [INFO] Epoch 12/15 - Policy Loss: 1.0976, Value Loss: 0.2418, Total Loss: 1.3394, LR: 0.000065
2025-05-12 13:25:11,298 [INFO] Epoch 13/15 - Policy Loss: 1.0958, Value Loss: 0.2412, Total Loss: 1.3369, LR: 0.001685
2025-05-12 13:25:41,262 [INFO] Epoch 14/15 - Policy Loss: 1.0945, Value Loss: 0.2406, Total Loss: 1.3350, LR: 0.003335
2025-05-12 13:26:11,470 [INFO] Epoch 15/15 - Policy Loss: 1.0939, Value Loss: 0.2405, Total Loss: 1.3344, LR: 0.004985
2025-05-12 13:26:11,486 [INFO] 训练完成，总损失: 1.3344
2025-05-12 13:26:11,486 [INFO] 保存迭代 52 的模型
2025-05-12 13:26:12,727 [INFO] Model saved to ./models/best.pt
2025-05-12 13:26:13,436 [INFO] Model saved to ./models/iteration_52.pt
2025-05-12 13:26:13,437 [INFO] 所有训练迭代完成
2025-05-12 13:26:13,437 [INFO] 开始迭代 53/300
2025-05-12 13:26:13,437 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 13:37:50,461 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 13:37:50,461 [INFO] 保存训练样本
2025-05-12 13:37:56,867 [INFO] 使用 114608 个样本训练神经网络
2025-05-12 13:37:56,868 [INFO] Training with 114608 examples
2025-05-12 13:37:56,869 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 13:37:57,000 [INFO] 循环学习率周期大小: 333 步
2025-05-12 13:38:27,775 [INFO] Epoch 1/15 - Policy Loss: 1.1443, Value Loss: 0.2782, Total Loss: 1.4225, LR: 0.001685
2025-05-12 13:38:57,237 [INFO] Epoch 2/15 - Policy Loss: 1.1298, Value Loss: 0.2714, Total Loss: 1.4012, LR: 0.003335
2025-05-12 13:39:27,410 [INFO] Epoch 3/15 - Policy Loss: 1.1243, Value Loss: 0.2670, Total Loss: 1.3913, LR: 0.004985
2025-05-12 13:39:57,976 [INFO] Epoch 4/15 - Policy Loss: 1.1207, Value Loss: 0.2655, Total Loss: 1.3862, LR: 0.003365
2025-05-12 13:40:27,937 [INFO] Epoch 5/15 - Policy Loss: 1.1152, Value Loss: 0.2622, Total Loss: 1.3774, LR: 0.001715
2025-05-12 13:40:57,356 [INFO] Epoch 6/15 - Policy Loss: 1.1109, Value Loss: 0.2598, Total Loss: 1.3707, LR: 0.000065
2025-05-12 13:41:26,992 [INFO] Epoch 7/15 - Policy Loss: 1.1069, Value Loss: 0.2579, Total Loss: 1.3648, LR: 0.001685
2025-05-12 13:41:57,286 [INFO] Epoch 8/15 - Policy Loss: 1.1046, Value Loss: 0.2565, Total Loss: 1.3611, LR: 0.003335
2025-05-12 13:42:26,599 [INFO] Epoch 9/15 - Policy Loss: 1.1024, Value Loss: 0.2548, Total Loss: 1.3572, LR: 0.004985
2025-05-12 13:42:56,667 [INFO] Epoch 10/15 - Policy Loss: 1.1014, Value Loss: 0.2545, Total Loss: 1.3559, LR: 0.003365
2025-05-12 13:43:26,076 [INFO] Epoch 11/15 - Policy Loss: 1.0997, Value Loss: 0.2545, Total Loss: 1.3542, LR: 0.001715
2025-05-12 13:43:56,202 [INFO] Epoch 12/15 - Policy Loss: 1.0976, Value Loss: 0.2542, Total Loss: 1.3518, LR: 0.000065
2025-05-12 13:44:26,630 [INFO] Epoch 13/15 - Policy Loss: 1.0959, Value Loss: 0.2541, Total Loss: 1.3500, LR: 0.001685
2025-05-12 13:44:56,171 [INFO] Epoch 14/15 - Policy Loss: 1.0943, Value Loss: 0.2537, Total Loss: 1.3480, LR: 0.003335
2025-05-12 13:45:27,042 [INFO] Epoch 15/15 - Policy Loss: 1.0929, Value Loss: 0.2531, Total Loss: 1.3460, LR: 0.004985
2025-05-12 13:45:27,058 [INFO] 训练完成，总损失: 1.3460
2025-05-12 13:45:27,058 [INFO] 保存迭代 53 的模型
2025-05-12 13:45:28,224 [INFO] Model saved to ./models/best.pt
2025-05-12 13:45:28,897 [INFO] Model saved to ./models/iteration_53.pt
2025-05-12 13:45:28,897 [INFO] 所有训练迭代完成
2025-05-12 13:45:28,897 [INFO] 开始迭代 54/300
2025-05-12 13:45:28,897 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 13:55:11,115 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 13:55:11,116 [INFO] 保存训练样本
2025-05-12 13:55:14,742 [INFO] 使用 114160 个样本训练神经网络
2025-05-12 13:55:14,742 [INFO] Training with 114160 examples
2025-05-12 13:55:14,742 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 13:55:14,788 [INFO] 循环学习率周期大小: 333 步
2025-05-12 13:55:46,131 [INFO] Epoch 1/15 - Policy Loss: 1.1119, Value Loss: 0.2728, Total Loss: 1.3847, LR: 0.001685
2025-05-12 13:56:16,043 [INFO] Epoch 2/15 - Policy Loss: 1.1075, Value Loss: 0.2710, Total Loss: 1.3786, LR: 0.003335
2025-05-12 13:56:45,300 [INFO] Epoch 3/15 - Policy Loss: 1.1052, Value Loss: 0.2698, Total Loss: 1.3749, LR: 0.004985
2025-05-12 13:57:15,828 [INFO] Epoch 4/15 - Policy Loss: 1.1034, Value Loss: 0.2678, Total Loss: 1.3712, LR: 0.003365
2025-05-12 13:57:45,408 [INFO] Epoch 5/15 - Policy Loss: 1.1013, Value Loss: 0.2662, Total Loss: 1.3675, LR: 0.001715
2025-05-12 13:58:14,963 [INFO] Epoch 6/15 - Policy Loss: 1.0973, Value Loss: 0.2647, Total Loss: 1.3619, LR: 0.000065
2025-05-12 13:58:44,753 [INFO] Epoch 7/15 - Policy Loss: 1.0941, Value Loss: 0.2629, Total Loss: 1.3569, LR: 0.001685
2025-05-12 13:59:15,209 [INFO] Epoch 8/15 - Policy Loss: 1.0917, Value Loss: 0.2610, Total Loss: 1.3527, LR: 0.003335
2025-05-12 13:59:44,608 [INFO] Epoch 9/15 - Policy Loss: 1.0902, Value Loss: 0.2596, Total Loss: 1.3498, LR: 0.004985
2025-05-12 14:00:15,390 [INFO] Epoch 10/15 - Policy Loss: 1.0902, Value Loss: 0.2587, Total Loss: 1.3489, LR: 0.003365
2025-05-12 14:00:44,828 [INFO] Epoch 11/15 - Policy Loss: 1.0896, Value Loss: 0.2579, Total Loss: 1.3475, LR: 0.001715
2025-05-12 14:01:14,451 [INFO] Epoch 12/15 - Policy Loss: 1.0881, Value Loss: 0.2571, Total Loss: 1.3451, LR: 0.000065
2025-05-12 14:01:43,874 [INFO] Epoch 13/15 - Policy Loss: 1.0871, Value Loss: 0.2559, Total Loss: 1.3430, LR: 0.001685
2025-05-12 14:02:14,027 [INFO] Epoch 14/15 - Policy Loss: 1.0859, Value Loss: 0.2550, Total Loss: 1.3409, LR: 0.003335
2025-05-12 14:02:45,067 [INFO] Epoch 15/15 - Policy Loss: 1.0851, Value Loss: 0.2545, Total Loss: 1.3396, LR: 0.004985
2025-05-12 14:02:45,083 [INFO] 训练完成，总损失: 1.3396
2025-05-12 14:02:45,083 [INFO] 保存迭代 54 的模型
2025-05-12 14:02:46,181 [INFO] Model saved to ./models/best.pt
2025-05-12 14:02:46,819 [INFO] Model saved to ./models/iteration_54.pt
2025-05-12 14:02:46,820 [INFO] 所有训练迭代完成
2025-05-12 14:02:46,820 [INFO] 开始迭代 55/300
2025-05-12 14:02:46,820 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 14:14:00,268 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 14:14:00,269 [INFO] 保存训练样本
2025-05-12 14:14:03,646 [INFO] 使用 114408 个样本训练神经网络
2025-05-12 14:14:03,646 [INFO] Training with 114408 examples
2025-05-12 14:14:03,647 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 14:14:03,961 [INFO] 循环学习率周期大小: 333 步
2025-05-12 14:14:34,202 [INFO] Epoch 1/15 - Policy Loss: 1.1326, Value Loss: 0.2775, Total Loss: 1.4102, LR: 0.001685
2025-05-12 14:15:06,100 [INFO] Epoch 2/15 - Policy Loss: 1.1225, Value Loss: 0.2730, Total Loss: 1.3956, LR: 0.003335
2025-05-12 14:15:35,445 [INFO] Epoch 3/15 - Policy Loss: 1.1158, Value Loss: 0.2692, Total Loss: 1.3849, LR: 0.004985
2025-05-12 14:16:06,477 [INFO] Epoch 4/15 - Policy Loss: 1.1133, Value Loss: 0.2670, Total Loss: 1.3803, LR: 0.003365
2025-05-12 14:16:36,199 [INFO] Epoch 5/15 - Policy Loss: 1.1097, Value Loss: 0.2652, Total Loss: 1.3749, LR: 0.001715
2025-05-12 14:17:05,608 [INFO] Epoch 6/15 - Policy Loss: 1.1055, Value Loss: 0.2641, Total Loss: 1.3696, LR: 0.000065
2025-05-12 14:17:36,436 [INFO] Epoch 7/15 - Policy Loss: 1.1018, Value Loss: 0.2625, Total Loss: 1.3643, LR: 0.001685
2025-05-12 14:18:06,074 [INFO] Epoch 8/15 - Policy Loss: 1.0996, Value Loss: 0.2615, Total Loss: 1.3611, LR: 0.003335
2025-05-12 14:18:36,476 [INFO] Epoch 9/15 - Policy Loss: 1.0986, Value Loss: 0.2606, Total Loss: 1.3592, LR: 0.004985
2025-05-12 14:19:05,875 [INFO] Epoch 10/15 - Policy Loss: 1.0982, Value Loss: 0.2604, Total Loss: 1.3586, LR: 0.003365
2025-05-12 14:19:36,301 [INFO] Epoch 11/15 - Policy Loss: 1.0963, Value Loss: 0.2601, Total Loss: 1.3564, LR: 0.001715
2025-05-12 14:20:07,958 [INFO] Epoch 12/15 - Policy Loss: 1.0941, Value Loss: 0.2594, Total Loss: 1.3535, LR: 0.000065
2025-05-12 14:20:38,228 [INFO] Epoch 13/15 - Policy Loss: 1.0929, Value Loss: 0.2589, Total Loss: 1.3519, LR: 0.001685
2025-05-12 14:21:07,719 [INFO] Epoch 14/15 - Policy Loss: 1.0917, Value Loss: 0.2583, Total Loss: 1.3500, LR: 0.003335
2025-05-12 14:21:37,206 [INFO] Epoch 15/15 - Policy Loss: 1.0910, Value Loss: 0.2579, Total Loss: 1.3489, LR: 0.004985
2025-05-12 14:21:37,229 [INFO] 训练完成，总损失: 1.3489
2025-05-12 14:21:37,229 [INFO] 保存迭代 55 的模型
2025-05-12 14:21:39,546 [INFO] Model saved to ./models/best.pt
2025-05-12 14:21:41,162 [INFO] Model saved to ./models/iteration_55.pt
2025-05-12 14:21:41,163 [INFO] 所有训练迭代完成
2025-05-12 14:21:41,164 [INFO] 开始迭代 56/300
2025-05-12 14:21:41,164 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 14:31:53,439 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 14:31:53,443 [INFO] 保存训练样本
2025-05-12 14:31:57,073 [INFO] 使用 114328 个样本训练神经网络
2025-05-12 14:31:57,073 [INFO] Training with 114328 examples
2025-05-12 14:31:57,073 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 14:31:57,428 [INFO] 循环学习率周期大小: 333 步
2025-05-12 14:32:26,719 [INFO] Epoch 1/15 - Policy Loss: 1.1164, Value Loss: 0.2730, Total Loss: 1.3894, LR: 0.001685
2025-05-12 14:32:57,359 [INFO] Epoch 2/15 - Policy Loss: 1.1107, Value Loss: 0.2682, Total Loss: 1.3789, LR: 0.003335
2025-05-12 14:33:26,638 [INFO] Epoch 3/15 - Policy Loss: 1.1064, Value Loss: 0.2640, Total Loss: 1.3705, LR: 0.004985
2025-05-12 14:33:55,923 [INFO] Epoch 4/15 - Policy Loss: 1.1039, Value Loss: 0.2631, Total Loss: 1.3670, LR: 0.003365
2025-05-12 14:34:27,421 [INFO] Epoch 5/15 - Policy Loss: 1.1003, Value Loss: 0.2613, Total Loss: 1.3616, LR: 0.001715
2025-05-12 14:34:57,471 [INFO] Epoch 6/15 - Policy Loss: 1.0966, Value Loss: 0.2603, Total Loss: 1.3569, LR: 0.000065
2025-05-12 14:35:27,004 [INFO] Epoch 7/15 - Policy Loss: 1.0937, Value Loss: 0.2600, Total Loss: 1.3537, LR: 0.001685
2025-05-12 14:35:58,673 [INFO] Epoch 8/15 - Policy Loss: 1.0922, Value Loss: 0.2588, Total Loss: 1.3510, LR: 0.003335
2025-05-12 14:36:28,286 [INFO] Epoch 9/15 - Policy Loss: 1.0923, Value Loss: 0.2583, Total Loss: 1.3505, LR: 0.004985
2025-05-12 14:36:58,107 [INFO] Epoch 10/15 - Policy Loss: 1.0918, Value Loss: 0.2580, Total Loss: 1.3499, LR: 0.003365
2025-05-12 14:37:27,631 [INFO] Epoch 11/15 - Policy Loss: 1.0911, Value Loss: 0.2575, Total Loss: 1.3486, LR: 0.001715
2025-05-12 14:37:58,345 [INFO] Epoch 12/15 - Policy Loss: 1.0899, Value Loss: 0.2570, Total Loss: 1.3469, LR: 0.000065
2025-05-12 14:38:29,070 [INFO] Epoch 13/15 - Policy Loss: 1.0880, Value Loss: 0.2565, Total Loss: 1.3446, LR: 0.001685
2025-05-12 14:38:58,697 [INFO] Epoch 14/15 - Policy Loss: 1.0871, Value Loss: 0.2563, Total Loss: 1.3434, LR: 0.003335
2025-05-12 14:39:28,206 [INFO] Epoch 15/15 - Policy Loss: 1.0863, Value Loss: 0.2559, Total Loss: 1.3422, LR: 0.004985
2025-05-12 14:39:28,222 [INFO] 训练完成，总损失: 1.3422
2025-05-12 14:39:28,222 [INFO] 保存迭代 56 的模型
2025-05-12 14:39:29,521 [INFO] Model saved to ./models/best.pt
2025-05-12 14:39:30,198 [INFO] Model saved to ./models/iteration_56.pt
2025-05-12 14:39:30,198 [INFO] 所有训练迭代完成
2025-05-12 14:39:30,198 [INFO] 开始迭代 57/300
2025-05-12 14:39:30,198 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 14:50:20,915 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 14:50:20,916 [INFO] 保存训练样本
2025-05-12 14:50:24,325 [INFO] 使用 114456 个样本训练神经网络
2025-05-12 14:50:24,325 [INFO] Training with 114456 examples
2025-05-12 14:50:24,325 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 14:50:24,664 [INFO] 循环学习率周期大小: 333 步
2025-05-12 14:50:54,209 [INFO] Epoch 1/15 - Policy Loss: 1.1253, Value Loss: 0.2908, Total Loss: 1.4161, LR: 0.001685
2025-05-12 14:51:25,951 [INFO] Epoch 2/15 - Policy Loss: 1.1158, Value Loss: 0.2841, Total Loss: 1.3999, LR: 0.003335
2025-05-12 14:51:56,268 [INFO] Epoch 3/15 - Policy Loss: 1.1118, Value Loss: 0.2797, Total Loss: 1.3915, LR: 0.004985
2025-05-12 14:52:26,843 [INFO] Epoch 4/15 - Policy Loss: 1.1113, Value Loss: 0.2768, Total Loss: 1.3881, LR: 0.003365
2025-05-12 14:52:56,157 [INFO] Epoch 5/15 - Policy Loss: 1.1080, Value Loss: 0.2745, Total Loss: 1.3825, LR: 0.001715
2025-05-12 14:53:25,449 [INFO] Epoch 6/15 - Policy Loss: 1.1037, Value Loss: 0.2715, Total Loss: 1.3752, LR: 0.000065
2025-05-12 14:53:56,968 [INFO] Epoch 7/15 - Policy Loss: 1.0995, Value Loss: 0.2697, Total Loss: 1.3692, LR: 0.001685
2025-05-12 14:54:26,606 [INFO] Epoch 8/15 - Policy Loss: 1.0965, Value Loss: 0.2685, Total Loss: 1.3650, LR: 0.003335
2025-05-12 14:54:56,205 [INFO] Epoch 9/15 - Policy Loss: 1.0951, Value Loss: 0.2675, Total Loss: 1.3627, LR: 0.004985
2025-05-12 14:55:25,825 [INFO] Epoch 10/15 - Policy Loss: 1.0946, Value Loss: 0.2669, Total Loss: 1.3616, LR: 0.003365
2025-05-12 14:55:56,190 [INFO] Epoch 11/15 - Policy Loss: 1.0938, Value Loss: 0.2658, Total Loss: 1.3596, LR: 0.001715
2025-05-12 14:56:27,243 [INFO] Epoch 12/15 - Policy Loss: 1.0926, Value Loss: 0.2650, Total Loss: 1.3576, LR: 0.000065
2025-05-12 14:56:56,748 [INFO] Epoch 13/15 - Policy Loss: 1.0909, Value Loss: 0.2643, Total Loss: 1.3552, LR: 0.001685
2025-05-12 14:57:26,985 [INFO] Epoch 14/15 - Policy Loss: 1.0896, Value Loss: 0.2640, Total Loss: 1.3535, LR: 0.003335
2025-05-12 14:57:56,484 [INFO] Epoch 15/15 - Policy Loss: 1.0886, Value Loss: 0.2635, Total Loss: 1.3521, LR: 0.004985
2025-05-12 14:57:56,500 [INFO] 训练完成，总损失: 1.3521
2025-05-12 14:57:56,500 [INFO] 保存迭代 57 的模型
2025-05-12 14:57:57,875 [INFO] Model saved to ./models/best.pt
2025-05-12 14:57:58,747 [INFO] Model saved to ./models/iteration_57.pt
2025-05-12 14:57:58,747 [INFO] 所有训练迭代完成
2025-05-12 14:57:58,747 [INFO] 开始迭代 58/300
2025-05-12 14:57:58,747 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 15:07:36,327 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 15:07:36,328 [INFO] 保存训练样本
2025-05-12 15:07:40,291 [INFO] 使用 113880 个样本训练神经网络
2025-05-12 15:07:40,291 [INFO] Training with 113880 examples
2025-05-12 15:07:40,292 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 15:07:40,731 [INFO] 循环学习率周期大小: 333 步
2025-05-12 15:08:10,092 [INFO] Epoch 1/15 - Policy Loss: 1.1266, Value Loss: 0.2894, Total Loss: 1.4160, LR: 0.001685
2025-05-12 15:08:40,715 [INFO] Epoch 2/15 - Policy Loss: 1.1149, Value Loss: 0.2857, Total Loss: 1.4006, LR: 0.003335
2025-05-12 15:09:09,996 [INFO] Epoch 3/15 - Policy Loss: 1.1102, Value Loss: 0.2824, Total Loss: 1.3926, LR: 0.004985
2025-05-12 15:09:39,278 [INFO] Epoch 4/15 - Policy Loss: 1.1075, Value Loss: 0.2801, Total Loss: 1.3876, LR: 0.003365
2025-05-12 15:10:10,202 [INFO] Epoch 5/15 - Policy Loss: 1.1038, Value Loss: 0.2783, Total Loss: 1.3821, LR: 0.001715
2025-05-12 15:10:39,752 [INFO] Epoch 6/15 - Policy Loss: 1.0997, Value Loss: 0.2765, Total Loss: 1.3761, LR: 0.000065
2025-05-12 15:11:10,629 [INFO] Epoch 7/15 - Policy Loss: 1.0959, Value Loss: 0.2749, Total Loss: 1.3708, LR: 0.001685
2025-05-12 15:11:40,189 [INFO] Epoch 8/15 - Policy Loss: 1.0933, Value Loss: 0.2737, Total Loss: 1.3670, LR: 0.003335
2025-05-12 15:12:09,981 [INFO] Epoch 9/15 - Policy Loss: 1.0918, Value Loss: 0.2734, Total Loss: 1.3652, LR: 0.004985
2025-05-12 15:12:41,691 [INFO] Epoch 10/15 - Policy Loss: 1.0909, Value Loss: 0.2731, Total Loss: 1.3640, LR: 0.003365
2025-05-12 15:13:11,223 [INFO] Epoch 11/15 - Policy Loss: 1.0896, Value Loss: 0.2728, Total Loss: 1.3624, LR: 0.001715
2025-05-12 15:13:42,539 [INFO] Epoch 12/15 - Policy Loss: 1.0885, Value Loss: 0.2721, Total Loss: 1.3606, LR: 0.000065
2025-05-12 15:14:12,010 [INFO] Epoch 13/15 - Policy Loss: 1.0875, Value Loss: 0.2713, Total Loss: 1.3588, LR: 0.001685
2025-05-12 15:14:42,868 [INFO] Epoch 14/15 - Policy Loss: 1.0867, Value Loss: 0.2709, Total Loss: 1.3576, LR: 0.003335
2025-05-12 15:15:12,482 [INFO] Epoch 15/15 - Policy Loss: 1.0861, Value Loss: 0.2704, Total Loss: 1.3565, LR: 0.004985
2025-05-12 15:15:12,512 [INFO] 训练完成，总损失: 1.3565
2025-05-12 15:15:12,512 [INFO] 保存迭代 58 的模型
2025-05-12 15:15:14,672 [INFO] Model saved to ./models/best.pt
2025-05-12 15:15:15,741 [INFO] Model saved to ./models/iteration_58.pt
2025-05-12 15:15:15,742 [INFO] 所有训练迭代完成
2025-05-12 15:15:15,742 [INFO] 开始迭代 59/300
2025-05-12 15:15:15,742 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 15:26:15,952 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 15:26:15,952 [INFO] 保存训练样本
2025-05-12 15:26:19,232 [INFO] 使用 114000 个样本训练神经网络
2025-05-12 15:26:19,232 [INFO] Training with 114000 examples
2025-05-12 15:26:19,233 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 15:26:19,673 [INFO] 循环学习率周期大小: 333 步
2025-05-12 15:26:50,941 [INFO] Epoch 1/15 - Policy Loss: 1.1333, Value Loss: 0.2847, Total Loss: 1.4180, LR: 0.001685
2025-05-12 15:27:39,986 [INFO] Epoch 2/15 - Policy Loss: 1.1198, Value Loss: 0.2776, Total Loss: 1.3973, LR: 0.003335
2025-05-12 15:28:37,946 [INFO] Epoch 3/15 - Policy Loss: 1.1134, Value Loss: 0.2749, Total Loss: 1.3884, LR: 0.004985
2025-05-12 15:29:42,493 [INFO] Epoch 4/15 - Policy Loss: 1.1093, Value Loss: 0.2738, Total Loss: 1.3832, LR: 0.003365
2025-05-12 15:30:31,100 [INFO] Epoch 5/15 - Policy Loss: 1.1048, Value Loss: 0.2722, Total Loss: 1.3770, LR: 0.001715
2025-05-12 15:31:22,439 [INFO] Epoch 6/15 - Policy Loss: 1.0982, Value Loss: 0.2710, Total Loss: 1.3691, LR: 0.000065
2025-05-12 15:32:18,041 [INFO] Epoch 7/15 - Policy Loss: 1.0949, Value Loss: 0.2695, Total Loss: 1.3644, LR: 0.001685
2025-05-12 15:32:47,486 [INFO] Epoch 8/15 - Policy Loss: 1.0914, Value Loss: 0.2686, Total Loss: 1.3601, LR: 0.003335
2025-05-12 15:33:17,812 [INFO] Epoch 9/15 - Policy Loss: 1.0903, Value Loss: 0.2683, Total Loss: 1.3587, LR: 0.004985
2025-05-12 15:33:59,721 [INFO] Epoch 10/15 - Policy Loss: 1.0894, Value Loss: 0.2683, Total Loss: 1.3577, LR: 0.003365
2025-05-12 15:35:04,953 [INFO] Epoch 11/15 - Policy Loss: 1.0885, Value Loss: 0.2679, Total Loss: 1.3564, LR: 0.001715
2025-05-12 15:36:09,776 [INFO] Epoch 12/15 - Policy Loss: 1.0864, Value Loss: 0.2674, Total Loss: 1.3538, LR: 0.000065
2025-05-12 15:36:40,295 [INFO] Epoch 13/15 - Policy Loss: 1.0851, Value Loss: 0.2670, Total Loss: 1.3521, LR: 0.001685
2025-05-12 15:37:29,085 [INFO] Epoch 14/15 - Policy Loss: 1.0841, Value Loss: 0.2668, Total Loss: 1.3509, LR: 0.003335
2025-05-12 15:38:33,886 [INFO] Epoch 15/15 - Policy Loss: 1.0840, Value Loss: 0.2666, Total Loss: 1.3506, LR: 0.004985
2025-05-12 15:38:33,918 [INFO] 训练完成，总损失: 1.3506
2025-05-12 15:38:33,919 [INFO] 保存迭代 59 的模型
2025-05-12 15:38:35,912 [INFO] Model saved to ./models/best.pt
2025-05-12 15:38:36,872 [INFO] Model saved to ./models/iteration_59.pt
2025-05-12 15:38:36,872 [INFO] 所有训练迭代完成
2025-05-12 15:38:36,872 [INFO] 开始迭代 60/300
2025-05-12 15:38:36,872 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 15:54:24,485 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 15:54:24,485 [INFO] 保存训练样本
2025-05-12 15:54:28,170 [INFO] 使用 114560 个样本训练神经网络
2025-05-12 15:54:28,170 [INFO] Training with 114560 examples
2025-05-12 15:54:28,172 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 15:54:28,498 [INFO] 循环学习率周期大小: 333 步
2025-05-12 15:57:53,429 [INFO] Epoch 1/15 - Policy Loss: 1.1304, Value Loss: 0.2840, Total Loss: 1.4144, LR: 0.001685
2025-05-12 16:01:32,960 [INFO] Epoch 2/15 - Policy Loss: 1.1219, Value Loss: 0.2798, Total Loss: 1.4017, LR: 0.003335
2025-05-12 16:05:10,913 [INFO] Epoch 3/15 - Policy Loss: 1.1165, Value Loss: 0.2790, Total Loss: 1.3954, LR: 0.004985
2025-05-12 16:08:51,654 [INFO] Epoch 4/15 - Policy Loss: 1.1131, Value Loss: 0.2775, Total Loss: 1.3907, LR: 0.003365
2025-05-12 16:12:38,325 [INFO] Epoch 5/15 - Policy Loss: 1.1075, Value Loss: 0.2752, Total Loss: 1.3826, LR: 0.001715
2025-05-12 16:16:24,354 [INFO] Epoch 6/15 - Policy Loss: 1.1022, Value Loss: 0.2729, Total Loss: 1.3751, LR: 0.000065
2025-05-12 16:20:11,410 [INFO] Epoch 7/15 - Policy Loss: 1.0980, Value Loss: 0.2719, Total Loss: 1.3699, LR: 0.001685
2025-05-12 16:23:58,130 [INFO] Epoch 8/15 - Policy Loss: 1.0955, Value Loss: 0.2707, Total Loss: 1.3662, LR: 0.003335
2025-05-12 16:27:46,162 [INFO] Epoch 9/15 - Policy Loss: 1.0937, Value Loss: 0.2699, Total Loss: 1.3637, LR: 0.004985
2025-05-12 16:31:26,545 [INFO] Epoch 10/15 - Policy Loss: 1.0927, Value Loss: 0.2696, Total Loss: 1.3622, LR: 0.003365
2025-05-12 16:34:58,459 [INFO] Epoch 11/15 - Policy Loss: 1.0910, Value Loss: 0.2693, Total Loss: 1.3603, LR: 0.001715
2025-05-12 16:38:40,666 [INFO] Epoch 12/15 - Policy Loss: 1.0890, Value Loss: 0.2684, Total Loss: 1.3574, LR: 0.000065
2025-05-12 16:42:21,271 [INFO] Epoch 13/15 - Policy Loss: 1.0874, Value Loss: 0.2677, Total Loss: 1.3551, LR: 0.001685
2025-05-12 16:46:07,079 [INFO] Epoch 14/15 - Policy Loss: 1.0859, Value Loss: 0.2672, Total Loss: 1.3531, LR: 0.003335
2025-05-12 16:49:53,489 [INFO] Epoch 15/15 - Policy Loss: 1.0849, Value Loss: 0.2667, Total Loss: 1.3516, LR: 0.004985
2025-05-12 16:49:53,549 [INFO] 训练完成，总损失: 1.3516
2025-05-12 16:49:53,549 [INFO] 保存迭代 60 的模型
2025-05-12 16:49:57,055 [INFO] Model saved to ./models/best.pt
2025-05-12 16:49:58,356 [INFO] Model saved to ./models/iteration_60.pt
2025-05-12 16:49:58,357 [INFO] 所有训练迭代完成
2025-05-12 16:49:58,357 [INFO] 开始迭代 61/300
2025-05-12 16:49:58,357 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 17:17:11,357 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 17:17:11,358 [INFO] 保存训练样本
2025-05-12 17:17:14,929 [INFO] 使用 113912 个样本训练神经网络
2025-05-12 17:17:14,930 [INFO] Training with 113912 examples
2025-05-12 17:17:14,930 [INFO] 总训练步数: 1665, 每轮次批次数: 111
2025-05-12 17:17:14,970 [INFO] 循环学习率周期大小: 333 步
2025-05-12 17:21:01,355 [INFO] Epoch 1/15 - Policy Loss: 1.1119, Value Loss: 0.2811, Total Loss: 1.3929, LR: 0.001685
2025-05-12 17:24:47,968 [INFO] Epoch 2/15 - Policy Loss: 1.1045, Value Loss: 0.2758, Total Loss: 1.3804, LR: 0.003335
2025-05-12 17:28:33,798 [INFO] Epoch 3/15 - Policy Loss: 1.1007, Value Loss: 0.2741, Total Loss: 1.3749, LR: 0.004985
2025-05-12 17:32:20,027 [INFO] Epoch 4/15 - Policy Loss: 1.1005, Value Loss: 0.2732, Total Loss: 1.3737, LR: 0.003365
2025-05-12 17:36:05,744 [INFO] Epoch 5/15 - Policy Loss: 1.0970, Value Loss: 0.2717, Total Loss: 1.3687, LR: 0.001715
2025-05-12 17:39:52,474 [INFO] Epoch 6/15 - Policy Loss: 1.0925, Value Loss: 0.2701, Total Loss: 1.3625, LR: 0.000065
2025-05-12 17:43:39,609 [INFO] Epoch 7/15 - Policy Loss: 1.0903, Value Loss: 0.2689, Total Loss: 1.3593, LR: 0.001685
2025-05-12 17:47:25,974 [INFO] Epoch 8/15 - Policy Loss: 1.0887, Value Loss: 0.2681, Total Loss: 1.3568, LR: 0.003335
2025-05-12 17:51:12,454 [INFO] Epoch 9/15 - Policy Loss: 1.0875, Value Loss: 0.2676, Total Loss: 1.3551, LR: 0.004985
2025-05-12 17:54:58,565 [INFO] Epoch 10/15 - Policy Loss: 1.0870, Value Loss: 0.2671, Total Loss: 1.3541, LR: 0.003365
2025-05-12 17:58:26,211 [INFO] Epoch 11/15 - Policy Loss: 1.0866, Value Loss: 0.2665, Total Loss: 1.3531, LR: 0.001715
2025-05-12 18:01:40,287 [INFO] Epoch 12/15 - Policy Loss: 1.0853, Value Loss: 0.2660, Total Loss: 1.3513, LR: 0.000065
2025-05-12 18:05:20,250 [INFO] Epoch 13/15 - Policy Loss: 1.0838, Value Loss: 0.2655, Total Loss: 1.3493, LR: 0.001685
2025-05-12 18:09:06,878 [INFO] Epoch 14/15 - Policy Loss: 1.0829, Value Loss: 0.2649, Total Loss: 1.3479, LR: 0.003335
2025-05-12 18:12:51,741 [INFO] Epoch 15/15 - Policy Loss: 1.0822, Value Loss: 0.2647, Total Loss: 1.3469, LR: 0.004985
2025-05-12 18:12:51,764 [INFO] 训练完成，总损失: 1.3469
2025-05-12 18:12:51,765 [INFO] 保存迭代 61 的模型
2025-05-12 18:12:53,786 [INFO] Model saved to ./models/best.pt
2025-05-12 18:12:55,128 [INFO] Model saved to ./models/iteration_61.pt
2025-05-12 18:12:55,128 [INFO] 所有训练迭代完成
2025-05-12 18:12:55,128 [INFO] 开始迭代 62/300
2025-05-12 18:12:55,128 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 18:56:12,255 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 18:56:12,256 [INFO] 保存训练样本
2025-05-12 18:56:17,991 [INFO] 使用 115176 个样本训练神经网络
2025-05-12 18:56:17,992 [INFO] Training with 115176 examples
2025-05-12 18:56:17,992 [INFO] 总训练步数: 1680, 每轮次批次数: 112
2025-05-12 18:56:18,061 [INFO] 循环学习率周期大小: 336 步
2025-05-12 19:00:03,200 [INFO] Epoch 1/15 - Policy Loss: 1.1522, Value Loss: 0.2977, Total Loss: 1.4499, LR: 0.001685
2025-05-12 19:03:50,020 [INFO] Epoch 2/15 - Policy Loss: 1.1393, Value Loss: 0.2916, Total Loss: 1.4309, LR: 0.003335
2025-05-12 19:07:37,670 [INFO] Epoch 3/15 - Policy Loss: 1.1323, Value Loss: 0.2873, Total Loss: 1.4196, LR: 0.004985
2025-05-12 19:11:23,088 [INFO] Epoch 4/15 - Policy Loss: 1.1269, Value Loss: 0.2854, Total Loss: 1.4123, LR: 0.003365
2025-05-12 19:15:10,302 [INFO] Epoch 5/15 - Policy Loss: 1.1211, Value Loss: 0.2835, Total Loss: 1.4046, LR: 0.001715
2025-05-12 19:18:57,695 [INFO] Epoch 6/15 - Policy Loss: 1.1161, Value Loss: 0.2815, Total Loss: 1.3976, LR: 0.000065
2025-05-12 19:22:45,097 [INFO] Epoch 7/15 - Policy Loss: 1.1123, Value Loss: 0.2794, Total Loss: 1.3917, LR: 0.001685
2025-05-12 19:26:32,809 [INFO] Epoch 8/15 - Policy Loss: 1.1081, Value Loss: 0.2781, Total Loss: 1.3862, LR: 0.003335
2025-05-12 19:30:20,376 [INFO] Epoch 9/15 - Policy Loss: 1.1064, Value Loss: 0.2769, Total Loss: 1.3832, LR: 0.004985
2025-05-12 19:33:56,577 [INFO] Epoch 10/15 - Policy Loss: 1.1047, Value Loss: 0.2761, Total Loss: 1.3808, LR: 0.003365
2025-05-12 19:37:34,870 [INFO] Epoch 11/15 - Policy Loss: 1.1025, Value Loss: 0.2755, Total Loss: 1.3780, LR: 0.001715
2025-05-12 19:41:04,470 [INFO] Epoch 12/15 - Policy Loss: 1.1002, Value Loss: 0.2744, Total Loss: 1.3746, LR: 0.000065
2025-05-12 19:44:47,065 [INFO] Epoch 13/15 - Policy Loss: 1.0981, Value Loss: 0.2737, Total Loss: 1.3718, LR: 0.001685
2025-05-12 19:48:32,103 [INFO] Epoch 14/15 - Policy Loss: 1.0963, Value Loss: 0.2730, Total Loss: 1.3692, LR: 0.003335
2025-05-12 19:52:11,810 [INFO] Epoch 15/15 - Policy Loss: 1.0951, Value Loss: 0.2725, Total Loss: 1.3677, LR: 0.004985
2025-05-12 19:52:11,828 [INFO] 训练完成，总损失: 1.3677
2025-05-12 19:52:11,828 [INFO] 保存迭代 62 的模型
2025-05-12 19:52:13,281 [INFO] Model saved to ./models/best.pt
2025-05-12 19:52:14,158 [INFO] Model saved to ./models/iteration_62.pt
2025-05-12 19:52:14,159 [INFO] 所有训练迭代完成
2025-05-12 19:52:14,159 [INFO] 开始迭代 63/300
2025-05-12 19:52:14,159 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 20:26:48,400 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 20:26:48,401 [INFO] 保存训练样本
2025-05-12 20:26:52,110 [INFO] 使用 116296 个样本训练神经网络
2025-05-12 20:26:52,110 [INFO] Training with 116296 examples
2025-05-12 20:26:52,110 [INFO] 总训练步数: 1695, 每轮次批次数: 113
2025-05-12 20:26:52,154 [INFO] 循环学习率周期大小: 339 步
2025-05-12 20:30:40,331 [INFO] Epoch 1/15 - Policy Loss: 1.1328, Value Loss: 0.2971, Total Loss: 1.4299, LR: 0.001685
2025-05-12 20:34:28,812 [INFO] Epoch 2/15 - Policy Loss: 1.1228, Value Loss: 0.2897, Total Loss: 1.4125, LR: 0.003335
2025-05-12 20:38:15,887 [INFO] Epoch 3/15 - Policy Loss: 1.1172, Value Loss: 0.2855, Total Loss: 1.4027, LR: 0.004985
2025-05-12 20:42:03,266 [INFO] Epoch 4/15 - Policy Loss: 1.1146, Value Loss: 0.2832, Total Loss: 1.3978, LR: 0.003365
2025-05-12 20:45:48,000 [INFO] Epoch 5/15 - Policy Loss: 1.1097, Value Loss: 0.2808, Total Loss: 1.3905, LR: 0.001715
2025-05-12 20:49:36,388 [INFO] Epoch 6/15 - Policy Loss: 1.1058, Value Loss: 0.2790, Total Loss: 1.3848, LR: 0.000065
2025-05-12 20:53:21,406 [INFO] Epoch 7/15 - Policy Loss: 1.1017, Value Loss: 0.2781, Total Loss: 1.3798, LR: 0.001685
2025-05-12 20:56:59,527 [INFO] Epoch 8/15 - Policy Loss: 1.0982, Value Loss: 0.2773, Total Loss: 1.3755, LR: 0.003335
2025-05-12 21:00:32,196 [INFO] Epoch 9/15 - Policy Loss: 1.0968, Value Loss: 0.2765, Total Loss: 1.3733, LR: 0.004985
2025-05-12 21:04:11,240 [INFO] Epoch 10/15 - Policy Loss: 1.0965, Value Loss: 0.2760, Total Loss: 1.3725, LR: 0.003365
2025-05-12 21:07:43,968 [INFO] Epoch 11/15 - Policy Loss: 1.0954, Value Loss: 0.2756, Total Loss: 1.3710, LR: 0.001715
2025-05-12 21:11:30,340 [INFO] Epoch 12/15 - Policy Loss: 1.0935, Value Loss: 0.2746, Total Loss: 1.3681, LR: 0.000065
2025-05-12 21:15:11,512 [INFO] Epoch 13/15 - Policy Loss: 1.0918, Value Loss: 0.2738, Total Loss: 1.3656, LR: 0.001685
2025-05-12 21:18:54,407 [INFO] Epoch 14/15 - Policy Loss: 1.0901, Value Loss: 0.2733, Total Loss: 1.3634, LR: 0.003335
2025-05-12 21:22:40,813 [INFO] Epoch 15/15 - Policy Loss: 1.0891, Value Loss: 0.2729, Total Loss: 1.3620, LR: 0.004985
2025-05-12 21:22:40,829 [INFO] 训练完成，总损失: 1.3620
2025-05-12 21:22:40,829 [INFO] 保存迭代 63 的模型
2025-05-12 21:22:42,066 [INFO] Model saved to ./models/best.pt
2025-05-12 21:22:42,955 [INFO] Model saved to ./models/iteration_63.pt
2025-05-12 21:22:42,955 [INFO] 所有训练迭代完成
2025-05-12 21:22:42,956 [INFO] 开始迭代 64/300
2025-05-12 21:22:42,956 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-12 21:56:16,607 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-12 21:56:16,607 [INFO] 保存训练样本
2025-05-12 21:56:20,641 [INFO] 使用 116208 个样本训练神经网络
2025-05-12 21:56:20,641 [INFO] Training with 116208 examples
2025-05-12 21:56:20,642 [INFO] 总训练步数: 1695, 每轮次批次数: 113
2025-05-12 21:56:21,054 [INFO] 循环学习率周期大小: 339 步
2025-05-12 22:00:06,078 [INFO] Epoch 1/15 - Policy Loss: 1.1220, Value Loss: 0.2912, Total Loss: 1.4132, LR: 0.001685
2025-05-12 22:03:46,536 [INFO] Epoch 2/15 - Policy Loss: 1.1139, Value Loss: 0.2848, Total Loss: 1.3986, LR: 0.003335
2025-05-12 22:07:31,412 [INFO] Epoch 3/15 - Policy Loss: 1.1111, Value Loss: 0.2815, Total Loss: 1.3926, LR: 0.004985
2025-05-12 22:11:20,465 [INFO] Epoch 4/15 - Policy Loss: 1.1067, Value Loss: 0.2792, Total Loss: 1.3859, LR: 0.003365
2025-05-12 22:15:09,577 [INFO] Epoch 5/15 - Policy Loss: 1.1028, Value Loss: 0.2777, Total Loss: 1.3805, LR: 0.001715
2025-05-12 22:18:58,535 [INFO] Epoch 6/15 - Policy Loss: 1.0989, Value Loss: 0.2764, Total Loss: 1.3753, LR: 0.000065
2025-05-12 22:22:47,132 [INFO] Epoch 7/15 - Policy Loss: 1.0959, Value Loss: 0.2754, Total Loss: 1.3712, LR: 0.001685
2025-05-12 22:26:35,581 [INFO] Epoch 8/15 - Policy Loss: 1.0928, Value Loss: 0.2739, Total Loss: 1.3667, LR: 0.003335
2025-05-12 22:30:03,083 [INFO] Epoch 9/15 - Policy Loss: 1.0918, Value Loss: 0.2734, Total Loss: 1.3652, LR: 0.004985
2025-05-12 22:33:46,644 [INFO] Epoch 10/15 - Policy Loss: 1.0907, Value Loss: 0.2728, Total Loss: 1.3635, LR: 0.003365
2025-05-12 22:37:34,128 [INFO] Epoch 11/15 - Policy Loss: 1.0900, Value Loss: 0.2724, Total Loss: 1.3624, LR: 0.001715
2025-05-12 22:41:22,564 [INFO] Epoch 12/15 - Policy Loss: 1.0883, Value Loss: 0.2718, Total Loss: 1.3601, LR: 0.000065
2025-05-12 22:45:11,028 [INFO] Epoch 13/15 - Policy Loss: 1.0865, Value Loss: 0.2712, Total Loss: 1.3578, LR: 0.001685
2025-05-12 22:49:00,858 [INFO] Epoch 14/15 - Policy Loss: 1.0854, Value Loss: 0.2707, Total Loss: 1.3561, LR: 0.003335
2025-05-12 22:52:50,401 [INFO] Epoch 15/15 - Policy Loss: 1.0853, Value Loss: 0.2705, Total Loss: 1.3558, LR: 0.004985
2025-05-12 22:52:50,417 [INFO] 训练完成，总损失: 1.3558
2025-05-12 22:52:50,417 [INFO] 保存迭代 64 的模型
2025-05-12 22:52:51,726 [INFO] Model saved to ./models/best.pt
2025-05-12 22:52:52,615 [INFO] Model saved to ./models/iteration_64.pt
2025-05-12 22:52:52,615 [INFO] 所有训练迭代完成
2025-05-12 22:52:52,615 [INFO] 开始迭代 65/300
2025-05-12 22:52:52,615 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 10:25:22,246 [INFO] 设置多进程启动方法为: spawn
2025-05-13 10:25:22,457 [INFO] CUDA可用，使用GPU
2025-05-13 10:25:22,457 [INFO] 配置参数:
2025-05-13 10:25:22,457 [INFO] 训练参数:
2025-05-13 10:25:22,457 [INFO]   训练轮数: 15
2025-05-13 10:25:22,457 [INFO]   批量大小: 1024
2025-05-13 10:25:22,457 [INFO]   迭代次数: 300
2025-05-13 10:25:22,457 [INFO]   每次迭代的自我对弈次数: 50
2025-05-13 10:25:22,457 [INFO]   训练样本队列最大长度: 200000
2025-05-13 10:25:22,457 [INFO]   保留的历史迭代数: 20
2025-05-13 10:25:22,457 [INFO]   新模型胜率阈值: 0.55
2025-05-13 10:25:22,457 [INFO]   竞技场比赛次数: 40
2025-05-13 10:25:22,457 [INFO]   温度阈值: 5
2025-05-13 10:25:22,457 [INFO] 神经网络参数:
2025-05-13 10:25:22,457 [INFO]   通道数: 256
2025-05-13 10:25:22,458 [INFO]   Dropout率: 0.3
2025-05-13 10:25:22,458 [INFO]   学习率范围: 5e-05 - 0.005
2025-05-13 10:25:22,458 [INFO]   梯度裁剪: 1.0
2025-05-13 10:25:22,458 [INFO]   优化器: adam
2025-05-13 10:25:22,458 [INFO] MCTS参数:
2025-05-13 10:25:22,458 [INFO]   模拟次数: 800
2025-05-13 10:25:22,458 [INFO]   PUCT常数: 4.0
2025-05-13 10:25:22,458 [INFO]   Dirichlet噪声参数: 0.3
2025-05-13 10:25:22,458 [INFO]   Dirichlet噪声权重: 0.25
2025-05-13 10:25:22,458 [INFO] 游戏参数:
2025-05-13 10:25:22,458 [INFO]   棋盘大小: 15
2025-05-13 10:25:22,458 [INFO]   获胜所需的连续棋子数: 5
2025-05-13 10:25:22,458 [INFO] 系统参数:
2025-05-13 10:25:22,458 [INFO]   使用CUDA: True
2025-05-13 10:25:22,458 [INFO]   检查点目录: ./models
2025-05-13 10:25:22,458 [INFO]   数据目录: ./data
2025-05-13 10:25:22,458 [INFO]   加载模型: False
2025-05-13 10:25:22,458 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-05-13 10:25:22,458 [INFO]   工作线程数: 4
2025-05-13 10:25:22,458 [INFO]   使用Weights & Biases: False
2025-05-13 10:25:22,458 [INFO] GUI参数:
2025-05-13 10:25:22,458 [INFO]   窗口宽度: 800
2025-05-13 10:25:22,458 [INFO]   窗口高度: 850
2025-05-13 10:25:22,458 [INFO]   格子大小: 40
2025-05-13 10:25:22,459 [INFO]   边距: 40
2025-05-13 10:25:22,459 [INFO]   底部边距: 80
2025-05-13 10:25:22,459 [INFO]   帧率: 30
2025-05-13 10:25:22,870 [INFO] Using device: cuda
2025-05-13 10:25:24,099 [INFO] 设置循环学习率: 最小值=5e-05, 最大值=0.005
2025-05-13 10:25:24,099 [INFO] 设置并行进程数为: 8
2025-05-13 10:25:24,099 [INFO] 开始训练
2025-05-13 10:25:24,100 [INFO] 加载之前的训练样本
2025-05-13 10:25:25,243 [INFO] 加载了 20 组训练样本
2025-05-13 10:25:25,243 [INFO] 开始迭代 1/300
2025-05-13 10:25:25,244 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 11:13:53,475 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 11:13:53,486 [INFO] 保存训练样本
2025-05-13 11:13:58,058 [INFO] 使用 129168 个样本训练神经网络
2025-05-13 11:13:58,058 [INFO] Training with 129168 examples
2025-05-13 11:13:58,059 [INFO] 总训练步数: 1890, 每轮次批次数: 126
2025-05-13 11:13:58,115 [INFO] 循环学习率周期大小: 378 步
2025-05-13 11:14:32,712 [INFO] Epoch 1/15 - Policy Loss: 3.6330, Value Loss: 0.7560, Total Loss: 4.3890, LR: 0.001687
2025-05-13 11:15:06,625 [INFO] Epoch 2/15 - Policy Loss: 3.1550, Value Loss: 0.6669, Total Loss: 3.8218, LR: 0.003337
2025-05-13 11:15:40,864 [INFO] Epoch 3/15 - Policy Loss: 2.9201, Value Loss: 0.6110, Total Loss: 3.5311, LR: 0.004987
2025-05-13 11:16:14,785 [INFO] Epoch 4/15 - Policy Loss: 2.7594, Value Loss: 0.5614, Total Loss: 3.3208, LR: 0.003363
2025-05-13 11:16:48,528 [INFO] Epoch 5/15 - Policy Loss: 2.6322, Value Loss: 0.5188, Total Loss: 3.1511, LR: 0.001713
2025-05-13 11:17:22,315 [INFO] Epoch 6/15 - Policy Loss: 2.5309, Value Loss: 0.4837, Total Loss: 3.0147, LR: 0.000063
2025-05-13 11:17:56,167 [INFO] Epoch 7/15 - Policy Loss: 2.4514, Value Loss: 0.4570, Total Loss: 2.9085, LR: 0.001687
2025-05-13 11:18:30,212 [INFO] Epoch 8/15 - Policy Loss: 2.3953, Value Loss: 0.4386, Total Loss: 2.8339, LR: 0.003337
2025-05-13 11:19:04,159 [INFO] Epoch 9/15 - Policy Loss: 2.3596, Value Loss: 0.4271, Total Loss: 2.7868, LR: 0.004987
2025-05-13 11:19:38,171 [INFO] Epoch 10/15 - Policy Loss: 2.3296, Value Loss: 0.4169, Total Loss: 2.7466, LR: 0.003363
2025-05-13 11:20:12,128 [INFO] Epoch 11/15 - Policy Loss: 2.2938, Value Loss: 0.4050, Total Loss: 2.6988, LR: 0.001713
2025-05-13 11:20:46,021 [INFO] Epoch 12/15 - Policy Loss: 2.2587, Value Loss: 0.3933, Total Loss: 2.6521, LR: 0.000063
2025-05-13 11:21:20,002 [INFO] Epoch 13/15 - Policy Loss: 2.2275, Value Loss: 0.3833, Total Loss: 2.6108, LR: 0.001687
2025-05-13 11:21:54,257 [INFO] Epoch 14/15 - Policy Loss: 2.2025, Value Loss: 0.3753, Total Loss: 2.5778, LR: 0.003337
2025-05-13 11:22:28,560 [INFO] Epoch 15/15 - Policy Loss: 2.1848, Value Loss: 0.3697, Total Loss: 2.5544, LR: 0.004987
2025-05-13 11:22:28,585 [INFO] 训练完成，总损失: 2.5544
2025-05-13 11:22:28,585 [INFO] 保存迭代 1 的模型
2025-05-13 11:22:30,278 [INFO] Model saved to ./models/best.pt
2025-05-13 11:22:31,224 [INFO] Model saved to ./models/iteration_1.pt
2025-05-13 11:22:31,225 [INFO] 所有训练迭代完成
2025-05-13 11:22:31,225 [INFO] 开始迭代 2/300
2025-05-13 11:22:31,225 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 11:34:32,649 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 11:34:32,650 [INFO] 保存训练样本
2025-05-13 11:34:37,360 [INFO] 使用 129312 个样本训练神经网络
2025-05-13 11:34:37,360 [INFO] Training with 129312 examples
2025-05-13 11:34:37,361 [INFO] 总训练步数: 1890, 每轮次批次数: 126
2025-05-13 11:34:37,872 [INFO] 循环学习率周期大小: 378 步
2025-05-13 11:35:11,600 [INFO] Epoch 1/15 - Policy Loss: 1.9666, Value Loss: 0.3014, Total Loss: 2.2681, LR: 0.001687
2025-05-13 11:35:45,371 [INFO] Epoch 2/15 - Policy Loss: 1.9324, Value Loss: 0.2923, Total Loss: 2.2248, LR: 0.003337
2025-05-13 11:36:19,178 [INFO] Epoch 3/15 - Policy Loss: 1.9323, Value Loss: 0.2928, Total Loss: 2.2251, LR: 0.004987
2025-05-13 11:36:52,891 [INFO] Epoch 4/15 - Policy Loss: 1.9365, Value Loss: 0.2934, Total Loss: 2.2299, LR: 0.003363
2025-05-13 11:37:26,613 [INFO] Epoch 5/15 - Policy Loss: 1.9240, Value Loss: 0.2881, Total Loss: 2.2120, LR: 0.001713
2025-05-13 11:38:00,533 [INFO] Epoch 6/15 - Policy Loss: 1.9058, Value Loss: 0.2825, Total Loss: 2.1883, LR: 0.000063
2025-05-13 11:38:34,426 [INFO] Epoch 7/15 - Policy Loss: 1.8888, Value Loss: 0.2774, Total Loss: 2.1662, LR: 0.001687
2025-05-13 11:39:08,429 [INFO] Epoch 8/15 - Policy Loss: 1.8797, Value Loss: 0.2748, Total Loss: 2.1545, LR: 0.003337
2025-05-13 11:39:42,420 [INFO] Epoch 9/15 - Policy Loss: 1.8773, Value Loss: 0.2741, Total Loss: 2.1514, LR: 0.004987
2025-05-13 11:40:16,492 [INFO] Epoch 10/15 - Policy Loss: 1.8792, Value Loss: 0.2744, Total Loss: 2.1536, LR: 0.003363
2025-05-13 11:40:50,540 [INFO] Epoch 11/15 - Policy Loss: 1.8754, Value Loss: 0.2737, Total Loss: 2.1491, LR: 0.001713
2025-05-13 11:41:24,515 [INFO] Epoch 12/15 - Policy Loss: 1.8670, Value Loss: 0.2715, Total Loss: 2.1385, LR: 0.000063
2025-05-13 11:41:58,533 [INFO] Epoch 13/15 - Policy Loss: 1.8598, Value Loss: 0.2694, Total Loss: 2.1292, LR: 0.001687
2025-05-13 11:42:32,576 [INFO] Epoch 14/15 - Policy Loss: 1.8542, Value Loss: 0.2680, Total Loss: 2.1222, LR: 0.003337
2025-05-13 11:43:06,684 [INFO] Epoch 15/15 - Policy Loss: 1.8534, Value Loss: 0.2673, Total Loss: 2.1207, LR: 0.004987
2025-05-13 11:43:06,705 [INFO] 训练完成，总损失: 2.1207
2025-05-13 11:43:06,705 [INFO] 保存迭代 2 的模型
2025-05-13 11:43:08,274 [INFO] Model saved to ./models/best.pt
2025-05-13 11:43:09,179 [INFO] Model saved to ./models/iteration_2.pt
2025-05-13 11:43:09,180 [INFO] 所有训练迭代完成
2025-05-13 11:43:09,180 [INFO] 开始迭代 3/300
2025-05-13 11:43:09,180 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 11:55:25,536 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 11:55:25,536 [INFO] 保存训练样本
2025-05-13 11:55:30,186 [INFO] 使用 130264 个样本训练神经网络
2025-05-13 11:55:30,187 [INFO] Training with 130264 examples
2025-05-13 11:55:30,187 [INFO] 总训练步数: 1905, 每轮次批次数: 127
2025-05-13 11:55:30,668 [INFO] 循环学习率周期大小: 381 步
2025-05-13 11:56:04,648 [INFO] Epoch 1/15 - Policy Loss: 1.8944, Value Loss: 0.2756, Total Loss: 2.1700, LR: 0.001687
2025-05-13 11:56:38,764 [INFO] Epoch 2/15 - Policy Loss: 1.8665, Value Loss: 0.2680, Total Loss: 2.1345, LR: 0.003337
2025-05-13 11:57:12,840 [INFO] Epoch 3/15 - Policy Loss: 1.8727, Value Loss: 0.2686, Total Loss: 2.1413, LR: 0.004987
2025-05-13 11:57:46,824 [INFO] Epoch 4/15 - Policy Loss: 1.8784, Value Loss: 0.2695, Total Loss: 2.1480, LR: 0.003363
2025-05-13 11:58:20,839 [INFO] Epoch 5/15 - Policy Loss: 1.8665, Value Loss: 0.2665, Total Loss: 2.1330, LR: 0.001713
2025-05-13 11:58:54,969 [INFO] Epoch 6/15 - Policy Loss: 1.8514, Value Loss: 0.2629, Total Loss: 2.1143, LR: 0.000063
2025-05-13 11:59:29,118 [INFO] Epoch 7/15 - Policy Loss: 1.8411, Value Loss: 0.2597, Total Loss: 2.1007, LR: 0.001687
2025-05-13 12:00:03,277 [INFO] Epoch 8/15 - Policy Loss: 1.8333, Value Loss: 0.2577, Total Loss: 2.0909, LR: 0.003337
2025-05-13 12:00:37,470 [INFO] Epoch 9/15 - Policy Loss: 1.8334, Value Loss: 0.2573, Total Loss: 2.0907, LR: 0.004987
2025-05-13 12:01:11,560 [INFO] Epoch 10/15 - Policy Loss: 1.8348, Value Loss: 0.2576, Total Loss: 2.0925, LR: 0.003363
2025-05-13 12:01:45,827 [INFO] Epoch 11/15 - Policy Loss: 1.8313, Value Loss: 0.2568, Total Loss: 2.0881, LR: 0.001713
2025-05-13 12:02:20,111 [INFO] Epoch 12/15 - Policy Loss: 1.8254, Value Loss: 0.2553, Total Loss: 2.0807, LR: 0.000063
2025-05-13 12:02:54,390 [INFO] Epoch 13/15 - Policy Loss: 1.8190, Value Loss: 0.2538, Total Loss: 2.0728, LR: 0.001687
2025-05-13 12:03:28,550 [INFO] Epoch 14/15 - Policy Loss: 1.8147, Value Loss: 0.2529, Total Loss: 2.0676, LR: 0.003337
2025-05-13 12:04:02,848 [INFO] Epoch 15/15 - Policy Loss: 1.8141, Value Loss: 0.2527, Total Loss: 2.0668, LR: 0.004987
2025-05-13 12:04:02,871 [INFO] 训练完成，总损失: 2.0668
2025-05-13 12:04:02,871 [INFO] 保存迭代 3 的模型
2025-05-13 12:04:04,310 [INFO] Model saved to ./models/best.pt
2025-05-13 12:04:05,447 [INFO] Model saved to ./models/iteration_3.pt
2025-05-13 12:04:05,448 [INFO] 所有训练迭代完成
2025-05-13 12:04:05,448 [INFO] 开始迭代 4/300
2025-05-13 12:04:05,448 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 12:17:15,522 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 12:17:15,523 [INFO] 保存训练样本
2025-05-13 12:17:19,816 [INFO] 使用 131136 个样本训练神经网络
2025-05-13 12:17:19,816 [INFO] Training with 131136 examples
2025-05-13 12:17:19,817 [INFO] 总训练步数: 1920, 每轮次批次数: 128
2025-05-13 12:17:20,259 [INFO] 循环学习率周期大小: 384 步
2025-05-13 12:17:54,315 [INFO] Epoch 1/15 - Policy Loss: 1.8649, Value Loss: 0.2722, Total Loss: 2.1371, LR: 0.001687
2025-05-13 12:18:28,495 [INFO] Epoch 2/15 - Policy Loss: 1.8412, Value Loss: 0.2599, Total Loss: 2.1012, LR: 0.003337
2025-05-13 12:19:02,721 [INFO] Epoch 3/15 - Policy Loss: 1.8426, Value Loss: 0.2587, Total Loss: 2.1013, LR: 0.004987
2025-05-13 12:19:36,869 [INFO] Epoch 4/15 - Policy Loss: 1.8471, Value Loss: 0.2579, Total Loss: 2.1050, LR: 0.003363
2025-05-13 12:20:11,225 [INFO] Epoch 5/15 - Policy Loss: 1.8366, Value Loss: 0.2551, Total Loss: 2.0917, LR: 0.001713
2025-05-13 12:20:45,704 [INFO] Epoch 6/15 - Policy Loss: 1.8238, Value Loss: 0.2514, Total Loss: 2.0752, LR: 0.000063
2025-05-13 12:21:20,067 [INFO] Epoch 7/15 - Policy Loss: 1.8141, Value Loss: 0.2484, Total Loss: 2.0625, LR: 0.001687
2025-05-13 12:21:54,388 [INFO] Epoch 8/15 - Policy Loss: 1.8075, Value Loss: 0.2469, Total Loss: 2.0544, LR: 0.003337
2025-05-13 12:22:28,891 [INFO] Epoch 9/15 - Policy Loss: 1.8079, Value Loss: 0.2463, Total Loss: 2.0542, LR: 0.004987
2025-05-13 12:23:03,201 [INFO] Epoch 10/15 - Policy Loss: 1.8106, Value Loss: 0.2468, Total Loss: 2.0574, LR: 0.003363
2025-05-13 12:23:37,571 [INFO] Epoch 11/15 - Policy Loss: 1.8083, Value Loss: 0.2459, Total Loss: 2.0542, LR: 0.001713
2025-05-13 12:24:12,472 [INFO] Epoch 12/15 - Policy Loss: 1.8037, Value Loss: 0.2446, Total Loss: 2.0483, LR: 0.000063
2025-05-13 12:24:46,999 [INFO] Epoch 13/15 - Policy Loss: 1.7983, Value Loss: 0.2431, Total Loss: 2.0414, LR: 0.001687
2025-05-13 12:25:21,514 [INFO] Epoch 14/15 - Policy Loss: 1.7946, Value Loss: 0.2421, Total Loss: 2.0367, LR: 0.003337
2025-05-13 12:25:56,028 [INFO] Epoch 15/15 - Policy Loss: 1.7935, Value Loss: 0.2419, Total Loss: 2.0355, LR: 0.004987
2025-05-13 12:25:56,052 [INFO] 训练完成，总损失: 2.0355
2025-05-13 12:25:56,052 [INFO] 保存迭代 4 的模型
2025-05-13 12:25:57,641 [INFO] Model saved to ./models/best.pt
2025-05-13 12:25:58,897 [INFO] Model saved to ./models/iteration_4.pt
2025-05-13 12:25:58,897 [INFO] 所有训练迭代完成
2025-05-13 12:25:58,897 [INFO] 开始迭代 5/300
2025-05-13 12:25:58,898 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 12:38:27,664 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 12:38:27,665 [INFO] 保存训练样本
2025-05-13 12:38:31,779 [INFO] 使用 131776 个样本训练神经网络
2025-05-13 12:38:31,779 [INFO] Training with 131776 examples
2025-05-13 12:38:31,780 [INFO] 总训练步数: 1920, 每轮次批次数: 128
2025-05-13 12:38:32,215 [INFO] 循环学习率周期大小: 384 步
2025-05-13 12:39:06,284 [INFO] Epoch 1/15 - Policy Loss: 1.8370, Value Loss: 0.2596, Total Loss: 2.0965, LR: 0.001687
2025-05-13 12:39:40,400 [INFO] Epoch 2/15 - Policy Loss: 1.8140, Value Loss: 0.2532, Total Loss: 2.0671, LR: 0.003337
2025-05-13 12:40:14,361 [INFO] Epoch 3/15 - Policy Loss: 1.8139, Value Loss: 0.2516, Total Loss: 2.0655, LR: 0.004987
2025-05-13 12:40:48,499 [INFO] Epoch 4/15 - Policy Loss: 1.8205, Value Loss: 0.2528, Total Loss: 2.0733, LR: 0.003363
2025-05-13 12:41:22,647 [INFO] Epoch 5/15 - Policy Loss: 1.8137, Value Loss: 0.2510, Total Loss: 2.0647, LR: 0.001713
2025-05-13 12:41:56,855 [INFO] Epoch 6/15 - Policy Loss: 1.8048, Value Loss: 0.2484, Total Loss: 2.0532, LR: 0.000063
2025-05-13 12:42:30,999 [INFO] Epoch 7/15 - Policy Loss: 1.7955, Value Loss: 0.2463, Total Loss: 2.0418, LR: 0.001687
2025-05-13 12:43:05,166 [INFO] Epoch 8/15 - Policy Loss: 1.7878, Value Loss: 0.2448, Total Loss: 2.0326, LR: 0.003337
2025-05-13 12:43:39,767 [INFO] Epoch 9/15 - Policy Loss: 1.7868, Value Loss: 0.2443, Total Loss: 2.0311, LR: 0.004987
2025-05-13 12:44:13,863 [INFO] Epoch 10/15 - Policy Loss: 1.7880, Value Loss: 0.2445, Total Loss: 2.0325, LR: 0.003363
2025-05-13 12:44:48,180 [INFO] Epoch 11/15 - Policy Loss: 1.7863, Value Loss: 0.2441, Total Loss: 2.0304, LR: 0.001713
2025-05-13 12:45:22,289 [INFO] Epoch 12/15 - Policy Loss: 1.7830, Value Loss: 0.2432, Total Loss: 2.0262, LR: 0.000063
2025-05-13 12:45:56,519 [INFO] Epoch 13/15 - Policy Loss: 1.7793, Value Loss: 0.2423, Total Loss: 2.0216, LR: 0.001687
2025-05-13 12:46:30,911 [INFO] Epoch 14/15 - Policy Loss: 1.7758, Value Loss: 0.2415, Total Loss: 2.0173, LR: 0.003337
2025-05-13 12:47:05,144 [INFO] Epoch 15/15 - Policy Loss: 1.7747, Value Loss: 0.2413, Total Loss: 2.0160, LR: 0.004987
2025-05-13 12:47:05,165 [INFO] 训练完成，总损失: 2.0160
2025-05-13 12:47:05,165 [INFO] 保存迭代 5 的模型
2025-05-13 12:47:06,518 [INFO] Model saved to ./models/best.pt
2025-05-13 12:47:07,770 [INFO] Model saved to ./models/iteration_5.pt
2025-05-13 12:47:07,771 [INFO] 所有训练迭代完成
2025-05-13 12:47:07,771 [INFO] 开始迭代 6/300
2025-05-13 12:47:07,771 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 12:59:45,569 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 12:59:45,570 [INFO] 保存训练样本
2025-05-13 12:59:50,193 [INFO] 使用 132960 个样本训练神经网络
2025-05-13 12:59:50,193 [INFO] Training with 132960 examples
2025-05-13 12:59:50,193 [INFO] 总训练步数: 1935, 每轮次批次数: 129
2025-05-13 12:59:50,253 [INFO] 循环学习率周期大小: 387 步
2025-05-13 13:00:24,603 [INFO] Epoch 1/15 - Policy Loss: 1.8085, Value Loss: 0.2660, Total Loss: 2.0744, LR: 0.001687
2025-05-13 13:00:58,880 [INFO] Epoch 2/15 - Policy Loss: 1.7941, Value Loss: 0.2583, Total Loss: 2.0524, LR: 0.003337
2025-05-13 13:01:33,225 [INFO] Epoch 3/15 - Policy Loss: 1.7958, Value Loss: 0.2557, Total Loss: 2.0515, LR: 0.004987
2025-05-13 13:02:07,528 [INFO] Epoch 4/15 - Policy Loss: 1.7989, Value Loss: 0.2546, Total Loss: 2.0535, LR: 0.003363
2025-05-13 13:02:41,967 [INFO] Epoch 5/15 - Policy Loss: 1.7929, Value Loss: 0.2518, Total Loss: 2.0447, LR: 0.001713
2025-05-13 13:03:16,908 [INFO] Epoch 6/15 - Policy Loss: 1.7847, Value Loss: 0.2492, Total Loss: 2.0340, LR: 0.000063
2025-05-13 13:03:51,360 [INFO] Epoch 7/15 - Policy Loss: 1.7760, Value Loss: 0.2473, Total Loss: 2.0233, LR: 0.001687
2025-05-13 13:04:25,920 [INFO] Epoch 8/15 - Policy Loss: 1.7707, Value Loss: 0.2462, Total Loss: 2.0169, LR: 0.003337
2025-05-13 13:05:00,531 [INFO] Epoch 9/15 - Policy Loss: 1.7698, Value Loss: 0.2458, Total Loss: 2.0156, LR: 0.004987
2025-05-13 13:05:35,108 [INFO] Epoch 10/15 - Policy Loss: 1.7729, Value Loss: 0.2458, Total Loss: 2.0188, LR: 0.003363
2025-05-13 13:06:09,542 [INFO] Epoch 11/15 - Policy Loss: 1.7714, Value Loss: 0.2451, Total Loss: 2.0165, LR: 0.001713
2025-05-13 13:06:44,066 [INFO] Epoch 12/15 - Policy Loss: 1.7683, Value Loss: 0.2443, Total Loss: 2.0126, LR: 0.000063
2025-05-13 13:07:18,754 [INFO] Epoch 13/15 - Policy Loss: 1.7653, Value Loss: 0.2434, Total Loss: 2.0087, LR: 0.001687
2025-05-13 13:07:53,475 [INFO] Epoch 14/15 - Policy Loss: 1.7628, Value Loss: 0.2428, Total Loss: 2.0055, LR: 0.003337
2025-05-13 13:08:28,341 [INFO] Epoch 15/15 - Policy Loss: 1.7630, Value Loss: 0.2425, Total Loss: 2.0055, LR: 0.004987
2025-05-13 13:08:28,362 [INFO] 训练完成，总损失: 2.0055
2025-05-13 13:08:28,362 [INFO] 保存迭代 6 的模型
2025-05-13 13:08:29,851 [INFO] Model saved to ./models/best.pt
2025-05-13 13:08:30,863 [INFO] Model saved to ./models/iteration_6.pt
2025-05-13 13:08:30,864 [INFO] 所有训练迭代完成
2025-05-13 13:08:30,864 [INFO] 开始迭代 7/300
2025-05-13 13:08:30,864 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 13:22:10,145 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 13:22:10,146 [INFO] 保存训练样本
2025-05-13 13:22:14,852 [INFO] 使用 133784 个样本训练神经网络
2025-05-13 13:22:14,853 [INFO] Training with 133784 examples
2025-05-13 13:22:14,853 [INFO] 总训练步数: 1950, 每轮次批次数: 130
2025-05-13 13:22:14,915 [INFO] 循环学习率周期大小: 390 步
2025-05-13 13:22:50,079 [INFO] Epoch 1/15 - Policy Loss: 1.8341, Value Loss: 0.2589, Total Loss: 2.0930, LR: 0.001687
2025-05-13 13:23:24,760 [INFO] Epoch 2/15 - Policy Loss: 1.8126, Value Loss: 0.2524, Total Loss: 2.0650, LR: 0.003337
2025-05-13 13:23:59,508 [INFO] Epoch 3/15 - Policy Loss: 1.8112, Value Loss: 0.2502, Total Loss: 2.0614, LR: 0.004987
2025-05-13 13:24:34,320 [INFO] Epoch 4/15 - Policy Loss: 1.8142, Value Loss: 0.2500, Total Loss: 2.0642, LR: 0.003363
2025-05-13 13:25:08,982 [INFO] Epoch 5/15 - Policy Loss: 1.8061, Value Loss: 0.2475, Total Loss: 2.0536, LR: 0.001713
2025-05-13 13:25:43,537 [INFO] Epoch 6/15 - Policy Loss: 1.7972, Value Loss: 0.2450, Total Loss: 2.0422, LR: 0.000063
2025-05-13 13:26:18,197 [INFO] Epoch 7/15 - Policy Loss: 1.7889, Value Loss: 0.2428, Total Loss: 2.0317, LR: 0.001687
2025-05-13 13:26:53,028 [INFO] Epoch 8/15 - Policy Loss: 1.7818, Value Loss: 0.2414, Total Loss: 2.0232, LR: 0.003337
2025-05-13 13:27:27,816 [INFO] Epoch 9/15 - Policy Loss: 1.7801, Value Loss: 0.2405, Total Loss: 2.0206, LR: 0.004987
2025-05-13 13:28:02,630 [INFO] Epoch 10/15 - Policy Loss: 1.7806, Value Loss: 0.2405, Total Loss: 2.0211, LR: 0.003363
2025-05-13 13:28:37,552 [INFO] Epoch 11/15 - Policy Loss: 1.7780, Value Loss: 0.2398, Total Loss: 2.0178, LR: 0.001713
2025-05-13 13:29:12,609 [INFO] Epoch 12/15 - Policy Loss: 1.7742, Value Loss: 0.2390, Total Loss: 2.0133, LR: 0.000063
2025-05-13 13:29:47,616 [INFO] Epoch 13/15 - Policy Loss: 1.7703, Value Loss: 0.2381, Total Loss: 2.0084, LR: 0.001687
2025-05-13 13:30:22,724 [INFO] Epoch 14/15 - Policy Loss: 1.7675, Value Loss: 0.2375, Total Loss: 2.0049, LR: 0.003337
2025-05-13 13:30:57,953 [INFO] Epoch 15/15 - Policy Loss: 1.7669, Value Loss: 0.2373, Total Loss: 2.0042, LR: 0.004987
2025-05-13 13:30:57,975 [INFO] 训练完成，总损失: 2.0042
2025-05-13 13:30:57,975 [INFO] 保存迭代 7 的模型
2025-05-13 13:30:59,400 [INFO] Model saved to ./models/best.pt
2025-05-13 13:31:00,663 [INFO] Model saved to ./models/iteration_7.pt
2025-05-13 13:31:00,664 [INFO] 所有训练迭代完成
2025-05-13 13:31:00,664 [INFO] 开始迭代 8/300
2025-05-13 13:31:00,664 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 13:44:41,388 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 13:44:41,388 [INFO] 保存训练样本
2025-05-13 13:44:45,485 [INFO] 使用 135168 个样本训练神经网络
2025-05-13 13:44:45,485 [INFO] Training with 135168 examples
2025-05-13 13:44:45,486 [INFO] 总训练步数: 1980, 每轮次批次数: 132
2025-05-13 13:44:45,902 [INFO] 循环学习率周期大小: 396 步
2025-05-13 13:45:20,897 [INFO] Epoch 1/15 - Policy Loss: 1.8304, Value Loss: 0.2605, Total Loss: 2.0909, LR: 0.001688
2025-05-13 13:45:55,999 [INFO] Epoch 2/15 - Policy Loss: 1.8048, Value Loss: 0.2547, Total Loss: 2.0595, LR: 0.003338
2025-05-13 13:46:31,093 [INFO] Epoch 3/15 - Policy Loss: 1.8001, Value Loss: 0.2528, Total Loss: 2.0529, LR: 0.004988
2025-05-13 13:47:06,473 [INFO] Epoch 4/15 - Policy Loss: 1.8026, Value Loss: 0.2530, Total Loss: 2.0556, LR: 0.003363
2025-05-13 13:47:41,811 [INFO] Epoch 5/15 - Policy Loss: 1.7952, Value Loss: 0.2509, Total Loss: 2.0461, LR: 0.001712
2025-05-13 13:48:17,070 [INFO] Epoch 6/15 - Policy Loss: 1.7856, Value Loss: 0.2483, Total Loss: 2.0339, LR: 0.000062
2025-05-13 13:48:52,497 [INFO] Epoch 7/15 - Policy Loss: 1.7781, Value Loss: 0.2465, Total Loss: 2.0246, LR: 0.001688
2025-05-13 13:49:27,872 [INFO] Epoch 8/15 - Policy Loss: 1.7729, Value Loss: 0.2451, Total Loss: 2.0180, LR: 0.003338
2025-05-13 13:50:03,232 [INFO] Epoch 9/15 - Policy Loss: 1.7704, Value Loss: 0.2445, Total Loss: 2.0149, LR: 0.004988
2025-05-13 13:50:38,614 [INFO] Epoch 10/15 - Policy Loss: 1.7692, Value Loss: 0.2441, Total Loss: 2.0133, LR: 0.003363
2025-05-13 13:51:14,105 [INFO] Epoch 11/15 - Policy Loss: 1.7667, Value Loss: 0.2436, Total Loss: 2.0103, LR: 0.001712
2025-05-13 13:51:49,431 [INFO] Epoch 12/15 - Policy Loss: 1.7631, Value Loss: 0.2426, Total Loss: 2.0057, LR: 0.000062
2025-05-13 13:52:24,892 [INFO] Epoch 13/15 - Policy Loss: 1.7599, Value Loss: 0.2416, Total Loss: 2.0015, LR: 0.001688
2025-05-13 13:53:00,406 [INFO] Epoch 14/15 - Policy Loss: 1.7575, Value Loss: 0.2411, Total Loss: 1.9986, LR: 0.003338
2025-05-13 13:53:35,761 [INFO] Epoch 15/15 - Policy Loss: 1.7570, Value Loss: 0.2407, Total Loss: 1.9977, LR: 0.004988
2025-05-13 13:53:35,786 [INFO] 训练完成，总损失: 1.9977
2025-05-13 13:53:35,786 [INFO] 保存迭代 8 的模型
2025-05-13 13:53:37,311 [INFO] Model saved to ./models/best.pt
2025-05-13 13:53:38,625 [INFO] Model saved to ./models/iteration_8.pt
2025-05-13 13:53:38,625 [INFO] 所有训练迭代完成
2025-05-13 13:53:38,625 [INFO] 开始迭代 9/300
2025-05-13 13:53:38,625 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 14:05:48,196 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 14:05:48,197 [INFO] 保存训练样本
2025-05-13 14:05:52,453 [INFO] 使用 135464 个样本训练神经网络
2025-05-13 14:05:52,453 [INFO] Training with 135464 examples
2025-05-13 14:05:52,454 [INFO] 总训练步数: 1980, 每轮次批次数: 132
2025-05-13 14:05:52,922 [INFO] 循环学习率周期大小: 396 步
2025-05-13 14:06:27,827 [INFO] Epoch 1/15 - Policy Loss: 1.8043, Value Loss: 0.2513, Total Loss: 2.0556, LR: 0.001688
2025-05-13 14:07:02,979 [INFO] Epoch 2/15 - Policy Loss: 1.7894, Value Loss: 0.2456, Total Loss: 2.0351, LR: 0.003338
2025-05-13 14:07:38,218 [INFO] Epoch 3/15 - Policy Loss: 1.7876, Value Loss: 0.2432, Total Loss: 2.0307, LR: 0.004988
2025-05-13 14:08:13,267 [INFO] Epoch 4/15 - Policy Loss: 1.7885, Value Loss: 0.2426, Total Loss: 2.0311, LR: 0.003363
2025-05-13 14:08:48,420 [INFO] Epoch 5/15 - Policy Loss: 1.7844, Value Loss: 0.2413, Total Loss: 2.0257, LR: 0.001712
2025-05-13 14:09:23,624 [INFO] Epoch 6/15 - Policy Loss: 1.7783, Value Loss: 0.2395, Total Loss: 2.0178, LR: 0.000062
2025-05-13 14:09:58,936 [INFO] Epoch 7/15 - Policy Loss: 1.7722, Value Loss: 0.2375, Total Loss: 2.0097, LR: 0.001688
2025-05-13 14:10:34,064 [INFO] Epoch 8/15 - Policy Loss: 1.7670, Value Loss: 0.2365, Total Loss: 2.0035, LR: 0.003338
2025-05-13 14:11:09,401 [INFO] Epoch 9/15 - Policy Loss: 1.7661, Value Loss: 0.2356, Total Loss: 2.0017, LR: 0.004988
2025-05-13 14:11:44,709 [INFO] Epoch 10/15 - Policy Loss: 1.7680, Value Loss: 0.2357, Total Loss: 2.0037, LR: 0.003363
2025-05-13 14:12:20,078 [INFO] Epoch 11/15 - Policy Loss: 1.7666, Value Loss: 0.2351, Total Loss: 2.0017, LR: 0.001712
2025-05-13 14:12:55,671 [INFO] Epoch 12/15 - Policy Loss: 1.7641, Value Loss: 0.2346, Total Loss: 1.9986, LR: 0.000062
2025-05-13 14:13:31,160 [INFO] Epoch 13/15 - Policy Loss: 1.7612, Value Loss: 0.2337, Total Loss: 1.9949, LR: 0.001688
2025-05-13 14:14:06,704 [INFO] Epoch 14/15 - Policy Loss: 1.7587, Value Loss: 0.2330, Total Loss: 1.9917, LR: 0.003338
2025-05-13 14:14:42,323 [INFO] Epoch 15/15 - Policy Loss: 1.7579, Value Loss: 0.2325, Total Loss: 1.9904, LR: 0.004988
2025-05-13 14:14:42,348 [INFO] 训练完成，总损失: 1.9904
2025-05-13 14:14:42,348 [INFO] 保存迭代 9 的模型
2025-05-13 14:14:43,929 [INFO] Model saved to ./models/best.pt
2025-05-13 14:14:45,178 [INFO] Model saved to ./models/iteration_9.pt
2025-05-13 14:14:45,178 [INFO] 所有训练迭代完成
2025-05-13 14:14:45,178 [INFO] 开始迭代 10/300
2025-05-13 14:14:45,178 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 14:29:03,344 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 14:29:03,345 [INFO] 保存训练样本
2025-05-13 14:29:07,521 [INFO] 使用 137400 个样本训练神经网络
2025-05-13 14:29:07,521 [INFO] Training with 137400 examples
2025-05-13 14:29:07,521 [INFO] 总训练步数: 2010, 每轮次批次数: 134
2025-05-13 14:29:07,913 [INFO] 循环学习率周期大小: 402 步
2025-05-13 14:29:43,484 [INFO] Epoch 1/15 - Policy Loss: 1.8083, Value Loss: 0.2478, Total Loss: 2.0561, LR: 0.001688
2025-05-13 14:30:19,030 [INFO] Epoch 2/15 - Policy Loss: 1.7863, Value Loss: 0.2417, Total Loss: 2.0280, LR: 0.003338
2025-05-13 14:30:54,687 [INFO] Epoch 3/15 - Policy Loss: 1.7791, Value Loss: 0.2397, Total Loss: 2.0188, LR: 0.004988
2025-05-13 14:31:30,195 [INFO] Epoch 4/15 - Policy Loss: 1.7801, Value Loss: 0.2400, Total Loss: 2.0201, LR: 0.003362
2025-05-13 14:32:05,916 [INFO] Epoch 5/15 - Policy Loss: 1.7756, Value Loss: 0.2384, Total Loss: 2.0139, LR: 0.001712
2025-05-13 14:32:41,685 [INFO] Epoch 6/15 - Policy Loss: 1.7675, Value Loss: 0.2362, Total Loss: 2.0038, LR: 0.000062
2025-05-13 14:33:17,314 [INFO] Epoch 7/15 - Policy Loss: 1.7604, Value Loss: 0.2342, Total Loss: 1.9946, LR: 0.001688
2025-05-13 14:33:53,127 [INFO] Epoch 8/15 - Policy Loss: 1.7561, Value Loss: 0.2330, Total Loss: 1.9891, LR: 0.003338
2025-05-13 14:34:28,973 [INFO] Epoch 9/15 - Policy Loss: 1.7539, Value Loss: 0.2325, Total Loss: 1.9864, LR: 0.004988
2025-05-13 14:35:05,249 [INFO] Epoch 10/15 - Policy Loss: 1.7544, Value Loss: 0.2324, Total Loss: 1.9869, LR: 0.003362
2025-05-13 14:35:41,017 [INFO] Epoch 11/15 - Policy Loss: 1.7529, Value Loss: 0.2319, Total Loss: 1.9849, LR: 0.001712
2025-05-13 14:36:16,939 [INFO] Epoch 12/15 - Policy Loss: 1.7501, Value Loss: 0.2312, Total Loss: 1.9812, LR: 0.000062
2025-05-13 14:36:52,951 [INFO] Epoch 13/15 - Policy Loss: 1.7469, Value Loss: 0.2305, Total Loss: 1.9774, LR: 0.001688
2025-05-13 14:37:28,955 [INFO] Epoch 14/15 - Policy Loss: 1.7451, Value Loss: 0.2302, Total Loss: 1.9753, LR: 0.003338
2025-05-13 14:38:04,919 [INFO] Epoch 15/15 - Policy Loss: 1.7449, Value Loss: 0.2299, Total Loss: 1.9748, LR: 0.004988
2025-05-13 14:38:04,941 [INFO] 训练完成，总损失: 1.9748
2025-05-13 14:38:04,941 [INFO] 保存迭代 10 的模型
2025-05-13 14:38:06,308 [INFO] Model saved to ./models/best.pt
2025-05-13 14:38:07,027 [INFO] Model saved to ./models/iteration_10.pt
2025-05-13 14:38:07,028 [INFO] 所有训练迭代完成
2025-05-13 14:38:07,028 [INFO] 开始迭代 11/300
2025-05-13 14:38:07,028 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 14:51:57,655 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 14:51:57,655 [INFO] 保存训练样本
2025-05-13 14:52:02,313 [INFO] 使用 138472 个样本训练神经网络
2025-05-13 14:52:02,314 [INFO] Training with 138472 examples
2025-05-13 14:52:02,314 [INFO] 总训练步数: 2025, 每轮次批次数: 135
2025-05-13 14:52:02,369 [INFO] 循环学习率周期大小: 405 步
2025-05-13 14:52:38,056 [INFO] Epoch 1/15 - Policy Loss: 1.7849, Value Loss: 0.2380, Total Loss: 2.0229, LR: 0.001688
2025-05-13 14:53:14,149 [INFO] Epoch 2/15 - Policy Loss: 1.7688, Value Loss: 0.2306, Total Loss: 1.9994, LR: 0.003338
2025-05-13 14:53:50,096 [INFO] Epoch 3/15 - Policy Loss: 1.7656, Value Loss: 0.2296, Total Loss: 1.9952, LR: 0.004988
2025-05-13 14:54:26,009 [INFO] Epoch 4/15 - Policy Loss: 1.7685, Value Loss: 0.2292, Total Loss: 1.9976, LR: 0.003362
2025-05-13 14:55:01,960 [INFO] Epoch 5/15 - Policy Loss: 1.7632, Value Loss: 0.2279, Total Loss: 1.9910, LR: 0.001712
2025-05-13 14:55:37,923 [INFO] Epoch 6/15 - Policy Loss: 1.7555, Value Loss: 0.2266, Total Loss: 1.9821, LR: 0.000062
2025-05-13 14:56:14,396 [INFO] Epoch 7/15 - Policy Loss: 1.7494, Value Loss: 0.2253, Total Loss: 1.9748, LR: 0.001688
2025-05-13 14:56:50,419 [INFO] Epoch 8/15 - Policy Loss: 1.7456, Value Loss: 0.2245, Total Loss: 1.9700, LR: 0.003338
2025-05-13 14:57:26,378 [INFO] Epoch 9/15 - Policy Loss: 1.7434, Value Loss: 0.2242, Total Loss: 1.9677, LR: 0.004988
2025-05-13 14:58:02,498 [INFO] Epoch 10/15 - Policy Loss: 1.7441, Value Loss: 0.2246, Total Loss: 1.9687, LR: 0.003362
2025-05-13 14:58:38,701 [INFO] Epoch 11/15 - Policy Loss: 1.7426, Value Loss: 0.2243, Total Loss: 1.9669, LR: 0.001712
2025-05-13 14:59:14,931 [INFO] Epoch 12/15 - Policy Loss: 1.7399, Value Loss: 0.2234, Total Loss: 1.9633, LR: 0.000062
2025-05-13 14:59:51,178 [INFO] Epoch 13/15 - Policy Loss: 1.7376, Value Loss: 0.2229, Total Loss: 1.9605, LR: 0.001688
2025-05-13 15:00:27,394 [INFO] Epoch 14/15 - Policy Loss: 1.7359, Value Loss: 0.2224, Total Loss: 1.9582, LR: 0.003338
2025-05-13 15:01:03,610 [INFO] Epoch 15/15 - Policy Loss: 1.7352, Value Loss: 0.2221, Total Loss: 1.9573, LR: 0.004988
2025-05-13 15:01:03,634 [INFO] 训练完成，总损失: 1.9573
2025-05-13 15:01:03,634 [INFO] 保存迭代 11 的模型
2025-05-13 15:01:04,954 [INFO] Model saved to ./models/best.pt
2025-05-13 15:01:05,806 [INFO] Model saved to ./models/iteration_11.pt
2025-05-13 15:01:05,807 [INFO] 所有训练迭代完成
2025-05-13 15:01:05,807 [INFO] 开始迭代 12/300
2025-05-13 15:01:05,807 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 15:15:02,085 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 15:15:02,085 [INFO] 保存训练样本
2025-05-13 15:15:06,696 [INFO] 使用 140408 个样本训练神经网络
2025-05-13 15:15:06,697 [INFO] Training with 140408 examples
2025-05-13 15:15:06,697 [INFO] 总训练步数: 2055, 每轮次批次数: 137
2025-05-13 15:15:06,756 [INFO] 循环学习率周期大小: 411 步
2025-05-13 15:15:42,964 [INFO] Epoch 1/15 - Policy Loss: 1.7800, Value Loss: 0.2494, Total Loss: 2.0294, LR: 0.001688
2025-05-13 15:16:19,491 [INFO] Epoch 2/15 - Policy Loss: 1.7595, Value Loss: 0.2431, Total Loss: 2.0026, LR: 0.003338
2025-05-13 15:16:55,844 [INFO] Epoch 3/15 - Policy Loss: 1.7525, Value Loss: 0.2399, Total Loss: 1.9925, LR: 0.004988
2025-05-13 15:17:32,082 [INFO] Epoch 4/15 - Policy Loss: 1.7514, Value Loss: 0.2378, Total Loss: 1.9892, LR: 0.003362
2025-05-13 15:18:08,490 [INFO] Epoch 5/15 - Policy Loss: 1.7457, Value Loss: 0.2351, Total Loss: 1.9808, LR: 0.001712
2025-05-13 15:18:44,729 [INFO] Epoch 6/15 - Policy Loss: 1.7394, Value Loss: 0.2329, Total Loss: 1.9722, LR: 0.000062
2025-05-13 15:19:21,173 [INFO] Epoch 7/15 - Policy Loss: 1.7331, Value Loss: 0.2306, Total Loss: 1.9636, LR: 0.001688
2025-05-13 15:19:57,628 [INFO] Epoch 8/15 - Policy Loss: 1.7291, Value Loss: 0.2286, Total Loss: 1.9577, LR: 0.003338
2025-05-13 15:20:33,988 [INFO] Epoch 9/15 - Policy Loss: 1.7286, Value Loss: 0.2274, Total Loss: 1.9560, LR: 0.004988
2025-05-13 15:21:10,502 [INFO] Epoch 10/15 - Policy Loss: 1.7290, Value Loss: 0.2272, Total Loss: 1.9562, LR: 0.003362
2025-05-13 15:21:46,999 [INFO] Epoch 11/15 - Policy Loss: 1.7274, Value Loss: 0.2264, Total Loss: 1.9538, LR: 0.001712
2025-05-13 15:22:23,695 [INFO] Epoch 12/15 - Policy Loss: 1.7249, Value Loss: 0.2255, Total Loss: 1.9504, LR: 0.000062
2025-05-13 15:23:00,443 [INFO] Epoch 13/15 - Policy Loss: 1.7226, Value Loss: 0.2245, Total Loss: 1.9471, LR: 0.001688
2025-05-13 15:23:37,170 [INFO] Epoch 14/15 - Policy Loss: 1.7207, Value Loss: 0.2239, Total Loss: 1.9446, LR: 0.003338
2025-05-13 15:24:14,037 [INFO] Epoch 15/15 - Policy Loss: 1.7197, Value Loss: 0.2234, Total Loss: 1.9431, LR: 0.004988
2025-05-13 15:24:14,063 [INFO] 训练完成，总损失: 1.9431
2025-05-13 15:24:14,063 [INFO] 保存迭代 12 的模型
2025-05-13 15:24:15,489 [INFO] Model saved to ./models/best.pt
2025-05-13 15:24:16,229 [INFO] Model saved to ./models/iteration_12.pt
2025-05-13 15:24:16,229 [INFO] 所有训练迭代完成
2025-05-13 15:24:16,229 [INFO] 开始迭代 13/300
2025-05-13 15:24:16,229 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 15:37:38,448 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 15:37:38,449 [INFO] 保存训练样本
2025-05-13 15:37:43,139 [INFO] 使用 141440 个样本训练神经网络
2025-05-13 15:37:43,140 [INFO] Training with 141440 examples
2025-05-13 15:37:43,140 [INFO] 总训练步数: 2070, 每轮次批次数: 138
2025-05-13 15:37:43,557 [INFO] 循环学习率周期大小: 414 步
2025-05-13 15:38:20,069 [INFO] Epoch 1/15 - Policy Loss: 1.7654, Value Loss: 0.2350, Total Loss: 2.0004, LR: 0.001688
2025-05-13 15:38:56,759 [INFO] Epoch 2/15 - Policy Loss: 1.7503, Value Loss: 0.2295, Total Loss: 1.9799, LR: 0.003338
2025-05-13 15:39:33,256 [INFO] Epoch 3/15 - Policy Loss: 1.7424, Value Loss: 0.2273, Total Loss: 1.9697, LR: 0.004988
2025-05-13 15:40:09,830 [INFO] Epoch 4/15 - Policy Loss: 1.7417, Value Loss: 0.2266, Total Loss: 1.9683, LR: 0.003362
2025-05-13 15:40:46,454 [INFO] Epoch 5/15 - Policy Loss: 1.7377, Value Loss: 0.2248, Total Loss: 1.9625, LR: 0.001712
2025-05-13 15:41:23,168 [INFO] Epoch 6/15 - Policy Loss: 1.7316, Value Loss: 0.2229, Total Loss: 1.9545, LR: 0.000062
2025-05-13 15:41:59,839 [INFO] Epoch 7/15 - Policy Loss: 1.7266, Value Loss: 0.2214, Total Loss: 1.9480, LR: 0.001688
2025-05-13 15:42:36,434 [INFO] Epoch 8/15 - Policy Loss: 1.7229, Value Loss: 0.2203, Total Loss: 1.9433, LR: 0.003338
2025-05-13 15:43:13,214 [INFO] Epoch 9/15 - Policy Loss: 1.7221, Value Loss: 0.2196, Total Loss: 1.9417, LR: 0.004988
2025-05-13 15:43:49,921 [INFO] Epoch 10/15 - Policy Loss: 1.7226, Value Loss: 0.2194, Total Loss: 1.9420, LR: 0.003362
2025-05-13 15:44:26,593 [INFO] Epoch 11/15 - Policy Loss: 1.7213, Value Loss: 0.2185, Total Loss: 1.9398, LR: 0.001712
2025-05-13 15:45:03,479 [INFO] Epoch 12/15 - Policy Loss: 1.7190, Value Loss: 0.2178, Total Loss: 1.9367, LR: 0.000062
2025-05-13 15:45:40,330 [INFO] Epoch 13/15 - Policy Loss: 1.7172, Value Loss: 0.2169, Total Loss: 1.9340, LR: 0.001688
2025-05-13 15:46:17,212 [INFO] Epoch 14/15 - Policy Loss: 1.7155, Value Loss: 0.2163, Total Loss: 1.9318, LR: 0.003338
2025-05-13 15:46:54,263 [INFO] Epoch 15/15 - Policy Loss: 1.7154, Value Loss: 0.2161, Total Loss: 1.9315, LR: 0.004988
2025-05-13 15:46:54,288 [INFO] 训练完成，总损失: 1.9315
2025-05-13 15:46:54,288 [INFO] 保存迭代 13 的模型
2025-05-13 15:46:55,597 [INFO] Model saved to ./models/best.pt
2025-05-13 15:46:56,659 [INFO] Model saved to ./models/iteration_13.pt
2025-05-13 15:46:56,659 [INFO] 所有训练迭代完成
2025-05-13 15:46:56,659 [INFO] 开始迭代 14/300
2025-05-13 15:46:56,659 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 16:00:36,815 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 16:00:36,815 [INFO] 保存训练样本
2025-05-13 16:00:40,429 [INFO] 使用 143048 个样本训练神经网络
2025-05-13 16:00:40,429 [INFO] Training with 143048 examples
2025-05-13 16:00:40,430 [INFO] 总训练步数: 2085, 每轮次批次数: 139
2025-05-13 16:00:40,861 [INFO] 循环学习率周期大小: 417 步
2025-05-13 16:01:17,791 [INFO] Epoch 1/15 - Policy Loss: 1.7855, Value Loss: 0.2484, Total Loss: 2.0339, LR: 0.001688
2025-05-13 16:01:54,699 [INFO] Epoch 2/15 - Policy Loss: 1.7686, Value Loss: 0.2362, Total Loss: 2.0048, LR: 0.003338
2025-05-13 16:02:31,577 [INFO] Epoch 3/15 - Policy Loss: 1.7623, Value Loss: 0.2309, Total Loss: 1.9931, LR: 0.004988
2025-05-13 16:03:08,643 [INFO] Epoch 4/15 - Policy Loss: 1.7608, Value Loss: 0.2285, Total Loss: 1.9893, LR: 0.003362
2025-05-13 16:03:45,584 [INFO] Epoch 5/15 - Policy Loss: 1.7529, Value Loss: 0.2254, Total Loss: 1.9783, LR: 0.001712
2025-05-13 16:04:22,552 [INFO] Epoch 6/15 - Policy Loss: 1.7440, Value Loss: 0.2223, Total Loss: 1.9663, LR: 0.000062
2025-05-13 16:04:59,704 [INFO] Epoch 7/15 - Policy Loss: 1.7376, Value Loss: 0.2200, Total Loss: 1.9576, LR: 0.001688
2025-05-13 16:05:36,670 [INFO] Epoch 8/15 - Policy Loss: 1.7317, Value Loss: 0.2185, Total Loss: 1.9502, LR: 0.003338
2025-05-13 16:06:13,652 [INFO] Epoch 9/15 - Policy Loss: 1.7294, Value Loss: 0.2175, Total Loss: 1.9469, LR: 0.004988
2025-05-13 16:06:50,985 [INFO] Epoch 10/15 - Policy Loss: 1.7292, Value Loss: 0.2169, Total Loss: 1.9461, LR: 0.003362
2025-05-13 16:07:28,188 [INFO] Epoch 11/15 - Policy Loss: 1.7276, Value Loss: 0.2161, Total Loss: 1.9438, LR: 0.001712
2025-05-13 16:08:05,244 [INFO] Epoch 12/15 - Policy Loss: 1.7251, Value Loss: 0.2154, Total Loss: 1.9404, LR: 0.000062
2025-05-13 16:08:42,493 [INFO] Epoch 13/15 - Policy Loss: 1.7221, Value Loss: 0.2145, Total Loss: 1.9366, LR: 0.001688
2025-05-13 16:09:19,869 [INFO] Epoch 14/15 - Policy Loss: 1.7197, Value Loss: 0.2137, Total Loss: 1.9334, LR: 0.003338
2025-05-13 16:09:57,175 [INFO] Epoch 15/15 - Policy Loss: 1.7191, Value Loss: 0.2132, Total Loss: 1.9323, LR: 0.004988
2025-05-13 16:09:57,200 [INFO] 训练完成，总损失: 1.9323
2025-05-13 16:09:57,200 [INFO] 保存迭代 14 的模型
2025-05-13 16:09:58,513 [INFO] Model saved to ./models/best.pt
2025-05-13 16:09:59,353 [INFO] Model saved to ./models/iteration_14.pt
2025-05-13 16:09:59,354 [INFO] 所有训练迭代完成
2025-05-13 16:09:59,354 [INFO] 开始迭代 15/300
2025-05-13 16:09:59,354 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 16:24:46,974 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 16:24:46,975 [INFO] 保存训练样本
2025-05-13 16:24:52,063 [INFO] 使用 144560 个样本训练神经网络
2025-05-13 16:24:52,063 [INFO] Training with 144560 examples
2025-05-13 16:24:52,064 [INFO] 总训练步数: 2115, 每轮次批次数: 141
2025-05-13 16:24:52,125 [INFO] 循环学习率周期大小: 423 步
2025-05-13 16:25:29,669 [INFO] Epoch 1/15 - Policy Loss: 1.7560, Value Loss: 0.2282, Total Loss: 1.9842, LR: 0.001688
2025-05-13 16:26:07,354 [INFO] Epoch 2/15 - Policy Loss: 1.7502, Value Loss: 0.2206, Total Loss: 1.9708, LR: 0.003338
2025-05-13 16:26:45,035 [INFO] Epoch 3/15 - Policy Loss: 1.7433, Value Loss: 0.2163, Total Loss: 1.9596, LR: 0.004988
2025-05-13 16:27:22,872 [INFO] Epoch 4/15 - Policy Loss: 1.7442, Value Loss: 0.2152, Total Loss: 1.9594, LR: 0.003362
2025-05-13 16:28:00,604 [INFO] Epoch 5/15 - Policy Loss: 1.7386, Value Loss: 0.2131, Total Loss: 1.9517, LR: 0.001712
2025-05-13 16:28:38,750 [INFO] Epoch 6/15 - Policy Loss: 1.7318, Value Loss: 0.2111, Total Loss: 1.9430, LR: 0.000062
2025-05-13 16:29:16,584 [INFO] Epoch 7/15 - Policy Loss: 1.7261, Value Loss: 0.2094, Total Loss: 1.9355, LR: 0.001688
2025-05-13 16:29:54,366 [INFO] Epoch 8/15 - Policy Loss: 1.7218, Value Loss: 0.2082, Total Loss: 1.9300, LR: 0.003338
2025-05-13 16:30:32,210 [INFO] Epoch 9/15 - Policy Loss: 1.7201, Value Loss: 0.2074, Total Loss: 1.9275, LR: 0.004988
2025-05-13 16:31:10,084 [INFO] Epoch 10/15 - Policy Loss: 1.7211, Value Loss: 0.2068, Total Loss: 1.9279, LR: 0.003362
2025-05-13 16:31:48,083 [INFO] Epoch 11/15 - Policy Loss: 1.7185, Value Loss: 0.2059, Total Loss: 1.9245, LR: 0.001712
2025-05-13 16:32:26,012 [INFO] Epoch 12/15 - Policy Loss: 1.7161, Value Loss: 0.2051, Total Loss: 1.9212, LR: 0.000062
2025-05-13 16:33:04,033 [INFO] Epoch 13/15 - Policy Loss: 1.7129, Value Loss: 0.2046, Total Loss: 1.9174, LR: 0.001688
2025-05-13 16:33:42,138 [INFO] Epoch 14/15 - Policy Loss: 1.7114, Value Loss: 0.2040, Total Loss: 1.9154, LR: 0.003338
2025-05-13 16:34:20,172 [INFO] Epoch 15/15 - Policy Loss: 1.7106, Value Loss: 0.2037, Total Loss: 1.9142, LR: 0.004988
2025-05-13 16:34:20,195 [INFO] 训练完成，总损失: 1.9142
2025-05-13 16:34:20,195 [INFO] 保存迭代 15 的模型
2025-05-13 16:34:21,338 [INFO] Model saved to ./models/best.pt
2025-05-13 16:34:22,189 [INFO] Model saved to ./models/iteration_15.pt
2025-05-13 16:34:22,189 [INFO] 所有训练迭代完成
2025-05-13 16:34:22,189 [INFO] 开始迭代 16/300
2025-05-13 16:34:22,189 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 16:47:39,896 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 16:47:39,896 [INFO] 保存训练样本
2025-05-13 16:47:44,865 [INFO] 使用 145200 个样本训练神经网络
2025-05-13 16:47:44,865 [INFO] Training with 145200 examples
2025-05-13 16:47:44,866 [INFO] 总训练步数: 2115, 每轮次批次数: 141
2025-05-13 16:47:44,931 [INFO] 循环学习率周期大小: 423 步
2025-05-13 16:48:22,270 [INFO] Epoch 1/15 - Policy Loss: 1.7395, Value Loss: 0.2212, Total Loss: 1.9607, LR: 0.001688
2025-05-13 16:49:00,250 [INFO] Epoch 2/15 - Policy Loss: 1.7299, Value Loss: 0.2159, Total Loss: 1.9458, LR: 0.003338
2025-05-13 16:49:37,848 [INFO] Epoch 3/15 - Policy Loss: 1.7303, Value Loss: 0.2137, Total Loss: 1.9440, LR: 0.004988
2025-05-13 16:50:15,537 [INFO] Epoch 4/15 - Policy Loss: 1.7311, Value Loss: 0.2138, Total Loss: 1.9449, LR: 0.003362
2025-05-13 16:50:53,093 [INFO] Epoch 5/15 - Policy Loss: 1.7270, Value Loss: 0.2118, Total Loss: 1.9388, LR: 0.001712
2025-05-13 16:51:30,789 [INFO] Epoch 6/15 - Policy Loss: 1.7216, Value Loss: 0.2096, Total Loss: 1.9312, LR: 0.000062
2025-05-13 16:52:08,538 [INFO] Epoch 7/15 - Policy Loss: 1.7159, Value Loss: 0.2079, Total Loss: 1.9238, LR: 0.001688
2025-05-13 16:52:46,326 [INFO] Epoch 8/15 - Policy Loss: 1.7131, Value Loss: 0.2067, Total Loss: 1.9198, LR: 0.003338
2025-05-13 16:53:24,105 [INFO] Epoch 9/15 - Policy Loss: 1.7118, Value Loss: 0.2060, Total Loss: 1.9178, LR: 0.004988
2025-05-13 16:54:01,972 [INFO] Epoch 10/15 - Policy Loss: 1.7124, Value Loss: 0.2053, Total Loss: 1.9177, LR: 0.003362
2025-05-13 16:54:39,831 [INFO] Epoch 11/15 - Policy Loss: 1.7111, Value Loss: 0.2043, Total Loss: 1.9154, LR: 0.001712
2025-05-13 16:55:17,755 [INFO] Epoch 12/15 - Policy Loss: 1.7091, Value Loss: 0.2034, Total Loss: 1.9125, LR: 0.000062
2025-05-13 16:55:55,582 [INFO] Epoch 13/15 - Policy Loss: 1.7063, Value Loss: 0.2025, Total Loss: 1.9088, LR: 0.001688
2025-05-13 16:56:33,466 [INFO] Epoch 14/15 - Policy Loss: 1.7044, Value Loss: 0.2018, Total Loss: 1.9062, LR: 0.003338
2025-05-13 16:57:11,435 [INFO] Epoch 15/15 - Policy Loss: 1.7037, Value Loss: 0.2013, Total Loss: 1.9050, LR: 0.004988
2025-05-13 16:57:11,461 [INFO] 训练完成，总损失: 1.9050
2025-05-13 16:57:11,461 [INFO] 保存迭代 16 的模型
2025-05-13 16:57:12,601 [INFO] Model saved to ./models/best.pt
2025-05-13 16:57:13,652 [INFO] Model saved to ./models/iteration_16.pt
2025-05-13 16:57:13,652 [INFO] 所有训练迭代完成
2025-05-13 16:57:13,652 [INFO] 开始迭代 17/300
2025-05-13 16:57:13,652 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 17:12:35,826 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 17:12:35,827 [INFO] 保存训练样本
2025-05-13 17:12:40,518 [INFO] 使用 147832 个样本训练神经网络
2025-05-13 17:12:40,518 [INFO] Training with 147832 examples
2025-05-13 17:12:40,519 [INFO] 总训练步数: 2160, 每轮次批次数: 144
2025-05-13 17:12:41,077 [INFO] 循环学习率周期大小: 432 步
2025-05-13 17:13:19,396 [INFO] Epoch 1/15 - Policy Loss: 1.7432, Value Loss: 0.2190, Total Loss: 1.9621, LR: 0.001689
2025-05-13 17:13:57,602 [INFO] Epoch 2/15 - Policy Loss: 1.7263, Value Loss: 0.2127, Total Loss: 1.9391, LR: 0.003339
2025-05-13 17:14:35,980 [INFO] Epoch 3/15 - Policy Loss: 1.7212, Value Loss: 0.2100, Total Loss: 1.9312, LR: 0.004989
2025-05-13 17:15:14,340 [INFO] Epoch 4/15 - Policy Loss: 1.7202, Value Loss: 0.2092, Total Loss: 1.9293, LR: 0.003361
2025-05-13 17:15:52,593 [INFO] Epoch 5/15 - Policy Loss: 1.7150, Value Loss: 0.2071, Total Loss: 1.9221, LR: 0.001711
2025-05-13 17:16:31,096 [INFO] Epoch 6/15 - Policy Loss: 1.7093, Value Loss: 0.2048, Total Loss: 1.9141, LR: 0.000061
2025-05-13 17:17:09,513 [INFO] Epoch 7/15 - Policy Loss: 1.7042, Value Loss: 0.2031, Total Loss: 1.9073, LR: 0.001689
2025-05-13 17:17:48,091 [INFO] Epoch 8/15 - Policy Loss: 1.7017, Value Loss: 0.2019, Total Loss: 1.9036, LR: 0.003339
2025-05-13 17:18:26,713 [INFO] Epoch 9/15 - Policy Loss: 1.6999, Value Loss: 0.2008, Total Loss: 1.9007, LR: 0.004989
2025-05-13 17:19:05,363 [INFO] Epoch 10/15 - Policy Loss: 1.7002, Value Loss: 0.2007, Total Loss: 1.9009, LR: 0.003361
2025-05-13 17:19:43,985 [INFO] Epoch 11/15 - Policy Loss: 1.6994, Value Loss: 0.2000, Total Loss: 1.8994, LR: 0.001711
2025-05-13 17:20:22,607 [INFO] Epoch 12/15 - Policy Loss: 1.6972, Value Loss: 0.1992, Total Loss: 1.8965, LR: 0.000061
2025-05-13 17:21:01,340 [INFO] Epoch 13/15 - Policy Loss: 1.6946, Value Loss: 0.1983, Total Loss: 1.8929, LR: 0.001689
2025-05-13 17:21:39,946 [INFO] Epoch 14/15 - Policy Loss: 1.6927, Value Loss: 0.1977, Total Loss: 1.8904, LR: 0.003339
2025-05-13 17:22:18,506 [INFO] Epoch 15/15 - Policy Loss: 1.6926, Value Loss: 0.1974, Total Loss: 1.8900, LR: 0.004989
2025-05-13 17:22:18,529 [INFO] 训练完成，总损失: 1.8900
2025-05-13 17:22:18,530 [INFO] 保存迭代 17 的模型
2025-05-13 17:22:19,897 [INFO] Model saved to ./models/best.pt
2025-05-13 17:22:20,944 [INFO] Model saved to ./models/iteration_17.pt
2025-05-13 17:22:20,944 [INFO] 所有训练迭代完成
2025-05-13 17:22:20,944 [INFO] 开始迭代 18/300
2025-05-13 17:22:20,945 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 17:35:37,992 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 17:35:37,992 [INFO] 保存训练样本
2025-05-13 17:35:42,687 [INFO] 使用 147928 个样本训练神经网络
2025-05-13 17:35:42,687 [INFO] Training with 147928 examples
2025-05-13 17:35:42,687 [INFO] 总训练步数: 2160, 每轮次批次数: 144
2025-05-13 17:35:43,209 [INFO] 循环学习率周期大小: 432 步
2025-05-13 22:16:04,089 [INFO] 设置多进程启动方法为: spawn
2025-05-13 22:16:04,358 [INFO] CUDA可用，使用GPU
2025-05-13 22:16:04,358 [INFO] 配置参数:
2025-05-13 22:16:04,358 [INFO] 训练参数:
2025-05-13 22:16:04,358 [INFO]   训练轮数: 15
2025-05-13 22:16:04,358 [INFO]   批量大小: 1024
2025-05-13 22:16:04,358 [INFO]   迭代次数: 300
2025-05-13 22:16:04,358 [INFO]   每次迭代的自我对弈次数: 50
2025-05-13 22:16:04,358 [INFO]   训练样本队列最大长度: 200000
2025-05-13 22:16:04,358 [INFO]   保留的历史迭代数: 20
2025-05-13 22:16:04,358 [INFO]   新模型胜率阈值: 0.55
2025-05-13 22:16:04,359 [INFO]   竞技场比赛次数: 40
2025-05-13 22:16:04,359 [INFO]   温度阈值: 5
2025-05-13 22:16:04,359 [INFO] 神经网络参数:
2025-05-13 22:16:04,359 [INFO]   通道数: 256
2025-05-13 22:16:04,359 [INFO]   Dropout率: 0.3
2025-05-13 22:16:04,359 [INFO]   学习率范围: 5e-05 - 0.005
2025-05-13 22:16:04,359 [INFO]   梯度裁剪: 1.0
2025-05-13 22:16:04,359 [INFO]   优化器: adam
2025-05-13 22:16:04,359 [INFO] MCTS参数:
2025-05-13 22:16:04,359 [INFO]   模拟次数: 800
2025-05-13 22:16:04,359 [INFO]   PUCT常数: 4.0
2025-05-13 22:16:04,359 [INFO]   Dirichlet噪声参数: 0.3
2025-05-13 22:16:04,359 [INFO]   Dirichlet噪声权重: 0.25
2025-05-13 22:16:04,359 [INFO] 游戏参数:
2025-05-13 22:16:04,359 [INFO]   棋盘大小: 15
2025-05-13 22:16:04,359 [INFO]   获胜所需的连续棋子数: 5
2025-05-13 22:16:04,359 [INFO] 系统参数:
2025-05-13 22:16:04,359 [INFO]   使用CUDA: True
2025-05-13 22:16:04,359 [INFO]   检查点目录: ./models
2025-05-13 22:16:04,359 [INFO]   数据目录: ./data
2025-05-13 22:16:04,359 [INFO]   加载模型: False
2025-05-13 22:16:04,359 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-05-13 22:16:04,359 [INFO]   工作线程数: 4
2025-05-13 22:16:04,359 [INFO]   使用Weights & Biases: False
2025-05-13 22:16:04,360 [INFO] GUI参数:
2025-05-13 22:16:04,360 [INFO]   窗口宽度: 800
2025-05-13 22:16:04,360 [INFO]   窗口高度: 850
2025-05-13 22:16:04,360 [INFO]   格子大小: 40
2025-05-13 22:16:04,360 [INFO]   边距: 40
2025-05-13 22:16:04,360 [INFO]   底部边距: 80
2025-05-13 22:16:04,360 [INFO]   帧率: 30
2025-05-13 22:16:04,830 [INFO] Using device: cuda
2025-05-13 22:16:06,340 [INFO] 设置循环学习率: 最小值=5e-05, 最大值=0.005
2025-05-13 22:16:06,340 [INFO] 设置并行进程数为: 8
2025-05-13 22:16:06,340 [INFO] 开始训练
2025-05-13 22:16:06,341 [INFO] 加载之前的训练样本
2025-05-13 22:16:07,956 [INFO] 加载了 20 组训练样本
2025-05-13 22:16:07,957 [INFO] 开始迭代 1/300
2025-05-13 22:16:07,957 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 23:01:53,296 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 23:01:53,307 [INFO] 保存训练样本
2025-05-13 23:01:59,110 [INFO] 使用 160256 个样本训练神经网络
2025-05-13 23:01:59,110 [INFO] Training with 160256 examples
2025-05-13 23:01:59,111 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-13 23:01:59,188 [INFO] 循环学习率周期大小: 468 步
2025-05-13 23:02:41,843 [INFO] Epoch 1/15 - Policy Loss: 4.0638, Value Loss: 0.7440, Total Loss: 4.8078, LR: 0.001689
2025-05-13 23:03:24,044 [INFO] Epoch 2/15 - Policy Loss: 3.6028, Value Loss: 0.6456, Total Loss: 4.2483, LR: 0.003339
2025-05-13 23:04:06,742 [INFO] Epoch 3/15 - Policy Loss: 3.3791, Value Loss: 0.5880, Total Loss: 3.9671, LR: 0.004989
2025-05-13 23:04:48,841 [INFO] Epoch 4/15 - Policy Loss: 3.2268, Value Loss: 0.5417, Total Loss: 3.7685, LR: 0.003361
2025-05-13 23:05:30,966 [INFO] Epoch 5/15 - Policy Loss: 3.1050, Value Loss: 0.4987, Total Loss: 3.6037, LR: 0.001711
2025-05-13 23:06:13,007 [INFO] Epoch 6/15 - Policy Loss: 3.0077, Value Loss: 0.4612, Total Loss: 3.4689, LR: 0.000061
2025-05-13 23:06:55,263 [INFO] Epoch 7/15 - Policy Loss: 2.9329, Value Loss: 0.4319, Total Loss: 3.3648, LR: 0.001689
2025-05-13 23:07:37,475 [INFO] Epoch 8/15 - Policy Loss: 2.8814, Value Loss: 0.4132, Total Loss: 3.2946, LR: 0.003339
2025-05-13 23:08:19,648 [INFO] Epoch 9/15 - Policy Loss: 2.8460, Value Loss: 0.4006, Total Loss: 3.2467, LR: 0.004989
2025-05-13 23:09:01,941 [INFO] Epoch 10/15 - Policy Loss: 2.8139, Value Loss: 0.3884, Total Loss: 3.2023, LR: 0.003361
2025-05-13 23:09:44,185 [INFO] Epoch 11/15 - Policy Loss: 2.7784, Value Loss: 0.3744, Total Loss: 3.1527, LR: 0.001711
2025-05-13 23:10:26,497 [INFO] Epoch 12/15 - Policy Loss: 2.7417, Value Loss: 0.3608, Total Loss: 3.1026, LR: 0.000061
2025-05-13 23:11:08,729 [INFO] Epoch 13/15 - Policy Loss: 2.7092, Value Loss: 0.3486, Total Loss: 3.0578, LR: 0.001689
2025-05-13 23:11:51,001 [INFO] Epoch 14/15 - Policy Loss: 2.6830, Value Loss: 0.3387, Total Loss: 3.0217, LR: 0.003339
2025-05-13 23:12:33,243 [INFO] Epoch 15/15 - Policy Loss: 2.6653, Value Loss: 0.3325, Total Loss: 2.9978, LR: 0.004989
2025-05-13 23:12:33,274 [INFO] 训练完成，总损失: 2.9978
2025-05-13 23:12:33,274 [INFO] 保存迭代 1 的模型
2025-05-13 23:12:35,470 [INFO] Model saved to ./models/best.pt
2025-05-13 23:12:37,609 [INFO] Model saved to ./models/iteration_1.pt
2025-05-13 23:12:37,610 [INFO] 所有训练迭代完成
2025-05-13 23:12:37,610 [INFO] 开始迭代 2/300
2025-05-13 23:12:37,610 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 23:31:58,675 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 23:31:58,675 [INFO] 保存训练样本
2025-05-13 23:32:04,829 [INFO] 使用 163704 个样本训练神经网络
2025-05-13 23:32:04,830 [INFO] Training with 163704 examples
2025-05-13 23:32:04,830 [INFO] 总训练步数: 2385, 每轮次批次数: 159
2025-05-13 23:32:05,467 [INFO] 循环学习率周期大小: 477 步
2025-05-13 23:32:47,843 [INFO] Epoch 1/15 - Policy Loss: 2.4482, Value Loss: 0.2419, Total Loss: 2.6902, LR: 0.001690
2025-05-13 23:33:30,376 [INFO] Epoch 2/15 - Policy Loss: 2.4155, Value Loss: 0.2322, Total Loss: 2.6477, LR: 0.003340
2025-05-13 23:34:12,875 [INFO] Epoch 3/15 - Policy Loss: 2.4183, Value Loss: 0.2335, Total Loss: 2.6519, LR: 0.004990
2025-05-13 23:34:55,337 [INFO] Epoch 4/15 - Policy Loss: 2.4171, Value Loss: 0.2346, Total Loss: 2.6517, LR: 0.003360
2025-05-13 23:35:37,755 [INFO] Epoch 5/15 - Policy Loss: 2.3993, Value Loss: 0.2287, Total Loss: 2.6280, LR: 0.001710
2025-05-13 23:36:20,330 [INFO] Epoch 6/15 - Policy Loss: 2.3760, Value Loss: 0.2219, Total Loss: 2.5979, LR: 0.000060
2025-05-13 23:37:02,955 [INFO] Epoch 7/15 - Policy Loss: 2.3571, Value Loss: 0.2167, Total Loss: 2.5738, LR: 0.001690
2025-05-13 23:37:45,636 [INFO] Epoch 8/15 - Policy Loss: 2.3452, Value Loss: 0.2133, Total Loss: 2.5584, LR: 0.003340
2025-05-13 23:38:28,392 [INFO] Epoch 9/15 - Policy Loss: 2.3420, Value Loss: 0.2127, Total Loss: 2.5547, LR: 0.004990
2025-05-13 23:39:11,094 [INFO] Epoch 10/15 - Policy Loss: 2.3419, Value Loss: 0.2131, Total Loss: 2.5551, LR: 0.003360
2025-05-13 23:39:53,852 [INFO] Epoch 11/15 - Policy Loss: 2.3351, Value Loss: 0.2115, Total Loss: 2.5466, LR: 0.001710
2025-05-13 23:40:36,732 [INFO] Epoch 12/15 - Policy Loss: 2.3250, Value Loss: 0.2090, Total Loss: 2.5340, LR: 0.000060
2025-05-13 23:41:19,589 [INFO] Epoch 13/15 - Policy Loss: 2.3152, Value Loss: 0.2064, Total Loss: 2.5216, LR: 0.001690
2025-05-13 23:42:02,251 [INFO] Epoch 14/15 - Policy Loss: 2.3080, Value Loss: 0.2047, Total Loss: 2.5127, LR: 0.003340
2025-05-13 23:42:45,398 [INFO] Epoch 15/15 - Policy Loss: 2.3061, Value Loss: 0.2044, Total Loss: 2.5105, LR: 0.004990
2025-05-13 23:42:45,425 [INFO] 训练完成，总损失: 2.5105
2025-05-13 23:42:45,425 [INFO] 保存迭代 2 的模型
2025-05-13 23:42:47,040 [INFO] Model saved to ./models/best.pt
2025-05-13 23:42:48,720 [INFO] Model saved to ./models/iteration_2.pt
2025-05-13 23:42:48,721 [INFO] 所有训练迭代完成
2025-05-13 23:42:48,721 [INFO] 开始迭代 3/300
2025-05-13 23:42:48,722 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-13 23:55:52,226 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-13 23:55:52,320 [INFO] 保存训练样本
2025-05-13 23:55:57,263 [INFO] 使用 151192 个样本训练神经网络
2025-05-13 23:55:57,263 [INFO] Training with 151192 examples
2025-05-13 23:55:57,263 [INFO] 总训练步数: 2205, 每轮次批次数: 147
2025-05-13 23:55:57,783 [INFO] 循环学习率周期大小: 441 步
2025-05-13 23:56:36,927 [INFO] Epoch 1/15 - Policy Loss: 1.8881, Value Loss: 0.2356, Total Loss: 2.1237, LR: 0.001689
2025-05-13 23:57:15,986 [INFO] Epoch 2/15 - Policy Loss: 1.8601, Value Loss: 0.2252, Total Loss: 2.0854, LR: 0.003339
2025-05-13 23:57:55,240 [INFO] Epoch 3/15 - Policy Loss: 1.8616, Value Loss: 0.2246, Total Loss: 2.0862, LR: 0.004989
2025-05-13 23:58:34,505 [INFO] Epoch 4/15 - Policy Loss: 1.8635, Value Loss: 0.2258, Total Loss: 2.0893, LR: 0.003361
2025-05-13 23:59:13,725 [INFO] Epoch 5/15 - Policy Loss: 1.8511, Value Loss: 0.2223, Total Loss: 2.0734, LR: 0.001711
2025-05-13 23:59:52,885 [INFO] Epoch 6/15 - Policy Loss: 1.8350, Value Loss: 0.2184, Total Loss: 2.0534, LR: 0.000061
2025-05-14 00:00:32,134 [INFO] Epoch 7/15 - Policy Loss: 1.8213, Value Loss: 0.2148, Total Loss: 2.0361, LR: 0.001689
2025-05-14 00:01:11,551 [INFO] Epoch 8/15 - Policy Loss: 1.8139, Value Loss: 0.2130, Total Loss: 2.0270, LR: 0.003339
2025-05-14 00:01:50,972 [INFO] Epoch 9/15 - Policy Loss: 1.8140, Value Loss: 0.2126, Total Loss: 2.0266, LR: 0.004989
2025-05-14 00:02:30,449 [INFO] Epoch 10/15 - Policy Loss: 1.8186, Value Loss: 0.2133, Total Loss: 2.0320, LR: 0.003361
2025-05-14 00:03:09,957 [INFO] Epoch 11/15 - Policy Loss: 1.8159, Value Loss: 0.2125, Total Loss: 2.0284, LR: 0.001711
2025-05-14 00:03:49,370 [INFO] Epoch 12/15 - Policy Loss: 1.8092, Value Loss: 0.2111, Total Loss: 2.0203, LR: 0.000061
2025-05-14 00:04:29,437 [INFO] Epoch 13/15 - Policy Loss: 1.8026, Value Loss: 0.2094, Total Loss: 2.0120, LR: 0.001689
2025-05-14 00:05:09,036 [INFO] Epoch 14/15 - Policy Loss: 1.7988, Value Loss: 0.2086, Total Loss: 2.0074, LR: 0.003339
2025-05-14 00:05:48,380 [INFO] Epoch 15/15 - Policy Loss: 1.7982, Value Loss: 0.2084, Total Loss: 2.0066, LR: 0.004989
2025-05-14 00:05:48,405 [INFO] 训练完成，总损失: 2.0066
2025-05-14 00:05:48,405 [INFO] 保存迭代 3 的模型
2025-05-14 00:05:49,819 [INFO] Model saved to ./models/best.pt
2025-05-14 00:05:51,223 [INFO] Model saved to ./models/iteration_3.pt
2025-05-14 00:05:51,224 [INFO] 所有训练迭代完成
2025-05-14 00:05:51,224 [INFO] 开始迭代 4/300
2025-05-14 00:05:51,224 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 00:22:29,991 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 00:22:29,991 [INFO] 保存训练样本
2025-05-14 00:22:34,849 [INFO] 使用 152664 个样本训练神经网络
2025-05-14 00:22:34,849 [INFO] Training with 152664 examples
2025-05-14 00:22:34,850 [INFO] 总训练步数: 2235, 每轮次批次数: 149
2025-05-14 00:22:35,385 [INFO] 循环学习率周期大小: 447 步
2025-05-14 00:23:14,999 [INFO] Epoch 1/15 - Policy Loss: 1.8219, Value Loss: 0.2369, Total Loss: 2.0588, LR: 0.001689
2025-05-14 00:23:54,733 [INFO] Epoch 2/15 - Policy Loss: 1.7972, Value Loss: 0.2270, Total Loss: 2.0242, LR: 0.003339
2025-05-14 00:24:34,475 [INFO] Epoch 3/15 - Policy Loss: 1.8023, Value Loss: 0.2244, Total Loss: 2.0266, LR: 0.004989
2025-05-14 00:25:14,170 [INFO] Epoch 4/15 - Policy Loss: 1.8094, Value Loss: 0.2246, Total Loss: 2.0340, LR: 0.003361
2025-05-14 00:25:53,993 [INFO] Epoch 5/15 - Policy Loss: 1.8014, Value Loss: 0.2206, Total Loss: 2.0220, LR: 0.001711
2025-05-14 00:26:33,840 [INFO] Epoch 6/15 - Policy Loss: 1.7883, Value Loss: 0.2161, Total Loss: 2.0045, LR: 0.000061
2025-05-14 00:27:13,642 [INFO] Epoch 7/15 - Policy Loss: 1.7786, Value Loss: 0.2126, Total Loss: 1.9913, LR: 0.001689
2025-05-14 00:27:53,422 [INFO] Epoch 8/15 - Policy Loss: 1.7706, Value Loss: 0.2102, Total Loss: 1.9808, LR: 0.003339
2025-05-14 00:28:33,918 [INFO] Epoch 9/15 - Policy Loss: 1.7690, Value Loss: 0.2088, Total Loss: 1.9778, LR: 0.004989
2025-05-14 00:29:13,759 [INFO] Epoch 10/15 - Policy Loss: 1.7707, Value Loss: 0.2081, Total Loss: 1.9788, LR: 0.003361
2025-05-14 00:29:53,593 [INFO] Epoch 11/15 - Policy Loss: 1.7681, Value Loss: 0.2071, Total Loss: 1.9752, LR: 0.001711
2025-05-14 00:30:33,627 [INFO] Epoch 12/15 - Policy Loss: 1.7629, Value Loss: 0.2055, Total Loss: 1.9684, LR: 0.000061
2025-05-14 00:31:13,705 [INFO] Epoch 13/15 - Policy Loss: 1.7575, Value Loss: 0.2039, Total Loss: 1.9613, LR: 0.001689
2025-05-14 00:31:53,769 [INFO] Epoch 14/15 - Policy Loss: 1.7535, Value Loss: 0.2027, Total Loss: 1.9562, LR: 0.003339
2025-05-14 00:32:33,863 [INFO] Epoch 15/15 - Policy Loss: 1.7529, Value Loss: 0.2021, Total Loss: 1.9550, LR: 0.004989
2025-05-14 00:32:33,891 [INFO] 训练完成，总损失: 1.9550
2025-05-14 00:32:33,891 [INFO] 保存迭代 4 的模型
2025-05-14 00:32:35,499 [INFO] Model saved to ./models/best.pt
2025-05-14 00:32:36,828 [INFO] Model saved to ./models/iteration_4.pt
2025-05-14 00:32:36,829 [INFO] 所有训练迭代完成
2025-05-14 00:32:36,829 [INFO] 开始迭代 5/300
2025-05-14 00:32:36,829 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 00:47:02,149 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 00:47:02,149 [INFO] 保存训练样本
2025-05-14 00:47:07,475 [INFO] 使用 153704 个样本训练神经网络
2025-05-14 00:47:07,475 [INFO] Training with 153704 examples
2025-05-14 00:47:07,476 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-14 00:47:07,547 [INFO] 循环学习率周期大小: 450 步
2025-05-14 00:47:47,349 [INFO] Epoch 1/15 - Policy Loss: 1.7846, Value Loss: 0.2180, Total Loss: 2.0026, LR: 0.001689
2025-05-14 00:48:27,041 [INFO] Epoch 2/15 - Policy Loss: 1.7576, Value Loss: 0.2103, Total Loss: 1.9679, LR: 0.003339
2025-05-14 00:49:07,505 [INFO] Epoch 3/15 - Policy Loss: 1.7581, Value Loss: 0.2078, Total Loss: 1.9659, LR: 0.004989
2025-05-14 00:49:47,348 [INFO] Epoch 4/15 - Policy Loss: 1.7637, Value Loss: 0.2078, Total Loss: 1.9715, LR: 0.003361
2025-05-14 00:50:27,230 [INFO] Epoch 5/15 - Policy Loss: 1.7552, Value Loss: 0.2049, Total Loss: 1.9602, LR: 0.001711
2025-05-14 00:51:07,215 [INFO] Epoch 6/15 - Policy Loss: 1.7436, Value Loss: 0.2020, Total Loss: 1.9456, LR: 0.000061
2025-05-14 00:51:47,301 [INFO] Epoch 7/15 - Policy Loss: 1.7347, Value Loss: 0.1990, Total Loss: 1.9337, LR: 0.001689
2025-05-14 00:52:27,312 [INFO] Epoch 8/15 - Policy Loss: 1.7288, Value Loss: 0.1974, Total Loss: 1.9262, LR: 0.003339
2025-05-14 00:53:07,449 [INFO] Epoch 9/15 - Policy Loss: 1.7287, Value Loss: 0.1966, Total Loss: 1.9252, LR: 0.004989
2025-05-14 00:53:47,633 [INFO] Epoch 10/15 - Policy Loss: 1.7312, Value Loss: 0.1967, Total Loss: 1.9279, LR: 0.003361
2025-05-14 00:54:27,786 [INFO] Epoch 11/15 - Policy Loss: 1.7303, Value Loss: 0.1961, Total Loss: 1.9264, LR: 0.001711
2025-05-14 00:55:08,049 [INFO] Epoch 12/15 - Policy Loss: 1.7281, Value Loss: 0.1950, Total Loss: 1.9231, LR: 0.000061
2025-05-14 00:55:48,265 [INFO] Epoch 13/15 - Policy Loss: 1.7249, Value Loss: 0.1940, Total Loss: 1.9190, LR: 0.001689
2025-05-14 00:56:28,477 [INFO] Epoch 14/15 - Policy Loss: 1.7216, Value Loss: 0.1932, Total Loss: 1.9147, LR: 0.003339
2025-05-14 00:57:08,775 [INFO] Epoch 15/15 - Policy Loss: 1.7204, Value Loss: 0.1927, Total Loss: 1.9131, LR: 0.004989
2025-05-14 00:57:08,803 [INFO] 训练完成，总损失: 1.9131
2025-05-14 00:57:08,803 [INFO] 保存迭代 5 的模型
2025-05-14 00:57:10,559 [INFO] Model saved to ./models/best.pt
2025-05-14 00:57:11,868 [INFO] Model saved to ./models/iteration_5.pt
2025-05-14 00:57:11,868 [INFO] 所有训练迭代完成
2025-05-14 00:57:11,869 [INFO] 开始迭代 6/300
2025-05-14 00:57:11,869 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 01:11:41,283 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 01:11:41,284 [INFO] 保存训练样本
2025-05-14 01:11:46,565 [INFO] 使用 154232 个样本训练神经网络
2025-05-14 01:11:46,565 [INFO] Training with 154232 examples
2025-05-14 01:11:46,566 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-14 01:11:47,122 [INFO] 循环学习率周期大小: 450 步
2025-05-14 01:12:26,721 [INFO] Epoch 1/15 - Policy Loss: 1.7418, Value Loss: 0.2032, Total Loss: 1.9449, LR: 0.001689
2025-05-14 01:13:06,525 [INFO] Epoch 2/15 - Policy Loss: 1.7209, Value Loss: 0.1957, Total Loss: 1.9167, LR: 0.003339
2025-05-14 01:13:46,420 [INFO] Epoch 3/15 - Policy Loss: 1.7200, Value Loss: 0.1946, Total Loss: 1.9146, LR: 0.004989
2025-05-14 01:14:26,392 [INFO] Epoch 4/15 - Policy Loss: 1.7255, Value Loss: 0.1963, Total Loss: 1.9218, LR: 0.003361
2025-05-14 01:15:07,057 [INFO] Epoch 5/15 - Policy Loss: 1.7208, Value Loss: 0.1944, Total Loss: 1.9152, LR: 0.001711
2025-05-14 01:15:47,260 [INFO] Epoch 6/15 - Policy Loss: 1.7117, Value Loss: 0.1922, Total Loss: 1.9039, LR: 0.000061
2025-05-14 01:16:27,439 [INFO] Epoch 7/15 - Policy Loss: 1.7038, Value Loss: 0.1906, Total Loss: 1.8944, LR: 0.001689
2025-05-14 01:17:07,765 [INFO] Epoch 8/15 - Policy Loss: 1.6986, Value Loss: 0.1890, Total Loss: 1.8876, LR: 0.003339
2025-05-14 01:17:47,905 [INFO] Epoch 9/15 - Policy Loss: 1.6986, Value Loss: 0.1885, Total Loss: 1.8871, LR: 0.004989
2025-05-14 01:18:28,167 [INFO] Epoch 10/15 - Policy Loss: 1.7003, Value Loss: 0.1888, Total Loss: 1.8890, LR: 0.003361
2025-05-14 01:19:08,549 [INFO] Epoch 11/15 - Policy Loss: 1.6994, Value Loss: 0.1884, Total Loss: 1.8877, LR: 0.001711
2025-05-14 01:19:48,816 [INFO] Epoch 12/15 - Policy Loss: 1.6957, Value Loss: 0.1875, Total Loss: 1.8832, LR: 0.000061
2025-05-14 01:20:29,017 [INFO] Epoch 13/15 - Policy Loss: 1.6923, Value Loss: 0.1866, Total Loss: 1.8788, LR: 0.001689
2025-05-14 01:21:09,377 [INFO] Epoch 14/15 - Policy Loss: 1.6898, Value Loss: 0.1859, Total Loss: 1.8756, LR: 0.003339
2025-05-14 01:21:49,704 [INFO] Epoch 15/15 - Policy Loss: 1.6894, Value Loss: 0.1855, Total Loss: 1.8749, LR: 0.004989
2025-05-14 01:21:49,733 [INFO] 训练完成，总损失: 1.8749
2025-05-14 01:21:49,734 [INFO] 保存迭代 6 的模型
2025-05-14 01:21:51,361 [INFO] Model saved to ./models/best.pt
2025-05-14 01:21:52,669 [INFO] Model saved to ./models/iteration_6.pt
2025-05-14 01:21:52,669 [INFO] 所有训练迭代完成
2025-05-14 01:21:52,669 [INFO] 开始迭代 7/300
2025-05-14 01:21:52,670 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 01:38:31,113 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 01:38:31,114 [INFO] 保存训练样本
2025-05-14 01:38:35,837 [INFO] 使用 155928 个样本训练神经网络
2025-05-14 01:38:35,837 [INFO] Training with 155928 examples
2025-05-14 01:38:35,837 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-14 01:38:36,424 [INFO] 循环学习率周期大小: 456 步
2025-05-14 01:39:16,872 [INFO] Epoch 1/15 - Policy Loss: 1.7436, Value Loss: 0.2058, Total Loss: 1.9494, LR: 0.001689
2025-05-14 01:39:57,418 [INFO] Epoch 2/15 - Policy Loss: 1.7145, Value Loss: 0.1964, Total Loss: 1.9110, LR: 0.003339
2025-05-14 01:40:37,794 [INFO] Epoch 3/15 - Policy Loss: 1.7089, Value Loss: 0.1941, Total Loss: 1.9031, LR: 0.004989
2025-05-14 01:41:18,304 [INFO] Epoch 4/15 - Policy Loss: 1.7104, Value Loss: 0.1931, Total Loss: 1.9035, LR: 0.003361
2025-05-14 01:41:58,608 [INFO] Epoch 5/15 - Policy Loss: 1.7048, Value Loss: 0.1907, Total Loss: 1.8955, LR: 0.001711
2025-05-14 01:42:39,151 [INFO] Epoch 6/15 - Policy Loss: 1.6955, Value Loss: 0.1885, Total Loss: 1.8840, LR: 0.000061
2025-05-14 01:43:19,803 [INFO] Epoch 7/15 - Policy Loss: 1.6882, Value Loss: 0.1863, Total Loss: 1.8745, LR: 0.001689
2025-05-14 01:44:00,471 [INFO] Epoch 8/15 - Policy Loss: 1.6838, Value Loss: 0.1847, Total Loss: 1.8686, LR: 0.003339
2025-05-14 01:44:41,018 [INFO] Epoch 9/15 - Policy Loss: 1.6821, Value Loss: 0.1840, Total Loss: 1.8661, LR: 0.004989
2025-05-14 01:45:21,735 [INFO] Epoch 10/15 - Policy Loss: 1.6833, Value Loss: 0.1843, Total Loss: 1.8676, LR: 0.003361
2025-05-14 01:46:02,508 [INFO] Epoch 11/15 - Policy Loss: 1.6820, Value Loss: 0.1838, Total Loss: 1.8658, LR: 0.001711
2025-05-14 01:46:43,826 [INFO] Epoch 12/15 - Policy Loss: 1.6782, Value Loss: 0.1829, Total Loss: 1.8611, LR: 0.000061
2025-05-14 01:47:24,654 [INFO] Epoch 13/15 - Policy Loss: 1.6743, Value Loss: 0.1820, Total Loss: 1.8563, LR: 0.001689
2025-05-14 01:48:05,481 [INFO] Epoch 14/15 - Policy Loss: 1.6713, Value Loss: 0.1812, Total Loss: 1.8525, LR: 0.003339
2025-05-14 01:48:46,327 [INFO] Epoch 15/15 - Policy Loss: 1.6704, Value Loss: 0.1808, Total Loss: 1.8512, LR: 0.004989
2025-05-14 01:48:46,355 [INFO] 训练完成，总损失: 1.8512
2025-05-14 01:48:46,355 [INFO] 保存迭代 7 的模型
2025-05-14 01:48:47,736 [INFO] Model saved to ./models/best.pt
2025-05-14 01:48:48,910 [INFO] Model saved to ./models/iteration_7.pt
2025-05-14 01:48:48,911 [INFO] 所有训练迭代完成
2025-05-14 01:48:48,911 [INFO] 开始迭代 8/300
2025-05-14 01:48:48,911 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 02:04:42,409 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 02:04:42,410 [INFO] 保存训练样本
2025-05-14 02:04:47,413 [INFO] 使用 157368 个样本训练神经网络
2025-05-14 02:04:47,413 [INFO] Training with 157368 examples
2025-05-14 02:04:47,414 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-14 02:04:48,017 [INFO] 循环学习率周期大小: 459 步
2025-05-14 02:05:28,674 [INFO] Epoch 1/15 - Policy Loss: 1.7128, Value Loss: 0.1978, Total Loss: 1.9105, LR: 0.001689
2025-05-14 02:06:09,595 [INFO] Epoch 2/15 - Policy Loss: 1.6928, Value Loss: 0.1910, Total Loss: 1.8837, LR: 0.003339
2025-05-14 02:06:50,437 [INFO] Epoch 3/15 - Policy Loss: 1.6889, Value Loss: 0.1879, Total Loss: 1.8768, LR: 0.004989
2025-05-14 02:07:31,241 [INFO] Epoch 4/15 - Policy Loss: 1.6908, Value Loss: 0.1878, Total Loss: 1.8786, LR: 0.003361
2025-05-14 02:08:12,244 [INFO] Epoch 5/15 - Policy Loss: 1.6848, Value Loss: 0.1858, Total Loss: 1.8706, LR: 0.001711
2025-05-14 02:08:53,111 [INFO] Epoch 6/15 - Policy Loss: 1.6752, Value Loss: 0.1838, Total Loss: 1.8590, LR: 0.000061
2025-05-14 02:09:34,135 [INFO] Epoch 7/15 - Policy Loss: 1.6675, Value Loss: 0.1819, Total Loss: 1.8494, LR: 0.001689
2025-05-14 02:10:15,796 [INFO] Epoch 8/15 - Policy Loss: 1.6615, Value Loss: 0.1806, Total Loss: 1.8421, LR: 0.003339
2025-05-14 02:10:56,888 [INFO] Epoch 9/15 - Policy Loss: 1.6599, Value Loss: 0.1800, Total Loss: 1.8399, LR: 0.004989
2025-05-14 02:11:37,975 [INFO] Epoch 10/15 - Policy Loss: 1.6602, Value Loss: 0.1802, Total Loss: 1.8403, LR: 0.003361
2025-05-14 02:12:19,041 [INFO] Epoch 11/15 - Policy Loss: 1.6590, Value Loss: 0.1797, Total Loss: 1.8387, LR: 0.001711
2025-05-14 02:13:00,336 [INFO] Epoch 12/15 - Policy Loss: 1.6554, Value Loss: 0.1790, Total Loss: 1.8344, LR: 0.000061
2025-05-14 02:13:41,528 [INFO] Epoch 13/15 - Policy Loss: 1.6525, Value Loss: 0.1782, Total Loss: 1.8307, LR: 0.001689
2025-05-14 02:14:22,770 [INFO] Epoch 14/15 - Policy Loss: 1.6503, Value Loss: 0.1774, Total Loss: 1.8277, LR: 0.003339
2025-05-14 02:15:03,878 [INFO] Epoch 15/15 - Policy Loss: 1.6497, Value Loss: 0.1773, Total Loss: 1.8269, LR: 0.004989
2025-05-14 02:15:03,905 [INFO] 训练完成，总损失: 1.8269
2025-05-14 02:15:03,905 [INFO] 保存迭代 8 的模型
2025-05-14 02:15:05,182 [INFO] Model saved to ./models/best.pt
2025-05-14 02:15:06,277 [INFO] Model saved to ./models/iteration_8.pt
2025-05-14 02:15:06,278 [INFO] 所有训练迭代完成
2025-05-14 02:15:06,278 [INFO] 开始迭代 9/300
2025-05-14 02:15:06,278 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 02:29:21,506 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 02:29:21,507 [INFO] 保存训练样本
2025-05-14 02:29:27,062 [INFO] 使用 157952 个样本训练神经网络
2025-05-14 02:29:27,062 [INFO] Training with 157952 examples
2025-05-14 02:29:27,063 [INFO] 总训练步数: 2310, 每轮次批次数: 154
2025-05-14 02:29:27,140 [INFO] 循环学习率周期大小: 462 步
2025-05-14 02:30:08,173 [INFO] Epoch 1/15 - Policy Loss: 1.6757, Value Loss: 0.1913, Total Loss: 1.8670, LR: 0.001689
2025-05-14 02:30:49,835 [INFO] Epoch 2/15 - Policy Loss: 1.6590, Value Loss: 0.1849, Total Loss: 1.8439, LR: 0.003339
2025-05-14 02:31:31,083 [INFO] Epoch 3/15 - Policy Loss: 1.6571, Value Loss: 0.1830, Total Loss: 1.8401, LR: 0.004989
2025-05-14 02:32:12,231 [INFO] Epoch 4/15 - Policy Loss: 1.6604, Value Loss: 0.1829, Total Loss: 1.8433, LR: 0.003361
2025-05-14 02:32:53,513 [INFO] Epoch 5/15 - Policy Loss: 1.6534, Value Loss: 0.1818, Total Loss: 1.8352, LR: 0.001711
2025-05-14 02:33:34,857 [INFO] Epoch 6/15 - Policy Loss: 1.6467, Value Loss: 0.1803, Total Loss: 1.8270, LR: 0.000061
2025-05-14 02:34:16,191 [INFO] Epoch 7/15 - Policy Loss: 1.6406, Value Loss: 0.1790, Total Loss: 1.8196, LR: 0.001689
2025-05-14 02:34:57,573 [INFO] Epoch 8/15 - Policy Loss: 1.6369, Value Loss: 0.1784, Total Loss: 1.8152, LR: 0.003339
2025-05-14 02:35:38,988 [INFO] Epoch 9/15 - Policy Loss: 1.6361, Value Loss: 0.1778, Total Loss: 1.8139, LR: 0.004989
2025-05-14 02:36:20,316 [INFO] Epoch 10/15 - Policy Loss: 1.6380, Value Loss: 0.1781, Total Loss: 1.8161, LR: 0.003361
2025-05-14 02:37:01,788 [INFO] Epoch 11/15 - Policy Loss: 1.6371, Value Loss: 0.1777, Total Loss: 1.8149, LR: 0.001711
2025-05-14 02:37:43,342 [INFO] Epoch 12/15 - Policy Loss: 1.6342, Value Loss: 0.1773, Total Loss: 1.8115, LR: 0.000061
2025-05-14 02:38:24,834 [INFO] Epoch 13/15 - Policy Loss: 1.6315, Value Loss: 0.1769, Total Loss: 1.8083, LR: 0.001689
2025-05-14 02:39:06,495 [INFO] Epoch 14/15 - Policy Loss: 1.6286, Value Loss: 0.1765, Total Loss: 1.8051, LR: 0.003339
2025-05-14 02:39:47,859 [INFO] Epoch 15/15 - Policy Loss: 1.6283, Value Loss: 0.1763, Total Loss: 1.8046, LR: 0.004989
2025-05-14 02:39:47,886 [INFO] 训练完成，总损失: 1.8046
2025-05-14 02:39:47,886 [INFO] 保存迭代 9 的模型
2025-05-14 02:39:49,481 [INFO] Model saved to ./models/best.pt
2025-05-14 02:39:50,739 [INFO] Model saved to ./models/iteration_9.pt
2025-05-14 02:39:50,740 [INFO] 所有训练迭代完成
2025-05-14 02:39:50,740 [INFO] 开始迭代 10/300
2025-05-14 02:39:50,740 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 02:55:32,419 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 02:55:32,419 [INFO] 保存训练样本
2025-05-14 02:55:37,652 [INFO] 使用 158648 个样本训练神经网络
2025-05-14 02:55:37,652 [INFO] Training with 158648 examples
2025-05-14 02:55:37,653 [INFO] 总训练步数: 2310, 每轮次批次数: 154
2025-05-14 02:55:38,218 [INFO] 循环学习率周期大小: 462 步
2025-05-14 02:56:18,986 [INFO] Epoch 1/15 - Policy Loss: 1.6642, Value Loss: 0.1961, Total Loss: 1.8603, LR: 0.001689
2025-05-14 02:56:59,865 [INFO] Epoch 2/15 - Policy Loss: 1.6526, Value Loss: 0.1900, Total Loss: 1.8427, LR: 0.003339
2025-05-14 02:57:40,884 [INFO] Epoch 3/15 - Policy Loss: 1.6482, Value Loss: 0.1878, Total Loss: 1.8360, LR: 0.004989
2025-05-14 02:58:21,756 [INFO] Epoch 4/15 - Policy Loss: 1.6510, Value Loss: 0.1879, Total Loss: 1.8389, LR: 0.003361
2025-05-14 02:59:02,690 [INFO] Epoch 5/15 - Policy Loss: 1.6472, Value Loss: 0.1859, Total Loss: 1.8332, LR: 0.001711
2025-05-14 02:59:43,748 [INFO] Epoch 6/15 - Policy Loss: 1.6395, Value Loss: 0.1834, Total Loss: 1.8228, LR: 0.000061
2025-05-14 03:00:24,817 [INFO] Epoch 7/15 - Policy Loss: 1.6340, Value Loss: 0.1818, Total Loss: 1.8158, LR: 0.001689
2025-05-14 03:01:06,016 [INFO] Epoch 8/15 - Policy Loss: 1.6293, Value Loss: 0.1801, Total Loss: 1.8094, LR: 0.003339
2025-05-14 03:01:47,036 [INFO] Epoch 9/15 - Policy Loss: 1.6275, Value Loss: 0.1794, Total Loss: 1.8069, LR: 0.004989
2025-05-14 03:02:28,284 [INFO] Epoch 10/15 - Policy Loss: 1.6275, Value Loss: 0.1789, Total Loss: 1.8064, LR: 0.003361
2025-05-14 03:03:09,603 [INFO] Epoch 11/15 - Policy Loss: 1.6257, Value Loss: 0.1782, Total Loss: 1.8039, LR: 0.001711
2025-05-14 03:03:50,822 [INFO] Epoch 12/15 - Policy Loss: 1.6228, Value Loss: 0.1772, Total Loss: 1.8000, LR: 0.000061
2025-05-14 03:04:31,916 [INFO] Epoch 13/15 - Policy Loss: 1.6191, Value Loss: 0.1764, Total Loss: 1.7955, LR: 0.001689
2025-05-14 03:05:13,148 [INFO] Epoch 14/15 - Policy Loss: 1.6175, Value Loss: 0.1759, Total Loss: 1.7934, LR: 0.003339
2025-05-14 03:05:54,340 [INFO] Epoch 15/15 - Policy Loss: 1.6174, Value Loss: 0.1757, Total Loss: 1.7930, LR: 0.004989
2025-05-14 03:05:54,366 [INFO] 训练完成，总损失: 1.7930
2025-05-14 03:05:54,366 [INFO] 保存迭代 10 的模型
2025-05-14 03:05:56,107 [INFO] Model saved to ./models/best.pt
2025-05-14 03:05:57,110 [INFO] Model saved to ./models/iteration_10.pt
2025-05-14 03:05:57,111 [INFO] 所有训练迭代完成
2025-05-14 03:05:57,111 [INFO] 开始迭代 11/300
2025-05-14 03:05:57,111 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 03:20:16,396 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 03:20:16,396 [INFO] 保存训练样本
2025-05-14 03:20:21,116 [INFO] 使用 159760 个样本训练神经网络
2025-05-14 03:20:21,117 [INFO] Training with 159760 examples
2025-05-14 03:20:21,117 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-14 03:20:21,745 [INFO] 循环学习率周期大小: 468 步
2025-05-14 03:21:03,334 [INFO] Epoch 1/15 - Policy Loss: 1.6499, Value Loss: 0.1990, Total Loss: 1.8489, LR: 0.001689
2025-05-14 03:21:45,013 [INFO] Epoch 2/15 - Policy Loss: 1.6386, Value Loss: 0.1923, Total Loss: 1.8309, LR: 0.003339
2025-05-14 03:22:26,724 [INFO] Epoch 3/15 - Policy Loss: 1.6324, Value Loss: 0.1899, Total Loss: 1.8223, LR: 0.004989
2025-05-14 03:23:08,424 [INFO] Epoch 4/15 - Policy Loss: 1.6339, Value Loss: 0.1890, Total Loss: 1.8229, LR: 0.003361
2025-05-14 03:23:50,149 [INFO] Epoch 5/15 - Policy Loss: 1.6285, Value Loss: 0.1871, Total Loss: 1.8156, LR: 0.001711
2025-05-14 03:24:31,896 [INFO] Epoch 6/15 - Policy Loss: 1.6219, Value Loss: 0.1844, Total Loss: 1.8063, LR: 0.000061
2025-05-14 03:25:13,813 [INFO] Epoch 7/15 - Policy Loss: 1.6159, Value Loss: 0.1825, Total Loss: 1.7983, LR: 0.001689
2025-05-14 03:25:55,585 [INFO] Epoch 8/15 - Policy Loss: 1.6122, Value Loss: 0.1808, Total Loss: 1.7931, LR: 0.003339
2025-05-14 03:26:37,952 [INFO] Epoch 9/15 - Policy Loss: 1.6103, Value Loss: 0.1800, Total Loss: 1.7902, LR: 0.004989
2025-05-14 03:27:19,837 [INFO] Epoch 10/15 - Policy Loss: 1.6110, Value Loss: 0.1796, Total Loss: 1.7905, LR: 0.003361
2025-05-14 03:28:01,716 [INFO] Epoch 11/15 - Policy Loss: 1.6094, Value Loss: 0.1789, Total Loss: 1.7883, LR: 0.001711
2025-05-14 03:28:43,658 [INFO] Epoch 12/15 - Policy Loss: 1.6065, Value Loss: 0.1780, Total Loss: 1.7845, LR: 0.000061
2025-05-14 03:29:25,747 [INFO] Epoch 13/15 - Policy Loss: 1.6035, Value Loss: 0.1772, Total Loss: 1.7806, LR: 0.001689
2025-05-14 03:30:07,767 [INFO] Epoch 14/15 - Policy Loss: 1.6017, Value Loss: 0.1764, Total Loss: 1.7782, LR: 0.003339
2025-05-14 03:30:49,808 [INFO] Epoch 15/15 - Policy Loss: 1.6011, Value Loss: 0.1761, Total Loss: 1.7771, LR: 0.004989
2025-05-14 03:30:49,839 [INFO] 训练完成，总损失: 1.7771
2025-05-14 03:30:49,839 [INFO] 保存迭代 11 的模型
2025-05-14 03:30:51,304 [INFO] Model saved to ./models/best.pt
2025-05-14 03:30:52,693 [INFO] Model saved to ./models/iteration_11.pt
2025-05-14 03:30:52,694 [INFO] 所有训练迭代完成
2025-05-14 03:30:52,694 [INFO] 开始迭代 12/300
2025-05-14 03:30:52,694 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 03:46:10,098 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 03:46:10,099 [INFO] 保存训练样本
2025-05-14 03:46:15,475 [INFO] 使用 160424 个样本训练神经网络
2025-05-14 03:46:15,476 [INFO] Training with 160424 examples
2025-05-14 03:46:15,476 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-14 03:46:15,553 [INFO] 循环学习率周期大小: 468 步
2025-05-14 03:46:57,143 [INFO] Epoch 1/15 - Policy Loss: 1.6359, Value Loss: 0.2007, Total Loss: 1.8366, LR: 0.001689
2025-05-14 03:47:38,753 [INFO] Epoch 2/15 - Policy Loss: 1.6227, Value Loss: 0.1945, Total Loss: 1.8172, LR: 0.003339
2025-05-14 03:48:20,442 [INFO] Epoch 3/15 - Policy Loss: 1.6212, Value Loss: 0.1919, Total Loss: 1.8131, LR: 0.004989
2025-05-14 03:49:02,008 [INFO] Epoch 4/15 - Policy Loss: 1.6233, Value Loss: 0.1917, Total Loss: 1.8150, LR: 0.003361
2025-05-14 03:49:44,087 [INFO] Epoch 5/15 - Policy Loss: 1.6199, Value Loss: 0.1890, Total Loss: 1.8088, LR: 0.001711
2025-05-14 03:50:25,887 [INFO] Epoch 6/15 - Policy Loss: 1.6126, Value Loss: 0.1866, Total Loss: 1.7993, LR: 0.000061
2025-05-14 03:51:07,756 [INFO] Epoch 7/15 - Policy Loss: 1.6069, Value Loss: 0.1843, Total Loss: 1.7912, LR: 0.001689
2025-05-14 03:51:49,740 [INFO] Epoch 8/15 - Policy Loss: 1.6031, Value Loss: 0.1827, Total Loss: 1.7858, LR: 0.003339
2025-05-14 03:52:31,620 [INFO] Epoch 9/15 - Policy Loss: 1.6018, Value Loss: 0.1818, Total Loss: 1.7836, LR: 0.004989
2025-05-14 03:53:13,591 [INFO] Epoch 10/15 - Policy Loss: 1.6034, Value Loss: 0.1816, Total Loss: 1.7850, LR: 0.003361
2025-05-14 03:53:55,431 [INFO] Epoch 11/15 - Policy Loss: 1.6024, Value Loss: 0.1810, Total Loss: 1.7834, LR: 0.001711
2025-05-14 03:54:37,235 [INFO] Epoch 12/15 - Policy Loss: 1.5998, Value Loss: 0.1800, Total Loss: 1.7799, LR: 0.000061
2025-05-14 03:55:19,397 [INFO] Epoch 13/15 - Policy Loss: 1.5960, Value Loss: 0.1790, Total Loss: 1.7750, LR: 0.001689
2025-05-14 03:56:01,374 [INFO] Epoch 14/15 - Policy Loss: 1.5946, Value Loss: 0.1783, Total Loss: 1.7729, LR: 0.003339
2025-05-14 03:56:43,390 [INFO] Epoch 15/15 - Policy Loss: 1.5957, Value Loss: 0.1780, Total Loss: 1.7738, LR: 0.004989
2025-05-14 03:56:43,420 [INFO] 训练完成，总损失: 1.7738
2025-05-14 03:56:43,421 [INFO] 保存迭代 12 的模型
2025-05-14 03:56:44,959 [INFO] Model saved to ./models/best.pt
2025-05-14 03:56:46,399 [INFO] Model saved to ./models/iteration_12.pt
2025-05-14 03:56:46,400 [INFO] 所有训练迭代完成
2025-05-14 03:56:46,400 [INFO] 开始迭代 13/300
2025-05-14 03:56:46,400 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 04:12:10,951 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 04:12:10,952 [INFO] 保存训练样本
2025-05-14 04:12:16,362 [INFO] 使用 161144 个样本训练神经网络
2025-05-14 04:12:16,362 [INFO] Training with 161144 examples
2025-05-14 04:12:16,363 [INFO] 总训练步数: 2355, 每轮次批次数: 157
2025-05-14 04:12:16,957 [INFO] 循环学习率周期大小: 471 步
2025-05-14 04:12:58,887 [INFO] Epoch 1/15 - Policy Loss: 1.6445, Value Loss: 0.2013, Total Loss: 1.8458, LR: 0.001689
2025-05-14 04:13:40,873 [INFO] Epoch 2/15 - Policy Loss: 1.6276, Value Loss: 0.1941, Total Loss: 1.8218, LR: 0.003339
2025-05-14 04:14:22,671 [INFO] Epoch 3/15 - Policy Loss: 1.6226, Value Loss: 0.1896, Total Loss: 1.8123, LR: 0.004989
2025-05-14 04:15:04,603 [INFO] Epoch 4/15 - Policy Loss: 1.6192, Value Loss: 0.1875, Total Loss: 1.8067, LR: 0.003361
2025-05-14 04:15:46,608 [INFO] Epoch 5/15 - Policy Loss: 1.6126, Value Loss: 0.1844, Total Loss: 1.7971, LR: 0.001711
2025-05-14 04:16:28,697 [INFO] Epoch 6/15 - Policy Loss: 1.6058, Value Loss: 0.1822, Total Loss: 1.7880, LR: 0.000061
2025-05-14 04:17:10,828 [INFO] Epoch 7/15 - Policy Loss: 1.5994, Value Loss: 0.1798, Total Loss: 1.7792, LR: 0.001689
2025-05-14 04:17:53,010 [INFO] Epoch 8/15 - Policy Loss: 1.5963, Value Loss: 0.1781, Total Loss: 1.7744, LR: 0.003339
2025-05-14 04:18:35,249 [INFO] Epoch 9/15 - Policy Loss: 1.5956, Value Loss: 0.1771, Total Loss: 1.7727, LR: 0.004989
2025-05-14 04:19:17,501 [INFO] Epoch 10/15 - Policy Loss: 1.5953, Value Loss: 0.1766, Total Loss: 1.7718, LR: 0.003361
2025-05-14 04:19:59,881 [INFO] Epoch 11/15 - Policy Loss: 1.5943, Value Loss: 0.1759, Total Loss: 1.7702, LR: 0.001711
2025-05-14 04:20:42,092 [INFO] Epoch 12/15 - Policy Loss: 1.5912, Value Loss: 0.1749, Total Loss: 1.7661, LR: 0.000061
2025-05-14 04:21:24,320 [INFO] Epoch 13/15 - Policy Loss: 1.5886, Value Loss: 0.1740, Total Loss: 1.7626, LR: 0.001689
2025-05-14 04:22:06,578 [INFO] Epoch 14/15 - Policy Loss: 1.5864, Value Loss: 0.1735, Total Loss: 1.7599, LR: 0.003339
2025-05-14 04:22:48,802 [INFO] Epoch 15/15 - Policy Loss: 1.5861, Value Loss: 0.1730, Total Loss: 1.7591, LR: 0.004989
2025-05-14 04:22:48,833 [INFO] 训练完成，总损失: 1.7591
2025-05-14 04:22:48,833 [INFO] 保存迭代 13 的模型
2025-05-14 04:22:50,437 [INFO] Model saved to ./models/best.pt
2025-05-14 04:22:51,664 [INFO] Model saved to ./models/iteration_13.pt
2025-05-14 04:22:51,664 [INFO] 所有训练迭代完成
2025-05-14 04:22:51,664 [INFO] 开始迭代 14/300
2025-05-14 04:22:51,664 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 04:37:47,241 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 04:37:47,242 [INFO] 保存训练样本
2025-05-14 04:37:52,283 [INFO] 使用 161944 个样本训练神经网络
2025-05-14 04:37:52,283 [INFO] Training with 161944 examples
2025-05-14 04:37:52,283 [INFO] 总训练步数: 2370, 每轮次批次数: 158
2025-05-14 04:37:52,887 [INFO] 循环学习率周期大小: 474 步
2025-05-14 04:38:34,780 [INFO] Epoch 1/15 - Policy Loss: 1.6152, Value Loss: 0.2025, Total Loss: 1.8177, LR: 0.001690
2025-05-14 04:39:16,872 [INFO] Epoch 2/15 - Policy Loss: 1.6063, Value Loss: 0.1921, Total Loss: 1.7985, LR: 0.003340
2025-05-14 04:39:59,171 [INFO] Epoch 3/15 - Policy Loss: 1.6031, Value Loss: 0.1876, Total Loss: 1.7907, LR: 0.004990
2025-05-14 04:40:41,318 [INFO] Epoch 4/15 - Policy Loss: 1.6033, Value Loss: 0.1855, Total Loss: 1.7888, LR: 0.003360
2025-05-14 04:41:23,461 [INFO] Epoch 5/15 - Policy Loss: 1.5982, Value Loss: 0.1830, Total Loss: 1.7812, LR: 0.001710
2025-05-14 04:42:05,943 [INFO] Epoch 6/15 - Policy Loss: 1.5932, Value Loss: 0.1808, Total Loss: 1.7741, LR: 0.000060
2025-05-14 04:42:48,166 [INFO] Epoch 7/15 - Policy Loss: 1.5864, Value Loss: 0.1789, Total Loss: 1.7653, LR: 0.001690
2025-05-14 04:43:30,629 [INFO] Epoch 8/15 - Policy Loss: 1.5828, Value Loss: 0.1773, Total Loss: 1.7601, LR: 0.003340
2025-05-14 04:44:13,159 [INFO] Epoch 9/15 - Policy Loss: 1.5812, Value Loss: 0.1763, Total Loss: 1.7575, LR: 0.004990
2025-05-14 04:44:55,719 [INFO] Epoch 10/15 - Policy Loss: 1.5821, Value Loss: 0.1758, Total Loss: 1.7579, LR: 0.003360
2025-05-14 04:45:38,209 [INFO] Epoch 11/15 - Policy Loss: 1.5809, Value Loss: 0.1753, Total Loss: 1.7561, LR: 0.001710
2025-05-14 04:46:21,278 [INFO] Epoch 12/15 - Policy Loss: 1.5787, Value Loss: 0.1747, Total Loss: 1.7534, LR: 0.000060
2025-05-14 04:47:03,747 [INFO] Epoch 13/15 - Policy Loss: 1.5761, Value Loss: 0.1738, Total Loss: 1.7499, LR: 0.001690
2025-05-14 04:47:46,411 [INFO] Epoch 14/15 - Policy Loss: 1.5744, Value Loss: 0.1731, Total Loss: 1.7474, LR: 0.003340
2025-05-14 04:48:29,002 [INFO] Epoch 15/15 - Policy Loss: 1.5741, Value Loss: 0.1727, Total Loss: 1.7468, LR: 0.004990
2025-05-14 04:48:29,032 [INFO] 训练完成，总损失: 1.7468
2025-05-14 04:48:29,032 [INFO] 保存迭代 14 的模型
2025-05-14 04:48:30,623 [INFO] Model saved to ./models/best.pt
2025-05-14 04:48:31,640 [INFO] Model saved to ./models/iteration_14.pt
2025-05-14 04:48:31,640 [INFO] 所有训练迭代完成
2025-05-14 04:48:31,641 [INFO] 开始迭代 15/300
2025-05-14 04:48:31,641 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 05:03:53,035 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 05:03:53,036 [INFO] 保存训练样本
2025-05-14 05:03:58,074 [INFO] 使用 163088 个样本训练神经网络
2025-05-14 05:03:58,074 [INFO] Training with 163088 examples
2025-05-14 05:03:58,075 [INFO] 总训练步数: 2385, 每轮次批次数: 159
2025-05-14 05:03:58,688 [INFO] 循环学习率周期大小: 477 步
2025-05-14 05:04:40,940 [INFO] Epoch 1/15 - Policy Loss: 1.6117, Value Loss: 0.1978, Total Loss: 1.8095, LR: 0.001690
2025-05-14 05:05:23,183 [INFO] Epoch 2/15 - Policy Loss: 1.5987, Value Loss: 0.1913, Total Loss: 1.7900, LR: 0.003340
2025-05-14 05:06:05,609 [INFO] Epoch 3/15 - Policy Loss: 1.5955, Value Loss: 0.1885, Total Loss: 1.7839, LR: 0.004990
2025-05-14 05:06:48,137 [INFO] Epoch 4/15 - Policy Loss: 1.5955, Value Loss: 0.1876, Total Loss: 1.7831, LR: 0.003360
2025-05-14 05:07:30,462 [INFO] Epoch 5/15 - Policy Loss: 1.5892, Value Loss: 0.1860, Total Loss: 1.7751, LR: 0.001710
2025-05-14 05:08:12,847 [INFO] Epoch 6/15 - Policy Loss: 1.5820, Value Loss: 0.1837, Total Loss: 1.7657, LR: 0.000060
2025-05-14 05:08:55,773 [INFO] Epoch 7/15 - Policy Loss: 1.5766, Value Loss: 0.1820, Total Loss: 1.7586, LR: 0.001690
2025-05-14 05:09:38,295 [INFO] Epoch 8/15 - Policy Loss: 1.5741, Value Loss: 0.1804, Total Loss: 1.7545, LR: 0.003340
2025-05-14 05:10:20,803 [INFO] Epoch 9/15 - Policy Loss: 1.5726, Value Loss: 0.1798, Total Loss: 1.7524, LR: 0.004990
2025-05-14 05:11:03,425 [INFO] Epoch 10/15 - Policy Loss: 1.5734, Value Loss: 0.1796, Total Loss: 1.7530, LR: 0.003360
2025-05-14 05:11:45,992 [INFO] Epoch 11/15 - Policy Loss: 1.5722, Value Loss: 0.1791, Total Loss: 1.7512, LR: 0.001710
2025-05-14 05:12:28,477 [INFO] Epoch 12/15 - Policy Loss: 1.5703, Value Loss: 0.1786, Total Loss: 1.7488, LR: 0.000060
2025-05-14 05:13:11,150 [INFO] Epoch 13/15 - Policy Loss: 1.5683, Value Loss: 0.1779, Total Loss: 1.7462, LR: 0.001690
2025-05-14 05:13:53,839 [INFO] Epoch 14/15 - Policy Loss: 1.5668, Value Loss: 0.1776, Total Loss: 1.7444, LR: 0.003340
2025-05-14 05:14:36,506 [INFO] Epoch 15/15 - Policy Loss: 1.5660, Value Loss: 0.1772, Total Loss: 1.7432, LR: 0.004990
2025-05-14 05:14:36,531 [INFO] 训练完成，总损失: 1.7432
2025-05-14 05:14:36,531 [INFO] 保存迭代 15 的模型
2025-05-14 05:14:37,602 [INFO] Model saved to ./models/best.pt
2025-05-14 05:14:38,530 [INFO] Model saved to ./models/iteration_15.pt
2025-05-14 05:14:38,531 [INFO] 所有训练迭代完成
2025-05-14 05:14:38,531 [INFO] 开始迭代 16/300
2025-05-14 05:14:38,531 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 05:29:54,622 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 05:29:54,623 [INFO] 保存训练样本
2025-05-14 05:30:00,424 [INFO] 使用 163760 个样本训练神经网络
2025-05-14 05:30:00,424 [INFO] Training with 163760 examples
2025-05-14 05:30:00,425 [INFO] 总训练步数: 2385, 每轮次批次数: 159
2025-05-14 05:30:00,503 [INFO] 循环学习率周期大小: 477 步
2025-05-14 05:30:42,759 [INFO] Epoch 1/15 - Policy Loss: 1.5897, Value Loss: 0.2002, Total Loss: 1.7899, LR: 0.001690
2025-05-14 05:31:25,768 [INFO] Epoch 2/15 - Policy Loss: 1.5754, Value Loss: 0.1941, Total Loss: 1.7695, LR: 0.003340
2025-05-14 05:32:08,352 [INFO] Epoch 3/15 - Policy Loss: 1.5740, Value Loss: 0.1917, Total Loss: 1.7657, LR: 0.004990
2025-05-14 05:32:50,741 [INFO] Epoch 4/15 - Policy Loss: 1.5746, Value Loss: 0.1904, Total Loss: 1.7649, LR: 0.003360
2025-05-14 05:33:33,238 [INFO] Epoch 5/15 - Policy Loss: 1.5685, Value Loss: 0.1885, Total Loss: 1.7570, LR: 0.001710
2025-05-14 05:34:15,891 [INFO] Epoch 6/15 - Policy Loss: 1.5640, Value Loss: 0.1870, Total Loss: 1.7511, LR: 0.000060
2025-05-14 05:34:58,494 [INFO] Epoch 7/15 - Policy Loss: 1.5590, Value Loss: 0.1854, Total Loss: 1.7444, LR: 0.001690
2025-05-14 05:35:41,124 [INFO] Epoch 8/15 - Policy Loss: 1.5548, Value Loss: 0.1841, Total Loss: 1.7389, LR: 0.003340
2025-05-14 05:36:23,761 [INFO] Epoch 9/15 - Policy Loss: 1.5532, Value Loss: 0.1834, Total Loss: 1.7365, LR: 0.004990
2025-05-14 05:37:06,282 [INFO] Epoch 10/15 - Policy Loss: 1.5539, Value Loss: 0.1833, Total Loss: 1.7373, LR: 0.003360
2025-05-14 05:37:48,779 [INFO] Epoch 11/15 - Policy Loss: 1.5538, Value Loss: 0.1829, Total Loss: 1.7367, LR: 0.001710
2025-05-14 05:38:31,314 [INFO] Epoch 12/15 - Policy Loss: 1.5515, Value Loss: 0.1822, Total Loss: 1.7337, LR: 0.000060
2025-05-14 05:39:13,976 [INFO] Epoch 13/15 - Policy Loss: 1.5492, Value Loss: 0.1817, Total Loss: 1.7309, LR: 0.001690
2025-05-14 05:39:56,546 [INFO] Epoch 14/15 - Policy Loss: 1.5475, Value Loss: 0.1811, Total Loss: 1.7286, LR: 0.003340
2025-05-14 05:40:39,207 [INFO] Epoch 15/15 - Policy Loss: 1.5469, Value Loss: 0.1808, Total Loss: 1.7278, LR: 0.004990
2025-05-14 05:40:39,232 [INFO] 训练完成，总损失: 1.7278
2025-05-14 05:40:39,232 [INFO] 保存迭代 16 的模型
2025-05-14 05:40:40,521 [INFO] Model saved to ./models/best.pt
2025-05-14 05:40:41,633 [INFO] Model saved to ./models/iteration_16.pt
2025-05-14 05:40:41,633 [INFO] 所有训练迭代完成
2025-05-14 05:40:41,634 [INFO] 开始迭代 17/300
2025-05-14 05:40:41,634 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 05:57:04,438 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 05:57:04,439 [INFO] 保存训练样本
2025-05-14 05:57:09,921 [INFO] 使用 164480 个样本训练神经网络
2025-05-14 05:57:09,921 [INFO] Training with 164480 examples
2025-05-14 05:57:09,922 [INFO] 总训练步数: 2400, 每轮次批次数: 160
2025-05-14 05:57:10,611 [INFO] 循环学习率周期大小: 480 步
2025-05-14 05:57:53,032 [INFO] Epoch 1/15 - Policy Loss: 1.5816, Value Loss: 0.2077, Total Loss: 1.7892, LR: 0.001690
2025-05-14 05:58:35,522 [INFO] Epoch 2/15 - Policy Loss: 1.5687, Value Loss: 0.2023, Total Loss: 1.7710, LR: 0.003340
2025-05-14 05:59:17,953 [INFO] Epoch 3/15 - Policy Loss: 1.5688, Value Loss: 0.1995, Total Loss: 1.7683, LR: 0.004990
2025-05-14 06:00:00,447 [INFO] Epoch 4/15 - Policy Loss: 1.5703, Value Loss: 0.1989, Total Loss: 1.7692, LR: 0.003360
2025-05-14 06:00:42,958 [INFO] Epoch 5/15 - Policy Loss: 1.5669, Value Loss: 0.1969, Total Loss: 1.7638, LR: 0.001710
2025-05-14 06:01:25,533 [INFO] Epoch 6/15 - Policy Loss: 1.5623, Value Loss: 0.1945, Total Loss: 1.7569, LR: 0.000060
2025-05-14 06:02:08,205 [INFO] Epoch 7/15 - Policy Loss: 1.5569, Value Loss: 0.1928, Total Loss: 1.7497, LR: 0.001690
2025-05-14 06:02:50,895 [INFO] Epoch 8/15 - Policy Loss: 1.5538, Value Loss: 0.1916, Total Loss: 1.7455, LR: 0.003340
2025-05-14 06:03:33,680 [INFO] Epoch 9/15 - Policy Loss: 1.5521, Value Loss: 0.1910, Total Loss: 1.7431, LR: 0.004990
2025-05-14 06:04:16,399 [INFO] Epoch 10/15 - Policy Loss: 1.5518, Value Loss: 0.1906, Total Loss: 1.7424, LR: 0.003360
2025-05-14 06:04:59,107 [INFO] Epoch 11/15 - Policy Loss: 1.5500, Value Loss: 0.1897, Total Loss: 1.7397, LR: 0.001710
2025-05-14 06:05:41,976 [INFO] Epoch 12/15 - Policy Loss: 1.5484, Value Loss: 0.1891, Total Loss: 1.7375, LR: 0.000060
2025-05-14 06:06:25,398 [INFO] Epoch 13/15 - Policy Loss: 1.5461, Value Loss: 0.1883, Total Loss: 1.7345, LR: 0.001690
2025-05-14 06:07:08,238 [INFO] Epoch 14/15 - Policy Loss: 1.5448, Value Loss: 0.1878, Total Loss: 1.7325, LR: 0.003340
2025-05-14 06:07:51,259 [INFO] Epoch 15/15 - Policy Loss: 1.5442, Value Loss: 0.1876, Total Loss: 1.7317, LR: 0.004990
2025-05-14 06:07:51,287 [INFO] 训练完成，总损失: 1.7317
2025-05-14 06:07:51,287 [INFO] 保存迭代 17 的模型
2025-05-14 06:07:52,801 [INFO] Model saved to ./models/best.pt
2025-05-14 06:07:53,993 [INFO] Model saved to ./models/iteration_17.pt
2025-05-14 06:07:53,994 [INFO] 所有训练迭代完成
2025-05-14 06:07:53,994 [INFO] 开始迭代 18/300
2025-05-14 06:07:53,994 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 06:24:09,562 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 06:24:09,563 [INFO] 保存训练样本
2025-05-14 06:24:14,216 [INFO] 使用 165872 个样本训练神经网络
2025-05-14 06:24:14,216 [INFO] Training with 165872 examples
2025-05-14 06:24:14,217 [INFO] 总训练步数: 2415, 每轮次批次数: 161
2025-05-14 06:24:14,720 [INFO] 循环学习率周期大小: 483 步
2025-05-14 06:24:57,278 [INFO] Epoch 1/15 - Policy Loss: 1.5748, Value Loss: 0.2243, Total Loss: 1.7991, LR: 0.001690
2025-05-14 06:25:40,042 [INFO] Epoch 2/15 - Policy Loss: 1.5672, Value Loss: 0.2144, Total Loss: 1.7816, LR: 0.003340
2025-05-14 06:26:23,053 [INFO] Epoch 3/15 - Policy Loss: 1.5647, Value Loss: 0.2116, Total Loss: 1.7764, LR: 0.004990
2025-05-14 06:27:05,827 [INFO] Epoch 4/15 - Policy Loss: 1.5637, Value Loss: 0.2096, Total Loss: 1.7733, LR: 0.003360
2025-05-14 06:27:48,697 [INFO] Epoch 5/15 - Policy Loss: 1.5584, Value Loss: 0.2065, Total Loss: 1.7649, LR: 0.001710
2025-05-14 06:28:31,872 [INFO] Epoch 6/15 - Policy Loss: 1.5523, Value Loss: 0.2037, Total Loss: 1.7560, LR: 0.000060
2025-05-14 06:29:14,698 [INFO] Epoch 7/15 - Policy Loss: 1.5468, Value Loss: 0.2013, Total Loss: 1.7481, LR: 0.001690
2025-05-14 06:29:58,312 [INFO] Epoch 8/15 - Policy Loss: 1.5433, Value Loss: 0.1998, Total Loss: 1.7431, LR: 0.003340
2025-05-14 06:30:41,268 [INFO] Epoch 9/15 - Policy Loss: 1.5413, Value Loss: 0.1986, Total Loss: 1.7399, LR: 0.004990
2025-05-14 06:31:24,205 [INFO] Epoch 10/15 - Policy Loss: 1.5411, Value Loss: 0.1979, Total Loss: 1.7390, LR: 0.003360
2025-05-14 06:32:07,380 [INFO] Epoch 11/15 - Policy Loss: 1.5392, Value Loss: 0.1968, Total Loss: 1.7360, LR: 0.001710
2025-05-14 06:32:50,426 [INFO] Epoch 12/15 - Policy Loss: 1.5369, Value Loss: 0.1956, Total Loss: 1.7325, LR: 0.000060
2025-05-14 06:33:33,538 [INFO] Epoch 13/15 - Policy Loss: 1.5345, Value Loss: 0.1946, Total Loss: 1.7291, LR: 0.001690
2025-05-14 06:34:16,664 [INFO] Epoch 14/15 - Policy Loss: 1.5327, Value Loss: 0.1938, Total Loss: 1.7265, LR: 0.003340
2025-05-14 06:34:59,595 [INFO] Epoch 15/15 - Policy Loss: 1.5328, Value Loss: 0.1932, Total Loss: 1.7260, LR: 0.004990
2025-05-14 06:34:59,620 [INFO] 训练完成，总损失: 1.7260
2025-05-14 06:34:59,621 [INFO] 保存迭代 18 的模型
2025-05-14 06:35:00,882 [INFO] Model saved to ./models/best.pt
2025-05-14 06:35:01,604 [INFO] Model saved to ./models/iteration_18.pt
2025-05-14 06:35:01,605 [INFO] 所有训练迭代完成
2025-05-14 06:35:01,605 [INFO] 开始迭代 19/300
2025-05-14 06:35:01,605 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 06:50:28,407 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 06:50:28,407 [INFO] 保存训练样本
2025-05-14 06:50:33,016 [INFO] 使用 165824 个样本训练神经网络
2025-05-14 06:50:33,016 [INFO] Training with 165824 examples
2025-05-14 06:50:33,022 [INFO] 总训练步数: 2415, 每轮次批次数: 161
2025-05-14 06:50:33,087 [INFO] 循环学习率周期大小: 483 步
2025-05-14 06:51:15,816 [INFO] Epoch 1/15 - Policy Loss: 1.5639, Value Loss: 0.2122, Total Loss: 1.7761, LR: 0.001690
2025-05-14 06:51:59,113 [INFO] Epoch 2/15 - Policy Loss: 1.5548, Value Loss: 0.2065, Total Loss: 1.7613, LR: 0.003340
2025-05-14 06:52:41,892 [INFO] Epoch 3/15 - Policy Loss: 1.5490, Value Loss: 0.2040, Total Loss: 1.7529, LR: 0.004990
2025-05-14 06:53:24,614 [INFO] Epoch 4/15 - Policy Loss: 1.5486, Value Loss: 0.2026, Total Loss: 1.7513, LR: 0.003360
2025-05-14 06:54:07,517 [INFO] Epoch 5/15 - Policy Loss: 1.5441, Value Loss: 0.2010, Total Loss: 1.7451, LR: 0.001710
2025-05-14 06:54:50,293 [INFO] Epoch 6/15 - Policy Loss: 1.5400, Value Loss: 0.1993, Total Loss: 1.7393, LR: 0.000060
2025-05-14 06:55:33,156 [INFO] Epoch 7/15 - Policy Loss: 1.5354, Value Loss: 0.1981, Total Loss: 1.7334, LR: 0.001690
2025-05-14 06:56:16,217 [INFO] Epoch 8/15 - Policy Loss: 1.5329, Value Loss: 0.1967, Total Loss: 1.7295, LR: 0.003340
2025-05-14 06:56:59,239 [INFO] Epoch 9/15 - Policy Loss: 1.5309, Value Loss: 0.1960, Total Loss: 1.7269, LR: 0.004990
2025-05-14 06:57:42,310 [INFO] Epoch 10/15 - Policy Loss: 1.5318, Value Loss: 0.1956, Total Loss: 1.7274, LR: 0.003360
2025-05-14 06:58:25,431 [INFO] Epoch 11/15 - Policy Loss: 1.5308, Value Loss: 0.1954, Total Loss: 1.7262, LR: 0.001710
2025-05-14 06:59:08,544 [INFO] Epoch 12/15 - Policy Loss: 1.5293, Value Loss: 0.1948, Total Loss: 1.7241, LR: 0.000060
2025-05-14 06:59:51,576 [INFO] Epoch 13/15 - Policy Loss: 1.5280, Value Loss: 0.1940, Total Loss: 1.7220, LR: 0.001690
2025-05-14 07:00:34,952 [INFO] Epoch 14/15 - Policy Loss: 1.5270, Value Loss: 0.1934, Total Loss: 1.7204, LR: 0.003340
2025-05-14 07:01:18,163 [INFO] Epoch 15/15 - Policy Loss: 1.5264, Value Loss: 0.1931, Total Loss: 1.7195, LR: 0.004990
2025-05-14 07:01:18,189 [INFO] 训练完成，总损失: 1.7195
2025-05-14 07:01:18,189 [INFO] 保存迭代 19 的模型
2025-05-14 07:01:19,369 [INFO] Model saved to ./models/best.pt
2025-05-14 07:01:20,025 [INFO] Model saved to ./models/iteration_19.pt
2025-05-14 07:01:20,025 [INFO] 所有训练迭代完成
2025-05-14 07:01:20,025 [INFO] 开始迭代 20/300
2025-05-14 07:01:20,025 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 07:17:36,453 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 07:17:36,454 [INFO] 保存训练样本
2025-05-14 07:17:41,479 [INFO] 使用 166936 个样本训练神经网络
2025-05-14 07:17:41,479 [INFO] Training with 166936 examples
2025-05-14 07:17:41,480 [INFO] 总训练步数: 2445, 每轮次批次数: 163
2025-05-14 07:17:42,054 [INFO] 循环学习率周期大小: 489 步
2025-05-14 07:18:25,516 [INFO] Epoch 1/15 - Policy Loss: 1.5632, Value Loss: 0.2096, Total Loss: 1.7728, LR: 0.001690
2025-05-14 07:19:08,887 [INFO] Epoch 2/15 - Policy Loss: 1.5500, Value Loss: 0.2047, Total Loss: 1.7547, LR: 0.003340
2025-05-14 07:19:52,318 [INFO] Epoch 3/15 - Policy Loss: 1.5473, Value Loss: 0.2020, Total Loss: 1.7493, LR: 0.004990
2025-05-14 07:20:35,787 [INFO] Epoch 4/15 - Policy Loss: 1.5451, Value Loss: 0.2007, Total Loss: 1.7458, LR: 0.003360
2025-05-14 07:21:19,192 [INFO] Epoch 5/15 - Policy Loss: 1.5417, Value Loss: 0.1990, Total Loss: 1.7408, LR: 0.001710
2025-05-14 07:22:02,702 [INFO] Epoch 6/15 - Policy Loss: 1.5358, Value Loss: 0.1977, Total Loss: 1.7335, LR: 0.000060
2025-05-14 07:22:46,078 [INFO] Epoch 7/15 - Policy Loss: 1.5315, Value Loss: 0.1957, Total Loss: 1.7272, LR: 0.001690
2025-05-14 07:23:29,698 [INFO] Epoch 8/15 - Policy Loss: 1.5285, Value Loss: 0.1946, Total Loss: 1.7231, LR: 0.003340
2025-05-14 07:24:13,365 [INFO] Epoch 9/15 - Policy Loss: 1.5271, Value Loss: 0.1937, Total Loss: 1.7208, LR: 0.004990
2025-05-14 07:24:56,941 [INFO] Epoch 10/15 - Policy Loss: 1.5263, Value Loss: 0.1932, Total Loss: 1.7195, LR: 0.003360
2025-05-14 07:25:40,591 [INFO] Epoch 11/15 - Policy Loss: 1.5252, Value Loss: 0.1928, Total Loss: 1.7180, LR: 0.001710
2025-05-14 07:26:24,289 [INFO] Epoch 12/15 - Policy Loss: 1.5231, Value Loss: 0.1921, Total Loss: 1.7153, LR: 0.000060
2025-05-14 07:27:07,894 [INFO] Epoch 13/15 - Policy Loss: 1.5212, Value Loss: 0.1915, Total Loss: 1.7127, LR: 0.001690
2025-05-14 07:27:52,070 [INFO] Epoch 14/15 - Policy Loss: 1.5195, Value Loss: 0.1911, Total Loss: 1.7106, LR: 0.003340
2025-05-14 07:28:35,784 [INFO] Epoch 15/15 - Policy Loss: 1.5190, Value Loss: 0.1908, Total Loss: 1.7098, LR: 0.004990
2025-05-14 07:28:35,810 [INFO] 训练完成，总损失: 1.7098
2025-05-14 07:28:35,810 [INFO] 保存迭代 20 的模型
2025-05-14 07:28:37,323 [INFO] Model saved to ./models/best.pt
2025-05-14 07:28:38,225 [INFO] Model saved to ./models/iteration_20.pt
2025-05-14 07:28:38,226 [INFO] 所有训练迭代完成
2025-05-14 07:28:38,226 [INFO] 开始迭代 21/300
2025-05-14 07:28:38,226 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 07:43:21,034 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 07:43:21,034 [INFO] 保存训练样本
2025-05-14 07:43:25,414 [INFO] 使用 155912 个样本训练神经网络
2025-05-14 07:43:25,414 [INFO] Training with 155912 examples
2025-05-14 07:43:25,415 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-14 07:43:25,983 [INFO] 循环学习率周期大小: 456 步
2025-05-14 07:44:06,274 [INFO] Epoch 1/15 - Policy Loss: 1.1459, Value Loss: 0.2314, Total Loss: 1.3773, LR: 0.001689
2025-05-14 07:44:46,626 [INFO] Epoch 2/15 - Policy Loss: 1.1149, Value Loss: 0.2253, Total Loss: 1.3402, LR: 0.003339
2025-05-14 07:45:27,001 [INFO] Epoch 3/15 - Policy Loss: 1.1039, Value Loss: 0.2232, Total Loss: 1.3271, LR: 0.004989
2025-05-14 07:46:07,564 [INFO] Epoch 4/15 - Policy Loss: 1.0987, Value Loss: 0.2220, Total Loss: 1.3207, LR: 0.003361
2025-05-14 07:46:48,051 [INFO] Epoch 5/15 - Policy Loss: 1.0909, Value Loss: 0.2192, Total Loss: 1.3102, LR: 0.001711
2025-05-14 07:47:28,649 [INFO] Epoch 6/15 - Policy Loss: 1.0839, Value Loss: 0.2169, Total Loss: 1.3008, LR: 0.000061
2025-05-14 07:48:09,221 [INFO] Epoch 7/15 - Policy Loss: 1.0777, Value Loss: 0.2154, Total Loss: 1.2931, LR: 0.001689
2025-05-14 07:48:49,808 [INFO] Epoch 8/15 - Policy Loss: 1.0739, Value Loss: 0.2143, Total Loss: 1.2883, LR: 0.003339
2025-05-14 07:49:30,496 [INFO] Epoch 9/15 - Policy Loss: 1.0719, Value Loss: 0.2134, Total Loss: 1.2853, LR: 0.004989
2025-05-14 07:50:11,219 [INFO] Epoch 10/15 - Policy Loss: 1.0715, Value Loss: 0.2133, Total Loss: 1.2847, LR: 0.003361
2025-05-14 07:50:51,967 [INFO] Epoch 11/15 - Policy Loss: 1.0703, Value Loss: 0.2128, Total Loss: 1.2831, LR: 0.001711
2025-05-14 07:51:33,253 [INFO] Epoch 12/15 - Policy Loss: 1.0678, Value Loss: 0.2121, Total Loss: 1.2799, LR: 0.000061
2025-05-14 07:52:14,097 [INFO] Epoch 13/15 - Policy Loss: 1.0659, Value Loss: 0.2117, Total Loss: 1.2775, LR: 0.001689
2025-05-14 07:52:54,744 [INFO] Epoch 14/15 - Policy Loss: 1.0641, Value Loss: 0.2113, Total Loss: 1.2754, LR: 0.003339
2025-05-14 07:53:35,442 [INFO] Epoch 15/15 - Policy Loss: 1.0637, Value Loss: 0.2109, Total Loss: 1.2746, LR: 0.004989
2025-05-14 07:53:35,466 [INFO] 训练完成，总损失: 1.2746
2025-05-14 07:53:35,466 [INFO] 保存迭代 21 的模型
2025-05-14 07:53:36,596 [INFO] Model saved to ./models/best.pt
2025-05-14 07:53:37,255 [INFO] Model saved to ./models/iteration_21.pt
2025-05-14 07:53:37,255 [INFO] 所有训练迭代完成
2025-05-14 07:53:37,255 [INFO] 开始迭代 22/300
2025-05-14 07:53:37,255 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 08:09:37,743 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 08:09:37,743 [INFO] 保存训练样本
2025-05-14 08:09:43,098 [INFO] 使用 154744 个样本训练神经网络
2025-05-14 08:09:43,098 [INFO] Training with 154744 examples
2025-05-14 08:09:43,099 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-14 08:09:43,176 [INFO] 循环学习率周期大小: 453 步
2025-05-14 08:10:23,514 [INFO] Epoch 1/15 - Policy Loss: 1.0804, Value Loss: 0.2210, Total Loss: 1.3014, LR: 0.001689
2025-05-14 08:11:03,913 [INFO] Epoch 2/15 - Policy Loss: 1.0753, Value Loss: 0.2170, Total Loss: 1.2923, LR: 0.003339
2025-05-14 08:11:44,247 [INFO] Epoch 3/15 - Policy Loss: 1.0707, Value Loss: 0.2148, Total Loss: 1.2855, LR: 0.004989
2025-05-14 08:12:24,641 [INFO] Epoch 4/15 - Policy Loss: 1.0706, Value Loss: 0.2134, Total Loss: 1.2840, LR: 0.003361
2025-05-14 08:13:04,974 [INFO] Epoch 5/15 - Policy Loss: 1.0672, Value Loss: 0.2116, Total Loss: 1.2789, LR: 0.001711
2025-05-14 08:13:45,519 [INFO] Epoch 6/15 - Policy Loss: 1.0621, Value Loss: 0.2098, Total Loss: 1.2719, LR: 0.000061
2025-05-14 08:14:26,691 [INFO] Epoch 7/15 - Policy Loss: 1.0579, Value Loss: 0.2080, Total Loss: 1.2659, LR: 0.001689
2025-05-14 08:15:07,165 [INFO] Epoch 8/15 - Policy Loss: 1.0544, Value Loss: 0.2069, Total Loss: 1.2614, LR: 0.003339
2025-05-14 08:15:47,730 [INFO] Epoch 9/15 - Policy Loss: 1.0529, Value Loss: 0.2062, Total Loss: 1.2591, LR: 0.004989
2025-05-14 08:16:28,464 [INFO] Epoch 10/15 - Policy Loss: 1.0559, Value Loss: 0.2063, Total Loss: 1.2622, LR: 0.003361
2025-05-14 08:17:09,155 [INFO] Epoch 11/15 - Policy Loss: 1.0549, Value Loss: 0.2057, Total Loss: 1.2606, LR: 0.001711
2025-05-14 08:17:49,843 [INFO] Epoch 12/15 - Policy Loss: 1.0527, Value Loss: 0.2051, Total Loss: 1.2578, LR: 0.000061
2025-05-14 08:18:30,587 [INFO] Epoch 13/15 - Policy Loss: 1.0504, Value Loss: 0.2046, Total Loss: 1.2550, LR: 0.001689
2025-05-14 08:19:11,314 [INFO] Epoch 14/15 - Policy Loss: 1.0485, Value Loss: 0.2039, Total Loss: 1.2524, LR: 0.003339
2025-05-14 08:19:52,005 [INFO] Epoch 15/15 - Policy Loss: 1.0474, Value Loss: 0.2035, Total Loss: 1.2509, LR: 0.004989
2025-05-14 08:19:52,033 [INFO] 训练完成，总损失: 1.2509
2025-05-14 08:19:52,033 [INFO] 保存迭代 22 的模型
2025-05-14 08:19:53,701 [INFO] Model saved to ./models/best.pt
2025-05-14 08:19:54,613 [INFO] Model saved to ./models/iteration_22.pt
2025-05-14 08:19:54,614 [INFO] 所有训练迭代完成
2025-05-14 08:19:54,614 [INFO] 开始迭代 23/300
2025-05-14 08:19:54,614 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 08:36:14,176 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 08:36:14,176 [INFO] 保存训练样本
2025-05-14 08:36:19,400 [INFO] 使用 156304 个样本训练神经网络
2025-05-14 08:36:19,400 [INFO] Training with 156304 examples
2025-05-14 08:36:19,401 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-14 08:36:19,460 [INFO] 循环学习率周期大小: 456 步
2025-05-14 08:36:59,731 [INFO] Epoch 1/15 - Policy Loss: 1.0865, Value Loss: 0.2297, Total Loss: 1.3162, LR: 0.001689
2025-05-14 08:37:40,514 [INFO] Epoch 2/15 - Policy Loss: 1.0742, Value Loss: 0.2236, Total Loss: 1.2979, LR: 0.003339
2025-05-14 08:38:20,857 [INFO] Epoch 3/15 - Policy Loss: 1.0687, Value Loss: 0.2214, Total Loss: 1.2901, LR: 0.004989
2025-05-14 08:39:01,160 [INFO] Epoch 4/15 - Policy Loss: 1.0686, Value Loss: 0.2212, Total Loss: 1.2898, LR: 0.003361
2025-05-14 08:39:41,646 [INFO] Epoch 5/15 - Policy Loss: 1.0637, Value Loss: 0.2198, Total Loss: 1.2835, LR: 0.001711
2025-05-14 08:40:22,413 [INFO] Epoch 6/15 - Policy Loss: 1.0581, Value Loss: 0.2174, Total Loss: 1.2755, LR: 0.000061
2025-05-14 08:41:03,159 [INFO] Epoch 7/15 - Policy Loss: 1.0527, Value Loss: 0.2157, Total Loss: 1.2684, LR: 0.001689
2025-05-14 08:41:43,852 [INFO] Epoch 8/15 - Policy Loss: 1.0488, Value Loss: 0.2141, Total Loss: 1.2629, LR: 0.003339
2025-05-14 08:42:24,697 [INFO] Epoch 9/15 - Policy Loss: 1.0467, Value Loss: 0.2131, Total Loss: 1.2598, LR: 0.004989
2025-05-14 08:43:05,531 [INFO] Epoch 10/15 - Policy Loss: 1.0462, Value Loss: 0.2127, Total Loss: 1.2590, LR: 0.003361
2025-05-14 08:43:46,416 [INFO] Epoch 11/15 - Policy Loss: 1.0444, Value Loss: 0.2120, Total Loss: 1.2564, LR: 0.001711
2025-05-14 08:44:27,460 [INFO] Epoch 12/15 - Policy Loss: 1.0422, Value Loss: 0.2111, Total Loss: 1.2532, LR: 0.000061
2025-05-14 08:45:08,361 [INFO] Epoch 13/15 - Policy Loss: 1.0398, Value Loss: 0.2104, Total Loss: 1.2503, LR: 0.001689
2025-05-14 08:45:49,185 [INFO] Epoch 14/15 - Policy Loss: 1.0379, Value Loss: 0.2098, Total Loss: 1.2478, LR: 0.003339
2025-05-14 08:46:30,292 [INFO] Epoch 15/15 - Policy Loss: 1.0371, Value Loss: 0.2093, Total Loss: 1.2464, LR: 0.004989
2025-05-14 08:46:30,318 [INFO] 训练完成，总损失: 1.2464
2025-05-14 08:46:30,319 [INFO] 保存迭代 23 的模型
2025-05-14 08:46:31,697 [INFO] Model saved to ./models/best.pt
2025-05-14 08:46:32,577 [INFO] Model saved to ./models/iteration_23.pt
2025-05-14 08:46:32,577 [INFO] 所有训练迭代完成
2025-05-14 08:46:32,578 [INFO] 开始迭代 24/300
2025-05-14 08:46:32,578 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 09:02:07,738 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 09:02:07,739 [INFO] 保存训练样本
2025-05-14 09:02:12,872 [INFO] 使用 156560 个样本训练神经网络
2025-05-14 09:02:12,872 [INFO] Training with 156560 examples
2025-05-14 09:02:12,872 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-14 09:02:13,396 [INFO] 循环学习率周期大小: 456 步
2025-05-14 09:02:53,718 [INFO] Epoch 1/15 - Policy Loss: 1.0664, Value Loss: 0.2289, Total Loss: 1.2953, LR: 0.001689
2025-05-14 09:03:34,092 [INFO] Epoch 2/15 - Policy Loss: 1.0595, Value Loss: 0.2259, Total Loss: 1.2854, LR: 0.003339
2025-05-14 09:04:14,433 [INFO] Epoch 3/15 - Policy Loss: 1.0538, Value Loss: 0.2240, Total Loss: 1.2777, LR: 0.004989
2025-05-14 09:04:54,790 [INFO] Epoch 4/15 - Policy Loss: 1.0536, Value Loss: 0.2236, Total Loss: 1.2772, LR: 0.003361
2025-05-14 09:05:35,212 [INFO] Epoch 5/15 - Policy Loss: 1.0485, Value Loss: 0.2212, Total Loss: 1.2697, LR: 0.001711
2025-05-14 09:06:15,654 [INFO] Epoch 6/15 - Policy Loss: 1.0437, Value Loss: 0.2191, Total Loss: 1.2628, LR: 0.000061
2025-05-14 09:06:56,245 [INFO] Epoch 7/15 - Policy Loss: 1.0396, Value Loss: 0.2179, Total Loss: 1.2575, LR: 0.001689
2025-05-14 09:07:36,827 [INFO] Epoch 8/15 - Policy Loss: 1.0365, Value Loss: 0.2167, Total Loss: 1.2532, LR: 0.003339
2025-05-14 09:08:17,345 [INFO] Epoch 9/15 - Policy Loss: 1.0352, Value Loss: 0.2159, Total Loss: 1.2511, LR: 0.004989
2025-05-14 09:08:58,185 [INFO] Epoch 10/15 - Policy Loss: 1.0369, Value Loss: 0.2156, Total Loss: 1.2525, LR: 0.003361
2025-05-14 09:09:38,944 [INFO] Epoch 11/15 - Policy Loss: 1.0357, Value Loss: 0.2149, Total Loss: 1.2506, LR: 0.001711
2025-05-14 09:10:19,549 [INFO] Epoch 12/15 - Policy Loss: 1.0337, Value Loss: 0.2141, Total Loss: 1.2479, LR: 0.000061
2025-05-14 09:11:00,229 [INFO] Epoch 13/15 - Policy Loss: 1.0314, Value Loss: 0.2132, Total Loss: 1.2446, LR: 0.001689
2025-05-14 09:11:40,978 [INFO] Epoch 14/15 - Policy Loss: 1.0299, Value Loss: 0.2126, Total Loss: 1.2425, LR: 0.003339
2025-05-14 09:12:22,234 [INFO] Epoch 15/15 - Policy Loss: 1.0291, Value Loss: 0.2122, Total Loss: 1.2412, LR: 0.004989
2025-05-14 09:12:22,260 [INFO] 训练完成，总损失: 1.2412
2025-05-14 09:12:22,260 [INFO] 保存迭代 24 的模型
2025-05-14 09:12:23,892 [INFO] Model saved to ./models/best.pt
2025-05-14 09:12:24,735 [INFO] Model saved to ./models/iteration_24.pt
2025-05-14 09:12:24,736 [INFO] 所有训练迭代完成
2025-05-14 09:12:24,736 [INFO] 开始迭代 25/300
2025-05-14 09:12:24,736 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 09:26:15,919 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 09:26:15,920 [INFO] 保存训练样本
2025-05-14 09:26:19,782 [INFO] 使用 156616 个样本训练神经网络
2025-05-14 09:26:19,782 [INFO] Training with 156616 examples
2025-05-14 09:26:19,782 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-14 09:26:20,218 [INFO] 循环学习率周期大小: 456 步
2025-05-14 09:27:00,488 [INFO] Epoch 1/15 - Policy Loss: 1.0468, Value Loss: 0.2193, Total Loss: 1.2662, LR: 0.001689
2025-05-14 09:27:40,720 [INFO] Epoch 2/15 - Policy Loss: 1.0388, Value Loss: 0.2157, Total Loss: 1.2546, LR: 0.003339
2025-05-14 09:28:20,942 [INFO] Epoch 3/15 - Policy Loss: 1.0355, Value Loss: 0.2142, Total Loss: 1.2496, LR: 0.004989
2025-05-14 09:29:01,389 [INFO] Epoch 4/15 - Policy Loss: 1.0361, Value Loss: 0.2136, Total Loss: 1.2497, LR: 0.003361
2025-05-14 09:29:41,950 [INFO] Epoch 5/15 - Policy Loss: 1.0333, Value Loss: 0.2126, Total Loss: 1.2459, LR: 0.001711
2025-05-14 09:30:22,593 [INFO] Epoch 6/15 - Policy Loss: 1.0296, Value Loss: 0.2111, Total Loss: 1.2407, LR: 0.000061
2025-05-14 09:31:03,418 [INFO] Epoch 7/15 - Policy Loss: 1.0258, Value Loss: 0.2100, Total Loss: 1.2358, LR: 0.001689
2025-05-14 09:31:44,086 [INFO] Epoch 8/15 - Policy Loss: 1.0239, Value Loss: 0.2092, Total Loss: 1.2331, LR: 0.003339
2025-05-14 09:32:24,621 [INFO] Epoch 9/15 - Policy Loss: 1.0227, Value Loss: 0.2086, Total Loss: 1.2313, LR: 0.004989
2025-05-14 09:33:05,293 [INFO] Epoch 10/15 - Policy Loss: 1.0232, Value Loss: 0.2083, Total Loss: 1.2315, LR: 0.003361
2025-05-14 09:33:45,892 [INFO] Epoch 11/15 - Policy Loss: 1.0226, Value Loss: 0.2078, Total Loss: 1.2303, LR: 0.001711
2025-05-14 09:34:26,429 [INFO] Epoch 12/15 - Policy Loss: 1.0213, Value Loss: 0.2070, Total Loss: 1.2283, LR: 0.000061
2025-05-14 09:35:07,577 [INFO] Epoch 13/15 - Policy Loss: 1.0198, Value Loss: 0.2064, Total Loss: 1.2262, LR: 0.001689
2025-05-14 09:35:48,074 [INFO] Epoch 14/15 - Policy Loss: 1.0186, Value Loss: 0.2060, Total Loss: 1.2246, LR: 0.003339
2025-05-14 09:36:28,793 [INFO] Epoch 15/15 - Policy Loss: 1.0179, Value Loss: 0.2054, Total Loss: 1.2233, LR: 0.004989
2025-05-14 09:36:28,820 [INFO] 训练完成，总损失: 1.2233
2025-05-14 09:36:28,820 [INFO] 保存迭代 25 的模型
2025-05-14 09:36:30,202 [INFO] Model saved to ./models/best.pt
2025-05-14 09:36:31,086 [INFO] Model saved to ./models/iteration_25.pt
2025-05-14 09:36:31,086 [INFO] 所有训练迭代完成
2025-05-14 09:36:31,086 [INFO] 开始迭代 26/300
2025-05-14 09:36:31,086 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 09:52:41,147 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 09:52:41,148 [INFO] 保存训练样本
2025-05-14 09:52:44,780 [INFO] 使用 157416 个样本训练神经网络
2025-05-14 09:52:44,781 [INFO] Training with 157416 examples
2025-05-14 09:52:44,781 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-14 09:52:45,221 [INFO] 循环学习率周期大小: 459 步
2025-05-14 09:53:25,654 [INFO] Epoch 1/15 - Policy Loss: 1.0515, Value Loss: 0.2255, Total Loss: 1.2770, LR: 0.001689
2025-05-14 09:54:06,306 [INFO] Epoch 2/15 - Policy Loss: 1.0415, Value Loss: 0.2205, Total Loss: 1.2620, LR: 0.003339
2025-05-14 09:54:46,918 [INFO] Epoch 3/15 - Policy Loss: 1.0380, Value Loss: 0.2186, Total Loss: 1.2565, LR: 0.004989
2025-05-14 09:55:27,568 [INFO] Epoch 4/15 - Policy Loss: 1.0373, Value Loss: 0.2188, Total Loss: 1.2561, LR: 0.003361
2025-05-14 09:56:08,277 [INFO] Epoch 5/15 - Policy Loss: 1.0333, Value Loss: 0.2167, Total Loss: 1.2500, LR: 0.001711
2025-05-14 09:56:48,935 [INFO] Epoch 6/15 - Policy Loss: 1.0290, Value Loss: 0.2146, Total Loss: 1.2436, LR: 0.000061
2025-05-14 09:57:29,755 [INFO] Epoch 7/15 - Policy Loss: 1.0248, Value Loss: 0.2129, Total Loss: 1.2377, LR: 0.001689
2025-05-14 09:58:11,053 [INFO] Epoch 8/15 - Policy Loss: 1.0217, Value Loss: 0.2119, Total Loss: 1.2335, LR: 0.003339
2025-05-14 09:58:52,001 [INFO] Epoch 9/15 - Policy Loss: 1.0203, Value Loss: 0.2111, Total Loss: 1.2314, LR: 0.004989
2025-05-14 09:59:32,957 [INFO] Epoch 10/15 - Policy Loss: 1.0205, Value Loss: 0.2107, Total Loss: 1.2312, LR: 0.003361
2025-05-14 10:00:14,072 [INFO] Epoch 11/15 - Policy Loss: 1.0195, Value Loss: 0.2104, Total Loss: 1.2299, LR: 0.001711
2025-05-14 10:00:55,332 [INFO] Epoch 12/15 - Policy Loss: 1.0178, Value Loss: 0.2095, Total Loss: 1.2273, LR: 0.000061
2025-05-14 10:01:36,580 [INFO] Epoch 13/15 - Policy Loss: 1.0164, Value Loss: 0.2088, Total Loss: 1.2252, LR: 0.001689
2025-05-14 10:02:17,616 [INFO] Epoch 14/15 - Policy Loss: 1.0146, Value Loss: 0.2080, Total Loss: 1.2225, LR: 0.003339
2025-05-14 10:02:58,585 [INFO] Epoch 15/15 - Policy Loss: 1.0138, Value Loss: 0.2073, Total Loss: 1.2211, LR: 0.004989
2025-05-14 10:02:58,609 [INFO] 训练完成，总损失: 1.2211
2025-05-14 10:02:58,609 [INFO] 保存迭代 26 的模型
2025-05-14 10:02:59,956 [INFO] Model saved to ./models/best.pt
2025-05-14 10:03:00,689 [INFO] Model saved to ./models/iteration_26.pt
2025-05-14 10:03:00,689 [INFO] 所有训练迭代完成
2025-05-14 10:03:00,690 [INFO] 开始迭代 27/300
2025-05-14 10:03:00,690 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 10:18:38,209 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 10:18:38,209 [INFO] 保存训练样本
2025-05-14 10:18:42,473 [INFO] 使用 157112 个样本训练神经网络
2025-05-14 10:18:42,473 [INFO] Training with 157112 examples
2025-05-14 10:18:42,474 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-14 10:18:42,529 [INFO] 循环学习率周期大小: 459 步
2025-05-14 10:19:23,085 [INFO] Epoch 1/15 - Policy Loss: 1.0453, Value Loss: 0.2287, Total Loss: 1.2740, LR: 0.001689
2025-05-14 10:20:04,228 [INFO] Epoch 2/15 - Policy Loss: 1.0374, Value Loss: 0.2223, Total Loss: 1.2598, LR: 0.003339
2025-05-14 10:20:44,779 [INFO] Epoch 3/15 - Policy Loss: 1.0343, Value Loss: 0.2196, Total Loss: 1.2539, LR: 0.004989
2025-05-14 10:21:25,363 [INFO] Epoch 4/15 - Policy Loss: 1.0325, Value Loss: 0.2181, Total Loss: 1.2506, LR: 0.003361
2025-05-14 10:22:06,178 [INFO] Epoch 5/15 - Policy Loss: 1.0287, Value Loss: 0.2162, Total Loss: 1.2449, LR: 0.001711
2025-05-14 10:22:47,032 [INFO] Epoch 6/15 - Policy Loss: 1.0244, Value Loss: 0.2135, Total Loss: 1.2380, LR: 0.000061
2025-05-14 10:23:27,870 [INFO] Epoch 7/15 - Policy Loss: 1.0207, Value Loss: 0.2121, Total Loss: 1.2328, LR: 0.001689
2025-05-14 10:24:08,801 [INFO] Epoch 8/15 - Policy Loss: 1.0182, Value Loss: 0.2107, Total Loss: 1.2289, LR: 0.003339
2025-05-14 10:24:49,627 [INFO] Epoch 9/15 - Policy Loss: 1.0172, Value Loss: 0.2099, Total Loss: 1.2270, LR: 0.004989
2025-05-14 10:25:30,639 [INFO] Epoch 10/15 - Policy Loss: 1.0168, Value Loss: 0.2092, Total Loss: 1.2259, LR: 0.003361
2025-05-14 10:26:11,557 [INFO] Epoch 11/15 - Policy Loss: 1.0153, Value Loss: 0.2086, Total Loss: 1.2239, LR: 0.001711
2025-05-14 10:26:52,528 [INFO] Epoch 12/15 - Policy Loss: 1.0133, Value Loss: 0.2078, Total Loss: 1.2212, LR: 0.000061
2025-05-14 10:27:33,430 [INFO] Epoch 13/15 - Policy Loss: 1.0116, Value Loss: 0.2071, Total Loss: 1.2187, LR: 0.001689
2025-05-14 10:28:14,347 [INFO] Epoch 14/15 - Policy Loss: 1.0100, Value Loss: 0.2064, Total Loss: 1.2164, LR: 0.003339
2025-05-14 10:28:55,323 [INFO] Epoch 15/15 - Policy Loss: 1.0095, Value Loss: 0.2059, Total Loss: 1.2153, LR: 0.004989
2025-05-14 10:28:55,349 [INFO] 训练完成，总损失: 1.2153
2025-05-14 10:28:55,349 [INFO] 保存迭代 27 的模型
2025-05-14 10:28:56,901 [INFO] Model saved to ./models/best.pt
2025-05-14 10:28:57,825 [INFO] Model saved to ./models/iteration_27.pt
2025-05-14 10:28:57,825 [INFO] 所有训练迭代完成
2025-05-14 10:28:57,825 [INFO] 开始迭代 28/300
2025-05-14 10:28:57,825 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 10:44:33,309 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 10:44:33,309 [INFO] 保存训练样本
2025-05-14 10:44:37,686 [INFO] 使用 156928 个样本训练神经网络
2025-05-14 10:44:37,686 [INFO] Training with 156928 examples
2025-05-14 10:44:37,687 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-14 10:44:38,251 [INFO] 循环学习率周期大小: 459 步
2025-05-14 10:45:18,752 [INFO] Epoch 1/15 - Policy Loss: 1.0356, Value Loss: 0.2193, Total Loss: 1.2549, LR: 0.001689
2025-05-14 10:45:59,311 [INFO] Epoch 2/15 - Policy Loss: 1.0310, Value Loss: 0.2143, Total Loss: 1.2453, LR: 0.003339
2025-05-14 10:46:39,927 [INFO] Epoch 3/15 - Policy Loss: 1.0283, Value Loss: 0.2130, Total Loss: 1.2413, LR: 0.004989
2025-05-14 10:47:20,490 [INFO] Epoch 4/15 - Policy Loss: 1.0276, Value Loss: 0.2121, Total Loss: 1.2397, LR: 0.003361
2025-05-14 10:48:01,027 [INFO] Epoch 5/15 - Policy Loss: 1.0233, Value Loss: 0.2100, Total Loss: 1.2333, LR: 0.001711
2025-05-14 10:48:41,612 [INFO] Epoch 6/15 - Policy Loss: 1.0182, Value Loss: 0.2081, Total Loss: 1.2263, LR: 0.000061
2025-05-14 10:49:22,452 [INFO] Epoch 7/15 - Policy Loss: 1.0144, Value Loss: 0.2066, Total Loss: 1.2210, LR: 0.001689
2025-05-14 10:50:03,232 [INFO] Epoch 8/15 - Policy Loss: 1.0115, Value Loss: 0.2055, Total Loss: 1.2170, LR: 0.003339
2025-05-14 10:50:44,106 [INFO] Epoch 9/15 - Policy Loss: 1.0102, Value Loss: 0.2049, Total Loss: 1.2151, LR: 0.004989
2025-05-14 10:51:25,004 [INFO] Epoch 10/15 - Policy Loss: 1.0106, Value Loss: 0.2047, Total Loss: 1.2153, LR: 0.003361
2025-05-14 10:52:05,927 [INFO] Epoch 11/15 - Policy Loss: 1.0096, Value Loss: 0.2042, Total Loss: 1.2138, LR: 0.001711
2025-05-14 10:52:46,885 [INFO] Epoch 12/15 - Policy Loss: 1.0076, Value Loss: 0.2032, Total Loss: 1.2108, LR: 0.000061
2025-05-14 10:53:28,383 [INFO] Epoch 13/15 - Policy Loss: 1.0059, Value Loss: 0.2025, Total Loss: 1.2085, LR: 0.001689
2025-05-14 10:54:09,393 [INFO] Epoch 14/15 - Policy Loss: 1.0045, Value Loss: 0.2021, Total Loss: 1.2066, LR: 0.003339
2025-05-14 10:54:50,455 [INFO] Epoch 15/15 - Policy Loss: 1.0038, Value Loss: 0.2017, Total Loss: 1.2055, LR: 0.004989
2025-05-14 10:54:50,482 [INFO] 训练完成，总损失: 1.2055
2025-05-14 10:54:50,482 [INFO] 保存迭代 28 的模型
2025-05-14 10:54:51,857 [INFO] Model saved to ./models/best.pt
2025-05-14 10:54:52,730 [INFO] Model saved to ./models/iteration_28.pt
2025-05-14 10:54:52,730 [INFO] 所有训练迭代完成
2025-05-14 10:54:52,730 [INFO] 开始迭代 29/300
2025-05-14 10:54:52,731 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 11:10:20,434 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 11:10:20,435 [INFO] 保存训练样本
2025-05-14 11:10:24,934 [INFO] 使用 157392 个样本训练神经网络
2025-05-14 11:10:24,934 [INFO] Training with 157392 examples
2025-05-14 11:10:24,935 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-14 11:10:25,591 [INFO] 循环学习率周期大小: 459 步
2025-05-14 11:11:06,145 [INFO] Epoch 1/15 - Policy Loss: 1.0400, Value Loss: 0.2215, Total Loss: 1.2615, LR: 0.001689
2025-05-14 11:11:46,957 [INFO] Epoch 2/15 - Policy Loss: 1.0288, Value Loss: 0.2176, Total Loss: 1.2464, LR: 0.003339
2025-05-14 11:12:27,743 [INFO] Epoch 3/15 - Policy Loss: 1.0240, Value Loss: 0.2152, Total Loss: 1.2391, LR: 0.004989
2025-05-14 11:13:08,863 [INFO] Epoch 4/15 - Policy Loss: 1.0249, Value Loss: 0.2148, Total Loss: 1.2398, LR: 0.003361
2025-05-14 11:13:49,863 [INFO] Epoch 5/15 - Policy Loss: 1.0220, Value Loss: 0.2129, Total Loss: 1.2349, LR: 0.001711
2025-05-14 11:14:30,820 [INFO] Epoch 6/15 - Policy Loss: 1.0171, Value Loss: 0.2108, Total Loss: 1.2280, LR: 0.000061
2025-05-14 11:15:11,996 [INFO] Epoch 7/15 - Policy Loss: 1.0121, Value Loss: 0.2091, Total Loss: 1.2212, LR: 0.001689
2025-05-14 11:15:53,032 [INFO] Epoch 8/15 - Policy Loss: 1.0100, Value Loss: 0.2075, Total Loss: 1.2175, LR: 0.003339
2025-05-14 11:16:34,531 [INFO] Epoch 9/15 - Policy Loss: 1.0085, Value Loss: 0.2067, Total Loss: 1.2152, LR: 0.004989
2025-05-14 11:17:15,697 [INFO] Epoch 10/15 - Policy Loss: 1.0081, Value Loss: 0.2064, Total Loss: 1.2145, LR: 0.003361
2025-05-14 11:17:56,714 [INFO] Epoch 11/15 - Policy Loss: 1.0071, Value Loss: 0.2057, Total Loss: 1.2129, LR: 0.001711
2025-05-14 11:18:37,789 [INFO] Epoch 12/15 - Policy Loss: 1.0052, Value Loss: 0.2050, Total Loss: 1.2101, LR: 0.000061
2025-05-14 11:19:19,182 [INFO] Epoch 13/15 - Policy Loss: 1.0035, Value Loss: 0.2044, Total Loss: 1.2079, LR: 0.001689
2025-05-14 11:20:00,419 [INFO] Epoch 14/15 - Policy Loss: 1.0022, Value Loss: 0.2038, Total Loss: 1.2060, LR: 0.003339
2025-05-14 11:20:41,538 [INFO] Epoch 15/15 - Policy Loss: 1.0014, Value Loss: 0.2033, Total Loss: 1.2046, LR: 0.004989
2025-05-14 11:20:41,566 [INFO] 训练完成，总损失: 1.2046
2025-05-14 11:20:41,566 [INFO] 保存迭代 29 的模型
2025-05-14 11:20:42,989 [INFO] Model saved to ./models/best.pt
2025-05-14 11:20:43,899 [INFO] Model saved to ./models/iteration_29.pt
2025-05-14 11:20:43,899 [INFO] 所有训练迭代完成
2025-05-14 11:20:43,899 [INFO] 开始迭代 30/300
2025-05-14 11:20:43,899 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 11:35:51,141 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 11:35:51,141 [INFO] 保存训练样本
2025-05-14 11:35:56,579 [INFO] 使用 157344 个样本训练神经网络
2025-05-14 11:35:56,579 [INFO] Training with 157344 examples
2025-05-14 11:35:56,580 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-14 11:35:56,654 [INFO] 循环学习率周期大小: 459 步
2025-05-14 11:36:37,277 [INFO] Epoch 1/15 - Policy Loss: 1.0352, Value Loss: 0.2374, Total Loss: 1.2726, LR: 0.001689
2025-05-14 11:37:18,138 [INFO] Epoch 2/15 - Policy Loss: 1.0230, Value Loss: 0.2309, Total Loss: 1.2539, LR: 0.003339
2025-05-14 11:37:58,755 [INFO] Epoch 3/15 - Policy Loss: 1.0190, Value Loss: 0.2266, Total Loss: 1.2456, LR: 0.004989
2025-05-14 11:38:39,425 [INFO] Epoch 4/15 - Policy Loss: 1.0183, Value Loss: 0.2244, Total Loss: 1.2427, LR: 0.003361
2025-05-14 11:39:20,558 [INFO] Epoch 5/15 - Policy Loss: 1.0141, Value Loss: 0.2222, Total Loss: 1.2363, LR: 0.001711
2025-05-14 11:40:01,397 [INFO] Epoch 6/15 - Policy Loss: 1.0099, Value Loss: 0.2205, Total Loss: 1.2304, LR: 0.000061
2025-05-14 11:40:42,198 [INFO] Epoch 7/15 - Policy Loss: 1.0056, Value Loss: 0.2185, Total Loss: 1.2241, LR: 0.001689
2025-05-14 11:41:22,994 [INFO] Epoch 8/15 - Policy Loss: 1.0030, Value Loss: 0.2169, Total Loss: 1.2199, LR: 0.003339
2025-05-14 11:42:03,802 [INFO] Epoch 9/15 - Policy Loss: 1.0017, Value Loss: 0.2160, Total Loss: 1.2177, LR: 0.004989
2025-05-14 11:42:44,628 [INFO] Epoch 10/15 - Policy Loss: 1.0009, Value Loss: 0.2155, Total Loss: 1.2164, LR: 0.003361
2025-05-14 11:43:25,635 [INFO] Epoch 11/15 - Policy Loss: 0.9993, Value Loss: 0.2147, Total Loss: 1.2140, LR: 0.001711
2025-05-14 11:44:06,431 [INFO] Epoch 12/15 - Policy Loss: 0.9974, Value Loss: 0.2136, Total Loss: 1.2110, LR: 0.000061
2025-05-14 11:44:47,280 [INFO] Epoch 13/15 - Policy Loss: 0.9956, Value Loss: 0.2127, Total Loss: 1.2083, LR: 0.001689
2025-05-14 11:45:28,602 [INFO] Epoch 14/15 - Policy Loss: 0.9942, Value Loss: 0.2121, Total Loss: 1.2064, LR: 0.003339
2025-05-14 11:46:09,902 [INFO] Epoch 15/15 - Policy Loss: 0.9938, Value Loss: 0.2117, Total Loss: 1.2055, LR: 0.004989
2025-05-14 11:46:09,927 [INFO] 训练完成，总损失: 1.2055
2025-05-14 11:46:09,927 [INFO] 保存迭代 30 的模型
2025-05-14 11:46:11,022 [INFO] Model saved to ./models/best.pt
2025-05-14 11:46:11,862 [INFO] Model saved to ./models/iteration_30.pt
2025-05-14 11:46:11,863 [INFO] 所有训练迭代完成
2025-05-14 11:46:11,863 [INFO] 开始迭代 31/300
2025-05-14 11:46:11,863 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 12:02:39,859 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 12:02:39,859 [INFO] 保存训练样本
2025-05-14 12:02:45,048 [INFO] 使用 158248 个样本训练神经网络
2025-05-14 12:02:45,048 [INFO] Training with 158248 examples
2025-05-14 12:02:45,049 [INFO] 总训练步数: 2310, 每轮次批次数: 154
2025-05-14 12:02:45,634 [INFO] 循环学习率周期大小: 462 步
2025-05-14 12:03:26,806 [INFO] Epoch 1/15 - Policy Loss: 1.0350, Value Loss: 0.2341, Total Loss: 1.2691, LR: 0.001689
2025-05-14 12:04:07,747 [INFO] Epoch 2/15 - Policy Loss: 1.0234, Value Loss: 0.2287, Total Loss: 1.2520, LR: 0.003339
2025-05-14 12:04:48,756 [INFO] Epoch 3/15 - Policy Loss: 1.0189, Value Loss: 0.2257, Total Loss: 1.2446, LR: 0.004989
2025-05-14 12:05:30,037 [INFO] Epoch 4/15 - Policy Loss: 1.0170, Value Loss: 0.2244, Total Loss: 1.2414, LR: 0.003361
2025-05-14 12:06:10,933 [INFO] Epoch 5/15 - Policy Loss: 1.0121, Value Loss: 0.2213, Total Loss: 1.2334, LR: 0.001711
2025-05-14 12:06:51,781 [INFO] Epoch 6/15 - Policy Loss: 1.0077, Value Loss: 0.2189, Total Loss: 1.2266, LR: 0.000061
2025-05-14 12:07:32,716 [INFO] Epoch 7/15 - Policy Loss: 1.0032, Value Loss: 0.2170, Total Loss: 1.2202, LR: 0.001689
2025-05-14 12:08:13,740 [INFO] Epoch 8/15 - Policy Loss: 1.0000, Value Loss: 0.2161, Total Loss: 1.2161, LR: 0.003339
2025-05-14 12:08:54,960 [INFO] Epoch 9/15 - Policy Loss: 0.9991, Value Loss: 0.2154, Total Loss: 1.2144, LR: 0.004989
2025-05-14 12:09:36,527 [INFO] Epoch 10/15 - Policy Loss: 0.9985, Value Loss: 0.2148, Total Loss: 1.2132, LR: 0.003361
2025-05-14 12:10:18,023 [INFO] Epoch 11/15 - Policy Loss: 0.9970, Value Loss: 0.2141, Total Loss: 1.2111, LR: 0.001711
2025-05-14 12:10:59,393 [INFO] Epoch 12/15 - Policy Loss: 0.9954, Value Loss: 0.2133, Total Loss: 1.2087, LR: 0.000061
2025-05-14 12:11:40,605 [INFO] Epoch 13/15 - Policy Loss: 0.9940, Value Loss: 0.2126, Total Loss: 1.2065, LR: 0.001689
2025-05-14 12:12:21,869 [INFO] Epoch 14/15 - Policy Loss: 0.9924, Value Loss: 0.2118, Total Loss: 1.2042, LR: 0.003339
2025-05-14 12:13:03,079 [INFO] Epoch 15/15 - Policy Loss: 0.9912, Value Loss: 0.2112, Total Loss: 1.2024, LR: 0.004989
2025-05-14 12:13:03,107 [INFO] 训练完成，总损失: 1.2024
2025-05-14 12:13:03,107 [INFO] 保存迭代 31 的模型
2025-05-14 12:13:04,380 [INFO] Model saved to ./models/best.pt
2025-05-14 12:13:05,234 [INFO] Model saved to ./models/iteration_31.pt
2025-05-14 12:13:05,234 [INFO] 所有训练迭代完成
2025-05-14 12:13:05,234 [INFO] 开始迭代 32/300
2025-05-14 12:13:05,234 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 12:27:44,009 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 12:27:44,010 [INFO] 保存训练样本
2025-05-14 12:27:48,701 [INFO] 使用 157944 个样本训练神经网络
2025-05-14 12:27:48,701 [INFO] Training with 157944 examples
2025-05-14 12:27:48,702 [INFO] 总训练步数: 2310, 每轮次批次数: 154
2025-05-14 12:27:49,216 [INFO] 循环学习率周期大小: 462 步
2025-05-14 12:28:29,892 [INFO] Epoch 1/15 - Policy Loss: 1.0171, Value Loss: 0.2238, Total Loss: 1.2409, LR: 0.001689
2025-05-14 12:29:10,797 [INFO] Epoch 2/15 - Policy Loss: 1.0111, Value Loss: 0.2197, Total Loss: 1.2308, LR: 0.003339
2025-05-14 12:29:51,691 [INFO] Epoch 3/15 - Policy Loss: 1.0072, Value Loss: 0.2185, Total Loss: 1.2258, LR: 0.004989
2025-05-14 12:30:32,569 [INFO] Epoch 4/15 - Policy Loss: 1.0059, Value Loss: 0.2170, Total Loss: 1.2229, LR: 0.003361
2025-05-14 12:31:13,589 [INFO] Epoch 5/15 - Policy Loss: 1.0026, Value Loss: 0.2154, Total Loss: 1.2180, LR: 0.001711
2025-05-14 12:31:54,452 [INFO] Epoch 6/15 - Policy Loss: 0.9971, Value Loss: 0.2136, Total Loss: 1.2107, LR: 0.000061
2025-05-14 12:32:35,322 [INFO] Epoch 7/15 - Policy Loss: 0.9936, Value Loss: 0.2124, Total Loss: 1.2059, LR: 0.001689
2025-05-14 12:33:16,448 [INFO] Epoch 8/15 - Policy Loss: 0.9906, Value Loss: 0.2113, Total Loss: 1.2019, LR: 0.003339
2025-05-14 12:33:57,496 [INFO] Epoch 9/15 - Policy Loss: 0.9901, Value Loss: 0.2105, Total Loss: 1.2006, LR: 0.004989
2025-05-14 12:34:38,615 [INFO] Epoch 10/15 - Policy Loss: 0.9902, Value Loss: 0.2103, Total Loss: 1.2005, LR: 0.003361
2025-05-14 12:35:19,935 [INFO] Epoch 11/15 - Policy Loss: 0.9890, Value Loss: 0.2096, Total Loss: 1.1986, LR: 0.001711
2025-05-14 12:36:02,882 [INFO] Epoch 12/15 - Policy Loss: 0.9871, Value Loss: 0.2090, Total Loss: 1.1961, LR: 0.000061
2025-05-14 12:36:44,155 [INFO] Epoch 13/15 - Policy Loss: 0.9856, Value Loss: 0.2086, Total Loss: 1.1942, LR: 0.001689
2025-05-14 12:37:25,807 [INFO] Epoch 14/15 - Policy Loss: 0.9841, Value Loss: 0.2080, Total Loss: 1.1921, LR: 0.003339
2025-05-14 12:38:07,228 [INFO] Epoch 15/15 - Policy Loss: 0.9831, Value Loss: 0.2076, Total Loss: 1.1907, LR: 0.004989
2025-05-14 12:38:07,254 [INFO] 训练完成，总损失: 1.1907
2025-05-14 12:38:07,255 [INFO] 保存迭代 32 的模型
2025-05-14 12:38:08,380 [INFO] Model saved to ./models/best.pt
2025-05-14 12:38:09,115 [INFO] Model saved to ./models/iteration_32.pt
2025-05-14 12:38:09,115 [INFO] 所有训练迭代完成
2025-05-14 12:38:09,115 [INFO] 开始迭代 33/300
2025-05-14 12:38:09,115 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 12:52:40,220 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 12:52:40,220 [INFO] 保存训练样本
2025-05-14 12:52:44,917 [INFO] 使用 157808 个样本训练神经网络
2025-05-14 12:52:44,918 [INFO] Training with 157808 examples
2025-05-14 12:52:44,918 [INFO] 总训练步数: 2310, 每轮次批次数: 154
2025-05-14 12:52:45,517 [INFO] 循环学习率周期大小: 462 步
2025-05-14 12:53:26,445 [INFO] Epoch 1/15 - Policy Loss: 1.0046, Value Loss: 0.2278, Total Loss: 1.2324, LR: 0.001689
2025-05-14 12:54:07,425 [INFO] Epoch 2/15 - Policy Loss: 1.0006, Value Loss: 0.2246, Total Loss: 1.2253, LR: 0.003339
2025-05-14 12:54:48,338 [INFO] Epoch 3/15 - Policy Loss: 0.9983, Value Loss: 0.2226, Total Loss: 1.2209, LR: 0.004989
2025-05-14 12:55:29,394 [INFO] Epoch 4/15 - Policy Loss: 0.9988, Value Loss: 0.2224, Total Loss: 1.2212, LR: 0.003361
2025-05-14 12:56:10,479 [INFO] Epoch 5/15 - Policy Loss: 0.9948, Value Loss: 0.2207, Total Loss: 1.2155, LR: 0.001711
2025-05-14 12:56:51,610 [INFO] Epoch 6/15 - Policy Loss: 0.9901, Value Loss: 0.2186, Total Loss: 1.2087, LR: 0.000061
2025-05-14 12:57:32,937 [INFO] Epoch 7/15 - Policy Loss: 0.9874, Value Loss: 0.2170, Total Loss: 1.2044, LR: 0.001689
2025-05-14 12:58:14,656 [INFO] Epoch 8/15 - Policy Loss: 0.9847, Value Loss: 0.2161, Total Loss: 1.2008, LR: 0.003339
2025-05-14 12:58:55,925 [INFO] Epoch 9/15 - Policy Loss: 0.9841, Value Loss: 0.2153, Total Loss: 1.1994, LR: 0.004989
2025-05-14 12:59:37,572 [INFO] Epoch 10/15 - Policy Loss: 0.9840, Value Loss: 0.2150, Total Loss: 1.1989, LR: 0.003361
2025-05-14 13:00:19,003 [INFO] Epoch 11/15 - Policy Loss: 0.9828, Value Loss: 0.2142, Total Loss: 1.1970, LR: 0.001711
2025-05-14 13:01:00,484 [INFO] Epoch 12/15 - Policy Loss: 0.9811, Value Loss: 0.2136, Total Loss: 1.1947, LR: 0.000061
2025-05-14 13:01:42,092 [INFO] Epoch 13/15 - Policy Loss: 0.9794, Value Loss: 0.2129, Total Loss: 1.1923, LR: 0.001689
2025-05-14 13:02:23,547 [INFO] Epoch 14/15 - Policy Loss: 0.9779, Value Loss: 0.2122, Total Loss: 1.1901, LR: 0.003339
2025-05-14 13:03:04,916 [INFO] Epoch 15/15 - Policy Loss: 0.9775, Value Loss: 0.2118, Total Loss: 1.1893, LR: 0.004989
2025-05-14 13:03:04,941 [INFO] 训练完成，总损失: 1.1893
2025-05-14 13:03:04,941 [INFO] 保存迭代 33 的模型
2025-05-14 13:03:06,238 [INFO] Model saved to ./models/best.pt
2025-05-14 13:03:07,097 [INFO] Model saved to ./models/iteration_33.pt
2025-05-14 13:03:07,098 [INFO] 所有训练迭代完成
2025-05-14 13:03:07,098 [INFO] 开始迭代 34/300
2025-05-14 13:03:07,098 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 13:18:30,576 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 13:18:30,577 [INFO] 保存训练样本
2025-05-14 13:18:35,609 [INFO] 使用 157904 个样本训练神经网络
2025-05-14 13:18:35,609 [INFO] Training with 157904 examples
2025-05-14 13:18:35,610 [INFO] 总训练步数: 2310, 每轮次批次数: 154
2025-05-14 13:18:35,681 [INFO] 循环学习率周期大小: 462 步
2025-05-14 13:19:16,772 [INFO] Epoch 1/15 - Policy Loss: 1.0058, Value Loss: 0.2272, Total Loss: 1.2330, LR: 0.001689
2025-05-14 13:19:57,956 [INFO] Epoch 2/15 - Policy Loss: 0.9965, Value Loss: 0.2228, Total Loss: 1.2193, LR: 0.003339
2025-05-14 13:20:39,713 [INFO] Epoch 3/15 - Policy Loss: 0.9934, Value Loss: 0.2202, Total Loss: 1.2136, LR: 0.004989
2025-05-14 13:21:21,022 [INFO] Epoch 4/15 - Policy Loss: 0.9931, Value Loss: 0.2192, Total Loss: 1.2123, LR: 0.003361
2025-05-14 13:22:34,657 [INFO] Epoch 5/15 - Policy Loss: 0.9890, Value Loss: 0.2174, Total Loss: 1.2065, LR: 0.001711
2025-05-14 13:24:00,831 [INFO] Epoch 6/15 - Policy Loss: 0.9848, Value Loss: 0.2158, Total Loss: 1.2006, LR: 0.000061
2025-05-14 13:26:13,305 [INFO] Epoch 7/15 - Policy Loss: 0.9815, Value Loss: 0.2144, Total Loss: 1.1960, LR: 0.001689
2025-05-14 13:27:45,128 [INFO] Epoch 8/15 - Policy Loss: 0.9791, Value Loss: 0.2137, Total Loss: 1.1927, LR: 0.003339
2025-05-14 13:28:26,519 [INFO] Epoch 9/15 - Policy Loss: 0.9783, Value Loss: 0.2132, Total Loss: 1.1915, LR: 0.004989
2025-05-14 13:29:07,676 [INFO] Epoch 10/15 - Policy Loss: 0.9788, Value Loss: 0.2131, Total Loss: 1.1919, LR: 0.003361
2025-05-14 13:29:49,018 [INFO] Epoch 11/15 - Policy Loss: 0.9782, Value Loss: 0.2128, Total Loss: 1.1910, LR: 0.001711
2025-05-14 13:30:30,409 [INFO] Epoch 12/15 - Policy Loss: 0.9763, Value Loss: 0.2121, Total Loss: 1.1884, LR: 0.000061
2025-05-14 13:31:11,900 [INFO] Epoch 13/15 - Policy Loss: 0.9743, Value Loss: 0.2115, Total Loss: 1.1858, LR: 0.001689
2025-05-14 13:32:25,465 [INFO] Epoch 14/15 - Policy Loss: 0.9733, Value Loss: 0.2110, Total Loss: 1.1842, LR: 0.003339
2025-05-14 13:34:29,561 [INFO] Epoch 15/15 - Policy Loss: 0.9727, Value Loss: 0.2105, Total Loss: 1.1832, LR: 0.004989
2025-05-14 13:34:29,585 [INFO] 训练完成，总损失: 1.1832
2025-05-14 13:34:29,586 [INFO] 保存迭代 34 的模型
2025-05-14 13:34:30,617 [INFO] Model saved to ./models/best.pt
2025-05-14 13:34:31,290 [INFO] Model saved to ./models/iteration_34.pt
2025-05-14 13:34:31,291 [INFO] 所有训练迭代完成
2025-05-14 13:34:31,291 [INFO] 开始迭代 35/300
2025-05-14 13:34:31,291 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 14:03:29,817 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 14:03:29,818 [INFO] 保存训练样本
2025-05-14 14:03:34,617 [INFO] 使用 158416 个样本训练神经网络
2025-05-14 14:03:34,617 [INFO] Training with 158416 examples
2025-05-14 14:03:34,618 [INFO] 总训练步数: 2310, 每轮次批次数: 154
2025-05-14 14:03:35,154 [INFO] 循环学习率周期大小: 462 步
2025-05-14 14:05:41,673 [INFO] Epoch 1/15 - Policy Loss: 1.0020, Value Loss: 0.2306, Total Loss: 1.2326, LR: 0.001689
2025-05-14 14:07:46,637 [INFO] Epoch 2/15 - Policy Loss: 0.9950, Value Loss: 0.2229, Total Loss: 1.2179, LR: 0.003339
2025-05-14 14:09:54,353 [INFO] Epoch 3/15 - Policy Loss: 0.9919, Value Loss: 0.2204, Total Loss: 1.2123, LR: 0.004989
2025-05-14 14:12:08,496 [INFO] Epoch 4/15 - Policy Loss: 0.9905, Value Loss: 0.2191, Total Loss: 1.2095, LR: 0.003361
2025-05-14 14:14:14,408 [INFO] Epoch 5/15 - Policy Loss: 0.9863, Value Loss: 0.2166, Total Loss: 1.2029, LR: 0.001711
2025-05-14 14:16:20,398 [INFO] Epoch 6/15 - Policy Loss: 0.9816, Value Loss: 0.2151, Total Loss: 1.1967, LR: 0.000061
2025-05-14 14:18:26,895 [INFO] Epoch 7/15 - Policy Loss: 0.9776, Value Loss: 0.2132, Total Loss: 1.1908, LR: 0.001689
2025-05-14 14:20:40,986 [INFO] Epoch 8/15 - Policy Loss: 0.9753, Value Loss: 0.2116, Total Loss: 1.1869, LR: 0.003339
2025-05-14 14:22:48,483 [INFO] Epoch 9/15 - Policy Loss: 0.9745, Value Loss: 0.2108, Total Loss: 1.1853, LR: 0.004989
2025-05-14 14:24:52,300 [INFO] Epoch 10/15 - Policy Loss: 0.9746, Value Loss: 0.2105, Total Loss: 1.1851, LR: 0.003361
2025-05-14 14:26:58,835 [INFO] Epoch 11/15 - Policy Loss: 0.9737, Value Loss: 0.2097, Total Loss: 1.1834, LR: 0.001711
2025-05-14 14:29:13,467 [INFO] Epoch 12/15 - Policy Loss: 0.9725, Value Loss: 0.2090, Total Loss: 1.1815, LR: 0.000061
2025-05-14 14:31:20,652 [INFO] Epoch 13/15 - Policy Loss: 0.9709, Value Loss: 0.2082, Total Loss: 1.1791, LR: 0.001689
2025-05-14 14:33:20,639 [INFO] Epoch 14/15 - Policy Loss: 0.9698, Value Loss: 0.2075, Total Loss: 1.1773, LR: 0.003339
2025-05-14 14:35:26,026 [INFO] Epoch 15/15 - Policy Loss: 0.9694, Value Loss: 0.2070, Total Loss: 1.1764, LR: 0.004989
2025-05-14 14:35:26,055 [INFO] 训练完成，总损失: 1.1764
2025-05-14 14:35:26,055 [INFO] 保存迭代 35 的模型
2025-05-14 14:35:27,487 [INFO] Model saved to ./models/best.pt
2025-05-14 14:35:28,781 [INFO] Model saved to ./models/iteration_35.pt
2025-05-14 14:35:28,782 [INFO] 所有训练迭代完成
2025-05-14 14:35:28,782 [INFO] 开始迭代 36/300
2025-05-14 14:35:28,782 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 15:02:55,996 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 15:02:55,997 [INFO] 保存训练样本
2025-05-14 15:03:00,299 [INFO] 使用 158832 个样本训练神经网络
2025-05-14 15:03:00,300 [INFO] Training with 158832 examples
2025-05-14 15:03:00,300 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-14 15:03:00,900 [INFO] 循环学习率周期大小: 465 步
2025-05-14 15:05:09,656 [INFO] Epoch 1/15 - Policy Loss: 1.0066, Value Loss: 0.2224, Total Loss: 1.2290, LR: 0.001689
2025-05-14 15:07:20,575 [INFO] Epoch 2/15 - Policy Loss: 0.9940, Value Loss: 0.2158, Total Loss: 1.2098, LR: 0.003339
2025-05-14 15:09:28,987 [INFO] Epoch 3/15 - Policy Loss: 0.9913, Value Loss: 0.2142, Total Loss: 1.2055, LR: 0.004989
2025-05-14 15:11:40,187 [INFO] Epoch 4/15 - Policy Loss: 0.9898, Value Loss: 0.2128, Total Loss: 1.2026, LR: 0.003361
2025-05-14 15:13:49,192 [INFO] Epoch 5/15 - Policy Loss: 0.9866, Value Loss: 0.2112, Total Loss: 1.1977, LR: 0.001711
2025-05-14 15:16:00,869 [INFO] Epoch 6/15 - Policy Loss: 0.9818, Value Loss: 0.2089, Total Loss: 1.1907, LR: 0.000061
2025-05-14 15:18:09,497 [INFO] Epoch 7/15 - Policy Loss: 0.9780, Value Loss: 0.2073, Total Loss: 1.1853, LR: 0.001689
2025-05-14 15:20:18,500 [INFO] Epoch 8/15 - Policy Loss: 0.9755, Value Loss: 0.2060, Total Loss: 1.1816, LR: 0.003339
2025-05-14 15:22:30,015 [INFO] Epoch 9/15 - Policy Loss: 0.9739, Value Loss: 0.2050, Total Loss: 1.1789, LR: 0.004989
2025-05-14 15:24:42,119 [INFO] Epoch 10/15 - Policy Loss: 0.9733, Value Loss: 0.2044, Total Loss: 1.1777, LR: 0.003361
2025-05-14 15:26:52,379 [INFO] Epoch 11/15 - Policy Loss: 0.9716, Value Loss: 0.2037, Total Loss: 1.1753, LR: 0.001711
2025-05-14 15:29:00,497 [INFO] Epoch 12/15 - Policy Loss: 0.9699, Value Loss: 0.2030, Total Loss: 1.1729, LR: 0.000061
2025-05-14 15:31:12,955 [INFO] Epoch 13/15 - Policy Loss: 0.9679, Value Loss: 0.2023, Total Loss: 1.1702, LR: 0.001689
2025-05-14 15:33:21,622 [INFO] Epoch 14/15 - Policy Loss: 0.9667, Value Loss: 0.2018, Total Loss: 1.1685, LR: 0.003339
2025-05-14 15:35:33,325 [INFO] Epoch 15/15 - Policy Loss: 0.9660, Value Loss: 0.2015, Total Loss: 1.1674, LR: 0.004989
2025-05-14 15:35:33,351 [INFO] 训练完成，总损失: 1.1674
2025-05-14 15:35:33,351 [INFO] 保存迭代 36 的模型
2025-05-14 15:35:34,488 [INFO] Model saved to ./models/best.pt
2025-05-14 15:35:35,348 [INFO] Model saved to ./models/iteration_36.pt
2025-05-14 15:35:35,348 [INFO] 所有训练迭代完成
2025-05-14 15:35:35,348 [INFO] 开始迭代 37/300
2025-05-14 15:35:35,348 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 16:02:37,127 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 16:02:37,128 [INFO] 保存训练样本
2025-05-14 16:02:41,510 [INFO] 使用 158776 个样本训练神经网络
2025-05-14 16:02:41,510 [INFO] Training with 158776 examples
2025-05-14 16:02:41,511 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-14 16:02:41,566 [INFO] 循环学习率周期大小: 465 步
2025-05-14 16:04:49,865 [INFO] Epoch 1/15 - Policy Loss: 0.9817, Value Loss: 0.2193, Total Loss: 1.2010, LR: 0.001689
2025-05-14 16:07:01,098 [INFO] Epoch 2/15 - Policy Loss: 0.9777, Value Loss: 0.2146, Total Loss: 1.1922, LR: 0.003339
2025-05-14 16:09:08,964 [INFO] Epoch 3/15 - Policy Loss: 0.9751, Value Loss: 0.2119, Total Loss: 1.1870, LR: 0.004989
2025-05-14 16:11:21,066 [INFO] Epoch 4/15 - Policy Loss: 0.9738, Value Loss: 0.2107, Total Loss: 1.1845, LR: 0.003361
2025-05-14 16:13:29,245 [INFO] Epoch 5/15 - Policy Loss: 0.9723, Value Loss: 0.2090, Total Loss: 1.1813, LR: 0.001711
2025-05-14 16:15:41,566 [INFO] Epoch 6/15 - Policy Loss: 0.9692, Value Loss: 0.2076, Total Loss: 1.1768, LR: 0.000061
2025-05-14 16:17:49,057 [INFO] Epoch 7/15 - Policy Loss: 0.9659, Value Loss: 0.2060, Total Loss: 1.1719, LR: 0.001689
2025-05-14 16:19:58,557 [INFO] Epoch 8/15 - Policy Loss: 0.9632, Value Loss: 0.2048, Total Loss: 1.1680, LR: 0.003339
2025-05-14 16:22:07,373 [INFO] Epoch 9/15 - Policy Loss: 0.9617, Value Loss: 0.2044, Total Loss: 1.1661, LR: 0.004989
2025-05-14 16:24:19,542 [INFO] Epoch 10/15 - Policy Loss: 0.9619, Value Loss: 0.2044, Total Loss: 1.1663, LR: 0.003361
2025-05-14 16:26:27,856 [INFO] Epoch 11/15 - Policy Loss: 0.9614, Value Loss: 0.2038, Total Loss: 1.1651, LR: 0.001711
2025-05-14 16:28:35,005 [INFO] Epoch 12/15 - Policy Loss: 0.9602, Value Loss: 0.2031, Total Loss: 1.1633, LR: 0.000061
2025-05-14 16:30:47,118 [INFO] Epoch 13/15 - Policy Loss: 0.9584, Value Loss: 0.2024, Total Loss: 1.1608, LR: 0.001689
2025-05-14 16:33:01,848 [INFO] Epoch 14/15 - Policy Loss: 0.9573, Value Loss: 0.2020, Total Loss: 1.1593, LR: 0.003339
2025-05-14 16:35:09,551 [INFO] Epoch 15/15 - Policy Loss: 0.9566, Value Loss: 0.2018, Total Loss: 1.1584, LR: 0.004989
2025-05-14 16:35:09,596 [INFO] 训练完成，总损失: 1.1584
2025-05-14 16:35:09,597 [INFO] 保存迭代 37 的模型
2025-05-14 16:35:11,073 [INFO] Model saved to ./models/best.pt
2025-05-14 16:35:11,974 [INFO] Model saved to ./models/iteration_37.pt
2025-05-14 16:35:11,975 [INFO] 所有训练迭代完成
2025-05-14 16:35:11,975 [INFO] 开始迭代 38/300
2025-05-14 16:35:11,975 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 17:02:25,612 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 17:02:25,612 [INFO] 保存训练样本
2025-05-14 17:02:30,306 [INFO] 使用 159000 个样本训练神经网络
2025-05-14 17:02:30,306 [INFO] Training with 159000 examples
2025-05-14 17:02:30,307 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-14 17:02:30,871 [INFO] 循环学习率周期大小: 465 步
2025-05-14 17:04:36,629 [INFO] Epoch 1/15 - Policy Loss: 0.9810, Value Loss: 0.2166, Total Loss: 1.1977, LR: 0.001689
2025-05-14 17:06:42,581 [INFO] Epoch 2/15 - Policy Loss: 0.9749, Value Loss: 0.2127, Total Loss: 1.1876, LR: 0.003339
2025-05-14 17:08:53,915 [INFO] Epoch 3/15 - Policy Loss: 0.9721, Value Loss: 0.2098, Total Loss: 1.1820, LR: 0.004989
2025-05-14 17:10:58,537 [INFO] Epoch 4/15 - Policy Loss: 0.9706, Value Loss: 0.2091, Total Loss: 1.1797, LR: 0.003361
2025-05-14 17:13:00,037 [INFO] Epoch 5/15 - Policy Loss: 0.9665, Value Loss: 0.2068, Total Loss: 1.1733, LR: 0.001711
2025-05-14 17:15:06,221 [INFO] Epoch 6/15 - Policy Loss: 0.9635, Value Loss: 0.2046, Total Loss: 1.1680, LR: 0.000061
2025-05-14 17:17:18,495 [INFO] Epoch 7/15 - Policy Loss: 0.9602, Value Loss: 0.2028, Total Loss: 1.1630, LR: 0.001689
2025-05-14 17:19:24,948 [INFO] Epoch 8/15 - Policy Loss: 0.9573, Value Loss: 0.2018, Total Loss: 1.1591, LR: 0.003339
2025-05-14 17:21:29,889 [INFO] Epoch 9/15 - Policy Loss: 0.9560, Value Loss: 0.2008, Total Loss: 1.1568, LR: 0.004989
2025-05-14 17:23:36,868 [INFO] Epoch 10/15 - Policy Loss: 0.9560, Value Loss: 0.2003, Total Loss: 1.1564, LR: 0.003361
2025-05-14 17:25:50,221 [INFO] Epoch 11/15 - Policy Loss: 0.9552, Value Loss: 0.1998, Total Loss: 1.1549, LR: 0.001711
2025-05-14 17:27:58,057 [INFO] Epoch 12/15 - Policy Loss: 0.9536, Value Loss: 0.1991, Total Loss: 1.1526, LR: 0.000061
2025-05-14 17:30:04,797 [INFO] Epoch 13/15 - Policy Loss: 0.9520, Value Loss: 0.1984, Total Loss: 1.1504, LR: 0.001689
2025-05-14 17:32:10,184 [INFO] Epoch 14/15 - Policy Loss: 0.9508, Value Loss: 0.1979, Total Loss: 1.1487, LR: 0.003339
2025-05-14 17:34:26,983 [INFO] Epoch 15/15 - Policy Loss: 0.9502, Value Loss: 0.1974, Total Loss: 1.1476, LR: 0.004989
2025-05-14 17:34:27,009 [INFO] 训练完成，总损失: 1.1476
2025-05-14 17:34:27,009 [INFO] 保存迭代 38 的模型
2025-05-14 17:34:28,480 [INFO] Model saved to ./models/best.pt
2025-05-14 17:34:29,288 [INFO] Model saved to ./models/iteration_38.pt
2025-05-14 17:34:29,289 [INFO] 所有训练迭代完成
2025-05-14 17:34:29,289 [INFO] 开始迭代 39/300
2025-05-14 17:34:29,289 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 18:00:43,058 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 18:00:43,059 [INFO] 保存训练样本
2025-05-14 18:00:48,403 [INFO] 使用 159400 个样本训练神经网络
2025-05-14 18:00:48,403 [INFO] Training with 159400 examples
2025-05-14 18:00:48,404 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-14 18:00:49,043 [INFO] 循环学习率周期大小: 465 步
2025-05-14 18:02:52,414 [INFO] Epoch 1/15 - Policy Loss: 0.9743, Value Loss: 0.2229, Total Loss: 1.1973, LR: 0.001689
2025-05-14 18:05:02,373 [INFO] Epoch 2/15 - Policy Loss: 0.9674, Value Loss: 0.2170, Total Loss: 1.1844, LR: 0.003339
2025-05-14 18:07:17,016 [INFO] Epoch 3/15 - Policy Loss: 0.9633, Value Loss: 0.2137, Total Loss: 1.1769, LR: 0.004989
2025-05-14 18:09:25,686 [INFO] Epoch 4/15 - Policy Loss: 0.9624, Value Loss: 0.2118, Total Loss: 1.1742, LR: 0.003361
2025-05-14 18:11:35,629 [INFO] Epoch 5/15 - Policy Loss: 0.9596, Value Loss: 0.2094, Total Loss: 1.1690, LR: 0.001711
2025-05-14 18:13:45,064 [INFO] Epoch 6/15 - Policy Loss: 0.9557, Value Loss: 0.2073, Total Loss: 1.1629, LR: 0.000061
2025-05-14 18:16:01,395 [INFO] Epoch 7/15 - Policy Loss: 0.9536, Value Loss: 0.2058, Total Loss: 1.1594, LR: 0.001689
2025-05-14 18:18:12,296 [INFO] Epoch 8/15 - Policy Loss: 0.9507, Value Loss: 0.2048, Total Loss: 1.1556, LR: 0.003339
2025-05-14 18:20:17,659 [INFO] Epoch 9/15 - Policy Loss: 0.9489, Value Loss: 0.2041, Total Loss: 1.1531, LR: 0.004989
2025-05-14 18:22:27,012 [INFO] Epoch 10/15 - Policy Loss: 0.9486, Value Loss: 0.2039, Total Loss: 1.1526, LR: 0.003361
2025-05-14 18:24:36,064 [INFO] Epoch 11/15 - Policy Loss: 0.9482, Value Loss: 0.2031, Total Loss: 1.1513, LR: 0.001711
2025-05-14 18:26:52,244 [INFO] Epoch 12/15 - Policy Loss: 0.9464, Value Loss: 0.2026, Total Loss: 1.1490, LR: 0.000061
2025-05-14 18:28:57,806 [INFO] Epoch 13/15 - Policy Loss: 0.9454, Value Loss: 0.2019, Total Loss: 1.1473, LR: 0.001689
2025-05-14 18:31:06,421 [INFO] Epoch 14/15 - Policy Loss: 0.9442, Value Loss: 0.2012, Total Loss: 1.1454, LR: 0.003339
2025-05-14 18:33:20,392 [INFO] Epoch 15/15 - Policy Loss: 0.9437, Value Loss: 0.2009, Total Loss: 1.1445, LR: 0.004989
2025-05-14 18:33:20,420 [INFO] 训练完成，总损失: 1.1445
2025-05-14 18:33:20,420 [INFO] 保存迭代 39 的模型
2025-05-14 18:33:22,271 [INFO] Model saved to ./models/best.pt
2025-05-14 18:33:23,215 [INFO] Model saved to ./models/iteration_39.pt
2025-05-14 18:33:23,215 [INFO] 所有训练迭代完成
2025-05-14 18:33:23,216 [INFO] 开始迭代 40/300
2025-05-14 18:33:23,216 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 19:01:16,809 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 19:01:16,810 [INFO] 保存训练样本
2025-05-14 19:01:21,820 [INFO] 使用 159440 个样本训练神经网络
2025-05-14 19:01:21,820 [INFO] Training with 159440 examples
2025-05-14 19:01:21,821 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-14 19:01:22,327 [INFO] 循环学习率周期大小: 465 步
2025-05-14 19:03:37,335 [INFO] Epoch 1/15 - Policy Loss: 0.9802, Value Loss: 0.2171, Total Loss: 1.1972, LR: 0.001689
2025-05-14 19:05:48,094 [INFO] Epoch 2/15 - Policy Loss: 0.9692, Value Loss: 0.2134, Total Loss: 1.1826, LR: 0.003339
2025-05-14 19:08:03,122 [INFO] Epoch 3/15 - Policy Loss: 0.9635, Value Loss: 0.2109, Total Loss: 1.1745, LR: 0.004989
2025-05-14 19:10:17,688 [INFO] Epoch 4/15 - Policy Loss: 0.9631, Value Loss: 0.2102, Total Loss: 1.1733, LR: 0.003361
2025-05-14 19:12:27,397 [INFO] Epoch 5/15 - Policy Loss: 0.9596, Value Loss: 0.2081, Total Loss: 1.1677, LR: 0.001711
2025-05-14 19:14:37,861 [INFO] Epoch 6/15 - Policy Loss: 0.9553, Value Loss: 0.2066, Total Loss: 1.1620, LR: 0.000061
2025-05-14 19:16:48,971 [INFO] Epoch 7/15 - Policy Loss: 0.9516, Value Loss: 0.2054, Total Loss: 1.1570, LR: 0.001689
2025-05-14 19:18:56,879 [INFO] Epoch 8/15 - Policy Loss: 0.9490, Value Loss: 0.2040, Total Loss: 1.1530, LR: 0.003339
2025-05-14 19:21:04,668 [INFO] Epoch 9/15 - Policy Loss: 0.9474, Value Loss: 0.2030, Total Loss: 1.1504, LR: 0.004989
2025-05-14 19:23:16,229 [INFO] Epoch 10/15 - Policy Loss: 0.9468, Value Loss: 0.2027, Total Loss: 1.1495, LR: 0.003361
2025-05-14 19:25:27,214 [INFO] Epoch 11/15 - Policy Loss: 0.9455, Value Loss: 0.2021, Total Loss: 1.1475, LR: 0.001711
2025-05-14 19:27:37,798 [INFO] Epoch 12/15 - Policy Loss: 0.9436, Value Loss: 0.2013, Total Loss: 1.1449, LR: 0.000061
2025-05-14 19:29:44,304 [INFO] Epoch 13/15 - Policy Loss: 0.9420, Value Loss: 0.2008, Total Loss: 1.1428, LR: 0.001689
2025-05-14 19:31:53,045 [INFO] Epoch 14/15 - Policy Loss: 0.9404, Value Loss: 0.2003, Total Loss: 1.1407, LR: 0.003339
2025-05-14 19:34:01,800 [INFO] Epoch 15/15 - Policy Loss: 0.9394, Value Loss: 0.2000, Total Loss: 1.1394, LR: 0.004989
2025-05-14 19:34:01,829 [INFO] 训练完成，总损失: 1.1394
2025-05-14 19:34:01,830 [INFO] 保存迭代 40 的模型
2025-05-14 19:34:03,743 [INFO] Model saved to ./models/best.pt
2025-05-14 19:34:04,635 [INFO] Model saved to ./models/iteration_40.pt
2025-05-14 19:34:04,635 [INFO] 所有训练迭代完成
2025-05-14 19:34:04,635 [INFO] 开始迭代 41/300
2025-05-14 19:34:04,635 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 20:00:01,158 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 20:00:01,161 [INFO] 保存训练样本
2025-05-14 20:00:06,315 [INFO] 使用 159856 个样本训练神经网络
2025-05-14 20:00:06,315 [INFO] Training with 159856 examples
2025-05-14 20:00:06,316 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-14 20:00:06,380 [INFO] 循环学习率周期大小: 468 步
2025-05-14 20:02:15,639 [INFO] Epoch 1/15 - Policy Loss: 0.9601, Value Loss: 0.2211, Total Loss: 1.1811, LR: 0.001689
2025-05-14 20:04:27,932 [INFO] Epoch 2/15 - Policy Loss: 0.9553, Value Loss: 0.2175, Total Loss: 1.1728, LR: 0.003339
2025-05-14 20:06:40,319 [INFO] Epoch 3/15 - Policy Loss: 0.9506, Value Loss: 0.2144, Total Loss: 1.1650, LR: 0.004989
2025-05-14 20:08:52,911 [INFO] Epoch 4/15 - Policy Loss: 0.9490, Value Loss: 0.2137, Total Loss: 1.1627, LR: 0.003361
2025-05-14 20:11:05,269 [INFO] Epoch 5/15 - Policy Loss: 0.9451, Value Loss: 0.2121, Total Loss: 1.1572, LR: 0.001711
2025-05-14 20:13:17,164 [INFO] Epoch 6/15 - Policy Loss: 0.9409, Value Loss: 0.2098, Total Loss: 1.1507, LR: 0.000061
2025-05-14 20:15:30,355 [INFO] Epoch 7/15 - Policy Loss: 0.9376, Value Loss: 0.2080, Total Loss: 1.1457, LR: 0.001689
2025-05-14 20:17:39,405 [INFO] Epoch 8/15 - Policy Loss: 0.9359, Value Loss: 0.2071, Total Loss: 1.1430, LR: 0.003339
2025-05-14 20:19:48,396 [INFO] Epoch 9/15 - Policy Loss: 0.9352, Value Loss: 0.2062, Total Loss: 1.1414, LR: 0.004989
2025-05-14 20:21:59,581 [INFO] Epoch 10/15 - Policy Loss: 0.9353, Value Loss: 0.2058, Total Loss: 1.1411, LR: 0.003361
2025-05-14 20:24:06,374 [INFO] Epoch 11/15 - Policy Loss: 0.9347, Value Loss: 0.2052, Total Loss: 1.1399, LR: 0.001711
2025-05-14 20:26:18,397 [INFO] Epoch 12/15 - Policy Loss: 0.9334, Value Loss: 0.2043, Total Loss: 1.1377, LR: 0.000061
2025-05-14 20:28:28,684 [INFO] Epoch 13/15 - Policy Loss: 0.9319, Value Loss: 0.2035, Total Loss: 1.1354, LR: 0.001689
2025-05-14 20:30:38,138 [INFO] Epoch 14/15 - Policy Loss: 0.9311, Value Loss: 0.2027, Total Loss: 1.1338, LR: 0.003339
2025-05-14 20:32:50,109 [INFO] Epoch 15/15 - Policy Loss: 0.9307, Value Loss: 0.2024, Total Loss: 1.1331, LR: 0.004989
2025-05-14 20:32:50,137 [INFO] 训练完成，总损失: 1.1331
2025-05-14 20:32:50,138 [INFO] 保存迭代 41 的模型
2025-05-14 20:32:52,266 [INFO] Model saved to ./models/best.pt
2025-05-14 20:32:53,193 [INFO] Model saved to ./models/iteration_41.pt
2025-05-14 20:32:53,194 [INFO] 所有训练迭代完成
2025-05-14 20:32:53,194 [INFO] 开始迭代 42/300
2025-05-14 20:32:53,194 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 21:01:14,919 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 21:01:14,920 [INFO] 保存训练样本
2025-05-14 21:01:20,579 [INFO] 使用 160360 个样本训练神经网络
2025-05-14 21:01:20,579 [INFO] Training with 160360 examples
2025-05-14 21:01:20,580 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-14 21:01:21,137 [INFO] 循环学习率周期大小: 468 步
2025-05-14 21:03:33,030 [INFO] Epoch 1/15 - Policy Loss: 0.9652, Value Loss: 0.2268, Total Loss: 1.1920, LR: 0.001689
2025-05-14 21:05:42,018 [INFO] Epoch 2/15 - Policy Loss: 0.9556, Value Loss: 0.2212, Total Loss: 1.1768, LR: 0.003339
2025-05-14 21:07:53,113 [INFO] Epoch 3/15 - Policy Loss: 0.9500, Value Loss: 0.2183, Total Loss: 1.1683, LR: 0.004989
2025-05-14 21:10:04,270 [INFO] Epoch 4/15 - Policy Loss: 0.9488, Value Loss: 0.2173, Total Loss: 1.1660, LR: 0.003361
2025-05-14 21:12:14,743 [INFO] Epoch 5/15 - Policy Loss: 0.9439, Value Loss: 0.2151, Total Loss: 1.1590, LR: 0.001711
2025-05-14 21:14:24,991 [INFO] Epoch 6/15 - Policy Loss: 0.9396, Value Loss: 0.2132, Total Loss: 1.1529, LR: 0.000061
2025-05-14 21:16:39,797 [INFO] Epoch 7/15 - Policy Loss: 0.9362, Value Loss: 0.2115, Total Loss: 1.1477, LR: 0.001689
2025-05-14 21:18:47,631 [INFO] Epoch 8/15 - Policy Loss: 0.9332, Value Loss: 0.2102, Total Loss: 1.1434, LR: 0.003339
2025-05-14 21:20:56,300 [INFO] Epoch 9/15 - Policy Loss: 0.9312, Value Loss: 0.2093, Total Loss: 1.1405, LR: 0.004989
2025-05-14 21:23:08,457 [INFO] Epoch 10/15 - Policy Loss: 0.9304, Value Loss: 0.2088, Total Loss: 1.1392, LR: 0.003361
2025-05-14 21:25:21,277 [INFO] Epoch 11/15 - Policy Loss: 0.9293, Value Loss: 0.2081, Total Loss: 1.1375, LR: 0.001711
2025-05-14 21:27:31,082 [INFO] Epoch 12/15 - Policy Loss: 0.9274, Value Loss: 0.2074, Total Loss: 1.1348, LR: 0.000061
2025-05-14 21:29:43,228 [INFO] Epoch 13/15 - Policy Loss: 0.9264, Value Loss: 0.2069, Total Loss: 1.1333, LR: 0.001689
2025-05-14 21:31:54,929 [INFO] Epoch 14/15 - Policy Loss: 0.9255, Value Loss: 0.2064, Total Loss: 1.1319, LR: 0.003339
2025-05-14 21:34:04,567 [INFO] Epoch 15/15 - Policy Loss: 0.9248, Value Loss: 0.2062, Total Loss: 1.1310, LR: 0.004989
2025-05-14 21:34:04,591 [INFO] 训练完成，总损失: 1.1310
2025-05-14 21:34:04,591 [INFO] 保存迭代 42 的模型
2025-05-14 21:34:05,743 [INFO] Model saved to ./models/best.pt
2025-05-14 21:34:06,512 [INFO] Model saved to ./models/iteration_42.pt
2025-05-14 21:34:06,513 [INFO] 所有训练迭代完成
2025-05-14 21:34:06,513 [INFO] 开始迭代 43/300
2025-05-14 21:34:06,513 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 21:59:02,683 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 21:59:02,684 [INFO] 保存训练样本
2025-05-14 21:59:07,271 [INFO] 使用 159696 个样本训练神经网络
2025-05-14 21:59:07,271 [INFO] Training with 159696 examples
2025-05-14 21:59:07,272 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-14 21:59:07,712 [INFO] 循环学习率周期大小: 465 步
2025-05-14 22:01:23,697 [INFO] Epoch 1/15 - Policy Loss: 0.9597, Value Loss: 0.2231, Total Loss: 1.1828, LR: 0.001689
2025-05-14 22:03:35,751 [INFO] Epoch 2/15 - Policy Loss: 0.9513, Value Loss: 0.2184, Total Loss: 1.1696, LR: 0.003339
2025-05-14 22:05:40,061 [INFO] Epoch 3/15 - Policy Loss: 0.9486, Value Loss: 0.2158, Total Loss: 1.1644, LR: 0.004989
2025-05-14 22:07:48,375 [INFO] Epoch 4/15 - Policy Loss: 0.9473, Value Loss: 0.2149, Total Loss: 1.1622, LR: 0.003361
2025-05-14 22:09:54,977 [INFO] Epoch 5/15 - Policy Loss: 0.9448, Value Loss: 0.2137, Total Loss: 1.1585, LR: 0.001711
2025-05-14 22:12:07,151 [INFO] Epoch 6/15 - Policy Loss: 0.9404, Value Loss: 0.2114, Total Loss: 1.1518, LR: 0.000061
2025-05-14 22:14:08,072 [INFO] Epoch 7/15 - Policy Loss: 0.9366, Value Loss: 0.2098, Total Loss: 1.1463, LR: 0.001689
2025-05-14 22:16:18,461 [INFO] Epoch 8/15 - Policy Loss: 0.9338, Value Loss: 0.2084, Total Loss: 1.1422, LR: 0.003339
2025-05-14 22:18:27,947 [INFO] Epoch 9/15 - Policy Loss: 0.9325, Value Loss: 0.2073, Total Loss: 1.1398, LR: 0.004989
2025-05-14 22:20:40,355 [INFO] Epoch 10/15 - Policy Loss: 0.9325, Value Loss: 0.2071, Total Loss: 1.1396, LR: 0.003361
2025-05-14 22:22:50,593 [INFO] Epoch 11/15 - Policy Loss: 0.9316, Value Loss: 0.2065, Total Loss: 1.1381, LR: 0.001711
2025-05-14 22:24:56,857 [INFO] Epoch 12/15 - Policy Loss: 0.9296, Value Loss: 0.2056, Total Loss: 1.1352, LR: 0.000061
2025-05-14 22:27:05,891 [INFO] Epoch 13/15 - Policy Loss: 0.9284, Value Loss: 0.2050, Total Loss: 1.1334, LR: 0.001689
2025-05-14 22:29:16,488 [INFO] Epoch 14/15 - Policy Loss: 0.9273, Value Loss: 0.2045, Total Loss: 1.1317, LR: 0.003339
2025-05-14 22:31:24,034 [INFO] Epoch 15/15 - Policy Loss: 0.9268, Value Loss: 0.2041, Total Loss: 1.1309, LR: 0.004989
2025-05-14 22:31:24,062 [INFO] 训练完成，总损失: 1.1309
2025-05-14 22:31:24,062 [INFO] 保存迭代 43 的模型
2025-05-14 22:31:25,523 [INFO] Model saved to ./models/best.pt
2025-05-14 22:31:26,499 [INFO] Model saved to ./models/iteration_43.pt
2025-05-14 22:31:26,499 [INFO] 所有训练迭代完成
2025-05-14 22:31:26,499 [INFO] 开始迭代 44/300
2025-05-14 22:31:26,499 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-14 22:57:25,899 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-14 22:57:25,900 [INFO] 保存训练样本
2025-05-14 22:57:30,445 [INFO] 使用 159784 个样本训练神经网络
2025-05-14 22:57:30,445 [INFO] Training with 159784 examples
2025-05-14 22:57:30,445 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-14 22:57:30,502 [INFO] 循环学习率周期大小: 468 步
2025-05-14 22:59:35,866 [INFO] Epoch 1/15 - Policy Loss: 0.9511, Value Loss: 0.2132, Total Loss: 1.1643, LR: 0.001689
2025-05-14 23:01:45,777 [INFO] Epoch 2/15 - Policy Loss: 0.9462, Value Loss: 0.2103, Total Loss: 1.1565, LR: 0.003339
2025-05-14 23:04:03,359 [INFO] Epoch 3/15 - Policy Loss: 0.9424, Value Loss: 0.2082, Total Loss: 1.1506, LR: 0.004989
2025-05-14 23:06:08,668 [INFO] Epoch 4/15 - Policy Loss: 0.9412, Value Loss: 0.2077, Total Loss: 1.1488, LR: 0.003361
2025-05-14 23:08:07,736 [INFO] Epoch 5/15 - Policy Loss: 0.9373, Value Loss: 0.2064, Total Loss: 1.1438, LR: 0.001711
2025-05-14 23:10:11,230 [INFO] Epoch 6/15 - Policy Loss: 0.9336, Value Loss: 0.2050, Total Loss: 1.1386, LR: 0.000061
2025-05-14 23:12:28,553 [INFO] Epoch 7/15 - Policy Loss: 0.9294, Value Loss: 0.2034, Total Loss: 1.1328, LR: 0.001689
2025-05-14 23:14:25,567 [INFO] Epoch 8/15 - Policy Loss: 0.9270, Value Loss: 0.2023, Total Loss: 1.1293, LR: 0.003339
2025-05-14 23:16:34,273 [INFO] Epoch 9/15 - Policy Loss: 0.9259, Value Loss: 0.2020, Total Loss: 1.1278, LR: 0.004989
2025-05-14 23:18:49,743 [INFO] Epoch 10/15 - Policy Loss: 0.9260, Value Loss: 0.2018, Total Loss: 1.1277, LR: 0.003361
2025-05-14 23:21:02,112 [INFO] Epoch 11/15 - Policy Loss: 0.9249, Value Loss: 0.2012, Total Loss: 1.1262, LR: 0.001711
2025-05-14 23:23:03,728 [INFO] Epoch 12/15 - Policy Loss: 0.9236, Value Loss: 0.2006, Total Loss: 1.1242, LR: 0.000061
2025-05-14 23:25:13,244 [INFO] Epoch 13/15 - Policy Loss: 0.9219, Value Loss: 0.2000, Total Loss: 1.1219, LR: 0.001689
2025-05-14 23:27:33,780 [INFO] Epoch 14/15 - Policy Loss: 0.9204, Value Loss: 0.1992, Total Loss: 1.1196, LR: 0.003339
2025-05-14 23:30:28,802 [INFO] Epoch 15/15 - Policy Loss: 0.9198, Value Loss: 0.1988, Total Loss: 1.1186, LR: 0.004989
2025-05-14 23:30:28,841 [INFO] 训练完成，总损失: 1.1186
2025-05-14 23:30:28,841 [INFO] 保存迭代 44 的模型
2025-05-14 23:30:30,210 [INFO] Model saved to ./models/best.pt
2025-05-14 23:30:31,165 [INFO] Model saved to ./models/iteration_44.pt
2025-05-14 23:30:31,166 [INFO] 所有训练迭代完成
2025-05-14 23:30:31,166 [INFO] 开始迭代 45/300
2025-05-14 23:30:31,166 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 00:05:25,265 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 00:05:25,265 [INFO] 保存训练样本
2025-05-15 00:05:30,691 [INFO] 使用 160648 个样本训练神经网络
2025-05-15 00:05:30,691 [INFO] Training with 160648 examples
2025-05-15 00:05:30,692 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-15 00:05:31,389 [INFO] 循环学习率周期大小: 468 步
2025-05-15 00:08:22,735 [INFO] Epoch 1/15 - Policy Loss: 0.9464, Value Loss: 0.2137, Total Loss: 1.1601, LR: 0.001689
2025-05-15 00:11:15,989 [INFO] Epoch 2/15 - Policy Loss: 0.9363, Value Loss: 0.2092, Total Loss: 1.1455, LR: 0.003339
2025-05-15 00:14:12,181 [INFO] Epoch 3/15 - Policy Loss: 0.9337, Value Loss: 0.2080, Total Loss: 1.1417, LR: 0.004989
2025-05-15 00:17:09,323 [INFO] Epoch 4/15 - Policy Loss: 0.9334, Value Loss: 0.2061, Total Loss: 1.1395, LR: 0.003361
2025-05-15 00:20:07,812 [INFO] Epoch 5/15 - Policy Loss: 0.9305, Value Loss: 0.2044, Total Loss: 1.1349, LR: 0.001711
2025-05-15 00:22:50,480 [INFO] Epoch 6/15 - Policy Loss: 0.9268, Value Loss: 0.2037, Total Loss: 1.1304, LR: 0.000061
2025-05-15 00:25:46,801 [INFO] Epoch 7/15 - Policy Loss: 0.9242, Value Loss: 0.2022, Total Loss: 1.1264, LR: 0.001689
2025-05-15 00:28:42,769 [INFO] Epoch 8/15 - Policy Loss: 0.9219, Value Loss: 0.2007, Total Loss: 1.1226, LR: 0.003339
2025-05-15 00:31:43,146 [INFO] Epoch 9/15 - Policy Loss: 0.9207, Value Loss: 0.1999, Total Loss: 1.1206, LR: 0.004989
2025-05-15 00:34:37,351 [INFO] Epoch 10/15 - Policy Loss: 0.9203, Value Loss: 0.1997, Total Loss: 1.1200, LR: 0.003361
2025-05-15 00:37:33,407 [INFO] Epoch 11/15 - Policy Loss: 0.9190, Value Loss: 0.1991, Total Loss: 1.1181, LR: 0.001711
2025-05-15 00:40:31,070 [INFO] Epoch 12/15 - Policy Loss: 0.9177, Value Loss: 0.1985, Total Loss: 1.1162, LR: 0.000061
2025-05-15 00:43:28,368 [INFO] Epoch 13/15 - Policy Loss: 0.9167, Value Loss: 0.1980, Total Loss: 1.1147, LR: 0.001689
2025-05-15 00:46:28,711 [INFO] Epoch 14/15 - Policy Loss: 0.9155, Value Loss: 0.1974, Total Loss: 1.1129, LR: 0.003339
2025-05-15 00:49:24,614 [INFO] Epoch 15/15 - Policy Loss: 0.9149, Value Loss: 0.1970, Total Loss: 1.1119, LR: 0.004989
2025-05-15 00:49:24,642 [INFO] 训练完成，总损失: 1.1119
2025-05-15 00:49:24,642 [INFO] 保存迭代 45 的模型
2025-05-15 00:49:26,253 [INFO] Model saved to ./models/best.pt
2025-05-15 00:49:27,485 [INFO] Model saved to ./models/iteration_45.pt
2025-05-15 00:49:27,485 [INFO] 所有训练迭代完成
2025-05-15 00:49:27,485 [INFO] 开始迭代 46/300
2025-05-15 00:49:27,485 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 01:24:03,983 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 01:24:03,983 [INFO] 保存训练样本
2025-05-15 01:24:08,521 [INFO] 使用 161016 个样本训练神经网络
2025-05-15 01:24:08,522 [INFO] Training with 161016 examples
2025-05-15 01:24:08,522 [INFO] 总训练步数: 2355, 每轮次批次数: 157
2025-05-15 01:24:09,057 [INFO] 循环学习率周期大小: 471 步
2025-05-15 01:27:04,735 [INFO] Epoch 1/15 - Policy Loss: 0.9434, Value Loss: 0.2253, Total Loss: 1.1687, LR: 0.001689
2025-05-15 01:30:03,104 [INFO] Epoch 2/15 - Policy Loss: 0.9339, Value Loss: 0.2216, Total Loss: 1.1555, LR: 0.003339
2025-05-15 01:33:07,619 [INFO] Epoch 3/15 - Policy Loss: 0.9313, Value Loss: 0.2206, Total Loss: 1.1518, LR: 0.004989
2025-05-15 01:36:04,425 [INFO] Epoch 4/15 - Policy Loss: 0.9291, Value Loss: 0.2189, Total Loss: 1.1480, LR: 0.003361
2025-05-15 01:39:01,355 [INFO] Epoch 5/15 - Policy Loss: 0.9263, Value Loss: 0.2175, Total Loss: 1.1437, LR: 0.001711
2025-05-15 01:41:58,054 [INFO] Epoch 6/15 - Policy Loss: 0.9227, Value Loss: 0.2156, Total Loss: 1.1383, LR: 0.000061
2025-05-15 01:44:56,834 [INFO] Epoch 7/15 - Policy Loss: 0.9193, Value Loss: 0.2141, Total Loss: 1.1334, LR: 0.001689
2025-05-15 01:47:53,780 [INFO] Epoch 8/15 - Policy Loss: 0.9168, Value Loss: 0.2124, Total Loss: 1.1293, LR: 0.003339
2025-05-15 01:50:50,903 [INFO] Epoch 9/15 - Policy Loss: 0.9156, Value Loss: 0.2114, Total Loss: 1.1270, LR: 0.004989
2025-05-15 01:53:37,848 [INFO] Epoch 10/15 - Policy Loss: 0.9153, Value Loss: 0.2109, Total Loss: 1.1263, LR: 0.003361
2025-05-15 01:56:32,675 [INFO] Epoch 11/15 - Policy Loss: 0.9144, Value Loss: 0.2104, Total Loss: 1.1249, LR: 0.001711
2025-05-15 01:59:34,510 [INFO] Epoch 12/15 - Policy Loss: 0.9128, Value Loss: 0.2096, Total Loss: 1.1224, LR: 0.000061
2025-05-15 02:02:31,783 [INFO] Epoch 13/15 - Policy Loss: 0.9115, Value Loss: 0.2088, Total Loss: 1.1203, LR: 0.001689
2025-05-15 02:05:26,606 [INFO] Epoch 14/15 - Policy Loss: 0.9101, Value Loss: 0.2083, Total Loss: 1.1184, LR: 0.003339
2025-05-15 02:08:19,545 [INFO] Epoch 15/15 - Policy Loss: 0.9097, Value Loss: 0.2081, Total Loss: 1.1178, LR: 0.004989
2025-05-15 02:08:19,572 [INFO] 训练完成，总损失: 1.1178
2025-05-15 02:08:19,573 [INFO] 保存迭代 46 的模型
2025-05-15 02:08:20,820 [INFO] Model saved to ./models/best.pt
2025-05-15 02:08:21,501 [INFO] Model saved to ./models/iteration_46.pt
2025-05-15 02:08:21,501 [INFO] 所有训练迭代完成
2025-05-15 02:08:21,502 [INFO] 开始迭代 47/300
2025-05-15 02:08:21,502 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 02:41:49,380 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 02:41:49,380 [INFO] 保存训练样本
2025-05-15 02:41:54,472 [INFO] 使用 161384 个样本训练神经网络
2025-05-15 02:41:54,472 [INFO] Training with 161384 examples
2025-05-15 02:41:54,473 [INFO] 总训练步数: 2355, 每轮次批次数: 157
2025-05-15 02:41:54,959 [INFO] 循环学习率周期大小: 471 步
2025-05-15 02:44:53,731 [INFO] Epoch 1/15 - Policy Loss: 0.9462, Value Loss: 0.2279, Total Loss: 1.1740, LR: 0.001689
2025-05-15 02:47:52,053 [INFO] Epoch 2/15 - Policy Loss: 0.9356, Value Loss: 0.2240, Total Loss: 1.1596, LR: 0.003339
2025-05-15 02:50:49,887 [INFO] Epoch 3/15 - Policy Loss: 0.9323, Value Loss: 0.2209, Total Loss: 1.1532, LR: 0.004989
2025-05-15 02:53:47,716 [INFO] Epoch 4/15 - Policy Loss: 0.9321, Value Loss: 0.2201, Total Loss: 1.1522, LR: 0.003361
2025-05-15 02:56:43,848 [INFO] Epoch 5/15 - Policy Loss: 0.9277, Value Loss: 0.2176, Total Loss: 1.1453, LR: 0.001711
2025-05-15 02:59:41,795 [INFO] Epoch 6/15 - Policy Loss: 0.9240, Value Loss: 0.2158, Total Loss: 1.1398, LR: 0.000061
2025-05-15 03:02:37,628 [INFO] Epoch 7/15 - Policy Loss: 0.9211, Value Loss: 0.2147, Total Loss: 1.1357, LR: 0.001689
2025-05-15 03:05:36,392 [INFO] Epoch 8/15 - Policy Loss: 0.9185, Value Loss: 0.2132, Total Loss: 1.1318, LR: 0.003339
2025-05-15 03:08:38,914 [INFO] Epoch 9/15 - Policy Loss: 0.9168, Value Loss: 0.2121, Total Loss: 1.1289, LR: 0.004989
2025-05-15 03:11:29,737 [INFO] Epoch 10/15 - Policy Loss: 0.9159, Value Loss: 0.2113, Total Loss: 1.1272, LR: 0.003361
2025-05-15 03:14:26,945 [INFO] Epoch 11/15 - Policy Loss: 0.9147, Value Loss: 0.2106, Total Loss: 1.1253, LR: 0.001711
2025-05-15 03:17:26,137 [INFO] Epoch 12/15 - Policy Loss: 0.9130, Value Loss: 0.2097, Total Loss: 1.1227, LR: 0.000061
2025-05-15 03:20:24,153 [INFO] Epoch 13/15 - Policy Loss: 0.9109, Value Loss: 0.2088, Total Loss: 1.1197, LR: 0.001689
2025-05-15 03:23:25,653 [INFO] Epoch 14/15 - Policy Loss: 0.9096, Value Loss: 0.2083, Total Loss: 1.1179, LR: 0.003339
2025-05-15 03:26:26,431 [INFO] Epoch 15/15 - Policy Loss: 0.9087, Value Loss: 0.2078, Total Loss: 1.1166, LR: 0.004989
2025-05-15 03:26:26,456 [INFO] 训练完成，总损失: 1.1166
2025-05-15 03:26:26,456 [INFO] 保存迭代 47 的模型
2025-05-15 03:26:28,147 [INFO] Model saved to ./models/best.pt
2025-05-15 03:26:29,135 [INFO] Model saved to ./models/iteration_47.pt
2025-05-15 03:26:29,135 [INFO] 所有训练迭代完成
2025-05-15 03:26:29,135 [INFO] 开始迭代 48/300
2025-05-15 03:26:29,135 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 03:58:35,373 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 03:58:35,373 [INFO] 保存训练样本
2025-05-15 03:58:40,638 [INFO] 使用 161848 个样本训练神经网络
2025-05-15 03:58:40,638 [INFO] Training with 161848 examples
2025-05-15 03:58:40,639 [INFO] 总训练步数: 2370, 每轮次批次数: 158
2025-05-15 03:58:40,704 [INFO] 循环学习率周期大小: 474 步
2025-05-15 04:01:43,844 [INFO] Epoch 1/15 - Policy Loss: 0.9252, Value Loss: 0.2192, Total Loss: 1.1444, LR: 0.001690
2025-05-15 04:04:41,892 [INFO] Epoch 2/15 - Policy Loss: 0.9228, Value Loss: 0.2167, Total Loss: 1.1394, LR: 0.003340
2025-05-15 04:07:41,483 [INFO] Epoch 3/15 - Policy Loss: 0.9211, Value Loss: 0.2138, Total Loss: 1.1349, LR: 0.004990
2025-05-15 04:10:40,793 [INFO] Epoch 4/15 - Policy Loss: 0.9198, Value Loss: 0.2135, Total Loss: 1.1332, LR: 0.003360
2025-05-15 04:13:38,445 [INFO] Epoch 5/15 - Policy Loss: 0.9169, Value Loss: 0.2122, Total Loss: 1.1291, LR: 0.001710
2025-05-15 04:16:42,235 [INFO] Epoch 6/15 - Policy Loss: 0.9127, Value Loss: 0.2109, Total Loss: 1.1236, LR: 0.000060
2025-05-15 04:19:37,212 [INFO] Epoch 7/15 - Policy Loss: 0.9087, Value Loss: 0.2096, Total Loss: 1.1182, LR: 0.001690
2025-05-15 04:22:35,808 [INFO] Epoch 8/15 - Policy Loss: 0.9059, Value Loss: 0.2083, Total Loss: 1.1142, LR: 0.003340
2025-05-15 04:25:29,029 [INFO] Epoch 9/15 - Policy Loss: 0.9061, Value Loss: 0.2077, Total Loss: 1.1138, LR: 0.004990
2025-05-15 04:28:33,798 [INFO] Epoch 10/15 - Policy Loss: 0.9063, Value Loss: 0.2077, Total Loss: 1.1141, LR: 0.003360
2025-05-15 04:31:31,866 [INFO] Epoch 11/15 - Policy Loss: 0.9060, Value Loss: 0.2076, Total Loss: 1.1136, LR: 0.001710
2025-05-15 04:34:26,649 [INFO] Epoch 12/15 - Policy Loss: 0.9046, Value Loss: 0.2071, Total Loss: 1.1116, LR: 0.000060
2025-05-15 04:37:27,312 [INFO] Epoch 13/15 - Policy Loss: 0.9031, Value Loss: 0.2064, Total Loss: 1.1096, LR: 0.001690
2025-05-15 04:40:28,677 [INFO] Epoch 14/15 - Policy Loss: 0.9019, Value Loss: 0.2060, Total Loss: 1.1079, LR: 0.003340
2025-05-15 04:43:30,119 [INFO] Epoch 15/15 - Policy Loss: 0.9014, Value Loss: 0.2057, Total Loss: 1.1071, LR: 0.004990
2025-05-15 04:43:30,144 [INFO] 训练完成，总损失: 1.1071
2025-05-15 04:43:30,144 [INFO] 保存迭代 48 的模型
2025-05-15 04:43:31,588 [INFO] Model saved to ./models/best.pt
2025-05-15 04:43:32,506 [INFO] Model saved to ./models/iteration_48.pt
2025-05-15 04:43:32,507 [INFO] 所有训练迭代完成
2025-05-15 04:43:32,507 [INFO] 开始迭代 49/300
2025-05-15 04:43:32,507 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 05:15:45,702 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 05:15:45,703 [INFO] 保存训练样本
2025-05-15 05:15:50,909 [INFO] 使用 161760 个样本训练神经网络
2025-05-15 05:15:50,909 [INFO] Training with 161760 examples
2025-05-15 05:15:50,910 [INFO] 总训练步数: 2355, 每轮次批次数: 157
2025-05-15 05:15:51,471 [INFO] 循环学习率周期大小: 471 步
2025-05-15 05:18:43,913 [INFO] Epoch 1/15 - Policy Loss: 0.9263, Value Loss: 0.2100, Total Loss: 1.1363, LR: 0.001689
2025-05-15 05:21:38,876 [INFO] Epoch 2/15 - Policy Loss: 0.9188, Value Loss: 0.2071, Total Loss: 1.1259, LR: 0.003339
2025-05-15 05:24:42,408 [INFO] Epoch 3/15 - Policy Loss: 0.9150, Value Loss: 0.2053, Total Loss: 1.1203, LR: 0.004989
2025-05-15 05:27:43,215 [INFO] Epoch 4/15 - Policy Loss: 0.9138, Value Loss: 0.2048, Total Loss: 1.1187, LR: 0.003361
2025-05-15 05:30:41,491 [INFO] Epoch 5/15 - Policy Loss: 0.9112, Value Loss: 0.2034, Total Loss: 1.1145, LR: 0.001711
2025-05-15 05:33:41,527 [INFO] Epoch 6/15 - Policy Loss: 0.9088, Value Loss: 0.2025, Total Loss: 1.1112, LR: 0.000061
2025-05-15 05:36:40,211 [INFO] Epoch 7/15 - Policy Loss: 0.9056, Value Loss: 0.2014, Total Loss: 1.1070, LR: 0.001689
2025-05-15 05:39:38,787 [INFO] Epoch 8/15 - Policy Loss: 0.9039, Value Loss: 0.2008, Total Loss: 1.1047, LR: 0.003339
2025-05-15 05:42:41,267 [INFO] Epoch 9/15 - Policy Loss: 0.9024, Value Loss: 0.2002, Total Loss: 1.1026, LR: 0.004989
2025-05-15 05:45:41,113 [INFO] Epoch 10/15 - Policy Loss: 0.9017, Value Loss: 0.2001, Total Loss: 1.1018, LR: 0.003361
2025-05-15 05:48:37,606 [INFO] Epoch 11/15 - Policy Loss: 0.9005, Value Loss: 0.1996, Total Loss: 1.1001, LR: 0.001711
2025-05-15 05:51:35,992 [INFO] Epoch 12/15 - Policy Loss: 0.8990, Value Loss: 0.1990, Total Loss: 1.0979, LR: 0.000061
2025-05-15 05:54:37,855 [INFO] Epoch 13/15 - Policy Loss: 0.8975, Value Loss: 0.1985, Total Loss: 1.0960, LR: 0.001689
2025-05-15 05:57:33,993 [INFO] Epoch 14/15 - Policy Loss: 0.8967, Value Loss: 0.1983, Total Loss: 1.0950, LR: 0.003339
2025-05-15 06:00:29,233 [INFO] Epoch 15/15 - Policy Loss: 0.8967, Value Loss: 0.1982, Total Loss: 1.0948, LR: 0.004989
2025-05-15 06:00:29,257 [INFO] 训练完成，总损失: 1.0948
2025-05-15 06:00:29,257 [INFO] 保存迭代 49 的模型
2025-05-15 06:00:31,064 [INFO] Model saved to ./models/best.pt
2025-05-15 06:00:32,016 [INFO] Model saved to ./models/iteration_49.pt
2025-05-15 06:00:32,017 [INFO] 所有训练迭代完成
2025-05-15 06:00:32,017 [INFO] 开始迭代 50/300
2025-05-15 06:00:32,017 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 06:32:11,302 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 06:32:11,303 [INFO] 保存训练样本
2025-05-15 06:32:16,680 [INFO] 使用 161864 个样本训练神经网络
2025-05-15 06:32:16,681 [INFO] Training with 161864 examples
2025-05-15 06:32:16,681 [INFO] 总训练步数: 2370, 每轮次批次数: 158
2025-05-15 06:32:17,283 [INFO] 循环学习率周期大小: 474 步
2025-05-15 06:35:15,565 [INFO] Epoch 1/15 - Policy Loss: 0.9312, Value Loss: 0.2147, Total Loss: 1.1459, LR: 0.001690
2025-05-15 06:38:15,028 [INFO] Epoch 2/15 - Policy Loss: 0.9202, Value Loss: 0.2099, Total Loss: 1.1301, LR: 0.003340
2025-05-15 06:41:14,108 [INFO] Epoch 3/15 - Policy Loss: 0.9148, Value Loss: 0.2084, Total Loss: 1.1232, LR: 0.004990
2025-05-15 06:44:17,980 [INFO] Epoch 4/15 - Policy Loss: 0.9140, Value Loss: 0.2082, Total Loss: 1.1223, LR: 0.003360
2025-05-15 06:47:21,243 [INFO] Epoch 5/15 - Policy Loss: 0.9108, Value Loss: 0.2071, Total Loss: 1.1178, LR: 0.001710
2025-05-15 06:50:22,829 [INFO] Epoch 6/15 - Policy Loss: 0.9077, Value Loss: 0.2060, Total Loss: 1.1136, LR: 0.000060
2025-05-15 06:53:24,887 [INFO] Epoch 7/15 - Policy Loss: 0.9052, Value Loss: 0.2046, Total Loss: 1.1098, LR: 0.001690
2025-05-15 06:56:27,416 [INFO] Epoch 8/15 - Policy Loss: 0.9028, Value Loss: 0.2037, Total Loss: 1.1065, LR: 0.003340
2025-05-15 06:59:30,182 [INFO] Epoch 9/15 - Policy Loss: 0.9014, Value Loss: 0.2033, Total Loss: 1.1047, LR: 0.004990
2025-05-15 07:02:29,709 [INFO] Epoch 10/15 - Policy Loss: 0.9011, Value Loss: 0.2031, Total Loss: 1.1042, LR: 0.003360
2025-05-15 07:05:31,416 [INFO] Epoch 11/15 - Policy Loss: 0.9002, Value Loss: 0.2028, Total Loss: 1.1030, LR: 0.001710
2025-05-15 07:08:19,390 [INFO] Epoch 12/15 - Policy Loss: 0.8989, Value Loss: 0.2020, Total Loss: 1.1009, LR: 0.000060
2025-05-15 07:11:10,519 [INFO] Epoch 13/15 - Policy Loss: 0.8974, Value Loss: 0.2013, Total Loss: 1.0987, LR: 0.001690
2025-05-15 07:14:07,989 [INFO] Epoch 14/15 - Policy Loss: 0.8961, Value Loss: 0.2009, Total Loss: 1.0970, LR: 0.003340
2025-05-15 07:17:12,435 [INFO] Epoch 15/15 - Policy Loss: 0.8953, Value Loss: 0.2007, Total Loss: 1.0960, LR: 0.004990
2025-05-15 07:17:12,463 [INFO] 训练完成，总损失: 1.0960
2025-05-15 07:17:12,464 [INFO] 保存迭代 50 的模型
2025-05-15 07:17:14,175 [INFO] Model saved to ./models/best.pt
2025-05-15 07:17:15,121 [INFO] Model saved to ./models/iteration_50.pt
2025-05-15 07:17:15,121 [INFO] 所有训练迭代完成
2025-05-15 07:17:15,121 [INFO] 开始迭代 51/300
2025-05-15 07:17:15,121 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 07:49:46,460 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 07:49:46,460 [INFO] 保存训练样本
2025-05-15 07:49:51,730 [INFO] 使用 161544 个样本训练神经网络
2025-05-15 07:49:51,731 [INFO] Training with 161544 examples
2025-05-15 07:49:51,731 [INFO] 总训练步数: 2355, 每轮次批次数: 157
2025-05-15 07:49:51,799 [INFO] 循环学习率周期大小: 471 步
2025-05-15 07:52:48,871 [INFO] Epoch 1/15 - Policy Loss: 0.9212, Value Loss: 0.2047, Total Loss: 1.1259, LR: 0.001689
2025-05-15 07:55:43,847 [INFO] Epoch 2/15 - Policy Loss: 0.9142, Value Loss: 0.2002, Total Loss: 1.1144, LR: 0.003339
2025-05-15 07:58:43,361 [INFO] Epoch 3/15 - Policy Loss: 0.9137, Value Loss: 0.1993, Total Loss: 1.1130, LR: 0.004989
2025-05-15 08:01:39,362 [INFO] Epoch 4/15 - Policy Loss: 0.9129, Value Loss: 0.1982, Total Loss: 1.1111, LR: 0.003361
2025-05-15 08:04:28,471 [INFO] Epoch 5/15 - Policy Loss: 0.9097, Value Loss: 0.1972, Total Loss: 1.1068, LR: 0.001711
2025-05-15 08:07:27,128 [INFO] Epoch 6/15 - Policy Loss: 0.9060, Value Loss: 0.1960, Total Loss: 1.1020, LR: 0.000061
2025-05-15 08:10:27,545 [INFO] Epoch 7/15 - Policy Loss: 0.9031, Value Loss: 0.1950, Total Loss: 1.0981, LR: 0.001689
2025-05-15 08:13:25,783 [INFO] Epoch 8/15 - Policy Loss: 0.9011, Value Loss: 0.1936, Total Loss: 1.0947, LR: 0.003339
2025-05-15 08:16:19,818 [INFO] Epoch 9/15 - Policy Loss: 0.8995, Value Loss: 0.1930, Total Loss: 1.0925, LR: 0.004989
2025-05-15 08:19:18,661 [INFO] Epoch 10/15 - Policy Loss: 0.8986, Value Loss: 0.1925, Total Loss: 1.0911, LR: 0.003361
2025-05-15 08:22:17,409 [INFO] Epoch 11/15 - Policy Loss: 0.8971, Value Loss: 0.1918, Total Loss: 1.0889, LR: 0.001711
2025-05-15 08:25:18,513 [INFO] Epoch 12/15 - Policy Loss: 0.8954, Value Loss: 0.1913, Total Loss: 1.0866, LR: 0.000061
2025-05-15 08:28:14,166 [INFO] Epoch 13/15 - Policy Loss: 0.8935, Value Loss: 0.1908, Total Loss: 1.0843, LR: 0.001689
2025-05-15 08:31:05,390 [INFO] Epoch 14/15 - Policy Loss: 0.8920, Value Loss: 0.1903, Total Loss: 1.0823, LR: 0.003339
2025-05-15 08:34:02,706 [INFO] Epoch 15/15 - Policy Loss: 0.8915, Value Loss: 0.1901, Total Loss: 1.0816, LR: 0.004989
2025-05-15 08:34:02,736 [INFO] 训练完成，总损失: 1.0816
2025-05-15 08:34:02,736 [INFO] 保存迭代 51 的模型
2025-05-15 08:34:04,518 [INFO] Model saved to ./models/best.pt
2025-05-15 08:34:05,487 [INFO] Model saved to ./models/iteration_51.pt
2025-05-15 08:34:05,488 [INFO] 所有训练迭代完成
2025-05-15 08:34:05,488 [INFO] 开始迭代 52/300
2025-05-15 08:34:05,488 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 09:07:04,073 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 09:07:04,073 [INFO] 保存训练样本
2025-05-15 09:07:09,554 [INFO] 使用 162120 个样本训练神经网络
2025-05-15 09:07:09,555 [INFO] Training with 162120 examples
2025-05-15 09:07:09,555 [INFO] 总训练步数: 2370, 每轮次批次数: 158
2025-05-15 09:07:10,079 [INFO] 循环学习率周期大小: 474 步
2025-05-15 09:10:10,750 [INFO] Epoch 1/15 - Policy Loss: 0.9151, Value Loss: 0.1962, Total Loss: 1.1113, LR: 0.001690
2025-05-15 09:13:04,907 [INFO] Epoch 2/15 - Policy Loss: 0.9070, Value Loss: 0.1930, Total Loss: 1.0999, LR: 0.003340
2025-05-15 09:16:00,335 [INFO] Epoch 3/15 - Policy Loss: 0.9043, Value Loss: 0.1912, Total Loss: 1.0955, LR: 0.004990
2025-05-15 09:18:58,914 [INFO] Epoch 4/15 - Policy Loss: 0.9031, Value Loss: 0.1911, Total Loss: 1.0942, LR: 0.003360
2025-05-15 09:21:53,691 [INFO] Epoch 5/15 - Policy Loss: 0.9006, Value Loss: 0.1895, Total Loss: 1.0901, LR: 0.001710
2025-05-15 09:24:49,906 [INFO] Epoch 6/15 - Policy Loss: 0.8977, Value Loss: 0.1883, Total Loss: 1.0860, LR: 0.000060
2025-05-15 09:27:44,249 [INFO] Epoch 7/15 - Policy Loss: 0.8950, Value Loss: 0.1874, Total Loss: 1.0824, LR: 0.001690
2025-05-15 09:30:41,799 [INFO] Epoch 8/15 - Policy Loss: 0.8928, Value Loss: 0.1869, Total Loss: 1.0798, LR: 0.003340
2025-05-15 09:33:35,883 [INFO] Epoch 9/15 - Policy Loss: 0.8920, Value Loss: 0.1864, Total Loss: 1.0784, LR: 0.004990
2025-05-15 09:36:37,193 [INFO] Epoch 10/15 - Policy Loss: 0.8923, Value Loss: 0.1867, Total Loss: 1.0790, LR: 0.003360
2025-05-15 09:39:31,751 [INFO] Epoch 11/15 - Policy Loss: 0.8912, Value Loss: 0.1871, Total Loss: 1.0783, LR: 0.001710
2025-05-15 09:42:33,043 [INFO] Epoch 12/15 - Policy Loss: 0.8897, Value Loss: 0.1871, Total Loss: 1.0768, LR: 0.000060
2025-05-15 09:45:32,716 [INFO] Epoch 13/15 - Policy Loss: 0.8885, Value Loss: 0.1869, Total Loss: 1.0754, LR: 0.001690
2025-05-15 09:48:32,699 [INFO] Epoch 14/15 - Policy Loss: 0.8877, Value Loss: 0.1871, Total Loss: 1.0749, LR: 0.003340
2025-05-15 09:51:28,373 [INFO] Epoch 15/15 - Policy Loss: 0.8875, Value Loss: 0.1873, Total Loss: 1.0748, LR: 0.004990
2025-05-15 09:51:28,398 [INFO] 训练完成，总损失: 1.0748
2025-05-15 09:51:28,398 [INFO] 保存迭代 52 的模型
2025-05-15 09:51:29,648 [INFO] Model saved to ./models/best.pt
2025-05-15 09:51:30,377 [INFO] Model saved to ./models/iteration_52.pt
2025-05-15 09:51:30,378 [INFO] 所有训练迭代完成
2025-05-15 09:51:30,378 [INFO] 开始迭代 53/300
2025-05-15 09:51:30,378 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 10:25:15,573 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 10:25:15,574 [INFO] 保存训练样本
2025-05-15 10:25:21,192 [INFO] 使用 162696 个样本训练神经网络
2025-05-15 10:25:21,192 [INFO] Training with 162696 examples
2025-05-15 10:25:21,194 [INFO] 总训练步数: 2370, 每轮次批次数: 158
2025-05-15 10:25:21,883 [INFO] 循环学习率周期大小: 474 步
2025-05-15 10:28:19,975 [INFO] Epoch 1/15 - Policy Loss: 0.9188, Value Loss: 0.2151, Total Loss: 1.1339, LR: 0.001690
2025-05-15 10:31:20,520 [INFO] Epoch 2/15 - Policy Loss: 0.9082, Value Loss: 0.2093, Total Loss: 1.1175, LR: 0.003340
2025-05-15 10:34:19,601 [INFO] Epoch 3/15 - Policy Loss: 0.9072, Value Loss: 0.2061, Total Loss: 1.1133, LR: 0.004990
2025-05-15 10:37:19,063 [INFO] Epoch 4/15 - Policy Loss: 0.9043, Value Loss: 0.2027, Total Loss: 1.1070, LR: 0.003360
2025-05-15 10:40:12,092 [INFO] Epoch 5/15 - Policy Loss: 0.9005, Value Loss: 0.1994, Total Loss: 1.0999, LR: 0.001710
2025-05-15 10:43:07,039 [INFO] Epoch 6/15 - Policy Loss: 0.8969, Value Loss: 0.1972, Total Loss: 1.0941, LR: 0.000060
2025-05-15 10:46:07,366 [INFO] Epoch 7/15 - Policy Loss: 0.8934, Value Loss: 0.1950, Total Loss: 1.0884, LR: 0.001690
2025-05-15 10:49:08,208 [INFO] Epoch 8/15 - Policy Loss: 0.8910, Value Loss: 0.1936, Total Loss: 1.0846, LR: 0.003340
2025-05-15 10:52:04,796 [INFO] Epoch 9/15 - Policy Loss: 0.8895, Value Loss: 0.1925, Total Loss: 1.0820, LR: 0.004990
2025-05-15 10:54:59,498 [INFO] Epoch 10/15 - Policy Loss: 0.8897, Value Loss: 0.1917, Total Loss: 1.0814, LR: 0.003360
2025-05-15 10:57:59,735 [INFO] Epoch 11/15 - Policy Loss: 0.8889, Value Loss: 0.1909, Total Loss: 1.0797, LR: 0.001710
2025-05-15 11:00:54,029 [INFO] Epoch 12/15 - Policy Loss: 0.8874, Value Loss: 0.1900, Total Loss: 1.0775, LR: 0.000060
2025-05-15 11:03:52,867 [INFO] Epoch 13/15 - Policy Loss: 0.8862, Value Loss: 0.1894, Total Loss: 1.0756, LR: 0.001690
2025-05-15 11:06:50,685 [INFO] Epoch 14/15 - Policy Loss: 0.8851, Value Loss: 0.1888, Total Loss: 1.0739, LR: 0.003340
2025-05-15 11:09:45,386 [INFO] Epoch 15/15 - Policy Loss: 0.8843, Value Loss: 0.1883, Total Loss: 1.0726, LR: 0.004990
2025-05-15 11:09:45,411 [INFO] 训练完成，总损失: 1.0726
2025-05-15 11:09:45,411 [INFO] 保存迭代 53 的模型
2025-05-15 11:09:46,745 [INFO] Model saved to ./models/best.pt
2025-05-15 11:09:47,512 [INFO] Model saved to ./models/iteration_53.pt
2025-05-15 11:09:47,512 [INFO] 所有训练迭代完成
2025-05-15 11:09:47,512 [INFO] 开始迭代 54/300
2025-05-15 11:09:47,512 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 11:42:44,389 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 11:42:44,390 [INFO] 保存训练样本
2025-05-15 11:42:49,833 [INFO] 使用 163064 个样本训练神经网络
2025-05-15 11:42:49,834 [INFO] Training with 163064 examples
2025-05-15 11:42:49,835 [INFO] 总训练步数: 2385, 每轮次批次数: 159
2025-05-15 11:42:50,460 [INFO] 循环学习率周期大小: 477 步
2025-05-15 11:45:00,163 [INFO] Epoch 1/15 - Policy Loss: 0.9110, Value Loss: 0.1949, Total Loss: 1.1058, LR: 0.001690
2025-05-15 11:47:12,879 [INFO] Epoch 2/15 - Policy Loss: 0.9029, Value Loss: 0.1914, Total Loss: 1.0943, LR: 0.003340
2025-05-15 11:49:27,085 [INFO] Epoch 3/15 - Policy Loss: 0.8995, Value Loss: 0.1903, Total Loss: 1.0898, LR: 0.004990
2025-05-15 11:51:38,977 [INFO] Epoch 4/15 - Policy Loss: 0.8973, Value Loss: 0.1898, Total Loss: 1.0871, LR: 0.003360
2025-05-15 11:53:52,885 [INFO] Epoch 5/15 - Policy Loss: 0.8948, Value Loss: 0.1888, Total Loss: 1.0837, LR: 0.001710
2025-05-15 11:56:11,329 [INFO] Epoch 6/15 - Policy Loss: 0.8914, Value Loss: 0.1876, Total Loss: 1.0790, LR: 0.000060
2025-05-15 11:58:22,197 [INFO] Epoch 7/15 - Policy Loss: 0.8883, Value Loss: 0.1859, Total Loss: 1.0742, LR: 0.001690
2025-05-15 12:00:37,163 [INFO] Epoch 8/15 - Policy Loss: 0.8864, Value Loss: 0.1850, Total Loss: 1.0714, LR: 0.003340
2025-05-15 12:02:47,368 [INFO] Epoch 9/15 - Policy Loss: 0.8851, Value Loss: 0.1846, Total Loss: 1.0697, LR: 0.004990
2025-05-15 12:05:01,819 [INFO] Epoch 10/15 - Policy Loss: 0.8848, Value Loss: 0.1843, Total Loss: 1.0690, LR: 0.003360
2025-05-15 12:07:15,581 [INFO] Epoch 11/15 - Policy Loss: 0.8837, Value Loss: 0.1837, Total Loss: 1.0674, LR: 0.001710
2025-05-15 12:09:24,065 [INFO] Epoch 12/15 - Policy Loss: 0.8826, Value Loss: 0.1831, Total Loss: 1.0657, LR: 0.000060
2025-05-15 12:11:38,889 [INFO] Epoch 13/15 - Policy Loss: 0.8812, Value Loss: 0.1828, Total Loss: 1.0640, LR: 0.001690
2025-05-15 12:13:51,603 [INFO] Epoch 14/15 - Policy Loss: 0.8799, Value Loss: 0.1824, Total Loss: 1.0623, LR: 0.003340
2025-05-15 12:16:07,454 [INFO] Epoch 15/15 - Policy Loss: 0.8793, Value Loss: 0.1820, Total Loss: 1.0612, LR: 0.004990
2025-05-15 12:16:07,479 [INFO] 训练完成，总损失: 1.0612
2025-05-15 12:16:07,479 [INFO] 保存迭代 54 的模型
2025-05-15 12:16:08,411 [INFO] Model saved to ./models/best.pt
2025-05-15 12:16:09,047 [INFO] Model saved to ./models/iteration_54.pt
2025-05-15 12:16:09,047 [INFO] 所有训练迭代完成
2025-05-15 12:16:09,047 [INFO] 开始迭代 55/300
2025-05-15 12:16:09,047 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 12:43:51,323 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 12:43:51,324 [INFO] 保存训练样本
2025-05-15 12:43:57,328 [INFO] 使用 163080 个样本训练神经网络
2025-05-15 12:43:57,328 [INFO] Training with 163080 examples
2025-05-15 12:43:57,329 [INFO] 总训练步数: 2385, 每轮次批次数: 159
2025-05-15 12:43:57,406 [INFO] 循环学习率周期大小: 477 步
2025-05-15 12:46:09,957 [INFO] Epoch 1/15 - Policy Loss: 0.9016, Value Loss: 0.1940, Total Loss: 1.0955, LR: 0.001690
2025-05-15 12:48:19,329 [INFO] Epoch 2/15 - Policy Loss: 0.8948, Value Loss: 0.1922, Total Loss: 1.0870, LR: 0.003340
2025-05-15 12:50:35,506 [INFO] Epoch 3/15 - Policy Loss: 0.8922, Value Loss: 0.1912, Total Loss: 1.0834, LR: 0.004990
2025-05-15 12:52:46,016 [INFO] Epoch 4/15 - Policy Loss: 0.8899, Value Loss: 0.1905, Total Loss: 1.0805, LR: 0.003360
2025-05-15 12:55:03,863 [INFO] Epoch 5/15 - Policy Loss: 0.8868, Value Loss: 0.1891, Total Loss: 1.0759, LR: 0.001710
2025-05-15 12:57:14,863 [INFO] Epoch 6/15 - Policy Loss: 0.8828, Value Loss: 0.1875, Total Loss: 1.0703, LR: 0.000060
2025-05-15 12:59:23,281 [INFO] Epoch 7/15 - Policy Loss: 0.8798, Value Loss: 0.1862, Total Loss: 1.0660, LR: 0.001690
2025-05-15 13:01:38,213 [INFO] Epoch 8/15 - Policy Loss: 0.8779, Value Loss: 0.1855, Total Loss: 1.0634, LR: 0.003340
2025-05-15 13:03:57,947 [INFO] Epoch 9/15 - Policy Loss: 0.8767, Value Loss: 0.1847, Total Loss: 1.0615, LR: 0.004990
2025-05-15 13:06:12,453 [INFO] Epoch 10/15 - Policy Loss: 0.8769, Value Loss: 0.1846, Total Loss: 1.0615, LR: 0.003360
2025-05-15 13:08:14,972 [INFO] Epoch 11/15 - Policy Loss: 0.8757, Value Loss: 0.1839, Total Loss: 1.0596, LR: 0.001710
2025-05-15 13:10:26,275 [INFO] Epoch 12/15 - Policy Loss: 0.8742, Value Loss: 0.1833, Total Loss: 1.0575, LR: 0.000060
2025-05-15 13:12:41,965 [INFO] Epoch 13/15 - Policy Loss: 0.8729, Value Loss: 0.1828, Total Loss: 1.0557, LR: 0.001690
2025-05-15 13:14:54,212 [INFO] Epoch 14/15 - Policy Loss: 0.8718, Value Loss: 0.1824, Total Loss: 1.0541, LR: 0.003340
2025-05-15 13:17:03,857 [INFO] Epoch 15/15 - Policy Loss: 0.8714, Value Loss: 0.1821, Total Loss: 1.0535, LR: 0.004990
2025-05-15 13:17:03,886 [INFO] 训练完成，总损失: 1.0535
2025-05-15 13:17:03,887 [INFO] 保存迭代 55 的模型
2025-05-15 13:17:05,340 [INFO] Model saved to ./models/best.pt
2025-05-15 13:17:06,287 [INFO] Model saved to ./models/iteration_55.pt
2025-05-15 13:17:06,287 [INFO] 所有训练迭代完成
2025-05-15 13:17:06,287 [INFO] 开始迭代 56/300
2025-05-15 13:17:06,287 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 13:42:19,390 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 13:42:19,392 [INFO] 保存训练样本
2025-05-15 13:42:24,526 [INFO] 使用 162824 个样本训练神经网络
2025-05-15 13:42:24,526 [INFO] Training with 162824 examples
2025-05-15 13:42:24,527 [INFO] 总训练步数: 2385, 每轮次批次数: 159
2025-05-15 13:42:24,990 [INFO] 循环学习率周期大小: 477 步
2025-05-15 13:44:39,160 [INFO] Epoch 1/15 - Policy Loss: 0.8962, Value Loss: 0.1876, Total Loss: 1.0838, LR: 0.001690
2025-05-15 13:46:54,205 [INFO] Epoch 2/15 - Policy Loss: 0.8862, Value Loss: 0.1840, Total Loss: 1.0703, LR: 0.003340
2025-05-15 13:49:04,128 [INFO] Epoch 3/15 - Policy Loss: 0.8842, Value Loss: 0.1836, Total Loss: 1.0678, LR: 0.004990
2025-05-15 13:51:19,848 [INFO] Epoch 4/15 - Policy Loss: 0.8824, Value Loss: 0.1825, Total Loss: 1.0649, LR: 0.003360
2025-05-15 13:53:31,357 [INFO] Epoch 5/15 - Policy Loss: 0.8786, Value Loss: 0.1806, Total Loss: 1.0592, LR: 0.001710
2025-05-15 13:55:41,528 [INFO] Epoch 6/15 - Policy Loss: 0.8755, Value Loss: 0.1792, Total Loss: 1.0547, LR: 0.000060
2025-05-15 13:57:54,872 [INFO] Epoch 7/15 - Policy Loss: 0.8732, Value Loss: 0.1782, Total Loss: 1.0514, LR: 0.001690
2025-05-15 14:00:15,528 [INFO] Epoch 8/15 - Policy Loss: 0.8717, Value Loss: 0.1778, Total Loss: 1.0495, LR: 0.003340
2025-05-15 14:02:23,686 [INFO] Epoch 9/15 - Policy Loss: 0.8711, Value Loss: 0.1772, Total Loss: 1.0483, LR: 0.004990
2025-05-15 14:04:32,665 [INFO] Epoch 10/15 - Policy Loss: 0.8705, Value Loss: 0.1767, Total Loss: 1.0472, LR: 0.003360
2025-05-15 14:06:45,904 [INFO] Epoch 11/15 - Policy Loss: 0.8696, Value Loss: 0.1762, Total Loss: 1.0458, LR: 0.001710
2025-05-15 14:09:06,244 [INFO] Epoch 12/15 - Policy Loss: 0.8682, Value Loss: 0.1755, Total Loss: 1.0437, LR: 0.000060
2025-05-15 14:11:12,103 [INFO] Epoch 13/15 - Policy Loss: 0.8674, Value Loss: 0.1751, Total Loss: 1.0424, LR: 0.001690
2025-05-15 14:13:22,853 [INFO] Epoch 14/15 - Policy Loss: 0.8661, Value Loss: 0.1746, Total Loss: 1.0408, LR: 0.003340
2025-05-15 14:15:35,426 [INFO] Epoch 15/15 - Policy Loss: 0.8657, Value Loss: 0.1743, Total Loss: 1.0400, LR: 0.004990
2025-05-15 14:15:35,449 [INFO] 训练完成，总损失: 1.0400
2025-05-15 14:15:35,449 [INFO] 保存迭代 56 的模型
2025-05-15 14:15:36,828 [INFO] Model saved to ./models/best.pt
2025-05-15 14:15:37,579 [INFO] Model saved to ./models/iteration_56.pt
2025-05-15 14:15:37,579 [INFO] 所有训练迭代完成
2025-05-15 14:15:37,579 [INFO] 开始迭代 57/300
2025-05-15 14:15:37,580 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 14:41:41,828 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 14:41:41,829 [INFO] 保存训练样本
2025-05-15 14:41:46,789 [INFO] 使用 163064 个样本训练神经网络
2025-05-15 14:41:46,789 [INFO] Training with 163064 examples
2025-05-15 14:41:46,789 [INFO] 总训练步数: 2385, 每轮次批次数: 159
2025-05-15 14:41:47,424 [INFO] 循环学习率周期大小: 477 步
2025-05-15 14:43:56,425 [INFO] Epoch 1/15 - Policy Loss: 0.8920, Value Loss: 0.2060, Total Loss: 1.0980, LR: 0.001690
2025-05-15 14:45:56,132 [INFO] Epoch 2/15 - Policy Loss: 0.8853, Value Loss: 0.2015, Total Loss: 1.0868, LR: 0.003340
2025-05-15 14:48:07,043 [INFO] Epoch 3/15 - Policy Loss: 0.8822, Value Loss: 0.1991, Total Loss: 1.0813, LR: 0.004990
2025-05-15 14:50:22,904 [INFO] Epoch 4/15 - Policy Loss: 0.8805, Value Loss: 0.1968, Total Loss: 1.0773, LR: 0.003360
2025-05-15 14:52:35,002 [INFO] Epoch 5/15 - Policy Loss: 0.8763, Value Loss: 0.1947, Total Loss: 1.0711, LR: 0.001710
2025-05-15 14:54:40,314 [INFO] Epoch 6/15 - Policy Loss: 0.8725, Value Loss: 0.1926, Total Loss: 1.0651, LR: 0.000060
2025-05-15 14:56:50,528 [INFO] Epoch 7/15 - Policy Loss: 0.8702, Value Loss: 0.1913, Total Loss: 1.0615, LR: 0.001690
2025-05-15 14:59:08,073 [INFO] Epoch 8/15 - Policy Loss: 0.8680, Value Loss: 0.1901, Total Loss: 1.0581, LR: 0.003340
2025-05-15 15:01:23,267 [INFO] Epoch 9/15 - Policy Loss: 0.8670, Value Loss: 0.1894, Total Loss: 1.0564, LR: 0.004990
2025-05-15 15:03:23,417 [INFO] Epoch 10/15 - Policy Loss: 0.8664, Value Loss: 0.1887, Total Loss: 1.0551, LR: 0.003360
2025-05-15 15:05:31,182 [INFO] Epoch 11/15 - Policy Loss: 0.8650, Value Loss: 0.1880, Total Loss: 1.0530, LR: 0.001710
2025-05-15 15:07:50,723 [INFO] Epoch 12/15 - Policy Loss: 0.8635, Value Loss: 0.1873, Total Loss: 1.0508, LR: 0.000060
2025-05-15 15:10:08,497 [INFO] Epoch 13/15 - Policy Loss: 0.8619, Value Loss: 0.1869, Total Loss: 1.0488, LR: 0.001690
2025-05-15 15:12:17,166 [INFO] Epoch 14/15 - Policy Loss: 0.8611, Value Loss: 0.1864, Total Loss: 1.0475, LR: 0.003340
2025-05-15 15:14:21,009 [INFO] Epoch 15/15 - Policy Loss: 0.8605, Value Loss: 0.1861, Total Loss: 1.0466, LR: 0.004990
2025-05-15 15:14:21,036 [INFO] 训练完成，总损失: 1.0466
2025-05-15 15:14:21,037 [INFO] 保存迭代 57 的模型
2025-05-15 15:14:23,254 [INFO] Model saved to ./models/best.pt
2025-05-15 15:14:24,342 [INFO] Model saved to ./models/iteration_57.pt
2025-05-15 15:14:24,342 [INFO] 所有训练迭代完成
2025-05-15 15:14:24,343 [INFO] 开始迭代 58/300
2025-05-15 15:14:24,343 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 15:42:32,895 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 15:42:32,895 [INFO] 保存训练样本
2025-05-15 15:42:37,786 [INFO] 使用 163016 个样本训练神经网络
2025-05-15 15:42:37,786 [INFO] Training with 163016 examples
2025-05-15 15:42:37,787 [INFO] 总训练步数: 2385, 每轮次批次数: 159
2025-05-15 15:42:37,864 [INFO] 循环学习率周期大小: 477 步
2025-05-15 15:44:51,358 [INFO] Epoch 1/15 - Policy Loss: 0.8850, Value Loss: 0.2035, Total Loss: 1.0885, LR: 0.001690
2025-05-15 15:47:11,078 [INFO] Epoch 2/15 - Policy Loss: 0.8798, Value Loss: 0.1975, Total Loss: 1.0773, LR: 0.003340
2025-05-15 15:49:26,449 [INFO] Epoch 3/15 - Policy Loss: 0.8779, Value Loss: 0.1951, Total Loss: 1.0730, LR: 0.004990
2025-05-15 15:51:33,739 [INFO] Epoch 4/15 - Policy Loss: 0.8755, Value Loss: 0.1932, Total Loss: 1.0687, LR: 0.003360
2025-05-15 15:53:44,886 [INFO] Epoch 5/15 - Policy Loss: 0.8722, Value Loss: 0.1915, Total Loss: 1.0637, LR: 0.001710
2025-05-15 15:55:57,199 [INFO] Epoch 6/15 - Policy Loss: 0.8695, Value Loss: 0.1897, Total Loss: 1.0592, LR: 0.000060
2025-05-15 15:58:09,760 [INFO] Epoch 7/15 - Policy Loss: 0.8667, Value Loss: 0.1882, Total Loss: 1.0549, LR: 0.001690
2025-05-15 16:00:15,415 [INFO] Epoch 8/15 - Policy Loss: 0.8652, Value Loss: 0.1871, Total Loss: 1.0523, LR: 0.003340
2025-05-15 16:02:24,867 [INFO] Epoch 9/15 - Policy Loss: 0.8643, Value Loss: 0.1863, Total Loss: 1.0506, LR: 0.004990
2025-05-15 16:04:40,740 [INFO] Epoch 10/15 - Policy Loss: 0.8644, Value Loss: 0.1863, Total Loss: 1.0507, LR: 0.003360
2025-05-15 16:06:55,849 [INFO] Epoch 11/15 - Policy Loss: 0.8639, Value Loss: 0.1859, Total Loss: 1.0498, LR: 0.001710
2025-05-15 16:09:11,272 [INFO] Epoch 12/15 - Policy Loss: 0.8623, Value Loss: 0.1854, Total Loss: 1.0477, LR: 0.000060
2025-05-15 16:11:21,354 [INFO] Epoch 13/15 - Policy Loss: 0.8611, Value Loss: 0.1848, Total Loss: 1.0459, LR: 0.001690
2025-05-15 16:13:36,597 [INFO] Epoch 14/15 - Policy Loss: 0.8600, Value Loss: 0.1843, Total Loss: 1.0442, LR: 0.003340
2025-05-15 16:15:57,096 [INFO] Epoch 15/15 - Policy Loss: 0.8597, Value Loss: 0.1838, Total Loss: 1.0436, LR: 0.004990
2025-05-15 16:15:57,120 [INFO] 训练完成，总损失: 1.0436
2025-05-15 16:15:57,120 [INFO] 保存迭代 58 的模型
2025-05-15 16:15:58,646 [INFO] Model saved to ./models/best.pt
2025-05-15 16:15:59,403 [INFO] Model saved to ./models/iteration_58.pt
2025-05-15 16:15:59,404 [INFO] 所有训练迭代完成
2025-05-15 16:15:59,404 [INFO] 开始迭代 59/300
2025-05-15 16:15:59,404 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-15 16:45:12,182 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-15 16:45:12,183 [INFO] 保存训练样本
2025-05-15 16:45:17,976 [INFO] 使用 163592 个样本训练神经网络
2025-05-15 16:45:17,976 [INFO] Training with 163592 examples
2025-05-15 16:45:17,977 [INFO] 总训练步数: 2385, 每轮次批次数: 159
2025-05-15 16:45:18,599 [INFO] 循环学习率周期大小: 477 步
2025-05-15 16:47:31,679 [INFO] Epoch 1/15 - Policy Loss: 0.8971, Value Loss: 0.2018, Total Loss: 1.0989, LR: 0.001690
2025-05-15 16:49:34,552 [INFO] Epoch 2/15 - Policy Loss: 0.8885, Value Loss: 0.1966, Total Loss: 1.0851, LR: 0.003340
2025-05-15 16:51:44,518 [INFO] Epoch 3/15 - Policy Loss: 0.8849, Value Loss: 0.1931, Total Loss: 1.0780, LR: 0.004990
2025-05-15 16:53:52,804 [INFO] Epoch 4/15 - Policy Loss: 0.8841, Value Loss: 0.1916, Total Loss: 1.0757, LR: 0.003360
2025-05-15 16:56:05,996 [INFO] Epoch 5/15 - Policy Loss: 0.8796, Value Loss: 0.1894, Total Loss: 1.0690, LR: 0.001710
2025-05-15 16:58:24,739 [INFO] Epoch 6/15 - Policy Loss: 0.8761, Value Loss: 0.1878, Total Loss: 1.0639, LR: 0.000060
2025-05-15 17:00:32,879 [INFO] Epoch 7/15 - Policy Loss: 0.8729, Value Loss: 0.1864, Total Loss: 1.0593, LR: 0.001690
2025-05-15 17:02:37,583 [INFO] Epoch 8/15 - Policy Loss: 0.8707, Value Loss: 0.1851, Total Loss: 1.0557, LR: 0.003340
2025-05-15 17:04:48,832 [INFO] Epoch 9/15 - Policy Loss: 0.8689, Value Loss: 0.1846, Total Loss: 1.0535, LR: 0.004990
2025-05-15 17:07:05,246 [INFO] Epoch 10/15 - Policy Loss: 0.8681, Value Loss: 0.1840, Total Loss: 1.0521, LR: 0.003360
2025-05-15 17:09:19,011 [INFO] Epoch 11/15 - Policy Loss: 0.8665, Value Loss: 0.1834, Total Loss: 1.0499, LR: 0.001710
2025-05-15 17:11:22,340 [INFO] Epoch 12/15 - Policy Loss: 0.8647, Value Loss: 0.1826, Total Loss: 1.0474, LR: 0.000060
2025-05-15 17:13:40,271 [INFO] Epoch 13/15 - Policy Loss: 0.8632, Value Loss: 0.1819, Total Loss: 1.0451, LR: 0.001690
2025-05-15 17:16:35,259 [INFO] Epoch 14/15 - Policy Loss: 0.8620, Value Loss: 0.1812, Total Loss: 1.0432, LR: 0.003340
2025-05-15 17:19:31,328 [INFO] Epoch 15/15 - Policy Loss: 0.8614, Value Loss: 0.1807, Total Loss: 1.0421, LR: 0.004990
2025-05-15 17:19:31,353 [INFO] 训练完成，总损失: 1.0421
2025-05-15 17:19:31,353 [INFO] 保存迭代 59 的模型
2025-05-15 17:19:32,530 [INFO] Model saved to ./models/best.pt
2025-05-15 17:19:33,222 [INFO] Model saved to ./models/iteration_59.pt
2025-05-15 17:19:33,223 [INFO] 所有训练迭代完成
2025-05-15 17:19:33,223 [INFO] 开始迭代 60/300
2025-05-15 17:19:33,223 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 10:35:25,776 [INFO] 设置多进程启动方法为: spawn
2025-05-16 10:35:26,015 [INFO] CUDA可用，使用GPU
2025-05-16 10:35:26,015 [INFO] 配置参数:
2025-05-16 10:35:26,015 [INFO] 训练参数:
2025-05-16 10:35:26,015 [INFO]   训练轮数: 15
2025-05-16 10:35:26,015 [INFO]   批量大小: 1024
2025-05-16 10:35:26,015 [INFO]   迭代次数: 300
2025-05-16 10:35:26,015 [INFO]   每次迭代的自我对弈次数: 50
2025-05-16 10:35:26,015 [INFO]   训练样本队列最大长度: 200000
2025-05-16 10:35:26,015 [INFO]   保留的历史迭代数: 20
2025-05-16 10:35:26,015 [INFO]   新模型胜率阈值: 0.55
2025-05-16 10:35:26,015 [INFO]   竞技场比赛次数: 40
2025-05-16 10:35:26,015 [INFO]   温度阈值: 5
2025-05-16 10:35:26,015 [INFO] 神经网络参数:
2025-05-16 10:35:26,015 [INFO]   通道数: 256
2025-05-16 10:35:26,016 [INFO]   Dropout率: 0.3
2025-05-16 10:35:26,016 [INFO]   学习率范围: 5e-05 - 0.005
2025-05-16 10:35:26,016 [INFO]   梯度裁剪: 1.0
2025-05-16 10:35:26,016 [INFO]   优化器: adam
2025-05-16 10:35:26,016 [INFO] MCTS参数:
2025-05-16 10:35:26,016 [INFO]   模拟次数: 800
2025-05-16 10:35:26,016 [INFO]   PUCT常数: 4.0
2025-05-16 10:35:26,016 [INFO]   Dirichlet噪声参数: 0.3
2025-05-16 10:35:26,016 [INFO]   Dirichlet噪声权重: 0.25
2025-05-16 10:35:26,016 [INFO] 游戏参数:
2025-05-16 10:35:26,016 [INFO]   棋盘大小: 15
2025-05-16 10:35:26,016 [INFO]   获胜所需的连续棋子数: 5
2025-05-16 10:35:26,016 [INFO] 系统参数:
2025-05-16 10:35:26,016 [INFO]   使用CUDA: True
2025-05-16 10:35:26,016 [INFO]   检查点目录: ./models
2025-05-16 10:35:26,016 [INFO]   数据目录: ./data
2025-05-16 10:35:26,016 [INFO]   加载模型: False
2025-05-16 10:35:26,016 [INFO]   加载模型路径: ['./models', 'best.pt']
2025-05-16 10:35:26,016 [INFO]   工作线程数: 4
2025-05-16 10:35:26,016 [INFO]   使用Weights & Biases: False
2025-05-16 10:35:26,016 [INFO] GUI参数:
2025-05-16 10:35:26,016 [INFO]   窗口宽度: 800
2025-05-16 10:35:26,016 [INFO]   窗口高度: 850
2025-05-16 10:35:26,016 [INFO]   格子大小: 40
2025-05-16 10:35:26,017 [INFO]   边距: 40
2025-05-16 10:35:26,017 [INFO]   底部边距: 80
2025-05-16 10:35:26,017 [INFO]   帧率: 30
2025-05-16 10:35:26,452 [INFO] Using device: cuda
2025-05-16 10:35:28,681 [INFO] 设置循环学习率: 最小值=5e-05, 最大值=0.005
2025-05-16 10:35:28,681 [INFO] 设置并行进程数为: 8
2025-05-16 10:35:28,681 [INFO] 开始训练
2025-05-16 10:35:28,682 [INFO] 加载之前的训练样本
2025-05-16 10:35:30,649 [INFO] 加载了 20 组训练样本
2025-05-16 10:35:30,649 [INFO] 开始迭代 1/300
2025-05-16 10:35:30,649 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 11:32:20,028 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 11:32:20,035 [INFO] 保存训练样本
2025-05-16 11:32:24,527 [INFO] 使用 174824 个样本训练神经网络
2025-05-16 11:32:24,527 [INFO] Training with 174824 examples
2025-05-16 11:32:24,528 [INFO] 总训练步数: 2550, 每轮次批次数: 170
2025-05-16 11:32:24,620 [INFO] 循环学习率周期大小: 510 步
2025-05-16 11:33:40,392 [INFO] Epoch 1/15 - Policy Loss: 3.3832, Value Loss: 0.5723, Total Loss: 3.9554, LR: 0.001690
2025-05-16 11:34:47,101 [INFO] Epoch 2/15 - Policy Loss: 2.8153, Value Loss: 0.5096, Total Loss: 3.3249, LR: 0.003340
2025-05-16 11:35:55,330 [INFO] Epoch 3/15 - Policy Loss: 2.5473, Value Loss: 0.4679, Total Loss: 3.0152, LR: 0.004990
2025-05-16 11:37:10,065 [INFO] Epoch 4/15 - Policy Loss: 2.3739, Value Loss: 0.4312, Total Loss: 2.8051, LR: 0.003360
2025-05-16 11:38:31,160 [INFO] Epoch 5/15 - Policy Loss: 2.2418, Value Loss: 0.3976, Total Loss: 2.6393, LR: 0.001710
2025-05-16 11:39:51,170 [INFO] Epoch 6/15 - Policy Loss: 2.1370, Value Loss: 0.3685, Total Loss: 2.5056, LR: 0.000060
2025-05-16 11:40:58,259 [INFO] Epoch 7/15 - Policy Loss: 2.0568, Value Loss: 0.3463, Total Loss: 2.4031, LR: 0.001690
2025-05-16 11:42:11,901 [INFO] Epoch 8/15 - Policy Loss: 2.0023, Value Loss: 0.3322, Total Loss: 2.3345, LR: 0.003340
2025-05-16 11:43:29,955 [INFO] Epoch 9/15 - Policy Loss: 1.9677, Value Loss: 0.3236, Total Loss: 2.2913, LR: 0.004990
2025-05-16 11:44:36,302 [INFO] Epoch 10/15 - Policy Loss: 1.9366, Value Loss: 0.3152, Total Loss: 2.2518, LR: 0.003360
2025-05-16 11:45:48,811 [INFO] Epoch 11/15 - Policy Loss: 1.9027, Value Loss: 0.3046, Total Loss: 2.2073, LR: 0.001710
2025-05-16 11:46:58,673 [INFO] Epoch 12/15 - Policy Loss: 1.8685, Value Loss: 0.2943, Total Loss: 2.1628, LR: 0.000060
2025-05-16 11:48:14,692 [INFO] Epoch 13/15 - Policy Loss: 1.8376, Value Loss: 0.2852, Total Loss: 2.1228, LR: 0.001690
2025-05-16 11:49:34,969 [INFO] Epoch 14/15 - Policy Loss: 1.8129, Value Loss: 0.2780, Total Loss: 2.0908, LR: 0.003340
2025-05-16 11:50:42,150 [INFO] Epoch 15/15 - Policy Loss: 1.7974, Value Loss: 0.2734, Total Loss: 2.0708, LR: 0.004990
2025-05-16 11:50:42,185 [INFO] 训练完成，总损失: 2.0708
2025-05-16 11:50:42,185 [INFO] 保存迭代 1 的模型
2025-05-16 11:50:44,042 [INFO] Model saved to ./models/best.pt
2025-05-16 11:50:45,410 [INFO] Model saved to ./models/iteration_1.pt
2025-05-16 11:50:45,411 [INFO] 所有训练迭代完成
2025-05-16 11:50:45,411 [INFO] 开始迭代 2/300
2025-05-16 11:50:45,411 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 12:15:21,029 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 12:15:21,030 [INFO] 保存训练样本
2025-05-16 12:15:26,229 [INFO] 使用 175904 个样本训练神经网络
2025-05-16 12:15:26,229 [INFO] Training with 175904 examples
2025-05-16 12:15:26,230 [INFO] 总训练步数: 2565, 每轮次批次数: 171
2025-05-16 12:15:26,935 [INFO] 循环学习率周期大小: 513 步
2025-05-16 12:16:52,533 [INFO] Epoch 1/15 - Policy Loss: 1.5785, Value Loss: 0.1967, Total Loss: 1.7753, LR: 0.001690
2025-05-16 12:18:05,911 [INFO] Epoch 2/15 - Policy Loss: 1.5532, Value Loss: 0.1887, Total Loss: 1.7419, LR: 0.003340
2025-05-16 12:19:15,517 [INFO] Epoch 3/15 - Policy Loss: 1.5550, Value Loss: 0.1920, Total Loss: 1.7470, LR: 0.004990
2025-05-16 12:20:34,557 [INFO] Epoch 4/15 - Policy Loss: 1.5606, Value Loss: 0.1938, Total Loss: 1.7544, LR: 0.003360
2025-05-16 12:21:57,595 [INFO] Epoch 5/15 - Policy Loss: 1.5469, Value Loss: 0.1901, Total Loss: 1.7370, LR: 0.001710
2025-05-16 12:23:26,310 [INFO] Epoch 6/15 - Policy Loss: 1.5279, Value Loss: 0.1857, Total Loss: 1.7136, LR: 0.000060
2025-05-16 12:24:39,675 [INFO] Epoch 7/15 - Policy Loss: 1.5143, Value Loss: 0.1819, Total Loss: 1.6962, LR: 0.001690
2025-05-16 12:25:48,869 [INFO] Epoch 8/15 - Policy Loss: 1.5045, Value Loss: 0.1798, Total Loss: 1.6843, LR: 0.003340
2025-05-16 12:27:03,477 [INFO] Epoch 9/15 - Policy Loss: 1.5040, Value Loss: 0.1796, Total Loss: 1.6837, LR: 0.004990
2025-05-16 12:28:18,944 [INFO] Epoch 10/15 - Policy Loss: 1.5067, Value Loss: 0.1802, Total Loss: 1.6869, LR: 0.003360
2025-05-16 12:29:41,430 [INFO] Epoch 11/15 - Policy Loss: 1.5022, Value Loss: 0.1792, Total Loss: 1.6814, LR: 0.001710
2025-05-16 12:30:58,700 [INFO] Epoch 12/15 - Policy Loss: 1.4945, Value Loss: 0.1775, Total Loss: 1.6720, LR: 0.000060
2025-05-16 12:32:14,540 [INFO] Epoch 13/15 - Policy Loss: 1.4878, Value Loss: 0.1761, Total Loss: 1.6639, LR: 0.001690
2025-05-16 12:33:39,064 [INFO] Epoch 14/15 - Policy Loss: 1.4830, Value Loss: 0.1749, Total Loss: 1.6579, LR: 0.003340
2025-05-16 12:35:21,896 [INFO] Epoch 15/15 - Policy Loss: 1.4824, Value Loss: 0.1746, Total Loss: 1.6570, LR: 0.004990
2025-05-16 12:35:21,921 [INFO] 训练完成，总损失: 1.6570
2025-05-16 12:35:21,921 [INFO] 保存迭代 2 的模型
2025-05-16 12:35:23,547 [INFO] Model saved to ./models/best.pt
2025-05-16 12:35:24,888 [INFO] Model saved to ./models/iteration_2.pt
2025-05-16 12:35:24,889 [INFO] 所有训练迭代完成
2025-05-16 12:35:24,889 [INFO] 开始迭代 3/300
2025-05-16 12:35:24,889 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 12:54:20,772 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 12:54:20,773 [INFO] 保存训练样本
2025-05-16 12:54:26,202 [INFO] 使用 175256 个样本训练神经网络
2025-05-16 12:54:26,203 [INFO] Training with 175256 examples
2025-05-16 12:54:26,203 [INFO] 总训练步数: 2565, 每轮次批次数: 171
2025-05-16 12:54:26,672 [INFO] 循环学习率周期大小: 513 步
2025-05-16 12:55:46,321 [INFO] Epoch 1/15 - Policy Loss: 1.5073, Value Loss: 0.1818, Total Loss: 1.6891, LR: 0.001690
2025-05-16 12:56:59,418 [INFO] Epoch 2/15 - Policy Loss: 1.4877, Value Loss: 0.1761, Total Loss: 1.6638, LR: 0.003340
2025-05-16 12:58:04,741 [INFO] Epoch 3/15 - Policy Loss: 1.4898, Value Loss: 0.1763, Total Loss: 1.6661, LR: 0.004990
2025-05-16 12:59:11,702 [INFO] Epoch 4/15 - Policy Loss: 1.4932, Value Loss: 0.1768, Total Loss: 1.6700, LR: 0.003360
2025-05-16 13:00:20,740 [INFO] Epoch 5/15 - Policy Loss: 1.4837, Value Loss: 0.1736, Total Loss: 1.6573, LR: 0.001710
2025-05-16 13:01:34,516 [INFO] Epoch 6/15 - Policy Loss: 1.4699, Value Loss: 0.1702, Total Loss: 1.6401, LR: 0.000060
2025-05-16 13:02:50,139 [INFO] Epoch 7/15 - Policy Loss: 1.4590, Value Loss: 0.1674, Total Loss: 1.6264, LR: 0.001690
2025-05-16 13:03:58,569 [INFO] Epoch 8/15 - Policy Loss: 1.4531, Value Loss: 0.1657, Total Loss: 1.6188, LR: 0.003340
2025-05-16 13:05:03,600 [INFO] Epoch 9/15 - Policy Loss: 1.4533, Value Loss: 0.1649, Total Loss: 1.6182, LR: 0.004990
2025-05-16 13:06:16,961 [INFO] Epoch 10/15 - Policy Loss: 1.4560, Value Loss: 0.1655, Total Loss: 1.6215, LR: 0.003360
2025-05-16 13:07:28,474 [INFO] Epoch 11/15 - Policy Loss: 1.4538, Value Loss: 0.1650, Total Loss: 1.6187, LR: 0.001710
2025-05-16 13:08:42,084 [INFO] Epoch 12/15 - Policy Loss: 1.4483, Value Loss: 0.1640, Total Loss: 1.6123, LR: 0.000060
2025-05-16 13:09:50,144 [INFO] Epoch 13/15 - Policy Loss: 1.4430, Value Loss: 0.1630, Total Loss: 1.6060, LR: 0.001690
2025-05-16 13:10:58,494 [INFO] Epoch 14/15 - Policy Loss: 1.4397, Value Loss: 0.1622, Total Loss: 1.6019, LR: 0.003340
2025-05-16 13:12:14,743 [INFO] Epoch 15/15 - Policy Loss: 1.4399, Value Loss: 0.1618, Total Loss: 1.6017, LR: 0.004990
2025-05-16 13:12:14,778 [INFO] 训练完成，总损失: 1.6017
2025-05-16 13:12:14,778 [INFO] 保存迭代 3 的模型
2025-05-16 13:12:16,547 [INFO] Model saved to ./models/best.pt
2025-05-16 13:12:17,967 [INFO] Model saved to ./models/iteration_3.pt
2025-05-16 13:12:17,967 [INFO] 所有训练迭代完成
2025-05-16 13:12:17,968 [INFO] 开始迭代 4/300
2025-05-16 13:12:17,968 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 13:33:11,061 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 13:33:11,061 [INFO] 保存训练样本
2025-05-16 13:33:16,679 [INFO] 使用 175736 个样本训练神经网络
2025-05-16 13:33:16,679 [INFO] Training with 175736 examples
2025-05-16 13:33:16,679 [INFO] 总训练步数: 2565, 每轮次批次数: 171
2025-05-16 13:33:16,744 [INFO] 循环学习率周期大小: 513 步
2025-05-16 13:34:43,543 [INFO] Epoch 1/15 - Policy Loss: 1.4774, Value Loss: 0.1704, Total Loss: 1.6479, LR: 0.001690
2025-05-16 13:35:57,761 [INFO] Epoch 2/15 - Policy Loss: 1.4571, Value Loss: 0.1664, Total Loss: 1.6235, LR: 0.003340
2025-05-16 13:37:25,288 [INFO] Epoch 3/15 - Policy Loss: 1.4583, Value Loss: 0.1663, Total Loss: 1.6246, LR: 0.004990
2025-05-16 13:39:13,503 [INFO] Epoch 4/15 - Policy Loss: 1.4663, Value Loss: 0.1678, Total Loss: 1.6341, LR: 0.003360
2025-05-16 13:41:09,047 [INFO] Epoch 5/15 - Policy Loss: 1.4580, Value Loss: 0.1659, Total Loss: 1.6239, LR: 0.001710
2025-05-16 13:42:46,554 [INFO] Epoch 6/15 - Policy Loss: 1.4470, Value Loss: 0.1635, Total Loss: 1.6104, LR: 0.000060
2025-05-16 13:44:50,028 [INFO] Epoch 7/15 - Policy Loss: 1.4379, Value Loss: 0.1613, Total Loss: 1.5992, LR: 0.001690
2025-05-16 13:46:12,925 [INFO] Epoch 8/15 - Policy Loss: 1.4325, Value Loss: 0.1600, Total Loss: 1.5925, LR: 0.003340
2025-05-16 13:47:19,993 [INFO] Epoch 9/15 - Policy Loss: 1.4316, Value Loss: 0.1594, Total Loss: 1.5910, LR: 0.004990
2025-05-16 13:48:35,480 [INFO] Epoch 10/15 - Policy Loss: 1.4341, Value Loss: 0.1598, Total Loss: 1.5939, LR: 0.003360
2025-05-16 13:49:46,838 [INFO] Epoch 11/15 - Policy Loss: 1.4320, Value Loss: 0.1592, Total Loss: 1.5912, LR: 0.001710
2025-05-16 13:51:17,211 [INFO] Epoch 12/15 - Policy Loss: 1.4282, Value Loss: 0.1582, Total Loss: 1.5864, LR: 0.000060
2025-05-16 13:52:26,229 [INFO] Epoch 13/15 - Policy Loss: 1.4242, Value Loss: 0.1573, Total Loss: 1.5815, LR: 0.001690
2025-05-16 13:53:39,317 [INFO] Epoch 14/15 - Policy Loss: 1.4212, Value Loss: 0.1565, Total Loss: 1.5778, LR: 0.003340
2025-05-16 13:54:49,433 [INFO] Epoch 15/15 - Policy Loss: 1.4208, Value Loss: 0.1562, Total Loss: 1.5770, LR: 0.004990
2025-05-16 13:54:49,465 [INFO] 训练完成，总损失: 1.5770
2025-05-16 13:54:49,465 [INFO] 保存迭代 4 的模型
2025-05-16 13:54:50,821 [INFO] Model saved to ./models/best.pt
2025-05-16 13:54:52,020 [INFO] Model saved to ./models/iteration_4.pt
2025-05-16 13:54:52,021 [INFO] 所有训练迭代完成
2025-05-16 13:54:52,021 [INFO] 开始迭代 5/300
2025-05-16 13:54:52,021 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 14:16:43,552 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 14:16:43,554 [INFO] 保存训练样本
2025-05-16 14:16:50,813 [INFO] 使用 175824 个样本训练神经网络
2025-05-16 14:16:50,813 [INFO] Training with 175824 examples
2025-05-16 14:16:50,814 [INFO] 总训练步数: 2565, 每轮次批次数: 171
2025-05-16 14:16:51,669 [INFO] 循环学习率周期大小: 513 步
2025-05-16 14:18:05,727 [INFO] Epoch 1/15 - Policy Loss: 1.4437, Value Loss: 0.1728, Total Loss: 1.6165, LR: 0.001690
2025-05-16 14:19:09,571 [INFO] Epoch 2/15 - Policy Loss: 1.4328, Value Loss: 0.1672, Total Loss: 1.6000, LR: 0.003340
2025-05-16 14:20:32,024 [INFO] Epoch 3/15 - Policy Loss: 1.4344, Value Loss: 0.1662, Total Loss: 1.6006, LR: 0.004990
2025-05-16 14:21:46,139 [INFO] Epoch 4/15 - Policy Loss: 1.4391, Value Loss: 0.1668, Total Loss: 1.6059, LR: 0.003360
2025-05-16 14:23:13,711 [INFO] Epoch 5/15 - Policy Loss: 1.4341, Value Loss: 0.1649, Total Loss: 1.5990, LR: 0.001710
2025-05-16 14:24:35,353 [INFO] Epoch 6/15 - Policy Loss: 1.4266, Value Loss: 0.1625, Total Loss: 1.5891, LR: 0.000060
2025-05-16 14:25:41,357 [INFO] Epoch 7/15 - Policy Loss: 1.4193, Value Loss: 0.1608, Total Loss: 1.5801, LR: 0.001690
2025-05-16 14:26:57,801 [INFO] Epoch 8/15 - Policy Loss: 1.4151, Value Loss: 0.1592, Total Loss: 1.5743, LR: 0.003340
2025-05-16 14:28:09,301 [INFO] Epoch 9/15 - Policy Loss: 1.4140, Value Loss: 0.1584, Total Loss: 1.5724, LR: 0.004990
2025-05-16 14:29:25,882 [INFO] Epoch 10/15 - Policy Loss: 1.4154, Value Loss: 0.1583, Total Loss: 1.5737, LR: 0.003360
2025-05-16 14:30:56,423 [INFO] Epoch 11/15 - Policy Loss: 1.4147, Value Loss: 0.1578, Total Loss: 1.5726, LR: 0.001710
2025-05-16 14:32:08,587 [INFO] Epoch 12/15 - Policy Loss: 1.4117, Value Loss: 0.1568, Total Loss: 1.5685, LR: 0.000060
2025-05-16 14:33:22,897 [INFO] Epoch 13/15 - Policy Loss: 1.4079, Value Loss: 0.1559, Total Loss: 1.5638, LR: 0.001690
2025-05-16 14:34:34,011 [INFO] Epoch 14/15 - Policy Loss: 1.4056, Value Loss: 0.1552, Total Loss: 1.5609, LR: 0.003340
2025-05-16 14:36:03,156 [INFO] Epoch 15/15 - Policy Loss: 1.4051, Value Loss: 0.1548, Total Loss: 1.5599, LR: 0.004990
2025-05-16 14:36:03,199 [INFO] 训练完成，总损失: 1.5599
2025-05-16 14:36:03,199 [INFO] 保存迭代 5 的模型
2025-05-16 14:36:04,953 [INFO] Model saved to ./models/best.pt
2025-05-16 14:36:06,342 [INFO] Model saved to ./models/iteration_5.pt
2025-05-16 14:36:06,342 [INFO] 所有训练迭代完成
2025-05-16 14:36:06,342 [INFO] 开始迭代 6/300
2025-05-16 14:36:06,342 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 14:56:48,531 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 14:56:48,531 [INFO] 保存训练样本
2025-05-16 14:56:54,428 [INFO] 使用 175744 个样本训练神经网络
2025-05-16 14:56:54,428 [INFO] Training with 175744 examples
2025-05-16 14:56:54,429 [INFO] 总训练步数: 2565, 每轮次批次数: 171
2025-05-16 14:56:54,957 [INFO] 循环学习率周期大小: 513 步
2025-05-16 14:58:11,427 [INFO] Epoch 1/15 - Policy Loss: 1.4389, Value Loss: 0.1672, Total Loss: 1.6061, LR: 0.001690
2025-05-16 14:59:15,575 [INFO] Epoch 2/15 - Policy Loss: 1.4280, Value Loss: 0.1631, Total Loss: 1.5911, LR: 0.003340
2025-05-16 15:00:28,174 [INFO] Epoch 3/15 - Policy Loss: 1.4275, Value Loss: 0.1618, Total Loss: 1.5894, LR: 0.004990
2025-05-16 15:01:37,562 [INFO] Epoch 4/15 - Policy Loss: 1.4322, Value Loss: 0.1632, Total Loss: 1.5954, LR: 0.003360
2025-05-16 15:02:50,945 [INFO] Epoch 5/15 - Policy Loss: 1.4276, Value Loss: 0.1615, Total Loss: 1.5892, LR: 0.001710
2025-05-16 15:04:15,977 [INFO] Epoch 6/15 - Policy Loss: 1.4214, Value Loss: 0.1586, Total Loss: 1.5800, LR: 0.000060
2025-05-16 15:05:32,229 [INFO] Epoch 7/15 - Policy Loss: 1.4149, Value Loss: 0.1571, Total Loss: 1.5720, LR: 0.001690
2025-05-16 15:06:48,559 [INFO] Epoch 8/15 - Policy Loss: 1.4107, Value Loss: 0.1558, Total Loss: 1.5665, LR: 0.003340
2025-05-16 15:08:00,656 [INFO] Epoch 9/15 - Policy Loss: 1.4098, Value Loss: 0.1550, Total Loss: 1.5649, LR: 0.004990
2025-05-16 15:09:16,292 [INFO] Epoch 10/15 - Policy Loss: 1.4109, Value Loss: 0.1549, Total Loss: 1.5658, LR: 0.003360
2025-05-16 15:10:29,065 [INFO] Epoch 11/15 - Policy Loss: 1.4102, Value Loss: 0.1545, Total Loss: 1.5647, LR: 0.001710
2025-05-16 15:11:42,874 [INFO] Epoch 12/15 - Policy Loss: 1.4072, Value Loss: 0.1535, Total Loss: 1.5608, LR: 0.000060
2025-05-16 15:12:49,217 [INFO] Epoch 13/15 - Policy Loss: 1.4043, Value Loss: 0.1529, Total Loss: 1.5571, LR: 0.001690
2025-05-16 15:14:05,058 [INFO] Epoch 14/15 - Policy Loss: 1.4019, Value Loss: 0.1523, Total Loss: 1.5542, LR: 0.003340
2025-05-16 15:15:14,123 [INFO] Epoch 15/15 - Policy Loss: 1.4020, Value Loss: 0.1521, Total Loss: 1.5541, LR: 0.004990
2025-05-16 15:15:14,145 [INFO] 训练完成，总损失: 1.5541
2025-05-16 15:15:14,145 [INFO] 保存迭代 6 的模型
2025-05-16 15:15:15,617 [INFO] Model saved to ./models/best.pt
2025-05-16 15:15:16,497 [INFO] Model saved to ./models/iteration_6.pt
2025-05-16 15:15:16,497 [INFO] 所有训练迭代完成
2025-05-16 15:15:16,497 [INFO] 开始迭代 7/300
2025-05-16 15:15:16,498 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 15:36:06,071 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 15:36:06,071 [INFO] 保存训练样本
2025-05-16 15:36:11,407 [INFO] 使用 175704 个样本训练神经网络
2025-05-16 15:36:11,407 [INFO] Training with 175704 examples
2025-05-16 15:36:11,407 [INFO] 总训练步数: 2565, 每轮次批次数: 171
2025-05-16 15:36:11,461 [INFO] 循环学习率周期大小: 513 步
2025-05-16 15:37:24,166 [INFO] Epoch 1/15 - Policy Loss: 1.4485, Value Loss: 0.1605, Total Loss: 1.6091, LR: 0.001690
2025-05-16 15:38:39,149 [INFO] Epoch 2/15 - Policy Loss: 1.4338, Value Loss: 0.1560, Total Loss: 1.5898, LR: 0.003340
2025-05-16 15:39:50,320 [INFO] Epoch 3/15 - Policy Loss: 1.4304, Value Loss: 0.1548, Total Loss: 1.5853, LR: 0.004990
2025-05-16 15:41:08,567 [INFO] Epoch 4/15 - Policy Loss: 1.4297, Value Loss: 0.1555, Total Loss: 1.5852, LR: 0.003360
2025-05-16 15:42:13,698 [INFO] Epoch 5/15 - Policy Loss: 1.4237, Value Loss: 0.1545, Total Loss: 1.5782, LR: 0.001710
2025-05-16 15:43:24,540 [INFO] Epoch 6/15 - Policy Loss: 1.4176, Value Loss: 0.1535, Total Loss: 1.5711, LR: 0.000060
2025-05-16 15:44:42,342 [INFO] Epoch 7/15 - Policy Loss: 1.4114, Value Loss: 0.1522, Total Loss: 1.5636, LR: 0.001690
2025-05-16 15:45:48,327 [INFO] Epoch 8/15 - Policy Loss: 1.4064, Value Loss: 0.1513, Total Loss: 1.5577, LR: 0.003340
2025-05-16 15:47:06,397 [INFO] Epoch 9/15 - Policy Loss: 1.4057, Value Loss: 0.1509, Total Loss: 1.5567, LR: 0.004990
2025-05-16 15:48:27,610 [INFO] Epoch 10/15 - Policy Loss: 1.4064, Value Loss: 0.1510, Total Loss: 1.5574, LR: 0.003360
2025-05-16 15:49:46,849 [INFO] Epoch 11/15 - Policy Loss: 1.4051, Value Loss: 0.1506, Total Loss: 1.5557, LR: 0.001710
2025-05-16 15:51:04,350 [INFO] Epoch 12/15 - Policy Loss: 1.4027, Value Loss: 0.1503, Total Loss: 1.5529, LR: 0.000060
2025-05-16 15:52:14,682 [INFO] Epoch 13/15 - Policy Loss: 1.3999, Value Loss: 0.1498, Total Loss: 1.5497, LR: 0.001690
2025-05-16 15:53:41,859 [INFO] Epoch 14/15 - Policy Loss: 1.3979, Value Loss: 0.1493, Total Loss: 1.5472, LR: 0.003340
2025-05-16 15:54:46,833 [INFO] Epoch 15/15 - Policy Loss: 1.3976, Value Loss: 0.1493, Total Loss: 1.5470, LR: 0.004990
2025-05-16 15:54:46,862 [INFO] 训练完成，总损失: 1.5470
2025-05-16 15:54:46,862 [INFO] 保存迭代 7 的模型
2025-05-16 15:54:48,106 [INFO] Model saved to ./models/best.pt
2025-05-16 15:54:48,833 [INFO] Model saved to ./models/iteration_7.pt
2025-05-16 15:54:48,833 [INFO] 所有训练迭代完成
2025-05-16 15:54:48,834 [INFO] 开始迭代 8/300
2025-05-16 15:54:48,834 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 16:13:50,275 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 16:13:50,276 [INFO] 保存训练样本
2025-05-16 16:13:55,706 [INFO] 使用 175288 个样本训练神经网络
2025-05-16 16:13:55,706 [INFO] Training with 175288 examples
2025-05-16 16:13:55,707 [INFO] 总训练步数: 2565, 每轮次批次数: 171
2025-05-16 16:13:56,131 [INFO] 循环学习率周期大小: 513 步
2025-05-16 16:15:08,813 [INFO] Epoch 1/15 - Policy Loss: 1.4265, Value Loss: 0.1608, Total Loss: 1.5873, LR: 0.001690
2025-05-16 16:16:24,833 [INFO] Epoch 2/15 - Policy Loss: 1.4138, Value Loss: 0.1569, Total Loss: 1.5707, LR: 0.003340
2025-05-16 16:17:49,958 [INFO] Epoch 3/15 - Policy Loss: 1.4116, Value Loss: 0.1553, Total Loss: 1.5668, LR: 0.004990
2025-05-16 16:19:23,963 [INFO] Epoch 4/15 - Policy Loss: 1.4135, Value Loss: 0.1561, Total Loss: 1.5696, LR: 0.003360
2025-05-16 16:20:48,145 [INFO] Epoch 5/15 - Policy Loss: 1.4103, Value Loss: 0.1542, Total Loss: 1.5645, LR: 0.001710
2025-05-16 16:21:54,673 [INFO] Epoch 6/15 - Policy Loss: 1.4054, Value Loss: 0.1524, Total Loss: 1.5578, LR: 0.000060
2025-05-16 16:23:25,860 [INFO] Epoch 7/15 - Policy Loss: 1.4002, Value Loss: 0.1511, Total Loss: 1.5513, LR: 0.001690
2025-05-16 16:24:45,119 [INFO] Epoch 8/15 - Policy Loss: 1.3966, Value Loss: 0.1500, Total Loss: 1.5466, LR: 0.003340
2025-05-16 16:25:56,095 [INFO] Epoch 9/15 - Policy Loss: 1.3967, Value Loss: 0.1495, Total Loss: 1.5462, LR: 0.004990
2025-05-16 16:27:09,822 [INFO] Epoch 10/15 - Policy Loss: 1.3985, Value Loss: 0.1498, Total Loss: 1.5483, LR: 0.003360
2025-05-16 16:28:32,227 [INFO] Epoch 11/15 - Policy Loss: 1.3972, Value Loss: 0.1495, Total Loss: 1.5467, LR: 0.001710
2025-05-16 16:29:50,711 [INFO] Epoch 12/15 - Policy Loss: 1.3948, Value Loss: 0.1489, Total Loss: 1.5437, LR: 0.000060
2025-05-16 16:30:59,018 [INFO] Epoch 13/15 - Policy Loss: 1.3926, Value Loss: 0.1482, Total Loss: 1.5408, LR: 0.001690
2025-05-16 16:32:10,614 [INFO] Epoch 14/15 - Policy Loss: 1.3914, Value Loss: 0.1478, Total Loss: 1.5392, LR: 0.003340
2025-05-16 16:32:56,501 [INFO] Epoch 15/15 - Policy Loss: 1.3914, Value Loss: 0.1475, Total Loss: 1.5389, LR: 0.004990
2025-05-16 16:32:56,533 [INFO] 训练完成，总损失: 1.5389
2025-05-16 16:32:56,533 [INFO] 保存迭代 8 的模型
2025-05-16 16:32:57,921 [INFO] Model saved to ./models/best.pt
2025-05-16 16:32:58,815 [INFO] Model saved to ./models/iteration_8.pt
2025-05-16 16:32:58,816 [INFO] 所有训练迭代完成
2025-05-16 16:32:58,816 [INFO] 开始迭代 9/300
2025-05-16 16:32:58,816 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 16:48:52,317 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 16:48:52,318 [INFO] 保存训练样本
2025-05-16 16:48:57,393 [INFO] 使用 175200 个样本训练神经网络
2025-05-16 16:48:57,393 [INFO] Training with 175200 examples
2025-05-16 16:48:57,393 [INFO] 总训练步数: 2565, 每轮次批次数: 171
2025-05-16 16:48:57,819 [INFO] 循环学习率周期大小: 513 步
2025-05-16 16:49:43,187 [INFO] Epoch 1/15 - Policy Loss: 1.4283, Value Loss: 0.1601, Total Loss: 1.5884, LR: 0.001690
2025-05-16 16:50:28,772 [INFO] Epoch 2/15 - Policy Loss: 1.4197, Value Loss: 0.1551, Total Loss: 1.5749, LR: 0.003340
2025-05-16 16:51:14,647 [INFO] Epoch 3/15 - Policy Loss: 1.4185, Value Loss: 0.1535, Total Loss: 1.5720, LR: 0.004990
2025-05-16 16:52:00,752 [INFO] Epoch 4/15 - Policy Loss: 1.4179, Value Loss: 0.1531, Total Loss: 1.5711, LR: 0.003360
2025-05-16 16:52:46,665 [INFO] Epoch 5/15 - Policy Loss: 1.4139, Value Loss: 0.1515, Total Loss: 1.5654, LR: 0.001710
2025-05-16 16:53:32,393 [INFO] Epoch 6/15 - Policy Loss: 1.4082, Value Loss: 0.1501, Total Loss: 1.5583, LR: 0.000060
2025-05-16 16:54:18,470 [INFO] Epoch 7/15 - Policy Loss: 1.4026, Value Loss: 0.1485, Total Loss: 1.5511, LR: 0.001690
2025-05-16 16:55:04,187 [INFO] Epoch 8/15 - Policy Loss: 1.3989, Value Loss: 0.1475, Total Loss: 1.5464, LR: 0.003340
2025-05-16 16:55:50,476 [INFO] Epoch 9/15 - Policy Loss: 1.3978, Value Loss: 0.1470, Total Loss: 1.5449, LR: 0.004990
2025-05-16 16:56:35,908 [INFO] Epoch 10/15 - Policy Loss: 1.3993, Value Loss: 0.1472, Total Loss: 1.5465, LR: 0.003360
2025-05-16 16:57:23,484 [INFO] Epoch 11/15 - Policy Loss: 1.3983, Value Loss: 0.1466, Total Loss: 1.5450, LR: 0.001710
2025-05-16 16:58:09,114 [INFO] Epoch 12/15 - Policy Loss: 1.3962, Value Loss: 0.1460, Total Loss: 1.5422, LR: 0.000060
2025-05-16 16:58:54,806 [INFO] Epoch 13/15 - Policy Loss: 1.3938, Value Loss: 0.1452, Total Loss: 1.5390, LR: 0.001690
2025-05-16 16:59:40,557 [INFO] Epoch 14/15 - Policy Loss: 1.3919, Value Loss: 0.1446, Total Loss: 1.5365, LR: 0.003340
2025-05-16 17:00:26,215 [INFO] Epoch 15/15 - Policy Loss: 1.3918, Value Loss: 0.1445, Total Loss: 1.5363, LR: 0.004990
2025-05-16 17:00:26,238 [INFO] 训练完成，总损失: 1.5363
2025-05-16 17:00:26,238 [INFO] 保存迭代 9 的模型
2025-05-16 17:00:27,575 [INFO] Model saved to ./models/best.pt
2025-05-16 17:00:28,423 [INFO] Model saved to ./models/iteration_9.pt
2025-05-16 17:00:28,423 [INFO] 所有训练迭代完成
2025-05-16 17:00:28,424 [INFO] 开始迭代 10/300
2025-05-16 17:00:28,424 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 17:17:10,098 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 17:17:10,099 [INFO] 保存训练样本
2025-05-16 17:17:16,209 [INFO] 使用 175664 个样本训练神经网络
2025-05-16 17:17:16,209 [INFO] Training with 175664 examples
2025-05-16 17:17:16,210 [INFO] 总训练步数: 2565, 每轮次批次数: 171
2025-05-16 17:17:16,288 [INFO] 循环学习率周期大小: 513 步
2025-05-16 17:18:02,007 [INFO] Epoch 1/15 - Policy Loss: 1.4216, Value Loss: 0.1698, Total Loss: 1.5915, LR: 0.001690
2025-05-16 17:18:47,958 [INFO] Epoch 2/15 - Policy Loss: 1.4177, Value Loss: 0.1647, Total Loss: 1.5824, LR: 0.003340
2025-05-16 17:19:34,290 [INFO] Epoch 3/15 - Policy Loss: 1.4133, Value Loss: 0.1619, Total Loss: 1.5752, LR: 0.004990
2025-05-16 17:20:20,254 [INFO] Epoch 4/15 - Policy Loss: 1.4128, Value Loss: 0.1608, Total Loss: 1.5736, LR: 0.003360
2025-05-16 17:21:06,285 [INFO] Epoch 5/15 - Policy Loss: 1.4078, Value Loss: 0.1587, Total Loss: 1.5665, LR: 0.001710
2025-05-16 17:21:52,315 [INFO] Epoch 6/15 - Policy Loss: 1.4026, Value Loss: 0.1567, Total Loss: 1.5593, LR: 0.000060
2025-05-16 17:22:38,529 [INFO] Epoch 7/15 - Policy Loss: 1.3981, Value Loss: 0.1552, Total Loss: 1.5534, LR: 0.001690
2025-05-16 17:23:24,746 [INFO] Epoch 8/15 - Policy Loss: 1.3952, Value Loss: 0.1539, Total Loss: 1.5490, LR: 0.003340
2025-05-16 17:24:10,897 [INFO] Epoch 9/15 - Policy Loss: 1.3945, Value Loss: 0.1533, Total Loss: 1.5478, LR: 0.004990
2025-05-16 17:24:56,991 [INFO] Epoch 10/15 - Policy Loss: 1.3949, Value Loss: 0.1529, Total Loss: 1.5478, LR: 0.003360
2025-05-16 17:25:43,112 [INFO] Epoch 11/15 - Policy Loss: 1.3939, Value Loss: 0.1521, Total Loss: 1.5460, LR: 0.001710
2025-05-16 17:26:29,189 [INFO] Epoch 12/15 - Policy Loss: 1.3923, Value Loss: 0.1514, Total Loss: 1.5437, LR: 0.000060
2025-05-16 17:27:17,584 [INFO] Epoch 13/15 - Policy Loss: 1.3900, Value Loss: 0.1508, Total Loss: 1.5408, LR: 0.001690
2025-05-16 17:28:06,556 [INFO] Epoch 14/15 - Policy Loss: 1.3885, Value Loss: 0.1501, Total Loss: 1.5387, LR: 0.003340
2025-05-16 17:28:55,561 [INFO] Epoch 15/15 - Policy Loss: 1.3881, Value Loss: 0.1498, Total Loss: 1.5379, LR: 0.004990
2025-05-16 17:28:55,593 [INFO] 训练完成，总损失: 1.5379
2025-05-16 17:28:55,593 [INFO] 保存迭代 10 的模型
2025-05-16 17:28:56,919 [INFO] Model saved to ./models/best.pt
2025-05-16 17:28:57,826 [INFO] Model saved to ./models/iteration_10.pt
2025-05-16 17:28:57,827 [INFO] 所有训练迭代完成
2025-05-16 17:28:57,827 [INFO] 开始迭代 11/300
2025-05-16 17:28:57,827 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 17:46:12,253 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 17:46:12,254 [INFO] 保存训练样本
2025-05-16 17:46:18,021 [INFO] 使用 176040 个样本训练神经网络
2025-05-16 17:46:18,021 [INFO] Training with 176040 examples
2025-05-16 17:46:18,022 [INFO] 总训练步数: 2565, 每轮次批次数: 171
2025-05-16 17:46:18,511 [INFO] 循环学习率周期大小: 513 步
2025-05-16 17:47:13,594 [INFO] Epoch 1/15 - Policy Loss: 1.4250, Value Loss: 0.1593, Total Loss: 1.5842, LR: 0.001690
2025-05-16 17:48:08,169 [INFO] Epoch 2/15 - Policy Loss: 1.4144, Value Loss: 0.1546, Total Loss: 1.5690, LR: 0.003340
2025-05-16 17:49:03,033 [INFO] Epoch 3/15 - Policy Loss: 1.4105, Value Loss: 0.1521, Total Loss: 1.5626, LR: 0.004990
2025-05-16 17:49:57,711 [INFO] Epoch 4/15 - Policy Loss: 1.4120, Value Loss: 0.1515, Total Loss: 1.5634, LR: 0.003360
2025-05-16 17:50:52,103 [INFO] Epoch 5/15 - Policy Loss: 1.4086, Value Loss: 0.1493, Total Loss: 1.5579, LR: 0.001710
2025-05-16 17:51:46,265 [INFO] Epoch 6/15 - Policy Loss: 1.4032, Value Loss: 0.1478, Total Loss: 1.5510, LR: 0.000060
2025-05-16 17:52:40,865 [INFO] Epoch 7/15 - Policy Loss: 1.3997, Value Loss: 0.1465, Total Loss: 1.5461, LR: 0.001690
2025-05-16 17:53:35,031 [INFO] Epoch 8/15 - Policy Loss: 1.3960, Value Loss: 0.1456, Total Loss: 1.5415, LR: 0.003340
2025-05-16 17:54:28,963 [INFO] Epoch 9/15 - Policy Loss: 1.3955, Value Loss: 0.1451, Total Loss: 1.5406, LR: 0.004990
2025-05-16 17:55:23,056 [INFO] Epoch 10/15 - Policy Loss: 1.3962, Value Loss: 0.1449, Total Loss: 1.5411, LR: 0.003360
2025-05-16 17:56:17,426 [INFO] Epoch 11/15 - Policy Loss: 1.3956, Value Loss: 0.1444, Total Loss: 1.5400, LR: 0.001710
2025-05-16 17:57:12,021 [INFO] Epoch 12/15 - Policy Loss: 1.3931, Value Loss: 0.1437, Total Loss: 1.5368, LR: 0.000060
2025-05-16 17:58:06,319 [INFO] Epoch 13/15 - Policy Loss: 1.3913, Value Loss: 0.1432, Total Loss: 1.5344, LR: 0.001690
2025-05-16 17:59:01,045 [INFO] Epoch 14/15 - Policy Loss: 1.3895, Value Loss: 0.1426, Total Loss: 1.5321, LR: 0.003340
2025-05-16 17:59:55,504 [INFO] Epoch 15/15 - Policy Loss: 1.3893, Value Loss: 0.1424, Total Loss: 1.5317, LR: 0.004990
2025-05-16 17:59:55,527 [INFO] 训练完成，总损失: 1.5317
2025-05-16 17:59:55,528 [INFO] 保存迭代 11 的模型
2025-05-16 17:59:56,993 [INFO] Model saved to ./models/best.pt
2025-05-16 17:59:57,870 [INFO] Model saved to ./models/iteration_11.pt
2025-05-16 17:59:57,870 [INFO] 所有训练迭代完成
2025-05-16 17:59:57,870 [INFO] 开始迭代 12/300
2025-05-16 17:59:57,870 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 18:17:31,219 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 18:17:31,221 [INFO] 保存训练样本
2025-05-16 18:17:36,194 [INFO] 使用 176208 个样本训练神经网络
2025-05-16 18:17:36,194 [INFO] Training with 176208 examples
2025-05-16 18:17:36,195 [INFO] 总训练步数: 2580, 每轮次批次数: 172
2025-05-16 18:17:36,636 [INFO] 循环学习率周期大小: 516 步
2025-05-16 18:18:30,510 [INFO] Epoch 1/15 - Policy Loss: 1.4210, Value Loss: 0.1535, Total Loss: 1.5746, LR: 0.001690
2025-05-16 18:19:25,133 [INFO] Epoch 2/15 - Policy Loss: 1.4083, Value Loss: 0.1490, Total Loss: 1.5574, LR: 0.003340
2025-05-16 18:20:18,457 [INFO] Epoch 3/15 - Policy Loss: 1.4055, Value Loss: 0.1483, Total Loss: 1.5538, LR: 0.004990
2025-05-16 18:21:12,912 [INFO] Epoch 4/15 - Policy Loss: 1.4082, Value Loss: 0.1488, Total Loss: 1.5570, LR: 0.003360
2025-05-16 18:22:06,738 [INFO] Epoch 5/15 - Policy Loss: 1.4031, Value Loss: 0.1477, Total Loss: 1.5509, LR: 0.001710
2025-05-16 18:23:00,886 [INFO] Epoch 6/15 - Policy Loss: 1.3991, Value Loss: 0.1464, Total Loss: 1.5455, LR: 0.000060
2025-05-16 18:23:55,017 [INFO] Epoch 7/15 - Policy Loss: 1.3938, Value Loss: 0.1452, Total Loss: 1.5390, LR: 0.001690
2025-05-16 18:24:50,114 [INFO] Epoch 8/15 - Policy Loss: 1.3901, Value Loss: 0.1443, Total Loss: 1.5344, LR: 0.003340
2025-05-16 18:25:44,472 [INFO] Epoch 9/15 - Policy Loss: 1.3894, Value Loss: 0.1435, Total Loss: 1.5330, LR: 0.004990
2025-05-16 18:26:38,664 [INFO] Epoch 10/15 - Policy Loss: 1.3906, Value Loss: 0.1436, Total Loss: 1.5343, LR: 0.003360
2025-05-16 18:27:32,922 [INFO] Epoch 11/15 - Policy Loss: 1.3904, Value Loss: 0.1433, Total Loss: 1.5336, LR: 0.001710
2025-05-16 18:28:27,117 [INFO] Epoch 12/15 - Policy Loss: 1.3877, Value Loss: 0.1428, Total Loss: 1.5305, LR: 0.000060
2025-05-16 18:29:22,199 [INFO] Epoch 13/15 - Policy Loss: 1.3854, Value Loss: 0.1423, Total Loss: 1.5276, LR: 0.001690
2025-05-16 18:30:17,030 [INFO] Epoch 14/15 - Policy Loss: 1.3839, Value Loss: 0.1417, Total Loss: 1.5256, LR: 0.003340
2025-05-16 18:31:11,353 [INFO] Epoch 15/15 - Policy Loss: 1.3836, Value Loss: 0.1416, Total Loss: 1.5252, LR: 0.004990
2025-05-16 18:31:11,378 [INFO] 训练完成，总损失: 1.5252
2025-05-16 18:31:11,378 [INFO] 保存迭代 12 的模型
2025-05-16 18:31:13,014 [INFO] Model saved to ./models/best.pt
2025-05-16 18:31:13,942 [INFO] Model saved to ./models/iteration_12.pt
2025-05-16 18:31:13,942 [INFO] 所有训练迭代完成
2025-05-16 18:31:13,942 [INFO] 开始迭代 13/300
2025-05-16 18:31:13,942 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 18:49:36,205 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 18:49:36,206 [INFO] 保存训练样本
2025-05-16 18:49:40,886 [INFO] 使用 176664 个样本训练神经网络
2025-05-16 18:49:40,886 [INFO] Training with 176664 examples
2025-05-16 18:49:40,887 [INFO] 总训练步数: 2580, 每轮次批次数: 172
2025-05-16 18:49:40,949 [INFO] 循环学习率周期大小: 516 步
2025-05-16 18:50:35,249 [INFO] Epoch 1/15 - Policy Loss: 1.4135, Value Loss: 0.1713, Total Loss: 1.5848, LR: 0.001690
2025-05-16 18:51:29,472 [INFO] Epoch 2/15 - Policy Loss: 1.4048, Value Loss: 0.1650, Total Loss: 1.5698, LR: 0.003340
2025-05-16 18:52:24,195 [INFO] Epoch 3/15 - Policy Loss: 1.4042, Value Loss: 0.1633, Total Loss: 1.5675, LR: 0.004990
2025-05-16 18:53:18,853 [INFO] Epoch 4/15 - Policy Loss: 1.4081, Value Loss: 0.1628, Total Loss: 1.5709, LR: 0.003360
2025-05-16 18:54:13,866 [INFO] Epoch 5/15 - Policy Loss: 1.4058, Value Loss: 0.1613, Total Loss: 1.5671, LR: 0.001710
2025-05-16 18:55:08,953 [INFO] Epoch 6/15 - Policy Loss: 1.3997, Value Loss: 0.1588, Total Loss: 1.5585, LR: 0.000060
2025-05-16 18:56:04,117 [INFO] Epoch 7/15 - Policy Loss: 1.3946, Value Loss: 0.1570, Total Loss: 1.5516, LR: 0.001690
2025-05-16 18:56:59,050 [INFO] Epoch 8/15 - Policy Loss: 1.3920, Value Loss: 0.1558, Total Loss: 1.5478, LR: 0.003340
2025-05-16 18:57:53,303 [INFO] Epoch 9/15 - Policy Loss: 1.3913, Value Loss: 0.1549, Total Loss: 1.5462, LR: 0.004990
2025-05-16 18:58:48,301 [INFO] Epoch 10/15 - Policy Loss: 1.3909, Value Loss: 0.1542, Total Loss: 1.5451, LR: 0.003360
2025-05-16 18:59:43,413 [INFO] Epoch 11/15 - Policy Loss: 1.3895, Value Loss: 0.1535, Total Loss: 1.5429, LR: 0.001710
2025-05-16 19:00:37,042 [INFO] Epoch 12/15 - Policy Loss: 1.3877, Value Loss: 0.1528, Total Loss: 1.5406, LR: 0.000060
2025-05-16 19:01:31,371 [INFO] Epoch 13/15 - Policy Loss: 1.3855, Value Loss: 0.1521, Total Loss: 1.5376, LR: 0.001690
2025-05-16 19:02:25,936 [INFO] Epoch 14/15 - Policy Loss: 1.3841, Value Loss: 0.1516, Total Loss: 1.5356, LR: 0.003340
2025-05-16 19:03:20,254 [INFO] Epoch 15/15 - Policy Loss: 1.3839, Value Loss: 0.1512, Total Loss: 1.5352, LR: 0.004990
2025-05-16 19:03:20,279 [INFO] 训练完成，总损失: 1.5352
2025-05-16 19:03:20,280 [INFO] 保存迭代 13 的模型
2025-05-16 19:03:21,874 [INFO] Model saved to ./models/best.pt
2025-05-16 19:03:22,817 [INFO] Model saved to ./models/iteration_13.pt
2025-05-16 19:03:22,817 [INFO] 所有训练迭代完成
2025-05-16 19:03:22,817 [INFO] 开始迭代 14/300
2025-05-16 19:03:22,817 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 19:20:17,748 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 19:20:17,749 [INFO] 保存训练样本
2025-05-16 19:20:23,891 [INFO] 使用 176672 个样本训练神经网络
2025-05-16 19:20:23,892 [INFO] Training with 176672 examples
2025-05-16 19:20:23,892 [INFO] 总训练步数: 2580, 每轮次批次数: 172
2025-05-16 19:20:24,430 [INFO] 循环学习率周期大小: 516 步
2025-05-16 19:21:18,857 [INFO] Epoch 1/15 - Policy Loss: 1.4143, Value Loss: 0.1608, Total Loss: 1.5752, LR: 0.001690
2025-05-16 19:22:13,620 [INFO] Epoch 2/15 - Policy Loss: 1.4062, Value Loss: 0.1580, Total Loss: 1.5642, LR: 0.003340
2025-05-16 19:23:06,750 [INFO] Epoch 3/15 - Policy Loss: 1.4047, Value Loss: 0.1573, Total Loss: 1.5620, LR: 0.004990
2025-05-16 19:23:59,139 [INFO] Epoch 4/15 - Policy Loss: 1.4046, Value Loss: 0.1566, Total Loss: 1.5612, LR: 0.003360
2025-05-16 19:24:51,163 [INFO] Epoch 5/15 - Policy Loss: 1.4007, Value Loss: 0.1558, Total Loss: 1.5564, LR: 0.001710
2025-05-16 19:25:43,199 [INFO] Epoch 6/15 - Policy Loss: 1.3962, Value Loss: 0.1543, Total Loss: 1.5505, LR: 0.000060
2025-05-16 19:26:35,129 [INFO] Epoch 7/15 - Policy Loss: 1.3922, Value Loss: 0.1530, Total Loss: 1.5451, LR: 0.001690
2025-05-16 19:27:27,096 [INFO] Epoch 8/15 - Policy Loss: 1.3894, Value Loss: 0.1520, Total Loss: 1.5414, LR: 0.003340
2025-05-16 19:28:19,168 [INFO] Epoch 9/15 - Policy Loss: 1.3891, Value Loss: 0.1513, Total Loss: 1.5404, LR: 0.004990
2025-05-16 19:29:09,357 [INFO] Epoch 10/15 - Policy Loss: 1.3889, Value Loss: 0.1510, Total Loss: 1.5399, LR: 0.003360
2025-05-16 19:29:58,345 [INFO] Epoch 11/15 - Policy Loss: 1.3881, Value Loss: 0.1505, Total Loss: 1.5387, LR: 0.001710
2025-05-16 19:30:47,233 [INFO] Epoch 12/15 - Policy Loss: 1.3862, Value Loss: 0.1498, Total Loss: 1.5360, LR: 0.000060
2025-05-16 19:31:36,543 [INFO] Epoch 13/15 - Policy Loss: 1.3849, Value Loss: 0.1493, Total Loss: 1.5342, LR: 0.001690
2025-05-16 19:32:25,911 [INFO] Epoch 14/15 - Policy Loss: 1.3831, Value Loss: 0.1489, Total Loss: 1.5320, LR: 0.003340
2025-05-16 19:33:15,234 [INFO] Epoch 15/15 - Policy Loss: 1.3831, Value Loss: 0.1487, Total Loss: 1.5319, LR: 0.004990
2025-05-16 19:33:15,256 [INFO] 训练完成，总损失: 1.5319
2025-05-16 19:33:15,256 [INFO] 保存迭代 14 的模型
2025-05-16 19:33:16,514 [INFO] Model saved to ./models/best.pt
2025-05-16 19:33:17,195 [INFO] Model saved to ./models/iteration_14.pt
2025-05-16 19:33:17,195 [INFO] 所有训练迭代完成
2025-05-16 19:33:17,195 [INFO] 开始迭代 15/300
2025-05-16 19:33:17,195 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 19:49:40,862 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 19:49:40,863 [INFO] 保存训练样本
2025-05-16 19:49:46,463 [INFO] 使用 176824 个样本训练神经网络
2025-05-16 19:49:46,463 [INFO] Training with 176824 examples
2025-05-16 19:49:46,464 [INFO] 总训练步数: 2580, 每轮次批次数: 172
2025-05-16 19:49:47,060 [INFO] 循环学习率周期大小: 516 步
2025-05-16 19:50:32,895 [INFO] Epoch 1/15 - Policy Loss: 1.4243, Value Loss: 0.1651, Total Loss: 1.5893, LR: 0.001690
2025-05-16 19:51:19,031 [INFO] Epoch 2/15 - Policy Loss: 1.4112, Value Loss: 0.1575, Total Loss: 1.5687, LR: 0.003340
2025-05-16 19:52:05,214 [INFO] Epoch 3/15 - Policy Loss: 1.4096, Value Loss: 0.1551, Total Loss: 1.5647, LR: 0.004990
2025-05-16 19:52:51,285 [INFO] Epoch 4/15 - Policy Loss: 1.4090, Value Loss: 0.1543, Total Loss: 1.5633, LR: 0.003360
2025-05-16 19:53:37,373 [INFO] Epoch 5/15 - Policy Loss: 1.4046, Value Loss: 0.1523, Total Loss: 1.5569, LR: 0.001710
2025-05-16 19:54:23,705 [INFO] Epoch 6/15 - Policy Loss: 1.4002, Value Loss: 0.1507, Total Loss: 1.5509, LR: 0.000060
2025-05-16 19:55:10,080 [INFO] Epoch 7/15 - Policy Loss: 1.3958, Value Loss: 0.1492, Total Loss: 1.5450, LR: 0.001690
2025-05-16 19:55:57,002 [INFO] Epoch 8/15 - Policy Loss: 1.3929, Value Loss: 0.1480, Total Loss: 1.5408, LR: 0.003340
2025-05-16 19:56:50,528 [INFO] Epoch 9/15 - Policy Loss: 1.3915, Value Loss: 0.1478, Total Loss: 1.5393, LR: 0.004990
2025-05-16 19:57:36,661 [INFO] Epoch 10/15 - Policy Loss: 1.3918, Value Loss: 0.1475, Total Loss: 1.5393, LR: 0.003360
2025-05-16 19:58:22,727 [INFO] Epoch 11/15 - Policy Loss: 1.3904, Value Loss: 0.1470, Total Loss: 1.5374, LR: 0.001710
2025-05-16 19:59:32,988 [INFO] Epoch 12/15 - Policy Loss: 1.3885, Value Loss: 0.1465, Total Loss: 1.5350, LR: 0.000060
2025-05-16 20:00:57,807 [INFO] Epoch 13/15 - Policy Loss: 1.3866, Value Loss: 0.1461, Total Loss: 1.5327, LR: 0.001690
2025-05-16 20:02:23,560 [INFO] Epoch 14/15 - Policy Loss: 1.3847, Value Loss: 0.1456, Total Loss: 1.5304, LR: 0.003340
2025-05-16 20:03:46,944 [INFO] Epoch 15/15 - Policy Loss: 1.3844, Value Loss: 0.1453, Total Loss: 1.5298, LR: 0.004990
2025-05-16 20:03:46,965 [INFO] 训练完成，总损失: 1.5298
2025-05-16 20:03:46,965 [INFO] 保存迭代 15 的模型
2025-05-16 20:03:48,230 [INFO] Model saved to ./models/best.pt
2025-05-16 20:03:48,941 [INFO] Model saved to ./models/iteration_15.pt
2025-05-16 20:03:48,942 [INFO] 所有训练迭代完成
2025-05-16 20:03:48,942 [INFO] 开始迭代 16/300
2025-05-16 20:03:48,942 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 20:23:33,329 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 20:23:33,330 [INFO] 保存训练样本
2025-05-16 20:23:38,626 [INFO] 使用 176176 个样本训练神经网络
2025-05-16 20:23:38,626 [INFO] Training with 176176 examples
2025-05-16 20:23:38,626 [INFO] 总训练步数: 2580, 每轮次批次数: 172
2025-05-16 20:23:38,676 [INFO] 循环学习率周期大小: 516 步
2025-05-16 20:24:52,449 [INFO] Epoch 1/15 - Policy Loss: 1.4163, Value Loss: 0.1510, Total Loss: 1.5673, LR: 0.001690
2025-05-16 20:26:29,985 [INFO] Epoch 2/15 - Policy Loss: 1.4079, Value Loss: 0.1490, Total Loss: 1.5569, LR: 0.003340
2025-05-16 20:27:53,234 [INFO] Epoch 3/15 - Policy Loss: 1.4058, Value Loss: 0.1488, Total Loss: 1.5546, LR: 0.004990
2025-05-16 20:29:20,033 [INFO] Epoch 4/15 - Policy Loss: 1.4064, Value Loss: 0.1494, Total Loss: 1.5558, LR: 0.003360
2025-05-16 20:30:50,276 [INFO] Epoch 5/15 - Policy Loss: 1.4017, Value Loss: 0.1482, Total Loss: 1.5499, LR: 0.001710
2025-05-16 20:32:13,797 [INFO] Epoch 6/15 - Policy Loss: 1.3981, Value Loss: 0.1475, Total Loss: 1.5456, LR: 0.000060
2025-05-16 20:33:39,485 [INFO] Epoch 7/15 - Policy Loss: 1.3954, Value Loss: 0.1463, Total Loss: 1.5417, LR: 0.001690
2025-05-16 20:35:05,840 [INFO] Epoch 8/15 - Policy Loss: 1.3923, Value Loss: 0.1454, Total Loss: 1.5377, LR: 0.003340
2025-05-16 20:36:28,408 [INFO] Epoch 9/15 - Policy Loss: 1.3917, Value Loss: 0.1451, Total Loss: 1.5367, LR: 0.004990
2025-05-16 20:37:42,171 [INFO] Epoch 10/15 - Policy Loss: 1.3922, Value Loss: 0.1452, Total Loss: 1.5375, LR: 0.003360
2025-05-16 20:38:27,736 [INFO] Epoch 11/15 - Policy Loss: 1.3916, Value Loss: 0.1450, Total Loss: 1.5366, LR: 0.001710
2025-05-16 20:39:13,557 [INFO] Epoch 12/15 - Policy Loss: 1.3893, Value Loss: 0.1444, Total Loss: 1.5338, LR: 0.000060
2025-05-16 20:39:59,624 [INFO] Epoch 13/15 - Policy Loss: 1.3875, Value Loss: 0.1441, Total Loss: 1.5316, LR: 0.001690
2025-05-16 20:40:45,674 [INFO] Epoch 14/15 - Policy Loss: 1.3856, Value Loss: 0.1438, Total Loss: 1.5294, LR: 0.003340
2025-05-16 20:41:31,662 [INFO] Epoch 15/15 - Policy Loss: 1.3853, Value Loss: 0.1435, Total Loss: 1.5288, LR: 0.004990
2025-05-16 20:41:31,683 [INFO] 训练完成，总损失: 1.5288
2025-05-16 20:41:31,683 [INFO] 保存迭代 16 的模型
2025-05-16 20:41:32,839 [INFO] Model saved to ./models/best.pt
2025-05-16 20:41:33,512 [INFO] Model saved to ./models/iteration_16.pt
2025-05-16 20:41:33,512 [INFO] 所有训练迭代完成
2025-05-16 20:41:33,512 [INFO] 开始迭代 17/300
2025-05-16 20:41:33,512 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 20:59:44,267 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 20:59:44,268 [INFO] 保存训练样本
2025-05-16 20:59:49,471 [INFO] 使用 177416 个样本训练神经网络
2025-05-16 20:59:49,471 [INFO] Training with 177416 examples
2025-05-16 20:59:49,472 [INFO] 总训练步数: 2595, 每轮次批次数: 173
2025-05-16 20:59:50,167 [INFO] 循环学习率周期大小: 519 步
2025-05-16 21:00:35,866 [INFO] Epoch 1/15 - Policy Loss: 1.4107, Value Loss: 0.1703, Total Loss: 1.5809, LR: 0.001690
2025-05-16 21:01:21,977 [INFO] Epoch 2/15 - Policy Loss: 1.4051, Value Loss: 0.1654, Total Loss: 1.5705, LR: 0.003340
2025-05-16 21:02:08,131 [INFO] Epoch 3/15 - Policy Loss: 1.4032, Value Loss: 0.1622, Total Loss: 1.5654, LR: 0.004990
2025-05-16 21:02:54,337 [INFO] Epoch 4/15 - Policy Loss: 1.4019, Value Loss: 0.1616, Total Loss: 1.5635, LR: 0.003360
2025-05-16 21:03:40,530 [INFO] Epoch 5/15 - Policy Loss: 1.4005, Value Loss: 0.1604, Total Loss: 1.5609, LR: 0.001710
2025-05-16 21:04:26,395 [INFO] Epoch 6/15 - Policy Loss: 1.3961, Value Loss: 0.1587, Total Loss: 1.5547, LR: 0.000060
2025-05-16 21:05:12,116 [INFO] Epoch 7/15 - Policy Loss: 1.3924, Value Loss: 0.1575, Total Loss: 1.5500, LR: 0.001690
2025-05-16 21:05:58,150 [INFO] Epoch 8/15 - Policy Loss: 1.3894, Value Loss: 0.1565, Total Loss: 1.5459, LR: 0.003340
2025-05-16 21:06:44,763 [INFO] Epoch 9/15 - Policy Loss: 1.3891, Value Loss: 0.1556, Total Loss: 1.5447, LR: 0.004990
2025-05-16 21:07:31,281 [INFO] Epoch 10/15 - Policy Loss: 1.3897, Value Loss: 0.1553, Total Loss: 1.5450, LR: 0.003360
2025-05-16 21:08:17,956 [INFO] Epoch 11/15 - Policy Loss: 1.3891, Value Loss: 0.1550, Total Loss: 1.5441, LR: 0.001710
2025-05-16 21:09:04,709 [INFO] Epoch 12/15 - Policy Loss: 1.3876, Value Loss: 0.1546, Total Loss: 1.5422, LR: 0.000060
2025-05-16 21:09:51,370 [INFO] Epoch 13/15 - Policy Loss: 1.3860, Value Loss: 0.1542, Total Loss: 1.5402, LR: 0.001690
2025-05-16 21:10:37,991 [INFO] Epoch 14/15 - Policy Loss: 1.3845, Value Loss: 0.1536, Total Loss: 1.5382, LR: 0.003340
2025-05-16 21:11:25,116 [INFO] Epoch 15/15 - Policy Loss: 1.3845, Value Loss: 0.1535, Total Loss: 1.5380, LR: 0.004990
2025-05-16 21:11:25,145 [INFO] 训练完成，总损失: 1.5380
2025-05-16 21:11:25,145 [INFO] 保存迭代 17 的模型
2025-05-16 21:11:26,338 [INFO] Model saved to ./models/best.pt
2025-05-16 21:11:27,058 [INFO] Model saved to ./models/iteration_17.pt
2025-05-16 21:11:27,058 [INFO] 所有训练迭代完成
2025-05-16 21:11:27,058 [INFO] 开始迭代 18/300
2025-05-16 21:11:27,059 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 21:27:09,643 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 21:27:09,643 [INFO] 保存训练样本
2025-05-16 21:27:13,540 [INFO] 使用 177256 个样本训练神经网络
2025-05-16 21:27:13,540 [INFO] Training with 177256 examples
2025-05-16 21:27:13,540 [INFO] 总训练步数: 2595, 每轮次批次数: 173
2025-05-16 21:27:13,928 [INFO] 循环学习率周期大小: 519 步
2025-05-16 21:28:00,088 [INFO] Epoch 1/15 - Policy Loss: 1.4157, Value Loss: 0.1622, Total Loss: 1.5779, LR: 0.001690
2025-05-16 21:29:10,843 [INFO] Epoch 2/15 - Policy Loss: 1.4049, Value Loss: 0.1571, Total Loss: 1.5620, LR: 0.003340
2025-05-16 21:30:34,983 [INFO] Epoch 3/15 - Policy Loss: 1.4040, Value Loss: 0.1567, Total Loss: 1.5607, LR: 0.004990
2025-05-16 21:32:02,947 [INFO] Epoch 4/15 - Policy Loss: 1.4059, Value Loss: 0.1568, Total Loss: 1.5627, LR: 0.003360
2025-05-16 21:33:27,329 [INFO] Epoch 5/15 - Policy Loss: 1.4024, Value Loss: 0.1559, Total Loss: 1.5583, LR: 0.001710
2025-05-16 21:34:50,452 [INFO] Epoch 6/15 - Policy Loss: 1.3995, Value Loss: 0.1544, Total Loss: 1.5539, LR: 0.000060
2025-05-16 21:36:20,864 [INFO] Epoch 7/15 - Policy Loss: 1.3957, Value Loss: 0.1535, Total Loss: 1.5492, LR: 0.001690
2025-05-16 21:37:37,474 [INFO] Epoch 8/15 - Policy Loss: 1.3929, Value Loss: 0.1528, Total Loss: 1.5457, LR: 0.003340
2025-05-16 21:38:55,747 [INFO] Epoch 9/15 - Policy Loss: 1.3918, Value Loss: 0.1522, Total Loss: 1.5440, LR: 0.004990
2025-05-16 21:40:21,948 [INFO] Epoch 10/15 - Policy Loss: 1.3926, Value Loss: 0.1519, Total Loss: 1.5445, LR: 0.003360
2025-05-16 21:41:53,325 [INFO] Epoch 11/15 - Policy Loss: 1.3922, Value Loss: 0.1514, Total Loss: 1.5437, LR: 0.001710
2025-05-16 21:43:19,979 [INFO] Epoch 12/15 - Policy Loss: 1.3908, Value Loss: 0.1509, Total Loss: 1.5417, LR: 0.000060
2025-05-16 21:44:47,854 [INFO] Epoch 13/15 - Policy Loss: 1.3888, Value Loss: 0.1504, Total Loss: 1.5392, LR: 0.001690
2025-05-16 21:46:09,885 [INFO] Epoch 14/15 - Policy Loss: 1.3873, Value Loss: 0.1499, Total Loss: 1.5372, LR: 0.003340
2025-05-16 21:47:41,919 [INFO] Epoch 15/15 - Policy Loss: 1.3867, Value Loss: 0.1494, Total Loss: 1.5361, LR: 0.004990
2025-05-16 21:47:41,941 [INFO] 训练完成，总损失: 1.5361
2025-05-16 21:47:41,942 [INFO] 保存迭代 18 的模型
2025-05-16 21:47:43,255 [INFO] Model saved to ./models/best.pt
2025-05-16 21:47:44,146 [INFO] Model saved to ./models/iteration_18.pt
2025-05-16 21:47:44,147 [INFO] 所有训练迭代完成
2025-05-16 21:47:44,147 [INFO] 开始迭代 19/300
2025-05-16 21:47:44,147 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 22:10:26,746 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 22:10:26,746 [INFO] 保存训练样本
2025-05-16 22:10:33,098 [INFO] 使用 177424 个样本训练神经网络
2025-05-16 22:10:33,098 [INFO] Training with 177424 examples
2025-05-16 22:10:33,098 [INFO] 总训练步数: 2595, 每轮次批次数: 173
2025-05-16 22:10:33,174 [INFO] 循环学习率周期大小: 519 步
2025-05-16 22:11:51,525 [INFO] Epoch 1/15 - Policy Loss: 1.4229, Value Loss: 0.1588, Total Loss: 1.5817, LR: 0.001690
2025-05-16 22:13:16,110 [INFO] Epoch 2/15 - Policy Loss: 1.4154, Value Loss: 0.1538, Total Loss: 1.5692, LR: 0.003340
2025-05-16 22:14:31,759 [INFO] Epoch 3/15 - Policy Loss: 1.4114, Value Loss: 0.1547, Total Loss: 1.5661, LR: 0.004990
2025-05-16 22:15:59,525 [INFO] Epoch 4/15 - Policy Loss: 1.4121, Value Loss: 0.1547, Total Loss: 1.5668, LR: 0.003360
2025-05-16 22:17:27,807 [INFO] Epoch 5/15 - Policy Loss: 1.4077, Value Loss: 0.1537, Total Loss: 1.5614, LR: 0.001710
2025-05-16 22:18:56,658 [INFO] Epoch 6/15 - Policy Loss: 1.4027, Value Loss: 0.1525, Total Loss: 1.5551, LR: 0.000060
2025-05-16 22:20:11,181 [INFO] Epoch 7/15 - Policy Loss: 1.3992, Value Loss: 0.1518, Total Loss: 1.5510, LR: 0.001690
2025-05-16 22:21:35,952 [INFO] Epoch 8/15 - Policy Loss: 1.3963, Value Loss: 0.1511, Total Loss: 1.5474, LR: 0.003340
2025-05-16 22:23:00,019 [INFO] Epoch 9/15 - Policy Loss: 1.3955, Value Loss: 0.1506, Total Loss: 1.5461, LR: 0.004990
2025-05-16 22:24:24,560 [INFO] Epoch 10/15 - Policy Loss: 1.3956, Value Loss: 0.1503, Total Loss: 1.5459, LR: 0.003360
2025-05-16 22:25:43,945 [INFO] Epoch 11/15 - Policy Loss: 1.3953, Value Loss: 0.1499, Total Loss: 1.5452, LR: 0.001710
2025-05-16 22:27:12,295 [INFO] Epoch 12/15 - Policy Loss: 1.3935, Value Loss: 0.1493, Total Loss: 1.5428, LR: 0.000060
2025-05-16 22:28:39,545 [INFO] Epoch 13/15 - Policy Loss: 1.3917, Value Loss: 0.1489, Total Loss: 1.5406, LR: 0.001690
2025-05-16 22:30:03,024 [INFO] Epoch 14/15 - Policy Loss: 1.3900, Value Loss: 0.1485, Total Loss: 1.5386, LR: 0.003340
2025-05-16 22:31:30,304 [INFO] Epoch 15/15 - Policy Loss: 1.3895, Value Loss: 0.1482, Total Loss: 1.5377, LR: 0.004990
2025-05-16 22:31:30,332 [INFO] 训练完成，总损失: 1.5377
2025-05-16 22:31:30,332 [INFO] 保存迭代 19 的模型
2025-05-16 22:31:31,579 [INFO] Model saved to ./models/best.pt
2025-05-16 22:31:32,323 [INFO] Model saved to ./models/iteration_19.pt
2025-05-16 22:31:32,323 [INFO] 所有训练迭代完成
2025-05-16 22:31:32,323 [INFO] 开始迭代 20/300
2025-05-16 22:31:32,323 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 22:53:32,523 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 22:53:32,523 [INFO] 保存训练样本
2025-05-16 22:53:37,684 [INFO] 使用 177352 个样本训练神经网络
2025-05-16 22:53:37,684 [INFO] Training with 177352 examples
2025-05-16 22:53:37,684 [INFO] 总训练步数: 2595, 每轮次批次数: 173
2025-05-16 22:53:38,089 [INFO] 循环学习率周期大小: 519 步
2025-05-16 22:55:11,296 [INFO] Epoch 1/15 - Policy Loss: 1.4223, Value Loss: 0.1685, Total Loss: 1.5908, LR: 0.001690
2025-05-16 22:56:41,187 [INFO] Epoch 2/15 - Policy Loss: 1.4128, Value Loss: 0.1638, Total Loss: 1.5766, LR: 0.003340
2025-05-16 22:58:04,218 [INFO] Epoch 3/15 - Policy Loss: 1.4102, Value Loss: 0.1622, Total Loss: 1.5724, LR: 0.004990
2025-05-16 22:59:32,754 [INFO] Epoch 4/15 - Policy Loss: 1.4071, Value Loss: 0.1612, Total Loss: 1.5683, LR: 0.003360
2025-05-16 23:00:54,987 [INFO] Epoch 5/15 - Policy Loss: 1.4043, Value Loss: 0.1595, Total Loss: 1.5637, LR: 0.001710
2025-05-16 23:02:14,845 [INFO] Epoch 6/15 - Policy Loss: 1.4005, Value Loss: 0.1577, Total Loss: 1.5582, LR: 0.000060
2025-05-16 23:03:42,303 [INFO] Epoch 7/15 - Policy Loss: 1.3972, Value Loss: 0.1564, Total Loss: 1.5536, LR: 0.001690
2025-05-16 23:05:04,895 [INFO] Epoch 8/15 - Policy Loss: 1.3956, Value Loss: 0.1557, Total Loss: 1.5513, LR: 0.003340
2025-05-16 23:06:17,076 [INFO] Epoch 9/15 - Policy Loss: 1.3948, Value Loss: 0.1548, Total Loss: 1.5496, LR: 0.004990
2025-05-16 23:07:28,497 [INFO] Epoch 10/15 - Policy Loss: 1.3956, Value Loss: 0.1552, Total Loss: 1.5508, LR: 0.003360
2025-05-16 23:08:37,924 [INFO] Epoch 11/15 - Policy Loss: 1.3941, Value Loss: 0.1546, Total Loss: 1.5488, LR: 0.001710
2025-05-16 23:09:45,388 [INFO] Epoch 12/15 - Policy Loss: 1.3924, Value Loss: 0.1538, Total Loss: 1.5463, LR: 0.000060
2025-05-16 23:11:02,495 [INFO] Epoch 13/15 - Policy Loss: 1.3912, Value Loss: 0.1534, Total Loss: 1.5445, LR: 0.001690
2025-05-16 23:12:05,611 [INFO] Epoch 14/15 - Policy Loss: 1.3902, Value Loss: 0.1530, Total Loss: 1.5432, LR: 0.003340
2025-05-16 23:13:18,795 [INFO] Epoch 15/15 - Policy Loss: 1.3904, Value Loss: 0.1526, Total Loss: 1.5430, LR: 0.004990
2025-05-16 23:13:18,849 [INFO] 训练完成，总损失: 1.5430
2025-05-16 23:13:18,849 [INFO] 保存迭代 20 的模型
2025-05-16 23:13:21,084 [INFO] Model saved to ./models/best.pt
2025-05-16 23:13:22,412 [INFO] Model saved to ./models/iteration_20.pt
2025-05-16 23:13:22,413 [INFO] 所有训练迭代完成
2025-05-16 23:13:22,414 [INFO] 开始迭代 21/300
2025-05-16 23:13:22,414 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-16 23:38:04,838 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-16 23:38:04,840 [INFO] 保存训练样本
2025-05-16 23:38:17,082 [INFO] 使用 166160 个样本训练神经网络
2025-05-16 23:38:17,082 [INFO] Training with 166160 examples
2025-05-16 23:38:17,083 [INFO] 总训练步数: 2430, 每轮次批次数: 162
2025-05-16 23:38:18,402 [INFO] 循环学习率周期大小: 486 步
2025-05-16 23:39:31,059 [INFO] Epoch 1/15 - Policy Loss: 0.9660, Value Loss: 0.1671, Total Loss: 1.1332, LR: 0.001690
2025-05-16 23:40:52,009 [INFO] Epoch 2/15 - Policy Loss: 0.9430, Value Loss: 0.1640, Total Loss: 1.1070, LR: 0.003340
2025-05-16 23:42:05,694 [INFO] Epoch 3/15 - Policy Loss: 0.9343, Value Loss: 0.1631, Total Loss: 1.0975, LR: 0.004990
2025-05-16 23:43:14,446 [INFO] Epoch 4/15 - Policy Loss: 0.9302, Value Loss: 0.1625, Total Loss: 1.0927, LR: 0.003360
2025-05-16 23:44:15,955 [INFO] Epoch 5/15 - Policy Loss: 0.9256, Value Loss: 0.1615, Total Loss: 1.0871, LR: 0.001710
2025-05-16 23:45:27,887 [INFO] Epoch 6/15 - Policy Loss: 0.9200, Value Loss: 0.1604, Total Loss: 1.0804, LR: 0.000060
2025-05-16 23:46:38,783 [INFO] Epoch 7/15 - Policy Loss: 0.9157, Value Loss: 0.1596, Total Loss: 1.0753, LR: 0.001690
2025-05-16 23:47:55,226 [INFO] Epoch 8/15 - Policy Loss: 0.9124, Value Loss: 0.1588, Total Loss: 1.0713, LR: 0.003340
2025-05-16 23:48:58,070 [INFO] Epoch 9/15 - Policy Loss: 0.9112, Value Loss: 0.1585, Total Loss: 1.0697, LR: 0.004990
2025-05-16 23:50:02,798 [INFO] Epoch 10/15 - Policy Loss: 0.9113, Value Loss: 0.1586, Total Loss: 1.0699, LR: 0.003360
2025-05-16 23:51:18,350 [INFO] Epoch 11/15 - Policy Loss: 0.9103, Value Loss: 0.1582, Total Loss: 1.0685, LR: 0.001710
2025-05-16 23:52:33,391 [INFO] Epoch 12/15 - Policy Loss: 0.9086, Value Loss: 0.1578, Total Loss: 1.0664, LR: 0.000060
2025-05-16 23:53:49,343 [INFO] Epoch 13/15 - Policy Loss: 0.9069, Value Loss: 0.1575, Total Loss: 1.0644, LR: 0.001690
2025-05-16 23:55:08,264 [INFO] Epoch 14/15 - Policy Loss: 0.9056, Value Loss: 0.1571, Total Loss: 1.0627, LR: 0.003340
2025-05-16 23:56:31,087 [INFO] Epoch 15/15 - Policy Loss: 0.9052, Value Loss: 0.1571, Total Loss: 1.0623, LR: 0.004990
2025-05-16 23:56:31,230 [INFO] 训练完成，总损失: 1.0623
2025-05-16 23:56:31,230 [INFO] 保存迭代 21 的模型
2025-05-16 23:56:33,477 [INFO] Model saved to ./models/best.pt
2025-05-16 23:56:34,776 [INFO] Model saved to ./models/iteration_21.pt
2025-05-16 23:56:34,777 [INFO] 所有训练迭代完成
2025-05-16 23:56:34,778 [INFO] 开始迭代 22/300
2025-05-16 23:56:34,778 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 00:19:22,307 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 00:19:22,307 [INFO] 保存训练样本
2025-05-17 00:19:38,113 [INFO] 使用 166144 个样本训练神经网络
2025-05-17 00:19:38,113 [INFO] Training with 166144 examples
2025-05-17 00:19:38,115 [INFO] 总训练步数: 2430, 每轮次批次数: 162
2025-05-17 00:19:39,618 [INFO] 循环学习率周期大小: 486 步
2025-05-17 00:20:27,400 [INFO] Epoch 1/15 - Policy Loss: 0.9327, Value Loss: 0.1818, Total Loss: 1.1145, LR: 0.001690
2025-05-17 00:21:14,302 [INFO] Epoch 2/15 - Policy Loss: 0.9226, Value Loss: 0.1767, Total Loss: 1.0993, LR: 0.003340
2025-05-17 00:22:02,123 [INFO] Epoch 3/15 - Policy Loss: 0.9194, Value Loss: 0.1739, Total Loss: 1.0933, LR: 0.004990
2025-05-17 00:22:50,287 [INFO] Epoch 4/15 - Policy Loss: 0.9181, Value Loss: 0.1735, Total Loss: 1.0916, LR: 0.003360
2025-05-17 00:23:38,114 [INFO] Epoch 5/15 - Policy Loss: 0.9147, Value Loss: 0.1715, Total Loss: 1.0863, LR: 0.001710
2025-05-17 00:24:25,489 [INFO] Epoch 6/15 - Policy Loss: 0.9104, Value Loss: 0.1694, Total Loss: 1.0798, LR: 0.000060
2025-05-17 00:25:13,262 [INFO] Epoch 7/15 - Policy Loss: 0.9069, Value Loss: 0.1674, Total Loss: 1.0743, LR: 0.001690
2025-05-17 00:26:01,288 [INFO] Epoch 8/15 - Policy Loss: 0.9047, Value Loss: 0.1661, Total Loss: 1.0707, LR: 0.003340
2025-05-17 00:26:49,168 [INFO] Epoch 9/15 - Policy Loss: 0.9037, Value Loss: 0.1653, Total Loss: 1.0690, LR: 0.004990
2025-05-17 00:27:37,119 [INFO] Epoch 10/15 - Policy Loss: 0.9041, Value Loss: 0.1651, Total Loss: 1.0691, LR: 0.003360
2025-05-17 00:28:24,558 [INFO] Epoch 11/15 - Policy Loss: 0.9032, Value Loss: 0.1646, Total Loss: 1.0678, LR: 0.001710
2025-05-17 00:29:12,142 [INFO] Epoch 12/15 - Policy Loss: 0.9016, Value Loss: 0.1641, Total Loss: 1.0657, LR: 0.000060
2025-05-17 00:29:59,652 [INFO] Epoch 13/15 - Policy Loss: 0.9000, Value Loss: 0.1635, Total Loss: 1.0636, LR: 0.001690
2025-05-17 00:30:47,154 [INFO] Epoch 14/15 - Policy Loss: 0.8987, Value Loss: 0.1629, Total Loss: 1.0615, LR: 0.003340
2025-05-17 00:31:33,278 [INFO] Epoch 15/15 - Policy Loss: 0.8983, Value Loss: 0.1626, Total Loss: 1.0608, LR: 0.004990
2025-05-17 00:31:33,342 [INFO] 训练完成，总损失: 1.0608
2025-05-17 00:31:33,342 [INFO] 保存迭代 22 的模型
2025-05-17 00:31:35,279 [INFO] Model saved to ./models/best.pt
2025-05-17 00:31:36,478 [INFO] Model saved to ./models/iteration_22.pt
2025-05-17 00:31:36,478 [INFO] 所有训练迭代完成
2025-05-17 00:31:36,478 [INFO] 开始迭代 23/300
2025-05-17 00:31:36,478 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 00:47:41,246 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 00:47:41,246 [INFO] 保存训练样本
2025-05-17 00:47:46,642 [INFO] 使用 166280 个样本训练神经网络
2025-05-17 00:47:46,642 [INFO] Training with 166280 examples
2025-05-17 00:47:46,643 [INFO] 总训练步数: 2430, 每轮次批次数: 162
2025-05-17 00:47:46,707 [INFO] 循环学习率周期大小: 486 步
2025-05-17 00:48:29,413 [INFO] Epoch 1/15 - Policy Loss: 0.9159, Value Loss: 0.1766, Total Loss: 1.0925, LR: 0.001690
2025-05-17 00:49:12,337 [INFO] Epoch 2/15 - Policy Loss: 0.9084, Value Loss: 0.1741, Total Loss: 1.0825, LR: 0.003340
2025-05-17 00:49:55,202 [INFO] Epoch 3/15 - Policy Loss: 0.9069, Value Loss: 0.1726, Total Loss: 1.0795, LR: 0.004990
2025-05-17 00:50:38,146 [INFO] Epoch 4/15 - Policy Loss: 0.9096, Value Loss: 0.1738, Total Loss: 1.0834, LR: 0.003360
2025-05-17 00:51:20,923 [INFO] Epoch 5/15 - Policy Loss: 0.9078, Value Loss: 0.1725, Total Loss: 1.0802, LR: 0.001710
2025-05-17 00:52:04,290 [INFO] Epoch 6/15 - Policy Loss: 0.9041, Value Loss: 0.1713, Total Loss: 1.0753, LR: 0.000060
2025-05-17 00:52:47,243 [INFO] Epoch 7/15 - Policy Loss: 0.9008, Value Loss: 0.1702, Total Loss: 1.0710, LR: 0.001690
2025-05-17 00:53:30,307 [INFO] Epoch 8/15 - Policy Loss: 0.8989, Value Loss: 0.1691, Total Loss: 1.0680, LR: 0.003340
2025-05-17 00:54:13,471 [INFO] Epoch 9/15 - Policy Loss: 0.8980, Value Loss: 0.1682, Total Loss: 1.0662, LR: 0.004990
2025-05-17 00:54:56,647 [INFO] Epoch 10/15 - Policy Loss: 0.8982, Value Loss: 0.1677, Total Loss: 1.0659, LR: 0.003360
2025-05-17 00:55:39,712 [INFO] Epoch 11/15 - Policy Loss: 0.8970, Value Loss: 0.1671, Total Loss: 1.0641, LR: 0.001710
2025-05-17 00:56:22,835 [INFO] Epoch 12/15 - Policy Loss: 0.8955, Value Loss: 0.1665, Total Loss: 1.0620, LR: 0.000060
2025-05-17 00:57:05,924 [INFO] Epoch 13/15 - Policy Loss: 0.8939, Value Loss: 0.1658, Total Loss: 1.0598, LR: 0.001690
2025-05-17 00:57:48,847 [INFO] Epoch 14/15 - Policy Loss: 0.8929, Value Loss: 0.1654, Total Loss: 1.0583, LR: 0.003340
2025-05-17 00:58:31,802 [INFO] Epoch 15/15 - Policy Loss: 0.8927, Value Loss: 0.1649, Total Loss: 1.0576, LR: 0.004990
2025-05-17 00:58:31,823 [INFO] 训练完成，总损失: 1.0576
2025-05-17 00:58:31,823 [INFO] 保存迭代 23 的模型
2025-05-17 00:58:33,217 [INFO] Model saved to ./models/best.pt
2025-05-17 00:58:34,082 [INFO] Model saved to ./models/iteration_23.pt
2025-05-17 00:58:34,083 [INFO] 所有训练迭代完成
2025-05-17 00:58:34,083 [INFO] 开始迭代 24/300
2025-05-17 00:58:34,083 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 01:15:02,711 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 01:15:02,712 [INFO] 保存训练样本
2025-05-17 01:15:07,223 [INFO] 使用 166504 个样本训练神经网络
2025-05-17 01:15:07,223 [INFO] Training with 166504 examples
2025-05-17 01:15:07,224 [INFO] 总训练步数: 2430, 每轮次批次数: 162
2025-05-17 01:15:07,673 [INFO] 循环学习率周期大小: 486 步
2025-05-17 01:15:50,158 [INFO] Epoch 1/15 - Policy Loss: 0.9137, Value Loss: 0.1666, Total Loss: 1.0803, LR: 0.001690
2025-05-17 01:16:33,053 [INFO] Epoch 2/15 - Policy Loss: 0.9066, Value Loss: 0.1638, Total Loss: 1.0704, LR: 0.003340
2025-05-17 01:17:15,871 [INFO] Epoch 3/15 - Policy Loss: 0.9037, Value Loss: 0.1630, Total Loss: 1.0667, LR: 0.004990
2025-05-17 01:17:58,853 [INFO] Epoch 4/15 - Policy Loss: 0.9041, Value Loss: 0.1626, Total Loss: 1.0667, LR: 0.003360
2025-05-17 01:18:41,663 [INFO] Epoch 5/15 - Policy Loss: 0.9010, Value Loss: 0.1615, Total Loss: 1.0625, LR: 0.001710
2025-05-17 01:19:24,820 [INFO] Epoch 6/15 - Policy Loss: 0.8971, Value Loss: 0.1603, Total Loss: 1.0574, LR: 0.000060
2025-05-17 01:20:07,981 [INFO] Epoch 7/15 - Policy Loss: 0.8938, Value Loss: 0.1596, Total Loss: 1.0534, LR: 0.001690
2025-05-17 01:20:51,405 [INFO] Epoch 8/15 - Policy Loss: 0.8917, Value Loss: 0.1589, Total Loss: 1.0506, LR: 0.003340
2025-05-17 01:21:34,720 [INFO] Epoch 9/15 - Policy Loss: 0.8907, Value Loss: 0.1584, Total Loss: 1.0491, LR: 0.004990
2025-05-17 01:22:18,311 [INFO] Epoch 10/15 - Policy Loss: 0.8910, Value Loss: 0.1584, Total Loss: 1.0494, LR: 0.003360
2025-05-17 01:23:01,615 [INFO] Epoch 11/15 - Policy Loss: 0.8906, Value Loss: 0.1579, Total Loss: 1.0484, LR: 0.001710
2025-05-17 01:23:44,838 [INFO] Epoch 12/15 - Policy Loss: 0.8890, Value Loss: 0.1573, Total Loss: 1.0464, LR: 0.000060
2025-05-17 01:24:27,993 [INFO] Epoch 13/15 - Policy Loss: 0.8876, Value Loss: 0.1567, Total Loss: 1.0443, LR: 0.001690
2025-05-17 01:25:11,363 [INFO] Epoch 14/15 - Policy Loss: 0.8864, Value Loss: 0.1563, Total Loss: 1.0426, LR: 0.003340
2025-05-17 01:25:54,509 [INFO] Epoch 15/15 - Policy Loss: 0.8857, Value Loss: 0.1560, Total Loss: 1.0418, LR: 0.004990
2025-05-17 01:25:54,537 [INFO] 训练完成，总损失: 1.0418
2025-05-17 01:25:54,537 [INFO] 保存迭代 24 的模型
2025-05-17 01:25:55,979 [INFO] Model saved to ./models/best.pt
2025-05-17 01:25:56,833 [INFO] Model saved to ./models/iteration_24.pt
2025-05-17 01:25:56,833 [INFO] 所有训练迭代完成
2025-05-17 01:25:56,833 [INFO] 开始迭代 25/300
2025-05-17 01:25:56,833 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 01:42:15,397 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 01:42:15,397 [INFO] 保存训练样本
2025-05-17 01:42:20,952 [INFO] 使用 166688 个样本训练神经网络
2025-05-17 01:42:20,952 [INFO] Training with 166688 examples
2025-05-17 01:42:20,953 [INFO] 总训练步数: 2430, 每轮次批次数: 162
2025-05-17 01:42:21,333 [INFO] 循环学习率周期大小: 486 步
2025-05-17 01:43:03,599 [INFO] Epoch 1/15 - Policy Loss: 0.9128, Value Loss: 0.1665, Total Loss: 1.0793, LR: 0.001690
2025-05-17 01:43:45,980 [INFO] Epoch 2/15 - Policy Loss: 0.9045, Value Loss: 0.1640, Total Loss: 1.0685, LR: 0.003340
2025-05-17 01:44:28,434 [INFO] Epoch 3/15 - Policy Loss: 0.9036, Value Loss: 0.1632, Total Loss: 1.0667, LR: 0.004990
2025-05-17 01:45:10,993 [INFO] Epoch 4/15 - Policy Loss: 0.9038, Value Loss: 0.1627, Total Loss: 1.0665, LR: 0.003360
2025-05-17 01:45:53,727 [INFO] Epoch 5/15 - Policy Loss: 0.9008, Value Loss: 0.1617, Total Loss: 1.0625, LR: 0.001710
2025-05-17 01:46:36,644 [INFO] Epoch 6/15 - Policy Loss: 0.8968, Value Loss: 0.1605, Total Loss: 1.0573, LR: 0.000060
2025-05-17 01:47:19,612 [INFO] Epoch 7/15 - Policy Loss: 0.8937, Value Loss: 0.1595, Total Loss: 1.0532, LR: 0.001690
2025-05-17 01:48:02,673 [INFO] Epoch 8/15 - Policy Loss: 0.8919, Value Loss: 0.1588, Total Loss: 1.0507, LR: 0.003340
2025-05-17 01:48:45,877 [INFO] Epoch 9/15 - Policy Loss: 0.8910, Value Loss: 0.1585, Total Loss: 1.0495, LR: 0.004990
2025-05-17 01:49:29,138 [INFO] Epoch 10/15 - Policy Loss: 0.8907, Value Loss: 0.1581, Total Loss: 1.0489, LR: 0.003360
2025-05-17 01:50:12,237 [INFO] Epoch 11/15 - Policy Loss: 0.8904, Value Loss: 0.1578, Total Loss: 1.0482, LR: 0.001710
2025-05-17 01:50:55,191 [INFO] Epoch 12/15 - Policy Loss: 0.8889, Value Loss: 0.1573, Total Loss: 1.0461, LR: 0.000060
2025-05-17 01:51:38,111 [INFO] Epoch 13/15 - Policy Loss: 0.8875, Value Loss: 0.1567, Total Loss: 1.0442, LR: 0.001690
2025-05-17 01:52:21,144 [INFO] Epoch 14/15 - Policy Loss: 0.8861, Value Loss: 0.1562, Total Loss: 1.0424, LR: 0.003340
2025-05-17 01:53:04,595 [INFO] Epoch 15/15 - Policy Loss: 0.8856, Value Loss: 0.1559, Total Loss: 1.0415, LR: 0.004990
2025-05-17 01:53:04,614 [INFO] 训练完成，总损失: 1.0415
2025-05-17 01:53:04,614 [INFO] 保存迭代 25 的模型
2025-05-17 01:53:06,068 [INFO] Model saved to ./models/best.pt
2025-05-17 01:53:06,920 [INFO] Model saved to ./models/iteration_25.pt
2025-05-17 01:53:06,920 [INFO] 所有训练迭代完成
2025-05-17 01:53:06,921 [INFO] 开始迭代 26/300
2025-05-17 01:53:06,921 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 02:09:51,777 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 02:09:51,778 [INFO] 保存训练样本
2025-05-17 02:09:56,878 [INFO] 使用 167296 个样本训练神经网络
2025-05-17 02:09:56,878 [INFO] Training with 167296 examples
2025-05-17 02:09:56,879 [INFO] 总训练步数: 2445, 每轮次批次数: 163
2025-05-17 02:09:57,348 [INFO] 循环学习率周期大小: 489 步
2025-05-17 02:10:40,241 [INFO] Epoch 1/15 - Policy Loss: 0.9078, Value Loss: 0.1744, Total Loss: 1.0821, LR: 0.001690
2025-05-17 02:11:23,319 [INFO] Epoch 2/15 - Policy Loss: 0.8996, Value Loss: 0.1706, Total Loss: 1.0703, LR: 0.003340
2025-05-17 02:12:06,221 [INFO] Epoch 3/15 - Policy Loss: 0.8967, Value Loss: 0.1674, Total Loss: 1.0640, LR: 0.004990
2025-05-17 02:12:49,267 [INFO] Epoch 4/15 - Policy Loss: 0.8973, Value Loss: 0.1675, Total Loss: 1.0648, LR: 0.003360
2025-05-17 02:13:32,463 [INFO] Epoch 5/15 - Policy Loss: 0.8948, Value Loss: 0.1665, Total Loss: 1.0612, LR: 0.001710
2025-05-17 02:14:15,996 [INFO] Epoch 6/15 - Policy Loss: 0.8918, Value Loss: 0.1649, Total Loss: 1.0567, LR: 0.000060
2025-05-17 02:14:59,477 [INFO] Epoch 7/15 - Policy Loss: 0.8887, Value Loss: 0.1638, Total Loss: 1.0525, LR: 0.001690
2025-05-17 02:15:43,040 [INFO] Epoch 8/15 - Policy Loss: 0.8863, Value Loss: 0.1630, Total Loss: 1.0493, LR: 0.003340
2025-05-17 02:16:26,464 [INFO] Epoch 9/15 - Policy Loss: 0.8847, Value Loss: 0.1625, Total Loss: 1.0472, LR: 0.004990
2025-05-17 02:17:10,002 [INFO] Epoch 10/15 - Policy Loss: 0.8852, Value Loss: 0.1624, Total Loss: 1.0476, LR: 0.003360
2025-05-17 02:17:53,980 [INFO] Epoch 11/15 - Policy Loss: 0.8838, Value Loss: 0.1618, Total Loss: 1.0456, LR: 0.001710
2025-05-17 02:18:37,426 [INFO] Epoch 12/15 - Policy Loss: 0.8825, Value Loss: 0.1614, Total Loss: 1.0438, LR: 0.000060
2025-05-17 02:19:20,647 [INFO] Epoch 13/15 - Policy Loss: 0.8812, Value Loss: 0.1609, Total Loss: 1.0421, LR: 0.001690
2025-05-17 02:20:03,976 [INFO] Epoch 14/15 - Policy Loss: 0.8800, Value Loss: 0.1606, Total Loss: 1.0406, LR: 0.003340
2025-05-17 02:20:47,337 [INFO] Epoch 15/15 - Policy Loss: 0.8792, Value Loss: 0.1602, Total Loss: 1.0394, LR: 0.004990
2025-05-17 02:20:47,358 [INFO] 训练完成，总损失: 1.0394
2025-05-17 02:20:47,358 [INFO] 保存迭代 26 的模型
2025-05-17 02:20:48,873 [INFO] Model saved to ./models/best.pt
2025-05-17 02:20:49,686 [INFO] Model saved to ./models/iteration_26.pt
2025-05-17 02:20:49,687 [INFO] 所有训练迭代完成
2025-05-17 02:20:49,687 [INFO] 开始迭代 27/300
2025-05-17 02:20:49,687 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 02:37:00,160 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 02:37:00,160 [INFO] 保存训练样本
2025-05-17 02:37:04,867 [INFO] 使用 167376 个样本训练神经网络
2025-05-17 02:37:04,867 [INFO] Training with 167376 examples
2025-05-17 02:37:04,868 [INFO] 总训练步数: 2445, 每轮次批次数: 163
2025-05-17 02:37:04,920 [INFO] 循环学习率周期大小: 489 步
2025-05-17 02:37:47,644 [INFO] Epoch 1/15 - Policy Loss: 0.9066, Value Loss: 0.1727, Total Loss: 1.0793, LR: 0.001690
2025-05-17 02:38:30,797 [INFO] Epoch 2/15 - Policy Loss: 0.8976, Value Loss: 0.1684, Total Loss: 1.0660, LR: 0.003340
2025-05-17 02:39:14,102 [INFO] Epoch 3/15 - Policy Loss: 0.8932, Value Loss: 0.1667, Total Loss: 1.0599, LR: 0.004990
2025-05-17 02:39:57,461 [INFO] Epoch 4/15 - Policy Loss: 0.8932, Value Loss: 0.1661, Total Loss: 1.0593, LR: 0.003360
2025-05-17 02:40:40,927 [INFO] Epoch 5/15 - Policy Loss: 0.8904, Value Loss: 0.1647, Total Loss: 1.0551, LR: 0.001710
2025-05-17 02:41:24,966 [INFO] Epoch 6/15 - Policy Loss: 0.8867, Value Loss: 0.1631, Total Loss: 1.0498, LR: 0.000060
2025-05-17 02:42:08,413 [INFO] Epoch 7/15 - Policy Loss: 0.8827, Value Loss: 0.1618, Total Loss: 1.0445, LR: 0.001690
2025-05-17 02:42:51,890 [INFO] Epoch 8/15 - Policy Loss: 0.8806, Value Loss: 0.1611, Total Loss: 1.0417, LR: 0.003340
2025-05-17 02:43:35,466 [INFO] Epoch 9/15 - Policy Loss: 0.8791, Value Loss: 0.1605, Total Loss: 1.0396, LR: 0.004990
2025-05-17 02:44:18,873 [INFO] Epoch 10/15 - Policy Loss: 0.8794, Value Loss: 0.1604, Total Loss: 1.0397, LR: 0.003360
2025-05-17 02:45:02,332 [INFO] Epoch 11/15 - Policy Loss: 0.8784, Value Loss: 0.1601, Total Loss: 1.0386, LR: 0.001710
2025-05-17 02:45:45,725 [INFO] Epoch 12/15 - Policy Loss: 0.8771, Value Loss: 0.1596, Total Loss: 1.0367, LR: 0.000060
2025-05-17 02:46:28,973 [INFO] Epoch 13/15 - Policy Loss: 0.8758, Value Loss: 0.1592, Total Loss: 1.0350, LR: 0.001690
2025-05-17 02:47:12,215 [INFO] Epoch 14/15 - Policy Loss: 0.8745, Value Loss: 0.1588, Total Loss: 1.0333, LR: 0.003340
2025-05-17 02:47:55,510 [INFO] Epoch 15/15 - Policy Loss: 0.8741, Value Loss: 0.1585, Total Loss: 1.0326, LR: 0.004990
2025-05-17 02:47:55,536 [INFO] 训练完成，总损失: 1.0326
2025-05-17 02:47:55,536 [INFO] 保存迭代 27 的模型
2025-05-17 02:47:56,797 [INFO] Model saved to ./models/best.pt
2025-05-17 02:47:57,499 [INFO] Model saved to ./models/iteration_27.pt
2025-05-17 02:47:57,499 [INFO] 所有训练迭代完成
2025-05-17 02:47:57,499 [INFO] 开始迭代 28/300
2025-05-17 02:47:57,499 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 03:04:42,482 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 03:04:42,483 [INFO] 保存训练样本
2025-05-17 03:04:48,096 [INFO] 使用 168400 个样本训练神经网络
2025-05-17 03:04:48,097 [INFO] Training with 168400 examples
2025-05-17 03:04:48,098 [INFO] 总训练步数: 2460, 每轮次批次数: 164
2025-05-17 03:04:48,601 [INFO] 循环学习率周期大小: 492 步
2025-05-17 03:05:31,555 [INFO] Epoch 1/15 - Policy Loss: 0.9057, Value Loss: 0.1738, Total Loss: 1.0795, LR: 0.001690
2025-05-17 03:06:14,588 [INFO] Epoch 2/15 - Policy Loss: 0.8947, Value Loss: 0.1696, Total Loss: 1.0644, LR: 0.003340
2025-05-17 03:06:58,101 [INFO] Epoch 3/15 - Policy Loss: 0.8925, Value Loss: 0.1676, Total Loss: 1.0601, LR: 0.004990
2025-05-17 03:07:41,449 [INFO] Epoch 4/15 - Policy Loss: 0.8886, Value Loss: 0.1661, Total Loss: 1.0547, LR: 0.003360
2025-05-17 03:08:24,793 [INFO] Epoch 5/15 - Policy Loss: 0.8848, Value Loss: 0.1642, Total Loss: 1.0490, LR: 0.001710
2025-05-17 03:09:08,193 [INFO] Epoch 6/15 - Policy Loss: 0.8800, Value Loss: 0.1623, Total Loss: 1.0423, LR: 0.000060
2025-05-17 03:09:51,572 [INFO] Epoch 7/15 - Policy Loss: 0.8762, Value Loss: 0.1609, Total Loss: 1.0371, LR: 0.001690
2025-05-17 03:10:35,196 [INFO] Epoch 8/15 - Policy Loss: 0.8740, Value Loss: 0.1598, Total Loss: 1.0338, LR: 0.003340
2025-05-17 03:11:19,062 [INFO] Epoch 9/15 - Policy Loss: 0.8728, Value Loss: 0.1595, Total Loss: 1.0323, LR: 0.004990
2025-05-17 03:12:02,831 [INFO] Epoch 10/15 - Policy Loss: 0.8720, Value Loss: 0.1592, Total Loss: 1.0312, LR: 0.003360
2025-05-17 03:12:46,529 [INFO] Epoch 11/15 - Policy Loss: 0.8712, Value Loss: 0.1587, Total Loss: 1.0299, LR: 0.001710
2025-05-17 03:13:30,226 [INFO] Epoch 12/15 - Policy Loss: 0.8702, Value Loss: 0.1582, Total Loss: 1.0284, LR: 0.000060
2025-05-17 03:14:13,816 [INFO] Epoch 13/15 - Policy Loss: 0.8684, Value Loss: 0.1576, Total Loss: 1.0260, LR: 0.001690
2025-05-17 03:14:57,617 [INFO] Epoch 14/15 - Policy Loss: 0.8673, Value Loss: 0.1571, Total Loss: 1.0244, LR: 0.003340
2025-05-17 03:15:41,265 [INFO] Epoch 15/15 - Policy Loss: 0.8667, Value Loss: 0.1567, Total Loss: 1.0234, LR: 0.004990
2025-05-17 03:15:41,290 [INFO] 训练完成，总损失: 1.0234
2025-05-17 03:15:41,291 [INFO] 保存迭代 28 的模型
2025-05-17 03:15:42,587 [INFO] Model saved to ./models/best.pt
2025-05-17 03:15:43,292 [INFO] Model saved to ./models/iteration_28.pt
2025-05-17 03:15:43,293 [INFO] 所有训练迭代完成
2025-05-17 03:15:43,293 [INFO] 开始迭代 29/300
2025-05-17 03:15:43,293 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 03:31:50,549 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 03:31:50,550 [INFO] 保存训练样本
2025-05-17 03:31:56,368 [INFO] 使用 168664 个样本训练神经网络
2025-05-17 03:31:56,368 [INFO] Training with 168664 examples
2025-05-17 03:31:56,368 [INFO] 总训练步数: 2460, 每轮次批次数: 164
2025-05-17 03:31:56,878 [INFO] 循环学习率周期大小: 492 步
2025-05-17 03:32:40,044 [INFO] Epoch 1/15 - Policy Loss: 0.8822, Value Loss: 0.1618, Total Loss: 1.0440, LR: 0.001690
2025-05-17 03:33:23,448 [INFO] Epoch 2/15 - Policy Loss: 0.8762, Value Loss: 0.1596, Total Loss: 1.0358, LR: 0.003340
2025-05-17 03:34:06,882 [INFO] Epoch 3/15 - Policy Loss: 0.8745, Value Loss: 0.1596, Total Loss: 1.0341, LR: 0.004990
2025-05-17 03:34:50,326 [INFO] Epoch 4/15 - Policy Loss: 0.8769, Value Loss: 0.1606, Total Loss: 1.0375, LR: 0.003360
2025-05-17 03:35:33,833 [INFO] Epoch 5/15 - Policy Loss: 0.8731, Value Loss: 0.1597, Total Loss: 1.0328, LR: 0.001710
2025-05-17 03:36:17,564 [INFO] Epoch 6/15 - Policy Loss: 0.8693, Value Loss: 0.1586, Total Loss: 1.0279, LR: 0.000060
2025-05-17 03:37:01,342 [INFO] Epoch 7/15 - Policy Loss: 0.8666, Value Loss: 0.1578, Total Loss: 1.0244, LR: 0.001690
2025-05-17 03:37:44,930 [INFO] Epoch 8/15 - Policy Loss: 0.8645, Value Loss: 0.1572, Total Loss: 1.0218, LR: 0.003340
2025-05-17 03:38:28,413 [INFO] Epoch 9/15 - Policy Loss: 0.8634, Value Loss: 0.1569, Total Loss: 1.0203, LR: 0.004990
2025-05-17 03:39:11,810 [INFO] Epoch 10/15 - Policy Loss: 0.8635, Value Loss: 0.1568, Total Loss: 1.0203, LR: 0.003360
2025-05-17 03:39:55,122 [INFO] Epoch 11/15 - Policy Loss: 0.8627, Value Loss: 0.1566, Total Loss: 1.0193, LR: 0.001710
2025-05-17 03:40:38,524 [INFO] Epoch 12/15 - Policy Loss: 0.8617, Value Loss: 0.1562, Total Loss: 1.0179, LR: 0.000060
2025-05-17 03:41:21,919 [INFO] Epoch 13/15 - Policy Loss: 0.8600, Value Loss: 0.1558, Total Loss: 1.0159, LR: 0.001690
2025-05-17 03:42:05,565 [INFO] Epoch 14/15 - Policy Loss: 0.8589, Value Loss: 0.1555, Total Loss: 1.0144, LR: 0.003340
2025-05-17 03:42:49,558 [INFO] Epoch 15/15 - Policy Loss: 0.8585, Value Loss: 0.1552, Total Loss: 1.0137, LR: 0.004990
2025-05-17 03:42:49,579 [INFO] 训练完成，总损失: 1.0137
2025-05-17 03:42:49,579 [INFO] 保存迭代 29 的模型
2025-05-17 03:42:51,065 [INFO] Model saved to ./models/best.pt
2025-05-17 03:42:51,721 [INFO] Model saved to ./models/iteration_29.pt
2025-05-17 03:42:51,721 [INFO] 所有训练迭代完成
2025-05-17 03:42:51,721 [INFO] 开始迭代 30/300
2025-05-17 03:42:51,721 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 03:58:59,026 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 03:58:59,027 [INFO] 保存训练样本
2025-05-17 03:59:03,520 [INFO] 使用 168704 个样本训练神经网络
2025-05-17 03:59:03,520 [INFO] Training with 168704 examples
2025-05-17 03:59:03,521 [INFO] 总训练步数: 2460, 每轮次批次数: 164
2025-05-17 03:59:03,845 [INFO] 循环学习率周期大小: 492 步
2025-05-17 03:59:46,921 [INFO] Epoch 1/15 - Policy Loss: 0.8811, Value Loss: 0.1765, Total Loss: 1.0576, LR: 0.001690
2025-05-17 04:00:30,050 [INFO] Epoch 2/15 - Policy Loss: 0.8754, Value Loss: 0.1719, Total Loss: 1.0473, LR: 0.003340
2025-05-17 04:01:13,376 [INFO] Epoch 3/15 - Policy Loss: 0.8745, Value Loss: 0.1694, Total Loss: 1.0439, LR: 0.004990
2025-05-17 04:01:56,665 [INFO] Epoch 4/15 - Policy Loss: 0.8731, Value Loss: 0.1676, Total Loss: 1.0407, LR: 0.003360
2025-05-17 04:02:40,141 [INFO] Epoch 5/15 - Policy Loss: 0.8704, Value Loss: 0.1659, Total Loss: 1.0362, LR: 0.001710
2025-05-17 04:03:23,549 [INFO] Epoch 6/15 - Policy Loss: 0.8669, Value Loss: 0.1644, Total Loss: 1.0312, LR: 0.000060
2025-05-17 04:04:07,128 [INFO] Epoch 7/15 - Policy Loss: 0.8636, Value Loss: 0.1628, Total Loss: 1.0264, LR: 0.001690
2025-05-17 04:04:50,689 [INFO] Epoch 8/15 - Policy Loss: 0.8617, Value Loss: 0.1617, Total Loss: 1.0234, LR: 0.003340
2025-05-17 04:05:34,233 [INFO] Epoch 9/15 - Policy Loss: 0.8609, Value Loss: 0.1608, Total Loss: 1.0217, LR: 0.004990
2025-05-17 04:06:17,555 [INFO] Epoch 10/15 - Policy Loss: 0.8610, Value Loss: 0.1605, Total Loss: 1.0215, LR: 0.003360
2025-05-17 04:07:01,405 [INFO] Epoch 11/15 - Policy Loss: 0.8599, Value Loss: 0.1597, Total Loss: 1.0196, LR: 0.001710
2025-05-17 04:07:44,915 [INFO] Epoch 12/15 - Policy Loss: 0.8585, Value Loss: 0.1591, Total Loss: 1.0176, LR: 0.000060
2025-05-17 04:08:28,495 [INFO] Epoch 13/15 - Policy Loss: 0.8571, Value Loss: 0.1584, Total Loss: 1.0155, LR: 0.001690
2025-05-17 04:09:11,802 [INFO] Epoch 14/15 - Policy Loss: 0.8559, Value Loss: 0.1578, Total Loss: 1.0137, LR: 0.003340
2025-05-17 04:09:55,292 [INFO] Epoch 15/15 - Policy Loss: 0.8554, Value Loss: 0.1574, Total Loss: 1.0128, LR: 0.004990
2025-05-17 04:09:55,314 [INFO] 训练完成，总损失: 1.0128
2025-05-17 04:09:55,314 [INFO] 保存迭代 30 的模型
2025-05-17 04:09:56,758 [INFO] Model saved to ./models/best.pt
2025-05-17 04:09:57,599 [INFO] Model saved to ./models/iteration_30.pt
2025-05-17 04:09:57,600 [INFO] 所有训练迭代完成
2025-05-17 04:09:57,600 [INFO] 开始迭代 31/300
2025-05-17 04:09:57,600 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 04:25:57,598 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 04:25:57,599 [INFO] 保存训练样本
2025-05-17 04:26:02,355 [INFO] 使用 169008 个样本训练神经网络
2025-05-17 04:26:02,355 [INFO] Training with 169008 examples
2025-05-17 04:26:02,355 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 04:26:02,408 [INFO] 循环学习率周期大小: 495 步
2025-05-17 04:26:45,688 [INFO] Epoch 1/15 - Policy Loss: 0.8837, Value Loss: 0.1685, Total Loss: 1.0521, LR: 0.001690
2025-05-17 04:27:29,154 [INFO] Epoch 2/15 - Policy Loss: 0.8761, Value Loss: 0.1663, Total Loss: 1.0424, LR: 0.003340
2025-05-17 04:28:12,665 [INFO] Epoch 3/15 - Policy Loss: 0.8743, Value Loss: 0.1644, Total Loss: 1.0386, LR: 0.004990
2025-05-17 04:28:56,205 [INFO] Epoch 4/15 - Policy Loss: 0.8732, Value Loss: 0.1633, Total Loss: 1.0365, LR: 0.003360
2025-05-17 04:29:39,769 [INFO] Epoch 5/15 - Policy Loss: 0.8689, Value Loss: 0.1618, Total Loss: 1.0307, LR: 0.001710
2025-05-17 04:30:23,605 [INFO] Epoch 6/15 - Policy Loss: 0.8649, Value Loss: 0.1600, Total Loss: 1.0249, LR: 0.000060
2025-05-17 04:31:07,267 [INFO] Epoch 7/15 - Policy Loss: 0.8614, Value Loss: 0.1591, Total Loss: 1.0204, LR: 0.001690
2025-05-17 04:31:51,047 [INFO] Epoch 8/15 - Policy Loss: 0.8596, Value Loss: 0.1582, Total Loss: 1.0178, LR: 0.003340
2025-05-17 04:32:34,695 [INFO] Epoch 9/15 - Policy Loss: 0.8585, Value Loss: 0.1577, Total Loss: 1.0162, LR: 0.004990
2025-05-17 04:33:18,371 [INFO] Epoch 10/15 - Policy Loss: 0.8584, Value Loss: 0.1572, Total Loss: 1.0157, LR: 0.003360
2025-05-17 04:34:02,325 [INFO] Epoch 11/15 - Policy Loss: 0.8578, Value Loss: 0.1567, Total Loss: 1.0145, LR: 0.001710
2025-05-17 04:34:46,317 [INFO] Epoch 12/15 - Policy Loss: 0.8566, Value Loss: 0.1564, Total Loss: 1.0130, LR: 0.000060
2025-05-17 04:35:30,145 [INFO] Epoch 13/15 - Policy Loss: 0.8556, Value Loss: 0.1559, Total Loss: 1.0115, LR: 0.001690
2025-05-17 04:36:13,880 [INFO] Epoch 14/15 - Policy Loss: 0.8541, Value Loss: 0.1554, Total Loss: 1.0095, LR: 0.003340
2025-05-17 04:36:57,622 [INFO] Epoch 15/15 - Policy Loss: 0.8534, Value Loss: 0.1551, Total Loss: 1.0085, LR: 0.004990
2025-05-17 04:36:57,640 [INFO] 训练完成，总损失: 1.0085
2025-05-17 04:36:57,640 [INFO] 保存迭代 31 的模型
2025-05-17 04:36:58,841 [INFO] Model saved to ./models/best.pt
2025-05-17 04:36:59,538 [INFO] Model saved to ./models/iteration_31.pt
2025-05-17 04:36:59,539 [INFO] 所有训练迭代完成
2025-05-17 04:36:59,539 [INFO] 开始迭代 32/300
2025-05-17 04:36:59,539 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 04:53:39,728 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 04:53:39,728 [INFO] 保存训练样本
2025-05-17 04:53:45,332 [INFO] 使用 169568 个样本训练神经网络
2025-05-17 04:53:45,333 [INFO] Training with 169568 examples
2025-05-17 04:53:45,333 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 04:53:46,009 [INFO] 循环学习率周期大小: 495 步
2025-05-17 04:54:29,355 [INFO] Epoch 1/15 - Policy Loss: 0.8774, Value Loss: 0.1630, Total Loss: 1.0404, LR: 0.001690
2025-05-17 04:55:12,866 [INFO] Epoch 2/15 - Policy Loss: 0.8687, Value Loss: 0.1595, Total Loss: 1.0282, LR: 0.003340
2025-05-17 04:55:56,575 [INFO] Epoch 3/15 - Policy Loss: 0.8640, Value Loss: 0.1587, Total Loss: 1.0227, LR: 0.004990
2025-05-17 04:56:40,166 [INFO] Epoch 4/15 - Policy Loss: 0.8632, Value Loss: 0.1586, Total Loss: 1.0218, LR: 0.003360
2025-05-17 04:57:23,635 [INFO] Epoch 5/15 - Policy Loss: 0.8614, Value Loss: 0.1579, Total Loss: 1.0193, LR: 0.001710
2025-05-17 04:58:07,355 [INFO] Epoch 6/15 - Policy Loss: 0.8588, Value Loss: 0.1567, Total Loss: 1.0155, LR: 0.000060
2025-05-17 04:58:50,979 [INFO] Epoch 7/15 - Policy Loss: 0.8563, Value Loss: 0.1555, Total Loss: 1.0118, LR: 0.001690
2025-05-17 04:59:34,885 [INFO] Epoch 8/15 - Policy Loss: 0.8538, Value Loss: 0.1547, Total Loss: 1.0085, LR: 0.003340
2025-05-17 05:00:18,862 [INFO] Epoch 9/15 - Policy Loss: 0.8530, Value Loss: 0.1541, Total Loss: 1.0071, LR: 0.004990
2025-05-17 05:01:02,910 [INFO] Epoch 10/15 - Policy Loss: 0.8526, Value Loss: 0.1539, Total Loss: 1.0064, LR: 0.003360
2025-05-17 05:01:46,865 [INFO] Epoch 11/15 - Policy Loss: 0.8515, Value Loss: 0.1534, Total Loss: 1.0049, LR: 0.001710
2025-05-17 05:02:30,870 [INFO] Epoch 12/15 - Policy Loss: 0.8505, Value Loss: 0.1530, Total Loss: 1.0035, LR: 0.000060
2025-05-17 05:03:14,717 [INFO] Epoch 13/15 - Policy Loss: 0.8490, Value Loss: 0.1524, Total Loss: 1.0013, LR: 0.001690
2025-05-17 05:03:58,711 [INFO] Epoch 14/15 - Policy Loss: 0.8479, Value Loss: 0.1519, Total Loss: 0.9998, LR: 0.003340
2025-05-17 05:04:42,613 [INFO] Epoch 15/15 - Policy Loss: 0.8474, Value Loss: 0.1516, Total Loss: 0.9990, LR: 0.004990
2025-05-17 05:04:42,633 [INFO] 训练完成，总损失: 0.9990
2025-05-17 05:04:42,634 [INFO] 保存迭代 32 的模型
2025-05-17 05:04:44,062 [INFO] Model saved to ./models/best.pt
2025-05-17 05:04:44,900 [INFO] Model saved to ./models/iteration_32.pt
2025-05-17 05:04:44,900 [INFO] 所有训练迭代完成
2025-05-17 05:04:44,900 [INFO] 开始迭代 33/300
2025-05-17 05:04:44,900 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 05:20:56,697 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 05:20:56,697 [INFO] 保存训练样本
2025-05-17 05:21:01,297 [INFO] 使用 169384 个样本训练神经网络
2025-05-17 05:21:01,297 [INFO] Training with 169384 examples
2025-05-17 05:21:01,298 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 05:21:01,731 [INFO] 循环学习率周期大小: 495 步
2025-05-17 05:21:45,164 [INFO] Epoch 1/15 - Policy Loss: 0.8697, Value Loss: 0.1525, Total Loss: 1.0222, LR: 0.001690
2025-05-17 05:22:28,538 [INFO] Epoch 2/15 - Policy Loss: 0.8618, Value Loss: 0.1497, Total Loss: 1.0115, LR: 0.003340
2025-05-17 05:23:12,003 [INFO] Epoch 3/15 - Policy Loss: 0.8597, Value Loss: 0.1482, Total Loss: 1.0079, LR: 0.004990
2025-05-17 05:23:55,478 [INFO] Epoch 4/15 - Policy Loss: 0.8580, Value Loss: 0.1474, Total Loss: 1.0054, LR: 0.003360
2025-05-17 05:24:39,224 [INFO] Epoch 5/15 - Policy Loss: 0.8552, Value Loss: 0.1466, Total Loss: 1.0018, LR: 0.001710
2025-05-17 05:25:22,874 [INFO] Epoch 6/15 - Policy Loss: 0.8526, Value Loss: 0.1454, Total Loss: 0.9979, LR: 0.000060
2025-05-17 05:26:06,746 [INFO] Epoch 7/15 - Policy Loss: 0.8499, Value Loss: 0.1447, Total Loss: 0.9946, LR: 0.001690
2025-05-17 05:26:50,492 [INFO] Epoch 8/15 - Policy Loss: 0.8480, Value Loss: 0.1442, Total Loss: 0.9922, LR: 0.003340
2025-05-17 05:27:34,391 [INFO] Epoch 9/15 - Policy Loss: 0.8470, Value Loss: 0.1437, Total Loss: 0.9908, LR: 0.004990
2025-05-17 05:28:18,244 [INFO] Epoch 10/15 - Policy Loss: 0.8477, Value Loss: 0.1437, Total Loss: 0.9914, LR: 0.003360
2025-05-17 05:29:02,332 [INFO] Epoch 11/15 - Policy Loss: 0.8470, Value Loss: 0.1432, Total Loss: 0.9903, LR: 0.001710
2025-05-17 05:29:46,293 [INFO] Epoch 12/15 - Policy Loss: 0.8458, Value Loss: 0.1427, Total Loss: 0.9886, LR: 0.000060
2025-05-17 05:30:30,405 [INFO] Epoch 13/15 - Policy Loss: 0.8448, Value Loss: 0.1424, Total Loss: 0.9872, LR: 0.001690
2025-05-17 05:31:14,904 [INFO] Epoch 14/15 - Policy Loss: 0.8435, Value Loss: 0.1419, Total Loss: 0.9855, LR: 0.003340
2025-05-17 05:31:58,979 [INFO] Epoch 15/15 - Policy Loss: 0.8432, Value Loss: 0.1417, Total Loss: 0.9849, LR: 0.004990
2025-05-17 05:31:59,007 [INFO] 训练完成，总损失: 0.9849
2025-05-17 05:31:59,007 [INFO] 保存迭代 33 的模型
2025-05-17 05:32:00,494 [INFO] Model saved to ./models/best.pt
2025-05-17 05:32:01,368 [INFO] Model saved to ./models/iteration_33.pt
2025-05-17 05:32:01,368 [INFO] 所有训练迭代完成
2025-05-17 05:32:01,368 [INFO] 开始迭代 34/300
2025-05-17 05:32:01,368 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 05:47:39,105 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 05:47:39,105 [INFO] 保存训练样本
2025-05-17 05:47:43,440 [INFO] 使用 169632 个样本训练神经网络
2025-05-17 05:47:43,440 [INFO] Training with 169632 examples
2025-05-17 05:47:43,441 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 05:47:43,796 [INFO] 循环学习率周期大小: 495 步
2025-05-17 05:48:27,196 [INFO] Epoch 1/15 - Policy Loss: 0.8583, Value Loss: 0.1597, Total Loss: 1.0180, LR: 0.001690
2025-05-17 05:49:10,411 [INFO] Epoch 2/15 - Policy Loss: 0.8540, Value Loss: 0.1582, Total Loss: 1.0122, LR: 0.003340
2025-05-17 05:49:53,743 [INFO] Epoch 3/15 - Policy Loss: 0.8522, Value Loss: 0.1565, Total Loss: 1.0086, LR: 0.004990
2025-05-17 05:50:37,262 [INFO] Epoch 4/15 - Policy Loss: 0.8532, Value Loss: 0.1564, Total Loss: 1.0096, LR: 0.003360
2025-05-17 05:51:20,964 [INFO] Epoch 5/15 - Policy Loss: 0.8517, Value Loss: 0.1543, Total Loss: 1.0060, LR: 0.001710
2025-05-17 05:52:04,734 [INFO] Epoch 6/15 - Policy Loss: 0.8486, Value Loss: 0.1529, Total Loss: 1.0015, LR: 0.000060
2025-05-17 05:52:48,402 [INFO] Epoch 7/15 - Policy Loss: 0.8464, Value Loss: 0.1518, Total Loss: 0.9982, LR: 0.001690
2025-05-17 05:53:32,003 [INFO] Epoch 8/15 - Policy Loss: 0.8452, Value Loss: 0.1510, Total Loss: 0.9962, LR: 0.003340
2025-05-17 05:54:16,164 [INFO] Epoch 9/15 - Policy Loss: 0.8442, Value Loss: 0.1503, Total Loss: 0.9944, LR: 0.004990
2025-05-17 05:54:59,875 [INFO] Epoch 10/15 - Policy Loss: 0.8438, Value Loss: 0.1499, Total Loss: 0.9937, LR: 0.003360
2025-05-17 05:55:43,759 [INFO] Epoch 11/15 - Policy Loss: 0.8435, Value Loss: 0.1494, Total Loss: 0.9929, LR: 0.001710
2025-05-17 05:56:27,400 [INFO] Epoch 12/15 - Policy Loss: 0.8424, Value Loss: 0.1486, Total Loss: 0.9910, LR: 0.000060
2025-05-17 05:57:11,292 [INFO] Epoch 13/15 - Policy Loss: 0.8413, Value Loss: 0.1480, Total Loss: 0.9893, LR: 0.001690
2025-05-17 05:57:55,010 [INFO] Epoch 14/15 - Policy Loss: 0.8403, Value Loss: 0.1474, Total Loss: 0.9877, LR: 0.003340
2025-05-17 05:58:38,877 [INFO] Epoch 15/15 - Policy Loss: 0.8398, Value Loss: 0.1471, Total Loss: 0.9869, LR: 0.004990
2025-05-17 05:58:38,896 [INFO] 训练完成，总损失: 0.9869
2025-05-17 05:58:38,896 [INFO] 保存迭代 34 的模型
2025-05-17 05:58:40,089 [INFO] Model saved to ./models/best.pt
2025-05-17 05:58:40,752 [INFO] Model saved to ./models/iteration_34.pt
2025-05-17 05:58:40,752 [INFO] 所有训练迭代完成
2025-05-17 05:58:40,752 [INFO] 开始迭代 35/300
2025-05-17 05:58:40,752 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 06:14:06,409 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 06:14:06,409 [INFO] 保存训练样本
2025-05-17 06:14:12,138 [INFO] 使用 169392 个样本训练神经网络
2025-05-17 06:14:12,138 [INFO] Training with 169392 examples
2025-05-17 06:14:12,139 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 06:14:12,210 [INFO] 循环学习率周期大小: 495 步
2025-05-17 06:14:55,708 [INFO] Epoch 1/15 - Policy Loss: 0.8562, Value Loss: 0.1499, Total Loss: 1.0061, LR: 0.001690
2025-05-17 06:15:39,698 [INFO] Epoch 2/15 - Policy Loss: 0.8514, Value Loss: 0.1474, Total Loss: 0.9988, LR: 0.003340
2025-05-17 06:16:23,176 [INFO] Epoch 3/15 - Policy Loss: 0.8483, Value Loss: 0.1465, Total Loss: 0.9948, LR: 0.004990
2025-05-17 06:17:06,701 [INFO] Epoch 4/15 - Policy Loss: 0.8487, Value Loss: 0.1462, Total Loss: 0.9950, LR: 0.003360
2025-05-17 06:17:50,217 [INFO] Epoch 5/15 - Policy Loss: 0.8465, Value Loss: 0.1456, Total Loss: 0.9921, LR: 0.001710
2025-05-17 06:18:33,997 [INFO] Epoch 6/15 - Policy Loss: 0.8437, Value Loss: 0.1448, Total Loss: 0.9884, LR: 0.000060
2025-05-17 06:19:17,893 [INFO] Epoch 7/15 - Policy Loss: 0.8406, Value Loss: 0.1438, Total Loss: 0.9844, LR: 0.001690
2025-05-17 06:20:01,926 [INFO] Epoch 8/15 - Policy Loss: 0.8385, Value Loss: 0.1429, Total Loss: 0.9814, LR: 0.003340
2025-05-17 06:20:45,871 [INFO] Epoch 9/15 - Policy Loss: 0.8373, Value Loss: 0.1426, Total Loss: 0.9799, LR: 0.004990
2025-05-17 06:21:29,887 [INFO] Epoch 10/15 - Policy Loss: 0.8376, Value Loss: 0.1424, Total Loss: 0.9800, LR: 0.003360
2025-05-17 06:22:13,839 [INFO] Epoch 11/15 - Policy Loss: 0.8367, Value Loss: 0.1420, Total Loss: 0.9787, LR: 0.001710
2025-05-17 06:22:57,854 [INFO] Epoch 12/15 - Policy Loss: 0.8355, Value Loss: 0.1415, Total Loss: 0.9770, LR: 0.000060
2025-05-17 06:23:41,965 [INFO] Epoch 13/15 - Policy Loss: 0.8343, Value Loss: 0.1411, Total Loss: 0.9754, LR: 0.001690
2025-05-17 06:24:25,847 [INFO] Epoch 14/15 - Policy Loss: 0.8336, Value Loss: 0.1410, Total Loss: 0.9746, LR: 0.003340
2025-05-17 06:25:10,016 [INFO] Epoch 15/15 - Policy Loss: 0.8330, Value Loss: 0.1408, Total Loss: 0.9738, LR: 0.004990
2025-05-17 06:25:10,045 [INFO] 训练完成，总损失: 0.9738
2025-05-17 06:25:10,045 [INFO] 保存迭代 35 的模型
2025-05-17 06:25:11,535 [INFO] Model saved to ./models/best.pt
2025-05-17 06:25:12,432 [INFO] Model saved to ./models/iteration_35.pt
2025-05-17 06:25:12,432 [INFO] 所有训练迭代完成
2025-05-17 06:25:12,432 [INFO] 开始迭代 36/300
2025-05-17 06:25:12,432 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 06:42:14,267 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 06:42:14,267 [INFO] 保存训练样本
2025-05-17 06:42:19,590 [INFO] 使用 170432 个样本训练神经网络
2025-05-17 06:42:19,590 [INFO] Training with 170432 examples
2025-05-17 06:42:19,591 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 06:42:20,070 [INFO] 循环学习率周期大小: 498 步
2025-05-17 06:43:03,814 [INFO] Epoch 1/15 - Policy Loss: 0.8643, Value Loss: 0.1509, Total Loss: 1.0152, LR: 0.001690
2025-05-17 06:43:47,781 [INFO] Epoch 2/15 - Policy Loss: 0.8569, Value Loss: 0.1475, Total Loss: 1.0044, LR: 0.003340
2025-05-17 06:44:31,804 [INFO] Epoch 3/15 - Policy Loss: 0.8529, Value Loss: 0.1475, Total Loss: 1.0004, LR: 0.004990
2025-05-17 06:45:15,852 [INFO] Epoch 4/15 - Policy Loss: 0.8518, Value Loss: 0.1474, Total Loss: 0.9992, LR: 0.003360
2025-05-17 06:45:59,777 [INFO] Epoch 5/15 - Policy Loss: 0.8484, Value Loss: 0.1461, Total Loss: 0.9946, LR: 0.001710
2025-05-17 06:46:43,743 [INFO] Epoch 6/15 - Policy Loss: 0.8443, Value Loss: 0.1441, Total Loss: 0.9884, LR: 0.000060
2025-05-17 06:47:27,698 [INFO] Epoch 7/15 - Policy Loss: 0.8408, Value Loss: 0.1430, Total Loss: 0.9838, LR: 0.001690
2025-05-17 06:48:11,849 [INFO] Epoch 8/15 - Policy Loss: 0.8383, Value Loss: 0.1420, Total Loss: 0.9803, LR: 0.003340
2025-05-17 06:48:55,926 [INFO] Epoch 9/15 - Policy Loss: 0.8368, Value Loss: 0.1412, Total Loss: 0.9779, LR: 0.004990
2025-05-17 06:49:40,226 [INFO] Epoch 10/15 - Policy Loss: 0.8363, Value Loss: 0.1407, Total Loss: 0.9769, LR: 0.003360
2025-05-17 06:50:24,325 [INFO] Epoch 11/15 - Policy Loss: 0.8352, Value Loss: 0.1402, Total Loss: 0.9754, LR: 0.001710
2025-05-17 06:51:08,674 [INFO] Epoch 12/15 - Policy Loss: 0.8338, Value Loss: 0.1397, Total Loss: 0.9735, LR: 0.000060
2025-05-17 06:51:53,469 [INFO] Epoch 13/15 - Policy Loss: 0.8327, Value Loss: 0.1393, Total Loss: 0.9720, LR: 0.001690
2025-05-17 06:52:37,877 [INFO] Epoch 14/15 - Policy Loss: 0.8314, Value Loss: 0.1388, Total Loss: 0.9702, LR: 0.003340
2025-05-17 06:53:22,286 [INFO] Epoch 15/15 - Policy Loss: 0.8306, Value Loss: 0.1385, Total Loss: 0.9691, LR: 0.004990
2025-05-17 06:53:22,314 [INFO] 训练完成，总损失: 0.9691
2025-05-17 06:53:22,315 [INFO] 保存迭代 36 的模型
2025-05-17 06:53:23,906 [INFO] Model saved to ./models/best.pt
2025-05-17 06:53:24,772 [INFO] Model saved to ./models/iteration_36.pt
2025-05-17 06:53:24,772 [INFO] 所有训练迭代完成
2025-05-17 06:53:24,772 [INFO] 开始迭代 37/300
2025-05-17 06:53:24,772 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 07:10:17,078 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 07:10:17,078 [INFO] 保存训练样本
2025-05-17 07:10:21,670 [INFO] 使用 170048 个样本训练神经网络
2025-05-17 07:10:21,671 [INFO] Training with 170048 examples
2025-05-17 07:10:21,671 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 07:10:22,158 [INFO] 循环学习率周期大小: 498 步
2025-05-17 07:11:05,667 [INFO] Epoch 1/15 - Policy Loss: 0.8554, Value Loss: 0.1446, Total Loss: 0.9999, LR: 0.001690
2025-05-17 07:11:49,275 [INFO] Epoch 2/15 - Policy Loss: 0.8513, Value Loss: 0.1412, Total Loss: 0.9925, LR: 0.003340
2025-05-17 07:12:33,149 [INFO] Epoch 3/15 - Policy Loss: 0.8474, Value Loss: 0.1400, Total Loss: 0.9874, LR: 0.004990
2025-05-17 07:13:16,756 [INFO] Epoch 4/15 - Policy Loss: 0.8464, Value Loss: 0.1397, Total Loss: 0.9861, LR: 0.003360
2025-05-17 07:14:00,779 [INFO] Epoch 5/15 - Policy Loss: 0.8437, Value Loss: 0.1386, Total Loss: 0.9823, LR: 0.001710
2025-05-17 07:14:44,867 [INFO] Epoch 6/15 - Policy Loss: 0.8401, Value Loss: 0.1373, Total Loss: 0.9774, LR: 0.000060
2025-05-17 07:15:29,042 [INFO] Epoch 7/15 - Policy Loss: 0.8375, Value Loss: 0.1362, Total Loss: 0.9737, LR: 0.001690
2025-05-17 07:16:13,503 [INFO] Epoch 8/15 - Policy Loss: 0.8351, Value Loss: 0.1357, Total Loss: 0.9707, LR: 0.003340
2025-05-17 07:16:57,632 [INFO] Epoch 9/15 - Policy Loss: 0.8344, Value Loss: 0.1356, Total Loss: 0.9701, LR: 0.004990
2025-05-17 07:17:41,618 [INFO] Epoch 10/15 - Policy Loss: 0.8351, Value Loss: 0.1354, Total Loss: 0.9705, LR: 0.003360
2025-05-17 07:18:25,929 [INFO] Epoch 11/15 - Policy Loss: 0.8339, Value Loss: 0.1350, Total Loss: 0.9689, LR: 0.001710
2025-05-17 07:19:10,117 [INFO] Epoch 12/15 - Policy Loss: 0.8326, Value Loss: 0.1349, Total Loss: 0.9674, LR: 0.000060
2025-05-17 07:19:54,238 [INFO] Epoch 13/15 - Policy Loss: 0.8312, Value Loss: 0.1345, Total Loss: 0.9657, LR: 0.001690
2025-05-17 07:20:38,320 [INFO] Epoch 14/15 - Policy Loss: 0.8299, Value Loss: 0.1341, Total Loss: 0.9639, LR: 0.003340
2025-05-17 07:21:22,444 [INFO] Epoch 15/15 - Policy Loss: 0.8295, Value Loss: 0.1337, Total Loss: 0.9633, LR: 0.004990
2025-05-17 07:21:22,465 [INFO] 训练完成，总损失: 0.9633
2025-05-17 07:21:22,465 [INFO] 保存迭代 37 的模型
2025-05-17 07:21:23,900 [INFO] Model saved to ./models/best.pt
2025-05-17 07:21:24,735 [INFO] Model saved to ./models/iteration_37.pt
2025-05-17 07:21:24,735 [INFO] 所有训练迭代完成
2025-05-17 07:21:24,735 [INFO] 开始迭代 38/300
2025-05-17 07:21:24,735 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 07:36:55,507 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 07:36:55,507 [INFO] 保存训练样本
2025-05-17 07:37:00,211 [INFO] 使用 170240 个样本训练神经网络
2025-05-17 07:37:00,212 [INFO] Training with 170240 examples
2025-05-17 07:37:00,212 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 07:37:00,262 [INFO] 循环学习率周期大小: 498 步
2025-05-17 07:37:43,919 [INFO] Epoch 1/15 - Policy Loss: 0.8571, Value Loss: 0.1442, Total Loss: 1.0013, LR: 0.001690
2025-05-17 07:38:28,221 [INFO] Epoch 2/15 - Policy Loss: 0.8471, Value Loss: 0.1420, Total Loss: 0.9890, LR: 0.003340
2025-05-17 07:39:12,172 [INFO] Epoch 3/15 - Policy Loss: 0.8454, Value Loss: 0.1411, Total Loss: 0.9865, LR: 0.004990
2025-05-17 07:39:56,052 [INFO] Epoch 4/15 - Policy Loss: 0.8430, Value Loss: 0.1406, Total Loss: 0.9836, LR: 0.003360
2025-05-17 07:40:39,815 [INFO] Epoch 5/15 - Policy Loss: 0.8407, Value Loss: 0.1392, Total Loss: 0.9800, LR: 0.001710
2025-05-17 07:41:23,915 [INFO] Epoch 6/15 - Policy Loss: 0.8370, Value Loss: 0.1378, Total Loss: 0.9748, LR: 0.000060
2025-05-17 07:42:07,897 [INFO] Epoch 7/15 - Policy Loss: 0.8345, Value Loss: 0.1367, Total Loss: 0.9712, LR: 0.001690
2025-05-17 07:42:52,177 [INFO] Epoch 8/15 - Policy Loss: 0.8319, Value Loss: 0.1358, Total Loss: 0.9678, LR: 0.003340
2025-05-17 07:43:36,324 [INFO] Epoch 9/15 - Policy Loss: 0.8309, Value Loss: 0.1354, Total Loss: 0.9664, LR: 0.004990
2025-05-17 07:44:20,737 [INFO] Epoch 10/15 - Policy Loss: 0.8307, Value Loss: 0.1353, Total Loss: 0.9660, LR: 0.003360
2025-05-17 07:45:04,962 [INFO] Epoch 11/15 - Policy Loss: 0.8301, Value Loss: 0.1349, Total Loss: 0.9650, LR: 0.001710
2025-05-17 07:45:49,223 [INFO] Epoch 12/15 - Policy Loss: 0.8291, Value Loss: 0.1344, Total Loss: 0.9634, LR: 0.000060
2025-05-17 07:46:33,386 [INFO] Epoch 13/15 - Policy Loss: 0.8279, Value Loss: 0.1339, Total Loss: 0.9618, LR: 0.001690
2025-05-17 07:47:17,741 [INFO] Epoch 14/15 - Policy Loss: 0.8267, Value Loss: 0.1336, Total Loss: 0.9603, LR: 0.003340
2025-05-17 07:48:01,832 [INFO] Epoch 15/15 - Policy Loss: 0.8262, Value Loss: 0.1334, Total Loss: 0.9596, LR: 0.004990
2025-05-17 07:48:01,865 [INFO] 训练完成，总损失: 0.9596
2025-05-17 07:48:01,866 [INFO] 保存迭代 38 的模型
2025-05-17 07:48:03,125 [INFO] Model saved to ./models/best.pt
2025-05-17 07:48:03,853 [INFO] Model saved to ./models/iteration_38.pt
2025-05-17 07:48:03,854 [INFO] 所有训练迭代完成
2025-05-17 07:48:03,854 [INFO] 开始迭代 39/300
2025-05-17 07:48:03,854 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 08:03:48,049 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 08:03:48,050 [INFO] 保存训练样本
2025-05-17 08:03:53,479 [INFO] 使用 170360 个样本训练神经网络
2025-05-17 08:03:53,479 [INFO] Training with 170360 examples
2025-05-17 08:03:53,480 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 08:03:53,946 [INFO] 循环学习率周期大小: 498 步
2025-05-17 08:04:37,620 [INFO] Epoch 1/15 - Policy Loss: 0.8510, Value Loss: 0.1374, Total Loss: 0.9884, LR: 0.001690
2025-05-17 08:05:21,371 [INFO] Epoch 2/15 - Policy Loss: 0.8429, Value Loss: 0.1362, Total Loss: 0.9791, LR: 0.003340
2025-05-17 08:06:04,930 [INFO] Epoch 3/15 - Policy Loss: 0.8395, Value Loss: 0.1356, Total Loss: 0.9751, LR: 0.004990
2025-05-17 08:06:48,508 [INFO] Epoch 4/15 - Policy Loss: 0.8380, Value Loss: 0.1353, Total Loss: 0.9733, LR: 0.003360
2025-05-17 08:07:32,427 [INFO] Epoch 5/15 - Policy Loss: 0.8356, Value Loss: 0.1350, Total Loss: 0.9706, LR: 0.001710
2025-05-17 08:08:16,419 [INFO] Epoch 6/15 - Policy Loss: 0.8325, Value Loss: 0.1342, Total Loss: 0.9667, LR: 0.000060
2025-05-17 08:09:00,518 [INFO] Epoch 7/15 - Policy Loss: 0.8298, Value Loss: 0.1330, Total Loss: 0.9628, LR: 0.001690
2025-05-17 08:09:44,586 [INFO] Epoch 8/15 - Policy Loss: 0.8277, Value Loss: 0.1325, Total Loss: 0.9602, LR: 0.003340
2025-05-17 08:10:28,802 [INFO] Epoch 9/15 - Policy Loss: 0.8271, Value Loss: 0.1321, Total Loss: 0.9593, LR: 0.004990
2025-05-17 08:11:13,026 [INFO] Epoch 10/15 - Policy Loss: 0.8276, Value Loss: 0.1318, Total Loss: 0.9594, LR: 0.003360
2025-05-17 08:11:57,248 [INFO] Epoch 11/15 - Policy Loss: 0.8270, Value Loss: 0.1314, Total Loss: 0.9584, LR: 0.001710
2025-05-17 08:12:41,522 [INFO] Epoch 12/15 - Policy Loss: 0.8257, Value Loss: 0.1309, Total Loss: 0.9567, LR: 0.000060
2025-05-17 08:13:26,308 [INFO] Epoch 13/15 - Policy Loss: 0.8241, Value Loss: 0.1305, Total Loss: 0.9545, LR: 0.001690
2025-05-17 08:14:10,589 [INFO] Epoch 14/15 - Policy Loss: 0.8229, Value Loss: 0.1301, Total Loss: 0.9530, LR: 0.003340
2025-05-17 08:14:54,901 [INFO] Epoch 15/15 - Policy Loss: 0.8224, Value Loss: 0.1298, Total Loss: 0.9522, LR: 0.004990
2025-05-17 08:14:54,929 [INFO] 训练完成，总损失: 0.9522
2025-05-17 08:14:54,929 [INFO] 保存迭代 39 的模型
2025-05-17 08:14:56,409 [INFO] Model saved to ./models/best.pt
2025-05-17 08:14:57,274 [INFO] Model saved to ./models/iteration_39.pt
2025-05-17 08:14:57,274 [INFO] 所有训练迭代完成
2025-05-17 08:14:57,274 [INFO] 开始迭代 40/300
2025-05-17 08:14:57,274 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 08:31:05,518 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 08:31:05,519 [INFO] 保存训练样本
2025-05-17 08:31:10,283 [INFO] 使用 170496 个样本训练神经网络
2025-05-17 08:31:10,283 [INFO] Training with 170496 examples
2025-05-17 08:31:10,284 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 08:31:10,735 [INFO] 循环学习率周期大小: 498 步
2025-05-17 08:31:54,232 [INFO] Epoch 1/15 - Policy Loss: 0.8364, Value Loss: 0.1328, Total Loss: 0.9692, LR: 0.001690
2025-05-17 08:32:37,820 [INFO] Epoch 2/15 - Policy Loss: 0.8344, Value Loss: 0.1317, Total Loss: 0.9661, LR: 0.003340
2025-05-17 08:33:21,466 [INFO] Epoch 3/15 - Policy Loss: 0.8346, Value Loss: 0.1311, Total Loss: 0.9657, LR: 0.004990
2025-05-17 08:34:05,225 [INFO] Epoch 4/15 - Policy Loss: 0.8331, Value Loss: 0.1307, Total Loss: 0.9637, LR: 0.003360
2025-05-17 08:34:49,313 [INFO] Epoch 5/15 - Policy Loss: 0.8295, Value Loss: 0.1295, Total Loss: 0.9590, LR: 0.001710
2025-05-17 08:35:33,250 [INFO] Epoch 6/15 - Policy Loss: 0.8265, Value Loss: 0.1290, Total Loss: 0.9555, LR: 0.000060
2025-05-17 08:36:17,415 [INFO] Epoch 7/15 - Policy Loss: 0.8239, Value Loss: 0.1285, Total Loss: 0.9524, LR: 0.001690
2025-05-17 08:37:02,081 [INFO] Epoch 8/15 - Policy Loss: 0.8223, Value Loss: 0.1282, Total Loss: 0.9505, LR: 0.003340
2025-05-17 08:37:46,157 [INFO] Epoch 9/15 - Policy Loss: 0.8212, Value Loss: 0.1278, Total Loss: 0.9490, LR: 0.004990
2025-05-17 08:38:30,318 [INFO] Epoch 10/15 - Policy Loss: 0.8216, Value Loss: 0.1276, Total Loss: 0.9492, LR: 0.003360
2025-05-17 08:39:14,585 [INFO] Epoch 11/15 - Policy Loss: 0.8212, Value Loss: 0.1275, Total Loss: 0.9488, LR: 0.001710
2025-05-17 08:39:58,789 [INFO] Epoch 12/15 - Policy Loss: 0.8201, Value Loss: 0.1273, Total Loss: 0.9474, LR: 0.000060
2025-05-17 08:40:43,055 [INFO] Epoch 13/15 - Policy Loss: 0.8188, Value Loss: 0.1270, Total Loss: 0.9458, LR: 0.001690
2025-05-17 08:41:27,268 [INFO] Epoch 14/15 - Policy Loss: 0.8178, Value Loss: 0.1267, Total Loss: 0.9445, LR: 0.003340
2025-05-17 08:42:11,477 [INFO] Epoch 15/15 - Policy Loss: 0.8172, Value Loss: 0.1265, Total Loss: 0.9437, LR: 0.004990
2025-05-17 08:42:11,498 [INFO] 训练完成，总损失: 0.9437
2025-05-17 08:42:11,498 [INFO] 保存迭代 40 的模型
2025-05-17 08:42:12,909 [INFO] Model saved to ./models/best.pt
2025-05-17 08:42:13,740 [INFO] Model saved to ./models/iteration_40.pt
2025-05-17 08:42:13,740 [INFO] 所有训练迭代完成
2025-05-17 08:42:13,740 [INFO] 开始迭代 41/300
2025-05-17 08:42:13,740 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 08:57:49,641 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 08:57:49,641 [INFO] 保存训练样本
2025-05-17 08:57:54,970 [INFO] 使用 170776 个样本训练神经网络
2025-05-17 08:57:54,970 [INFO] Training with 170776 examples
2025-05-17 08:57:54,971 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 08:57:55,032 [INFO] 循环学习率周期大小: 498 步
2025-05-17 08:58:38,752 [INFO] Epoch 1/15 - Policy Loss: 0.8325, Value Loss: 0.1411, Total Loss: 0.9736, LR: 0.001690
2025-05-17 08:59:22,452 [INFO] Epoch 2/15 - Policy Loss: 0.8292, Value Loss: 0.1381, Total Loss: 0.9673, LR: 0.003340
2025-05-17 09:00:06,939 [INFO] Epoch 3/15 - Policy Loss: 0.8282, Value Loss: 0.1369, Total Loss: 0.9651, LR: 0.004990
2025-05-17 09:00:50,931 [INFO] Epoch 4/15 - Policy Loss: 0.8269, Value Loss: 0.1365, Total Loss: 0.9634, LR: 0.003360
2025-05-17 09:01:35,063 [INFO] Epoch 5/15 - Policy Loss: 0.8244, Value Loss: 0.1356, Total Loss: 0.9600, LR: 0.001710
2025-05-17 09:02:19,043 [INFO] Epoch 6/15 - Policy Loss: 0.8212, Value Loss: 0.1345, Total Loss: 0.9557, LR: 0.000060
2025-05-17 09:03:03,235 [INFO] Epoch 7/15 - Policy Loss: 0.8188, Value Loss: 0.1334, Total Loss: 0.9522, LR: 0.001690
2025-05-17 09:03:47,467 [INFO] Epoch 8/15 - Policy Loss: 0.8170, Value Loss: 0.1326, Total Loss: 0.9496, LR: 0.003340
2025-05-17 09:04:31,653 [INFO] Epoch 9/15 - Policy Loss: 0.8161, Value Loss: 0.1318, Total Loss: 0.9479, LR: 0.004990
2025-05-17 09:05:15,834 [INFO] Epoch 10/15 - Policy Loss: 0.8160, Value Loss: 0.1316, Total Loss: 0.9476, LR: 0.003360
2025-05-17 09:06:00,002 [INFO] Epoch 11/15 - Policy Loss: 0.8155, Value Loss: 0.1312, Total Loss: 0.9467, LR: 0.001710
2025-05-17 09:06:44,117 [INFO] Epoch 12/15 - Policy Loss: 0.8145, Value Loss: 0.1307, Total Loss: 0.9452, LR: 0.000060
2025-05-17 09:07:28,242 [INFO] Epoch 13/15 - Policy Loss: 0.8135, Value Loss: 0.1304, Total Loss: 0.9439, LR: 0.001690
2025-05-17 09:08:12,184 [INFO] Epoch 14/15 - Policy Loss: 0.8125, Value Loss: 0.1302, Total Loss: 0.9426, LR: 0.003340
2025-05-17 09:08:56,424 [INFO] Epoch 15/15 - Policy Loss: 0.8122, Value Loss: 0.1299, Total Loss: 0.9421, LR: 0.004990
2025-05-17 09:08:56,445 [INFO] 训练完成，总损失: 0.9421
2025-05-17 09:08:56,445 [INFO] 保存迭代 41 的模型
2025-05-17 09:08:57,954 [INFO] Model saved to ./models/best.pt
2025-05-17 09:08:58,806 [INFO] Model saved to ./models/iteration_41.pt
2025-05-17 09:08:58,807 [INFO] 所有训练迭代完成
2025-05-17 09:08:58,807 [INFO] 开始迭代 42/300
2025-05-17 09:08:58,807 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 09:24:30,757 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 09:24:30,757 [INFO] 保存训练样本
2025-05-17 09:24:36,089 [INFO] 使用 170432 个样本训练神经网络
2025-05-17 09:24:36,089 [INFO] Training with 170432 examples
2025-05-17 09:24:36,090 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 09:24:36,547 [INFO] 循环学习率周期大小: 498 步
2025-05-17 09:25:20,325 [INFO] Epoch 1/15 - Policy Loss: 0.8334, Value Loss: 0.1454, Total Loss: 0.9789, LR: 0.001690
2025-05-17 09:26:04,072 [INFO] Epoch 2/15 - Policy Loss: 0.8265, Value Loss: 0.1411, Total Loss: 0.9676, LR: 0.003340
2025-05-17 09:26:47,820 [INFO] Epoch 3/15 - Policy Loss: 0.8242, Value Loss: 0.1397, Total Loss: 0.9639, LR: 0.004990
2025-05-17 09:27:31,670 [INFO] Epoch 4/15 - Policy Loss: 0.8241, Value Loss: 0.1387, Total Loss: 0.9627, LR: 0.003360
2025-05-17 09:28:15,690 [INFO] Epoch 5/15 - Policy Loss: 0.8229, Value Loss: 0.1375, Total Loss: 0.9604, LR: 0.001710
2025-05-17 09:28:59,628 [INFO] Epoch 6/15 - Policy Loss: 0.8202, Value Loss: 0.1362, Total Loss: 0.9564, LR: 0.000060
2025-05-17 09:29:43,697 [INFO] Epoch 7/15 - Policy Loss: 0.8183, Value Loss: 0.1351, Total Loss: 0.9534, LR: 0.001690
2025-05-17 09:30:27,825 [INFO] Epoch 8/15 - Policy Loss: 0.8162, Value Loss: 0.1344, Total Loss: 0.9506, LR: 0.003340
2025-05-17 09:31:12,107 [INFO] Epoch 9/15 - Policy Loss: 0.8149, Value Loss: 0.1339, Total Loss: 0.9487, LR: 0.004990
2025-05-17 09:31:56,031 [INFO] Epoch 10/15 - Policy Loss: 0.8145, Value Loss: 0.1335, Total Loss: 0.9480, LR: 0.003360
2025-05-17 09:32:39,953 [INFO] Epoch 11/15 - Policy Loss: 0.8135, Value Loss: 0.1329, Total Loss: 0.9464, LR: 0.001710
2025-05-17 09:33:23,774 [INFO] Epoch 12/15 - Policy Loss: 0.8126, Value Loss: 0.1323, Total Loss: 0.9449, LR: 0.000060
2025-05-17 09:34:07,992 [INFO] Epoch 13/15 - Policy Loss: 0.8114, Value Loss: 0.1320, Total Loss: 0.9434, LR: 0.001690
2025-05-17 09:34:52,276 [INFO] Epoch 14/15 - Policy Loss: 0.8105, Value Loss: 0.1318, Total Loss: 0.9423, LR: 0.003340
2025-05-17 09:35:36,876 [INFO] Epoch 15/15 - Policy Loss: 0.8101, Value Loss: 0.1314, Total Loss: 0.9415, LR: 0.004990
2025-05-17 09:35:36,904 [INFO] 训练完成，总损失: 0.9415
2025-05-17 09:35:36,904 [INFO] 保存迭代 42 的模型
2025-05-17 09:35:38,369 [INFO] Model saved to ./models/best.pt
2025-05-17 09:35:39,219 [INFO] Model saved to ./models/iteration_42.pt
2025-05-17 09:35:39,220 [INFO] 所有训练迭代完成
2025-05-17 09:35:39,220 [INFO] 开始迭代 43/300
2025-05-17 09:35:39,220 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 09:53:01,480 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 09:53:01,481 [INFO] 保存训练样本
2025-05-17 09:53:06,597 [INFO] 使用 170704 个样本训练神经网络
2025-05-17 09:53:06,597 [INFO] Training with 170704 examples
2025-05-17 09:53:06,598 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 09:53:07,026 [INFO] 循环学习率周期大小: 498 步
2025-05-17 09:54:32,873 [INFO] Epoch 1/15 - Policy Loss: 0.8269, Value Loss: 0.1437, Total Loss: 0.9706, LR: 0.001690
2025-05-17 09:56:02,722 [INFO] Epoch 2/15 - Policy Loss: 0.8216, Value Loss: 0.1405, Total Loss: 0.9621, LR: 0.003340
2025-05-17 09:57:23,165 [INFO] Epoch 3/15 - Policy Loss: 0.8210, Value Loss: 0.1403, Total Loss: 0.9612, LR: 0.004990
2025-05-17 09:58:45,946 [INFO] Epoch 4/15 - Policy Loss: 0.8195, Value Loss: 0.1395, Total Loss: 0.9589, LR: 0.003360
2025-05-17 10:00:06,862 [INFO] Epoch 5/15 - Policy Loss: 0.8177, Value Loss: 0.1381, Total Loss: 0.9558, LR: 0.001710
2025-05-17 10:01:23,873 [INFO] Epoch 6/15 - Policy Loss: 0.8138, Value Loss: 0.1372, Total Loss: 0.9509, LR: 0.000060
2025-05-17 10:02:45,684 [INFO] Epoch 7/15 - Policy Loss: 0.8111, Value Loss: 0.1362, Total Loss: 0.9474, LR: 0.001690
2025-05-17 10:04:04,055 [INFO] Epoch 8/15 - Policy Loss: 0.8089, Value Loss: 0.1356, Total Loss: 0.9444, LR: 0.003340
2025-05-17 10:05:26,631 [INFO] Epoch 9/15 - Policy Loss: 0.8082, Value Loss: 0.1352, Total Loss: 0.9434, LR: 0.004990
2025-05-17 10:06:48,107 [INFO] Epoch 10/15 - Policy Loss: 0.8072, Value Loss: 0.1346, Total Loss: 0.9418, LR: 0.003360
2025-05-17 10:08:08,840 [INFO] Epoch 11/15 - Policy Loss: 0.8061, Value Loss: 0.1341, Total Loss: 0.9402, LR: 0.001710
2025-05-17 10:09:24,102 [INFO] Epoch 12/15 - Policy Loss: 0.8049, Value Loss: 0.1337, Total Loss: 0.9386, LR: 0.000060
2025-05-17 10:10:59,882 [INFO] Epoch 13/15 - Policy Loss: 0.8040, Value Loss: 0.1334, Total Loss: 0.9375, LR: 0.001690
2025-05-17 10:12:28,155 [INFO] Epoch 14/15 - Policy Loss: 0.8029, Value Loss: 0.1330, Total Loss: 0.9359, LR: 0.003340
2025-05-17 10:13:49,827 [INFO] Epoch 15/15 - Policy Loss: 0.8029, Value Loss: 0.1327, Total Loss: 0.9356, LR: 0.004990
2025-05-17 10:13:49,852 [INFO] 训练完成，总损失: 0.9356
2025-05-17 10:13:49,852 [INFO] 保存迭代 43 的模型
2025-05-17 10:13:51,208 [INFO] Model saved to ./models/best.pt
2025-05-17 10:13:51,914 [INFO] Model saved to ./models/iteration_43.pt
2025-05-17 10:13:51,915 [INFO] 所有训练迭代完成
2025-05-17 10:13:51,915 [INFO] 开始迭代 44/300
2025-05-17 10:13:51,915 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 10:34:08,140 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 10:34:08,141 [INFO] 保存训练样本
2025-05-17 10:34:12,838 [INFO] 使用 170560 个样本训练神经网络
2025-05-17 10:34:12,838 [INFO] Training with 170560 examples
2025-05-17 10:34:12,839 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 10:34:12,893 [INFO] 循环学习率周期大小: 498 步
2025-05-17 10:35:34,606 [INFO] Epoch 1/15 - Policy Loss: 0.8242, Value Loss: 0.1505, Total Loss: 0.9747, LR: 0.001690
2025-05-17 10:37:00,731 [INFO] Epoch 2/15 - Policy Loss: 0.8178, Value Loss: 0.1472, Total Loss: 0.9650, LR: 0.003340
2025-05-17 10:38:26,769 [INFO] Epoch 3/15 - Policy Loss: 0.8152, Value Loss: 0.1455, Total Loss: 0.9607, LR: 0.004990
2025-05-17 10:39:56,369 [INFO] Epoch 4/15 - Policy Loss: 0.8142, Value Loss: 0.1445, Total Loss: 0.9588, LR: 0.003360
2025-05-17 10:41:15,406 [INFO] Epoch 5/15 - Policy Loss: 0.8128, Value Loss: 0.1432, Total Loss: 0.9560, LR: 0.001710
2025-05-17 10:42:32,615 [INFO] Epoch 6/15 - Policy Loss: 0.8095, Value Loss: 0.1412, Total Loss: 0.9507, LR: 0.000060
2025-05-17 10:43:54,892 [INFO] Epoch 7/15 - Policy Loss: 0.8072, Value Loss: 0.1400, Total Loss: 0.9473, LR: 0.001690
2025-05-17 10:45:16,931 [INFO] Epoch 8/15 - Policy Loss: 0.8059, Value Loss: 0.1390, Total Loss: 0.9449, LR: 0.003340
2025-05-17 10:46:46,251 [INFO] Epoch 9/15 - Policy Loss: 0.8054, Value Loss: 0.1382, Total Loss: 0.9437, LR: 0.004990
2025-05-17 10:48:12,991 [INFO] Epoch 10/15 - Policy Loss: 0.8051, Value Loss: 0.1376, Total Loss: 0.9427, LR: 0.003360
2025-05-17 10:49:33,166 [INFO] Epoch 11/15 - Policy Loss: 0.8044, Value Loss: 0.1367, Total Loss: 0.9412, LR: 0.001710
2025-05-17 10:50:59,989 [INFO] Epoch 12/15 - Policy Loss: 0.8036, Value Loss: 0.1360, Total Loss: 0.9396, LR: 0.000060
2025-05-17 10:52:20,830 [INFO] Epoch 13/15 - Policy Loss: 0.8023, Value Loss: 0.1353, Total Loss: 0.9377, LR: 0.001690
2025-05-17 10:53:45,827 [INFO] Epoch 14/15 - Policy Loss: 0.8015, Value Loss: 0.1347, Total Loss: 0.9362, LR: 0.003340
2025-05-17 10:55:07,456 [INFO] Epoch 15/15 - Policy Loss: 0.8013, Value Loss: 0.1344, Total Loss: 0.9357, LR: 0.004990
2025-05-17 10:55:07,475 [INFO] 训练完成，总损失: 0.9357
2025-05-17 10:55:07,476 [INFO] 保存迭代 44 的模型
2025-05-17 10:55:08,740 [INFO] Model saved to ./models/best.pt
2025-05-17 10:55:09,593 [INFO] Model saved to ./models/iteration_44.pt
2025-05-17 10:55:09,594 [INFO] 所有训练迭代完成
2025-05-17 10:55:09,594 [INFO] 开始迭代 45/300
2025-05-17 10:55:09,594 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 11:16:24,417 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 11:16:24,418 [INFO] 保存训练样本
2025-05-17 11:16:29,252 [INFO] 使用 170736 个样本训练神经网络
2025-05-17 11:16:29,252 [INFO] Training with 170736 examples
2025-05-17 11:16:29,253 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 11:16:29,637 [INFO] 循环学习率周期大小: 498 步
2025-05-17 11:17:56,218 [INFO] Epoch 1/15 - Policy Loss: 0.8233, Value Loss: 0.1472, Total Loss: 0.9705, LR: 0.001690
2025-05-17 11:19:19,207 [INFO] Epoch 2/15 - Policy Loss: 0.8168, Value Loss: 0.1440, Total Loss: 0.9608, LR: 0.003340
2025-05-17 11:20:47,209 [INFO] Epoch 3/15 - Policy Loss: 0.8158, Value Loss: 0.1430, Total Loss: 0.9588, LR: 0.004990
2025-05-17 11:22:05,405 [INFO] Epoch 4/15 - Policy Loss: 0.8145, Value Loss: 0.1424, Total Loss: 0.9570, LR: 0.003360
2025-05-17 11:23:27,850 [INFO] Epoch 5/15 - Policy Loss: 0.8118, Value Loss: 0.1410, Total Loss: 0.9528, LR: 0.001710
2025-05-17 11:24:52,429 [INFO] Epoch 6/15 - Policy Loss: 0.8087, Value Loss: 0.1399, Total Loss: 0.9486, LR: 0.000060
2025-05-17 11:26:18,330 [INFO] Epoch 7/15 - Policy Loss: 0.8062, Value Loss: 0.1386, Total Loss: 0.9448, LR: 0.001690
2025-05-17 11:27:43,787 [INFO] Epoch 8/15 - Policy Loss: 0.8045, Value Loss: 0.1378, Total Loss: 0.9422, LR: 0.003340
2025-05-17 11:29:12,343 [INFO] Epoch 9/15 - Policy Loss: 0.8037, Value Loss: 0.1370, Total Loss: 0.9407, LR: 0.004990
2025-05-17 11:30:29,891 [INFO] Epoch 10/15 - Policy Loss: 0.8037, Value Loss: 0.1370, Total Loss: 0.9406, LR: 0.003360
2025-05-17 11:31:55,589 [INFO] Epoch 11/15 - Policy Loss: 0.8025, Value Loss: 0.1364, Total Loss: 0.9388, LR: 0.001710
2025-05-17 11:33:15,538 [INFO] Epoch 12/15 - Policy Loss: 0.8009, Value Loss: 0.1358, Total Loss: 0.9368, LR: 0.000060
2025-05-17 11:34:37,312 [INFO] Epoch 13/15 - Policy Loss: 0.7993, Value Loss: 0.1354, Total Loss: 0.9346, LR: 0.001690
2025-05-17 11:36:06,563 [INFO] Epoch 14/15 - Policy Loss: 0.7984, Value Loss: 0.1349, Total Loss: 0.9333, LR: 0.003340
2025-05-17 11:37:26,784 [INFO] Epoch 15/15 - Policy Loss: 0.7977, Value Loss: 0.1345, Total Loss: 0.9323, LR: 0.004990
2025-05-17 11:37:26,803 [INFO] 训练完成，总损失: 0.9323
2025-05-17 11:37:26,803 [INFO] 保存迭代 45 的模型
2025-05-17 11:37:28,117 [INFO] Model saved to ./models/best.pt
2025-05-17 11:37:28,837 [INFO] Model saved to ./models/iteration_45.pt
2025-05-17 11:37:28,837 [INFO] 所有训练迭代完成
2025-05-17 11:37:28,837 [INFO] 开始迭代 46/300
2025-05-17 11:37:28,837 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 11:57:30,031 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 11:57:30,032 [INFO] 保存训练样本
2025-05-17 11:57:34,026 [INFO] 使用 170336 个样本训练神经网络
2025-05-17 11:57:34,026 [INFO] Training with 170336 examples
2025-05-17 11:57:34,026 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 11:57:34,370 [INFO] 循环学习率周期大小: 498 步
2025-05-17 11:59:04,243 [INFO] Epoch 1/15 - Policy Loss: 0.8109, Value Loss: 0.1338, Total Loss: 0.9446, LR: 0.001690
2025-05-17 12:00:32,703 [INFO] Epoch 2/15 - Policy Loss: 0.8051, Value Loss: 0.1323, Total Loss: 0.9374, LR: 0.003340
2025-05-17 12:01:56,112 [INFO] Epoch 3/15 - Policy Loss: 0.8025, Value Loss: 0.1310, Total Loss: 0.9335, LR: 0.004990
2025-05-17 12:03:21,171 [INFO] Epoch 4/15 - Policy Loss: 0.8021, Value Loss: 0.1307, Total Loss: 0.9328, LR: 0.003360
2025-05-17 12:04:43,639 [INFO] Epoch 5/15 - Policy Loss: 0.8004, Value Loss: 0.1300, Total Loss: 0.9303, LR: 0.001710
2025-05-17 12:06:03,064 [INFO] Epoch 6/15 - Policy Loss: 0.7987, Value Loss: 0.1292, Total Loss: 0.9279, LR: 0.000060
2025-05-17 12:07:32,091 [INFO] Epoch 7/15 - Policy Loss: 0.7960, Value Loss: 0.1282, Total Loss: 0.9242, LR: 0.001690
2025-05-17 12:09:04,945 [INFO] Epoch 8/15 - Policy Loss: 0.7943, Value Loss: 0.1279, Total Loss: 0.9222, LR: 0.003340
2025-05-17 12:10:38,447 [INFO] Epoch 9/15 - Policy Loss: 0.7939, Value Loss: 0.1279, Total Loss: 0.9218, LR: 0.004990
2025-05-17 12:12:02,542 [INFO] Epoch 10/15 - Policy Loss: 0.7942, Value Loss: 0.1282, Total Loss: 0.9225, LR: 0.003360
2025-05-17 12:13:24,431 [INFO] Epoch 11/15 - Policy Loss: 0.7936, Value Loss: 0.1283, Total Loss: 0.9220, LR: 0.001710
2025-05-17 12:14:58,291 [INFO] Epoch 12/15 - Policy Loss: 0.7931, Value Loss: 0.1282, Total Loss: 0.9213, LR: 0.000060
2025-05-17 12:16:20,076 [INFO] Epoch 13/15 - Policy Loss: 0.7924, Value Loss: 0.1282, Total Loss: 0.9207, LR: 0.001690
2025-05-17 12:17:40,968 [INFO] Epoch 14/15 - Policy Loss: 0.7917, Value Loss: 0.1280, Total Loss: 0.9197, LR: 0.003340
2025-05-17 12:19:05,647 [INFO] Epoch 15/15 - Policy Loss: 0.7916, Value Loss: 0.1277, Total Loss: 0.9193, LR: 0.004990
2025-05-17 12:19:05,673 [INFO] 训练完成，总损失: 0.9193
2025-05-17 12:19:05,673 [INFO] 保存迭代 46 的模型
2025-05-17 12:19:06,947 [INFO] Model saved to ./models/best.pt
2025-05-17 12:19:07,641 [INFO] Model saved to ./models/iteration_46.pt
2025-05-17 12:19:07,642 [INFO] 所有训练迭代完成
2025-05-17 12:19:07,642 [INFO] 开始迭代 47/300
2025-05-17 12:19:07,642 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 12:40:11,167 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 12:40:11,168 [INFO] 保存训练样本
2025-05-17 12:40:15,410 [INFO] 使用 170616 个样本训练神经网络
2025-05-17 12:40:15,411 [INFO] Training with 170616 examples
2025-05-17 12:40:15,411 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 12:40:15,860 [INFO] 循环学习率周期大小: 498 步
2025-05-17 12:41:35,478 [INFO] Epoch 1/15 - Policy Loss: 0.8189, Value Loss: 0.1332, Total Loss: 0.9520, LR: 0.001690
2025-05-17 12:42:57,292 [INFO] Epoch 2/15 - Policy Loss: 0.8125, Value Loss: 0.1302, Total Loss: 0.9426, LR: 0.003340
2025-05-17 12:44:12,156 [INFO] Epoch 3/15 - Policy Loss: 0.8092, Value Loss: 0.1300, Total Loss: 0.9392, LR: 0.004990
2025-05-17 12:45:40,545 [INFO] Epoch 4/15 - Policy Loss: 0.8073, Value Loss: 0.1292, Total Loss: 0.9365, LR: 0.003360
2025-05-17 12:47:00,427 [INFO] Epoch 5/15 - Policy Loss: 0.8044, Value Loss: 0.1282, Total Loss: 0.9326, LR: 0.001710
2025-05-17 12:48:24,751 [INFO] Epoch 6/15 - Policy Loss: 0.8020, Value Loss: 0.1276, Total Loss: 0.9296, LR: 0.000060
2025-05-17 12:49:43,007 [INFO] Epoch 7/15 - Policy Loss: 0.7998, Value Loss: 0.1267, Total Loss: 0.9265, LR: 0.001690
2025-05-17 12:50:58,691 [INFO] Epoch 8/15 - Policy Loss: 0.7983, Value Loss: 0.1262, Total Loss: 0.9245, LR: 0.003340
2025-05-17 12:52:11,961 [INFO] Epoch 9/15 - Policy Loss: 0.7972, Value Loss: 0.1258, Total Loss: 0.9230, LR: 0.004990
2025-05-17 12:53:38,155 [INFO] Epoch 10/15 - Policy Loss: 0.7965, Value Loss: 0.1254, Total Loss: 0.9219, LR: 0.003360
2025-05-17 12:55:04,923 [INFO] Epoch 11/15 - Policy Loss: 0.7954, Value Loss: 0.1252, Total Loss: 0.9206, LR: 0.001710
2025-05-17 12:56:19,486 [INFO] Epoch 12/15 - Policy Loss: 0.7942, Value Loss: 0.1249, Total Loss: 0.9192, LR: 0.000060
2025-05-17 12:57:47,448 [INFO] Epoch 13/15 - Policy Loss: 0.7928, Value Loss: 0.1245, Total Loss: 0.9173, LR: 0.001690
2025-05-17 12:59:13,553 [INFO] Epoch 14/15 - Policy Loss: 0.7921, Value Loss: 0.1242, Total Loss: 0.9163, LR: 0.003340
2025-05-17 13:00:30,677 [INFO] Epoch 15/15 - Policy Loss: 0.7918, Value Loss: 0.1241, Total Loss: 0.9159, LR: 0.004990
2025-05-17 13:00:30,702 [INFO] 训练完成，总损失: 0.9159
2025-05-17 13:00:30,702 [INFO] 保存迭代 47 的模型
2025-05-17 13:00:31,941 [INFO] Model saved to ./models/best.pt
2025-05-17 13:00:32,650 [INFO] Model saved to ./models/iteration_47.pt
2025-05-17 13:00:32,651 [INFO] 所有训练迭代完成
2025-05-17 13:00:32,651 [INFO] 开始迭代 48/300
2025-05-17 13:00:32,651 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 13:21:19,545 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 13:21:19,545 [INFO] 保存训练样本
2025-05-17 13:21:24,277 [INFO] 使用 170248 个样本训练神经网络
2025-05-17 13:21:24,277 [INFO] Training with 170248 examples
2025-05-17 13:21:24,278 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 13:21:24,327 [INFO] 循环学习率周期大小: 498 步
2025-05-17 13:22:46,230 [INFO] Epoch 1/15 - Policy Loss: 0.8230, Value Loss: 0.1381, Total Loss: 0.9611, LR: 0.001690
2025-05-17 13:24:03,801 [INFO] Epoch 2/15 - Policy Loss: 0.8149, Value Loss: 0.1352, Total Loss: 0.9500, LR: 0.003340
2025-05-17 13:25:20,613 [INFO] Epoch 3/15 - Policy Loss: 0.8110, Value Loss: 0.1334, Total Loss: 0.9444, LR: 0.004990
2025-05-17 13:26:04,544 [INFO] Epoch 4/15 - Policy Loss: 0.8090, Value Loss: 0.1327, Total Loss: 0.9418, LR: 0.003360
2025-05-17 13:26:48,622 [INFO] Epoch 5/15 - Policy Loss: 0.8053, Value Loss: 0.1312, Total Loss: 0.9365, LR: 0.001710
2025-05-17 13:27:32,832 [INFO] Epoch 6/15 - Policy Loss: 0.8023, Value Loss: 0.1300, Total Loss: 0.9323, LR: 0.000060
2025-05-17 13:28:17,045 [INFO] Epoch 7/15 - Policy Loss: 0.7994, Value Loss: 0.1293, Total Loss: 0.9287, LR: 0.001690
2025-05-17 13:29:01,315 [INFO] Epoch 8/15 - Policy Loss: 0.7976, Value Loss: 0.1286, Total Loss: 0.9262, LR: 0.003340
2025-05-17 13:29:45,393 [INFO] Epoch 9/15 - Policy Loss: 0.7970, Value Loss: 0.1279, Total Loss: 0.9250, LR: 0.004990
2025-05-17 13:30:29,418 [INFO] Epoch 10/15 - Policy Loss: 0.7963, Value Loss: 0.1273, Total Loss: 0.9236, LR: 0.003360
2025-05-17 13:31:13,346 [INFO] Epoch 11/15 - Policy Loss: 0.7953, Value Loss: 0.1269, Total Loss: 0.9221, LR: 0.001710
2025-05-17 13:31:57,465 [INFO] Epoch 12/15 - Policy Loss: 0.7939, Value Loss: 0.1263, Total Loss: 0.9201, LR: 0.000060
2025-05-17 13:32:41,452 [INFO] Epoch 13/15 - Policy Loss: 0.7925, Value Loss: 0.1258, Total Loss: 0.9183, LR: 0.001690
2025-05-17 13:33:25,642 [INFO] Epoch 14/15 - Policy Loss: 0.7912, Value Loss: 0.1254, Total Loss: 0.9166, LR: 0.003340
2025-05-17 13:34:09,717 [INFO] Epoch 15/15 - Policy Loss: 0.7908, Value Loss: 0.1253, Total Loss: 0.9161, LR: 0.004990
2025-05-17 13:34:09,738 [INFO] 训练完成，总损失: 0.9161
2025-05-17 13:34:09,738 [INFO] 保存迭代 48 的模型
2025-05-17 13:34:11,378 [INFO] Model saved to ./models/best.pt
2025-05-17 13:34:12,167 [INFO] Model saved to ./models/iteration_48.pt
2025-05-17 13:34:12,167 [INFO] 所有训练迭代完成
2025-05-17 13:34:12,167 [INFO] 开始迭代 49/300
2025-05-17 13:34:12,167 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 13:49:32,455 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 13:49:32,456 [INFO] 保存训练样本
2025-05-17 13:49:37,362 [INFO] 使用 170400 个样本训练神经网络
2025-05-17 13:49:37,362 [INFO] Training with 170400 examples
2025-05-17 13:49:37,363 [INFO] 总训练步数: 2490, 每轮次批次数: 166
2025-05-17 13:49:37,731 [INFO] 循环学习率周期大小: 498 步
2025-05-17 13:50:21,541 [INFO] Epoch 1/15 - Policy Loss: 0.8251, Value Loss: 0.1410, Total Loss: 0.9661, LR: 0.001690
2025-05-17 13:51:05,621 [INFO] Epoch 2/15 - Policy Loss: 0.8159, Value Loss: 0.1377, Total Loss: 0.9536, LR: 0.003340
2025-05-17 13:51:49,537 [INFO] Epoch 3/15 - Policy Loss: 0.8108, Value Loss: 0.1364, Total Loss: 0.9472, LR: 0.004990
2025-05-17 13:52:33,483 [INFO] Epoch 4/15 - Policy Loss: 0.8077, Value Loss: 0.1347, Total Loss: 0.9424, LR: 0.003360
2025-05-17 13:53:17,165 [INFO] Epoch 5/15 - Policy Loss: 0.8040, Value Loss: 0.1334, Total Loss: 0.9375, LR: 0.001710
2025-05-17 13:54:01,153 [INFO] Epoch 6/15 - Policy Loss: 0.8000, Value Loss: 0.1324, Total Loss: 0.9324, LR: 0.000060
2025-05-17 13:54:44,932 [INFO] Epoch 7/15 - Policy Loss: 0.7967, Value Loss: 0.1316, Total Loss: 0.9283, LR: 0.001690
2025-05-17 13:55:29,367 [INFO] Epoch 8/15 - Policy Loss: 0.7947, Value Loss: 0.1308, Total Loss: 0.9256, LR: 0.003340
2025-05-17 13:56:13,272 [INFO] Epoch 9/15 - Policy Loss: 0.7936, Value Loss: 0.1304, Total Loss: 0.9240, LR: 0.004990
2025-05-17 13:56:57,094 [INFO] Epoch 10/15 - Policy Loss: 0.7931, Value Loss: 0.1302, Total Loss: 0.9233, LR: 0.003360
2025-05-17 13:57:42,579 [INFO] Epoch 11/15 - Policy Loss: 0.7929, Value Loss: 0.1297, Total Loss: 0.9226, LR: 0.001710
2025-05-17 13:58:26,399 [INFO] Epoch 12/15 - Policy Loss: 0.7918, Value Loss: 0.1293, Total Loss: 0.9210, LR: 0.000060
2025-05-17 13:59:10,287 [INFO] Epoch 13/15 - Policy Loss: 0.7905, Value Loss: 0.1290, Total Loss: 0.9195, LR: 0.001690
2025-05-17 13:59:54,918 [INFO] Epoch 14/15 - Policy Loss: 0.7892, Value Loss: 0.1286, Total Loss: 0.9179, LR: 0.003340
2025-05-17 14:00:38,962 [INFO] Epoch 15/15 - Policy Loss: 0.7883, Value Loss: 0.1284, Total Loss: 0.9167, LR: 0.004990
2025-05-17 14:00:38,990 [INFO] 训练完成，总损失: 0.9167
2025-05-17 14:00:38,990 [INFO] 保存迭代 49 的模型
2025-05-17 14:00:40,543 [INFO] Model saved to ./models/best.pt
2025-05-17 14:00:41,412 [INFO] Model saved to ./models/iteration_49.pt
2025-05-17 14:00:41,412 [INFO] 所有训练迭代完成
2025-05-17 14:00:41,412 [INFO] 开始迭代 50/300
2025-05-17 14:00:41,412 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 14:14:43,004 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 14:14:43,004 [INFO] 保存训练样本
2025-05-17 14:14:47,714 [INFO] 使用 169784 个样本训练神经网络
2025-05-17 14:14:47,714 [INFO] Training with 169784 examples
2025-05-17 14:14:47,714 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 14:14:48,061 [INFO] 循环学习率周期大小: 495 步
2025-05-17 14:15:31,341 [INFO] Epoch 1/15 - Policy Loss: 0.8062, Value Loss: 0.1373, Total Loss: 0.9435, LR: 0.001690
2025-05-17 14:16:14,768 [INFO] Epoch 2/15 - Policy Loss: 0.8021, Value Loss: 0.1354, Total Loss: 0.9376, LR: 0.003340
2025-05-17 14:16:58,299 [INFO] Epoch 3/15 - Policy Loss: 0.8012, Value Loss: 0.1350, Total Loss: 0.9361, LR: 0.004990
2025-05-17 14:17:41,755 [INFO] Epoch 4/15 - Policy Loss: 0.8003, Value Loss: 0.1348, Total Loss: 0.9351, LR: 0.003360
2025-05-17 14:18:25,459 [INFO] Epoch 5/15 - Policy Loss: 0.7983, Value Loss: 0.1339, Total Loss: 0.9322, LR: 0.001710
2025-05-17 14:19:09,393 [INFO] Epoch 6/15 - Policy Loss: 0.7969, Value Loss: 0.1327, Total Loss: 0.9296, LR: 0.000060
2025-05-17 14:19:53,189 [INFO] Epoch 7/15 - Policy Loss: 0.7949, Value Loss: 0.1316, Total Loss: 0.9265, LR: 0.001690
2025-05-17 14:20:37,038 [INFO] Epoch 8/15 - Policy Loss: 0.7924, Value Loss: 0.1307, Total Loss: 0.9231, LR: 0.003340
2025-05-17 14:21:20,972 [INFO] Epoch 9/15 - Policy Loss: 0.7918, Value Loss: 0.1303, Total Loss: 0.9221, LR: 0.004990
2025-05-17 14:22:04,889 [INFO] Epoch 10/15 - Policy Loss: 0.7922, Value Loss: 0.1302, Total Loss: 0.9223, LR: 0.003360
2025-05-17 14:22:48,733 [INFO] Epoch 11/15 - Policy Loss: 0.7909, Value Loss: 0.1293, Total Loss: 0.9202, LR: 0.001710
2025-05-17 14:23:34,305 [INFO] Epoch 12/15 - Policy Loss: 0.7902, Value Loss: 0.1287, Total Loss: 0.9189, LR: 0.000060
2025-05-17 14:24:18,261 [INFO] Epoch 13/15 - Policy Loss: 0.7893, Value Loss: 0.1281, Total Loss: 0.9174, LR: 0.001690
2025-05-17 14:25:02,217 [INFO] Epoch 14/15 - Policy Loss: 0.7883, Value Loss: 0.1275, Total Loss: 0.9158, LR: 0.003340
2025-05-17 14:25:46,080 [INFO] Epoch 15/15 - Policy Loss: 0.7879, Value Loss: 0.1270, Total Loss: 0.9148, LR: 0.004990
2025-05-17 14:25:46,102 [INFO] 训练完成，总损失: 0.9148
2025-05-17 14:25:46,102 [INFO] 保存迭代 50 的模型
2025-05-17 14:25:47,513 [INFO] Model saved to ./models/best.pt
2025-05-17 14:25:48,365 [INFO] Model saved to ./models/iteration_50.pt
2025-05-17 14:25:48,365 [INFO] 所有训练迭代完成
2025-05-17 14:25:48,365 [INFO] 开始迭代 51/300
2025-05-17 14:25:48,365 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 14:40:58,332 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 14:40:58,333 [INFO] 保存训练样本
2025-05-17 14:41:03,155 [INFO] 使用 169752 个样本训练神经网络
2025-05-17 14:41:03,155 [INFO] Training with 169752 examples
2025-05-17 14:41:03,155 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 14:41:03,205 [INFO] 循环学习率周期大小: 495 步
2025-05-17 14:41:46,630 [INFO] Epoch 1/15 - Policy Loss: 0.8066, Value Loss: 0.1313, Total Loss: 0.9379, LR: 0.001690
2025-05-17 14:42:29,949 [INFO] Epoch 2/15 - Policy Loss: 0.8002, Value Loss: 0.1303, Total Loss: 0.9305, LR: 0.003340
2025-05-17 14:43:13,816 [INFO] Epoch 3/15 - Policy Loss: 0.7984, Value Loss: 0.1290, Total Loss: 0.9274, LR: 0.004990
2025-05-17 14:43:57,348 [INFO] Epoch 4/15 - Policy Loss: 0.7971, Value Loss: 0.1286, Total Loss: 0.9256, LR: 0.003360
2025-05-17 14:44:41,023 [INFO] Epoch 5/15 - Policy Loss: 0.7950, Value Loss: 0.1279, Total Loss: 0.9229, LR: 0.001710
2025-05-17 14:45:24,509 [INFO] Epoch 6/15 - Policy Loss: 0.7930, Value Loss: 0.1268, Total Loss: 0.9199, LR: 0.000060
2025-05-17 14:46:08,240 [INFO] Epoch 7/15 - Policy Loss: 0.7910, Value Loss: 0.1263, Total Loss: 0.9173, LR: 0.001690
2025-05-17 14:46:51,929 [INFO] Epoch 8/15 - Policy Loss: 0.7894, Value Loss: 0.1256, Total Loss: 0.9150, LR: 0.003340
2025-05-17 14:47:35,641 [INFO] Epoch 9/15 - Policy Loss: 0.7891, Value Loss: 0.1251, Total Loss: 0.9142, LR: 0.004990
2025-05-17 14:48:19,320 [INFO] Epoch 10/15 - Policy Loss: 0.7885, Value Loss: 0.1252, Total Loss: 0.9137, LR: 0.003360
2025-05-17 14:49:02,993 [INFO] Epoch 11/15 - Policy Loss: 0.7877, Value Loss: 0.1251, Total Loss: 0.9128, LR: 0.001710
2025-05-17 14:49:46,895 [INFO] Epoch 12/15 - Policy Loss: 0.7867, Value Loss: 0.1246, Total Loss: 0.9114, LR: 0.000060
2025-05-17 14:50:30,820 [INFO] Epoch 13/15 - Policy Loss: 0.7855, Value Loss: 0.1241, Total Loss: 0.9096, LR: 0.001690
2025-05-17 14:51:14,664 [INFO] Epoch 14/15 - Policy Loss: 0.7846, Value Loss: 0.1236, Total Loss: 0.9082, LR: 0.003340
2025-05-17 14:51:58,577 [INFO] Epoch 15/15 - Policy Loss: 0.7843, Value Loss: 0.1233, Total Loss: 0.9075, LR: 0.004990
2025-05-17 14:51:58,605 [INFO] 训练完成，总损失: 0.9075
2025-05-17 14:51:58,605 [INFO] 保存迭代 51 的模型
2025-05-17 14:52:00,118 [INFO] Model saved to ./models/best.pt
2025-05-17 14:52:00,970 [INFO] Model saved to ./models/iteration_51.pt
2025-05-17 14:52:00,970 [INFO] 所有训练迭代完成
2025-05-17 14:52:00,970 [INFO] 开始迭代 52/300
2025-05-17 14:52:00,970 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 15:07:33,688 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 15:07:33,689 [INFO] 保存训练样本
2025-05-17 15:07:39,120 [INFO] 使用 169624 个样本训练神经网络
2025-05-17 15:07:39,121 [INFO] Training with 169624 examples
2025-05-17 15:07:39,121 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 15:07:39,637 [INFO] 循环学习率周期大小: 495 步
2025-05-17 15:08:22,811 [INFO] Epoch 1/15 - Policy Loss: 0.7971, Value Loss: 0.1326, Total Loss: 0.9297, LR: 0.001690
2025-05-17 15:09:06,380 [INFO] Epoch 2/15 - Policy Loss: 0.7944, Value Loss: 0.1313, Total Loss: 0.9257, LR: 0.003340
2025-05-17 15:09:50,038 [INFO] Epoch 3/15 - Policy Loss: 0.7928, Value Loss: 0.1310, Total Loss: 0.9238, LR: 0.004990
2025-05-17 15:10:33,646 [INFO] Epoch 4/15 - Policy Loss: 0.7935, Value Loss: 0.1318, Total Loss: 0.9253, LR: 0.003360
2025-05-17 15:11:17,197 [INFO] Epoch 5/15 - Policy Loss: 0.7919, Value Loss: 0.1304, Total Loss: 0.9223, LR: 0.001710
2025-05-17 15:12:00,742 [INFO] Epoch 6/15 - Policy Loss: 0.7896, Value Loss: 0.1293, Total Loss: 0.9190, LR: 0.000060
2025-05-17 15:12:44,278 [INFO] Epoch 7/15 - Policy Loss: 0.7880, Value Loss: 0.1288, Total Loss: 0.9168, LR: 0.001690
2025-05-17 15:13:28,037 [INFO] Epoch 8/15 - Policy Loss: 0.7863, Value Loss: 0.1279, Total Loss: 0.9142, LR: 0.003340
2025-05-17 15:14:11,889 [INFO] Epoch 9/15 - Policy Loss: 0.7853, Value Loss: 0.1278, Total Loss: 0.9130, LR: 0.004990
2025-05-17 15:14:55,709 [INFO] Epoch 10/15 - Policy Loss: 0.7847, Value Loss: 0.1273, Total Loss: 0.9120, LR: 0.003360
2025-05-17 15:15:39,527 [INFO] Epoch 11/15 - Policy Loss: 0.7840, Value Loss: 0.1272, Total Loss: 0.9112, LR: 0.001710
2025-05-17 15:16:23,357 [INFO] Epoch 12/15 - Policy Loss: 0.7831, Value Loss: 0.1267, Total Loss: 0.9098, LR: 0.000060
2025-05-17 15:17:07,210 [INFO] Epoch 13/15 - Policy Loss: 0.7821, Value Loss: 0.1261, Total Loss: 0.9082, LR: 0.001690
2025-05-17 15:17:50,958 [INFO] Epoch 14/15 - Policy Loss: 0.7811, Value Loss: 0.1256, Total Loss: 0.9067, LR: 0.003340
2025-05-17 15:18:34,780 [INFO] Epoch 15/15 - Policy Loss: 0.7807, Value Loss: 0.1253, Total Loss: 0.9060, LR: 0.004990
2025-05-17 15:18:34,801 [INFO] 训练完成，总损失: 0.9060
2025-05-17 15:18:34,801 [INFO] 保存迭代 52 的模型
2025-05-17 15:18:36,209 [INFO] Model saved to ./models/best.pt
2025-05-17 15:18:37,032 [INFO] Model saved to ./models/iteration_52.pt
2025-05-17 15:18:37,032 [INFO] 所有训练迭代完成
2025-05-17 15:18:37,032 [INFO] 开始迭代 53/300
2025-05-17 15:18:37,032 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 15:33:31,229 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 15:33:31,230 [INFO] 保存训练样本
2025-05-17 15:33:35,616 [INFO] 使用 169520 个样本训练神经网络
2025-05-17 15:33:35,617 [INFO] Training with 169520 examples
2025-05-17 15:33:35,617 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 15:33:36,022 [INFO] 循环学习率周期大小: 495 步
2025-05-17 15:34:19,225 [INFO] Epoch 1/15 - Policy Loss: 0.7959, Value Loss: 0.1439, Total Loss: 0.9398, LR: 0.001690
2025-05-17 15:35:02,637 [INFO] Epoch 2/15 - Policy Loss: 0.7931, Value Loss: 0.1426, Total Loss: 0.9357, LR: 0.003340
2025-05-17 15:35:46,075 [INFO] Epoch 3/15 - Policy Loss: 0.7900, Value Loss: 0.1415, Total Loss: 0.9315, LR: 0.004990
2025-05-17 15:36:29,514 [INFO] Epoch 4/15 - Policy Loss: 0.7902, Value Loss: 0.1416, Total Loss: 0.9318, LR: 0.003360
2025-05-17 15:37:13,059 [INFO] Epoch 5/15 - Policy Loss: 0.7886, Value Loss: 0.1406, Total Loss: 0.9292, LR: 0.001710
2025-05-17 15:37:56,941 [INFO] Epoch 6/15 - Policy Loss: 0.7867, Value Loss: 0.1395, Total Loss: 0.9262, LR: 0.000060
2025-05-17 15:38:40,717 [INFO] Epoch 7/15 - Policy Loss: 0.7845, Value Loss: 0.1385, Total Loss: 0.9230, LR: 0.001690
2025-05-17 15:39:24,569 [INFO] Epoch 8/15 - Policy Loss: 0.7830, Value Loss: 0.1377, Total Loss: 0.9208, LR: 0.003340
2025-05-17 15:40:08,497 [INFO] Epoch 9/15 - Policy Loss: 0.7818, Value Loss: 0.1372, Total Loss: 0.9190, LR: 0.004990
2025-05-17 15:40:52,165 [INFO] Epoch 10/15 - Policy Loss: 0.7815, Value Loss: 0.1365, Total Loss: 0.9180, LR: 0.003360
2025-05-17 15:41:36,053 [INFO] Epoch 11/15 - Policy Loss: 0.7808, Value Loss: 0.1361, Total Loss: 0.9168, LR: 0.001710
2025-05-17 15:42:19,911 [INFO] Epoch 12/15 - Policy Loss: 0.7799, Value Loss: 0.1354, Total Loss: 0.9153, LR: 0.000060
2025-05-17 15:43:03,788 [INFO] Epoch 13/15 - Policy Loss: 0.7788, Value Loss: 0.1348, Total Loss: 0.9137, LR: 0.001690
2025-05-17 15:43:47,531 [INFO] Epoch 14/15 - Policy Loss: 0.7785, Value Loss: 0.1346, Total Loss: 0.9132, LR: 0.003340
2025-05-17 15:44:31,198 [INFO] Epoch 15/15 - Policy Loss: 0.7787, Value Loss: 0.1344, Total Loss: 0.9131, LR: 0.004990
2025-05-17 15:44:31,219 [INFO] 训练完成，总损失: 0.9131
2025-05-17 15:44:31,219 [INFO] 保存迭代 53 的模型
2025-05-17 15:44:32,502 [INFO] Model saved to ./models/best.pt
2025-05-17 15:44:33,310 [INFO] Model saved to ./models/iteration_53.pt
2025-05-17 15:44:33,310 [INFO] 所有训练迭代完成
2025-05-17 15:44:33,311 [INFO] 开始迭代 54/300
2025-05-17 15:44:33,311 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 15:59:26,157 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 15:59:26,158 [INFO] 保存训练样本
2025-05-17 15:59:30,854 [INFO] 使用 169584 个样本训练神经网络
2025-05-17 15:59:30,854 [INFO] Training with 169584 examples
2025-05-17 15:59:30,855 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 15:59:30,904 [INFO] 循环学习率周期大小: 495 步
2025-05-17 16:00:14,152 [INFO] Epoch 1/15 - Policy Loss: 0.7936, Value Loss: 0.1406, Total Loss: 0.9342, LR: 0.001690
2025-05-17 16:00:57,722 [INFO] Epoch 2/15 - Policy Loss: 0.7922, Value Loss: 0.1371, Total Loss: 0.9293, LR: 0.003340
2025-05-17 16:01:41,414 [INFO] Epoch 3/15 - Policy Loss: 0.7921, Value Loss: 0.1397, Total Loss: 0.9318, LR: 0.004990
2025-05-17 16:02:25,197 [INFO] Epoch 4/15 - Policy Loss: 0.7909, Value Loss: 0.1389, Total Loss: 0.9298, LR: 0.003360
2025-05-17 16:03:09,022 [INFO] Epoch 5/15 - Policy Loss: 0.7883, Value Loss: 0.1376, Total Loss: 0.9259, LR: 0.001710
2025-05-17 16:03:52,896 [INFO] Epoch 6/15 - Policy Loss: 0.7855, Value Loss: 0.1366, Total Loss: 0.9221, LR: 0.000060
2025-05-17 16:04:36,769 [INFO] Epoch 7/15 - Policy Loss: 0.7829, Value Loss: 0.1356, Total Loss: 0.9186, LR: 0.001690
2025-05-17 16:05:20,934 [INFO] Epoch 8/15 - Policy Loss: 0.7812, Value Loss: 0.1347, Total Loss: 0.9160, LR: 0.003340
2025-05-17 16:06:04,978 [INFO] Epoch 9/15 - Policy Loss: 0.7800, Value Loss: 0.1340, Total Loss: 0.9140, LR: 0.004990
2025-05-17 16:06:49,021 [INFO] Epoch 10/15 - Policy Loss: 0.7795, Value Loss: 0.1336, Total Loss: 0.9131, LR: 0.003360
2025-05-17 16:07:33,083 [INFO] Epoch 11/15 - Policy Loss: 0.7786, Value Loss: 0.1333, Total Loss: 0.9118, LR: 0.001710
2025-05-17 16:08:17,031 [INFO] Epoch 12/15 - Policy Loss: 0.7775, Value Loss: 0.1327, Total Loss: 0.9102, LR: 0.000060
2025-05-17 16:09:01,055 [INFO] Epoch 13/15 - Policy Loss: 0.7763, Value Loss: 0.1322, Total Loss: 0.9085, LR: 0.001690
2025-05-17 16:09:45,239 [INFO] Epoch 14/15 - Policy Loss: 0.7756, Value Loss: 0.1317, Total Loss: 0.9073, LR: 0.003340
2025-05-17 16:10:29,356 [INFO] Epoch 15/15 - Policy Loss: 0.7750, Value Loss: 0.1312, Total Loss: 0.9062, LR: 0.004990
2025-05-17 16:10:29,384 [INFO] 训练完成，总损失: 0.9062
2025-05-17 16:10:29,384 [INFO] 保存迭代 54 的模型
2025-05-17 16:10:30,824 [INFO] Model saved to ./models/best.pt
2025-05-17 16:10:31,785 [INFO] Model saved to ./models/iteration_54.pt
2025-05-17 16:10:31,786 [INFO] 所有训练迭代完成
2025-05-17 16:10:31,786 [INFO] 开始迭代 55/300
2025-05-17 16:10:31,786 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 16:26:00,166 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 16:26:00,166 [INFO] 保存训练样本
2025-05-17 16:26:05,617 [INFO] 使用 169736 个样本训练神经网络
2025-05-17 16:26:05,617 [INFO] Training with 169736 examples
2025-05-17 16:26:05,618 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 16:26:06,126 [INFO] 循环学习率周期大小: 495 步
2025-05-17 16:26:49,540 [INFO] Epoch 1/15 - Policy Loss: 0.7948, Value Loss: 0.1291, Total Loss: 0.9240, LR: 0.001690
2025-05-17 16:27:33,217 [INFO] Epoch 2/15 - Policy Loss: 0.7889, Value Loss: 0.1291, Total Loss: 0.9179, LR: 0.003340
2025-05-17 16:28:16,738 [INFO] Epoch 3/15 - Policy Loss: 0.7847, Value Loss: 0.1283, Total Loss: 0.9130, LR: 0.004990
2025-05-17 16:29:00,266 [INFO] Epoch 4/15 - Policy Loss: 0.7832, Value Loss: 0.1283, Total Loss: 0.9114, LR: 0.003360
2025-05-17 16:29:43,925 [INFO] Epoch 5/15 - Policy Loss: 0.7809, Value Loss: 0.1279, Total Loss: 0.9088, LR: 0.001710
2025-05-17 16:30:27,781 [INFO] Epoch 6/15 - Policy Loss: 0.7782, Value Loss: 0.1277, Total Loss: 0.9059, LR: 0.000060
2025-05-17 16:31:11,684 [INFO] Epoch 7/15 - Policy Loss: 0.7764, Value Loss: 0.1273, Total Loss: 0.9038, LR: 0.001690
2025-05-17 16:31:55,660 [INFO] Epoch 8/15 - Policy Loss: 0.7747, Value Loss: 0.1266, Total Loss: 0.9013, LR: 0.003340
2025-05-17 16:32:39,475 [INFO] Epoch 9/15 - Policy Loss: 0.7737, Value Loss: 0.1261, Total Loss: 0.8998, LR: 0.004990
2025-05-17 16:33:23,182 [INFO] Epoch 10/15 - Policy Loss: 0.7732, Value Loss: 0.1257, Total Loss: 0.8989, LR: 0.003360
2025-05-17 16:34:06,893 [INFO] Epoch 11/15 - Policy Loss: 0.7724, Value Loss: 0.1253, Total Loss: 0.8976, LR: 0.001710
2025-05-17 16:34:50,818 [INFO] Epoch 12/15 - Policy Loss: 0.7717, Value Loss: 0.1247, Total Loss: 0.8963, LR: 0.000060
2025-05-17 16:35:34,643 [INFO] Epoch 13/15 - Policy Loss: 0.7704, Value Loss: 0.1243, Total Loss: 0.8947, LR: 0.001690
2025-05-17 16:36:18,922 [INFO] Epoch 14/15 - Policy Loss: 0.7697, Value Loss: 0.1240, Total Loss: 0.8937, LR: 0.003340
2025-05-17 16:37:02,817 [INFO] Epoch 15/15 - Policy Loss: 0.7695, Value Loss: 0.1238, Total Loss: 0.8933, LR: 0.004990
2025-05-17 16:37:02,839 [INFO] 训练完成，总损失: 0.8933
2025-05-17 16:37:02,839 [INFO] 保存迭代 55 的模型
2025-05-17 16:37:04,039 [INFO] Model saved to ./models/best.pt
2025-05-17 16:37:04,842 [INFO] Model saved to ./models/iteration_55.pt
2025-05-17 16:37:04,843 [INFO] 所有训练迭代完成
2025-05-17 16:37:04,843 [INFO] 开始迭代 56/300
2025-05-17 16:37:04,843 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 16:51:59,799 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 16:51:59,799 [INFO] 保存训练样本
2025-05-17 16:52:03,651 [INFO] 使用 169360 个样本训练神经网络
2025-05-17 16:52:03,651 [INFO] Training with 169360 examples
2025-05-17 16:52:03,652 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 16:52:04,104 [INFO] 循环学习率周期大小: 495 步
2025-05-17 16:52:47,317 [INFO] Epoch 1/15 - Policy Loss: 0.7876, Value Loss: 0.1317, Total Loss: 0.9193, LR: 0.001690
2025-05-17 16:53:30,666 [INFO] Epoch 2/15 - Policy Loss: 0.7844, Value Loss: 0.1291, Total Loss: 0.9134, LR: 0.003340
2025-05-17 16:54:14,020 [INFO] Epoch 3/15 - Policy Loss: 0.7818, Value Loss: 0.1280, Total Loss: 0.9098, LR: 0.004990
2025-05-17 16:54:57,620 [INFO] Epoch 4/15 - Policy Loss: 0.7808, Value Loss: 0.1271, Total Loss: 0.9079, LR: 0.003360
2025-05-17 16:55:41,078 [INFO] Epoch 5/15 - Policy Loss: 0.7780, Value Loss: 0.1269, Total Loss: 0.9049, LR: 0.001710
2025-05-17 16:56:24,662 [INFO] Epoch 6/15 - Policy Loss: 0.7762, Value Loss: 0.1266, Total Loss: 0.9028, LR: 0.000060
2025-05-17 16:57:08,260 [INFO] Epoch 7/15 - Policy Loss: 0.7743, Value Loss: 0.1258, Total Loss: 0.9001, LR: 0.001690
2025-05-17 16:57:52,021 [INFO] Epoch 8/15 - Policy Loss: 0.7729, Value Loss: 0.1256, Total Loss: 0.8985, LR: 0.003340
2025-05-17 16:58:36,040 [INFO] Epoch 9/15 - Policy Loss: 0.7723, Value Loss: 0.1254, Total Loss: 0.8978, LR: 0.004990
2025-05-17 16:59:20,489 [INFO] Epoch 10/15 - Policy Loss: 0.7721, Value Loss: 0.1253, Total Loss: 0.8974, LR: 0.003360
2025-05-17 17:00:04,541 [INFO] Epoch 11/15 - Policy Loss: 0.7715, Value Loss: 0.1250, Total Loss: 0.8965, LR: 0.001710
2025-05-17 17:00:48,637 [INFO] Epoch 12/15 - Policy Loss: 0.7709, Value Loss: 0.1248, Total Loss: 0.8957, LR: 0.000060
2025-05-17 17:01:32,657 [INFO] Epoch 13/15 - Policy Loss: 0.7695, Value Loss: 0.1242, Total Loss: 0.8937, LR: 0.001690
2025-05-17 17:02:16,530 [INFO] Epoch 14/15 - Policy Loss: 0.7688, Value Loss: 0.1236, Total Loss: 0.8924, LR: 0.003340
2025-05-17 17:03:00,435 [INFO] Epoch 15/15 - Policy Loss: 0.7682, Value Loss: 0.1234, Total Loss: 0.8917, LR: 0.004990
2025-05-17 17:03:00,460 [INFO] 训练完成，总损失: 0.8917
2025-05-17 17:03:00,460 [INFO] 保存迭代 56 的模型
2025-05-17 17:03:01,465 [INFO] Model saved to ./models/best.pt
2025-05-17 17:03:02,162 [INFO] Model saved to ./models/iteration_56.pt
2025-05-17 17:03:02,163 [INFO] 所有训练迭代完成
2025-05-17 17:03:02,163 [INFO] 开始迭代 57/300
2025-05-17 17:03:02,163 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 17:16:55,221 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 17:16:55,221 [INFO] 保存训练样本
2025-05-17 17:17:00,323 [INFO] 使用 168624 个样本训练神经网络
2025-05-17 17:17:00,323 [INFO] Training with 168624 examples
2025-05-17 17:17:00,324 [INFO] 总训练步数: 2460, 每轮次批次数: 164
2025-05-17 17:17:00,380 [INFO] 循环学习率周期大小: 492 步
2025-05-17 17:17:43,548 [INFO] Epoch 1/15 - Policy Loss: 0.7826, Value Loss: 0.1282, Total Loss: 0.9108, LR: 0.001690
2025-05-17 17:18:26,901 [INFO] Epoch 2/15 - Policy Loss: 0.7801, Value Loss: 0.1257, Total Loss: 0.9057, LR: 0.003340
2025-05-17 17:19:10,210 [INFO] Epoch 3/15 - Policy Loss: 0.7767, Value Loss: 0.1247, Total Loss: 0.9014, LR: 0.004990
2025-05-17 17:19:53,475 [INFO] Epoch 4/15 - Policy Loss: 0.7760, Value Loss: 0.1252, Total Loss: 0.9012, LR: 0.003360
2025-05-17 17:20:36,560 [INFO] Epoch 5/15 - Policy Loss: 0.7742, Value Loss: 0.1246, Total Loss: 0.8988, LR: 0.001710
2025-05-17 17:21:20,235 [INFO] Epoch 6/15 - Policy Loss: 0.7710, Value Loss: 0.1237, Total Loss: 0.8947, LR: 0.000060
2025-05-17 17:22:03,526 [INFO] Epoch 7/15 - Policy Loss: 0.7686, Value Loss: 0.1230, Total Loss: 0.8916, LR: 0.001690
2025-05-17 17:22:47,005 [INFO] Epoch 8/15 - Policy Loss: 0.7669, Value Loss: 0.1222, Total Loss: 0.8891, LR: 0.003340
2025-05-17 17:23:30,334 [INFO] Epoch 9/15 - Policy Loss: 0.7664, Value Loss: 0.1220, Total Loss: 0.8883, LR: 0.004990
2025-05-17 17:24:13,861 [INFO] Epoch 10/15 - Policy Loss: 0.7664, Value Loss: 0.1217, Total Loss: 0.8881, LR: 0.003360
2025-05-17 17:24:57,503 [INFO] Epoch 11/15 - Policy Loss: 0.7652, Value Loss: 0.1214, Total Loss: 0.8866, LR: 0.001710
2025-05-17 17:25:41,172 [INFO] Epoch 12/15 - Policy Loss: 0.7648, Value Loss: 0.1210, Total Loss: 0.8857, LR: 0.000060
2025-05-17 17:26:24,668 [INFO] Epoch 13/15 - Policy Loss: 0.7640, Value Loss: 0.1207, Total Loss: 0.8847, LR: 0.001690
2025-05-17 17:27:08,283 [INFO] Epoch 14/15 - Policy Loss: 0.7632, Value Loss: 0.1205, Total Loss: 0.8837, LR: 0.003340
2025-05-17 17:27:51,956 [INFO] Epoch 15/15 - Policy Loss: 0.7632, Value Loss: 0.1207, Total Loss: 0.8838, LR: 0.004990
2025-05-17 17:27:51,977 [INFO] 训练完成，总损失: 0.8838
2025-05-17 17:27:51,977 [INFO] 保存迭代 57 的模型
2025-05-17 17:27:53,215 [INFO] Model saved to ./models/best.pt
2025-05-17 17:27:54,082 [INFO] Model saved to ./models/iteration_57.pt
2025-05-17 17:27:54,082 [INFO] 所有训练迭代完成
2025-05-17 17:27:54,082 [INFO] 开始迭代 58/300
2025-05-17 17:27:54,082 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 17:43:54,535 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 17:43:54,535 [INFO] 保存训练样本
2025-05-17 17:44:00,211 [INFO] 使用 169120 个样本训练神经网络
2025-05-17 17:44:00,211 [INFO] Training with 169120 examples
2025-05-17 17:44:00,212 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 17:44:00,820 [INFO] 循环学习率周期大小: 495 步
2025-05-17 17:44:44,205 [INFO] Epoch 1/15 - Policy Loss: 0.7781, Value Loss: 0.1363, Total Loss: 0.9144, LR: 0.001690
2025-05-17 17:45:27,644 [INFO] Epoch 2/15 - Policy Loss: 0.7785, Value Loss: 0.1355, Total Loss: 0.9140, LR: 0.003340
2025-05-17 17:46:11,012 [INFO] Epoch 3/15 - Policy Loss: 0.7758, Value Loss: 0.1341, Total Loss: 0.9099, LR: 0.004990
2025-05-17 17:46:54,574 [INFO] Epoch 4/15 - Policy Loss: 0.7731, Value Loss: 0.1331, Total Loss: 0.9062, LR: 0.003360
2025-05-17 17:47:38,315 [INFO] Epoch 5/15 - Policy Loss: 0.7700, Value Loss: 0.1315, Total Loss: 0.9015, LR: 0.001710
2025-05-17 17:48:21,935 [INFO] Epoch 6/15 - Policy Loss: 0.7680, Value Loss: 0.1304, Total Loss: 0.8984, LR: 0.000060
2025-05-17 17:49:05,975 [INFO] Epoch 7/15 - Policy Loss: 0.7662, Value Loss: 0.1295, Total Loss: 0.8957, LR: 0.001690
2025-05-17 17:49:49,869 [INFO] Epoch 8/15 - Policy Loss: 0.7643, Value Loss: 0.1286, Total Loss: 0.8930, LR: 0.003340
2025-05-17 17:50:33,892 [INFO] Epoch 9/15 - Policy Loss: 0.7642, Value Loss: 0.1284, Total Loss: 0.8926, LR: 0.004990
2025-05-17 17:51:17,955 [INFO] Epoch 10/15 - Policy Loss: 0.7637, Value Loss: 0.1283, Total Loss: 0.8920, LR: 0.003360
2025-05-17 17:52:02,085 [INFO] Epoch 11/15 - Policy Loss: 0.7630, Value Loss: 0.1280, Total Loss: 0.8910, LR: 0.001710
2025-05-17 17:52:46,122 [INFO] Epoch 12/15 - Policy Loss: 0.7617, Value Loss: 0.1274, Total Loss: 0.8892, LR: 0.000060
2025-05-17 17:53:30,214 [INFO] Epoch 13/15 - Policy Loss: 0.7612, Value Loss: 0.1271, Total Loss: 0.8883, LR: 0.001690
2025-05-17 17:54:14,157 [INFO] Epoch 14/15 - Policy Loss: 0.7604, Value Loss: 0.1266, Total Loss: 0.8870, LR: 0.003340
2025-05-17 17:54:58,242 [INFO] Epoch 15/15 - Policy Loss: 0.7601, Value Loss: 0.1262, Total Loss: 0.8863, LR: 0.004990
2025-05-17 17:54:58,263 [INFO] 训练完成，总损失: 0.8863
2025-05-17 17:54:58,263 [INFO] 保存迭代 58 的模型
2025-05-17 17:54:59,430 [INFO] Model saved to ./models/best.pt
2025-05-17 17:55:00,222 [INFO] Model saved to ./models/iteration_58.pt
2025-05-17 17:55:00,223 [INFO] 所有训练迭代完成
2025-05-17 17:55:00,223 [INFO] 开始迭代 59/300
2025-05-17 17:55:00,223 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 18:09:27,443 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 18:09:27,443 [INFO] 保存训练样本
2025-05-17 18:09:33,321 [INFO] 使用 168880 个样本训练神经网络
2025-05-17 18:09:33,322 [INFO] Training with 168880 examples
2025-05-17 18:09:33,322 [INFO] 总训练步数: 2460, 每轮次批次数: 164
2025-05-17 18:09:33,944 [INFO] 循环学习率周期大小: 492 步
2025-05-17 18:10:16,992 [INFO] Epoch 1/15 - Policy Loss: 0.7872, Value Loss: 0.1285, Total Loss: 0.9156, LR: 0.001690
2025-05-17 18:11:00,483 [INFO] Epoch 2/15 - Policy Loss: 0.7776, Value Loss: 0.1269, Total Loss: 0.9045, LR: 0.003340
2025-05-17 18:11:43,905 [INFO] Epoch 3/15 - Policy Loss: 0.7760, Value Loss: 0.1267, Total Loss: 0.9027, LR: 0.004990
2025-05-17 18:12:27,807 [INFO] Epoch 4/15 - Policy Loss: 0.7743, Value Loss: 0.1250, Total Loss: 0.8993, LR: 0.003360
2025-05-17 18:13:11,798 [INFO] Epoch 5/15 - Policy Loss: 0.7715, Value Loss: 0.1236, Total Loss: 0.8951, LR: 0.001710
2025-05-17 18:13:55,841 [INFO] Epoch 6/15 - Policy Loss: 0.7691, Value Loss: 0.1225, Total Loss: 0.8916, LR: 0.000060
2025-05-17 18:14:39,879 [INFO] Epoch 7/15 - Policy Loss: 0.7673, Value Loss: 0.1212, Total Loss: 0.8884, LR: 0.001690
2025-05-17 18:15:23,979 [INFO] Epoch 8/15 - Policy Loss: 0.7654, Value Loss: 0.1201, Total Loss: 0.8855, LR: 0.003340
2025-05-17 18:16:08,200 [INFO] Epoch 9/15 - Policy Loss: 0.7651, Value Loss: 0.1196, Total Loss: 0.8846, LR: 0.004990
2025-05-17 18:16:52,385 [INFO] Epoch 10/15 - Policy Loss: 0.7646, Value Loss: 0.1193, Total Loss: 0.8839, LR: 0.003360
2025-05-17 18:17:36,417 [INFO] Epoch 11/15 - Policy Loss: 0.7639, Value Loss: 0.1191, Total Loss: 0.8830, LR: 0.001710
2025-05-17 18:18:20,540 [INFO] Epoch 12/15 - Policy Loss: 0.7632, Value Loss: 0.1187, Total Loss: 0.8819, LR: 0.000060
2025-05-17 18:19:04,637 [INFO] Epoch 13/15 - Policy Loss: 0.7623, Value Loss: 0.1183, Total Loss: 0.8806, LR: 0.001690
2025-05-17 18:19:48,647 [INFO] Epoch 14/15 - Policy Loss: 0.7615, Value Loss: 0.1180, Total Loss: 0.8796, LR: 0.003340
2025-05-17 18:20:33,533 [INFO] Epoch 15/15 - Policy Loss: 0.7612, Value Loss: 0.1181, Total Loss: 0.8792, LR: 0.004990
2025-05-17 18:20:33,562 [INFO] 训练完成，总损失: 0.8792
2025-05-17 18:20:33,562 [INFO] 保存迭代 59 的模型
2025-05-17 18:20:34,703 [INFO] Model saved to ./models/best.pt
2025-05-17 18:20:35,517 [INFO] Model saved to ./models/iteration_59.pt
2025-05-17 18:20:35,518 [INFO] 所有训练迭代完成
2025-05-17 18:20:35,518 [INFO] 开始迭代 60/300
2025-05-17 18:20:35,518 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 18:35:39,119 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 18:35:39,119 [INFO] 保存训练样本
2025-05-17 18:35:43,692 [INFO] 使用 168728 个样本训练神经网络
2025-05-17 18:35:43,692 [INFO] Training with 168728 examples
2025-05-17 18:35:43,693 [INFO] 总训练步数: 2460, 每轮次批次数: 164
2025-05-17 18:35:44,041 [INFO] 循环学习率周期大小: 492 步
2025-05-17 18:36:27,280 [INFO] Epoch 1/15 - Policy Loss: 0.7793, Value Loss: 0.1328, Total Loss: 0.9121, LR: 0.001690
2025-05-17 18:37:10,582 [INFO] Epoch 2/15 - Policy Loss: 0.7769, Value Loss: 0.1307, Total Loss: 0.9077, LR: 0.003340
2025-05-17 18:37:53,954 [INFO] Epoch 3/15 - Policy Loss: 0.7737, Value Loss: 0.1309, Total Loss: 0.9046, LR: 0.004990
2025-05-17 18:38:37,332 [INFO] Epoch 4/15 - Policy Loss: 0.7736, Value Loss: 0.1316, Total Loss: 0.9052, LR: 0.003360
2025-05-17 18:39:21,032 [INFO] Epoch 5/15 - Policy Loss: 0.7712, Value Loss: 0.1309, Total Loss: 0.9021, LR: 0.001710
2025-05-17 18:40:04,594 [INFO] Epoch 6/15 - Policy Loss: 0.7687, Value Loss: 0.1298, Total Loss: 0.8985, LR: 0.000060
2025-05-17 18:40:48,124 [INFO] Epoch 7/15 - Policy Loss: 0.7662, Value Loss: 0.1282, Total Loss: 0.8944, LR: 0.001690
2025-05-17 18:41:31,538 [INFO] Epoch 8/15 - Policy Loss: 0.7645, Value Loss: 0.1270, Total Loss: 0.8916, LR: 0.003340
2025-05-17 18:42:15,181 [INFO] Epoch 9/15 - Policy Loss: 0.7636, Value Loss: 0.1263, Total Loss: 0.8899, LR: 0.004990
2025-05-17 18:42:59,162 [INFO] Epoch 10/15 - Policy Loss: 0.7631, Value Loss: 0.1257, Total Loss: 0.8888, LR: 0.003360
2025-05-17 18:43:42,796 [INFO] Epoch 11/15 - Policy Loss: 0.7619, Value Loss: 0.1250, Total Loss: 0.8869, LR: 0.001710
2025-05-17 18:44:26,363 [INFO] Epoch 12/15 - Policy Loss: 0.7608, Value Loss: 0.1243, Total Loss: 0.8851, LR: 0.000060
2025-05-17 18:45:09,821 [INFO] Epoch 13/15 - Policy Loss: 0.7598, Value Loss: 0.1236, Total Loss: 0.8834, LR: 0.001690
2025-05-17 18:45:53,476 [INFO] Epoch 14/15 - Policy Loss: 0.7588, Value Loss: 0.1232, Total Loss: 0.8820, LR: 0.003340
2025-05-17 18:46:37,470 [INFO] Epoch 15/15 - Policy Loss: 0.7583, Value Loss: 0.1228, Total Loss: 0.8811, LR: 0.004990
2025-05-17 18:46:37,498 [INFO] 训练完成，总损失: 0.8811
2025-05-17 18:46:37,498 [INFO] 保存迭代 60 的模型
2025-05-17 18:46:38,721 [INFO] Model saved to ./models/best.pt
2025-05-17 18:46:39,574 [INFO] Model saved to ./models/iteration_60.pt
2025-05-17 18:46:39,574 [INFO] 所有训练迭代完成
2025-05-17 18:46:39,574 [INFO] 开始迭代 61/300
2025-05-17 18:46:39,575 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 19:02:14,791 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 19:02:14,791 [INFO] 保存训练样本
2025-05-17 19:02:20,180 [INFO] 使用 169216 个样本训练神经网络
2025-05-17 19:02:20,180 [INFO] Training with 169216 examples
2025-05-17 19:02:20,181 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 19:02:20,243 [INFO] 循环学习率周期大小: 495 步
2025-05-17 19:03:03,769 [INFO] Epoch 1/15 - Policy Loss: 0.7711, Value Loss: 0.1207, Total Loss: 0.8919, LR: 0.001690
2025-05-17 19:03:47,351 [INFO] Epoch 2/15 - Policy Loss: 0.7677, Value Loss: 0.1191, Total Loss: 0.8868, LR: 0.003340
2025-05-17 19:04:31,237 [INFO] Epoch 3/15 - Policy Loss: 0.7652, Value Loss: 0.1205, Total Loss: 0.8857, LR: 0.004990
2025-05-17 19:05:27,653 [INFO] Epoch 4/15 - Policy Loss: 0.7663, Value Loss: 0.1203, Total Loss: 0.8866, LR: 0.003360
2025-05-17 19:06:48,790 [INFO] Epoch 5/15 - Policy Loss: 0.7632, Value Loss: 0.1189, Total Loss: 0.8821, LR: 0.001710
2025-05-17 19:07:55,308 [INFO] Epoch 6/15 - Policy Loss: 0.7607, Value Loss: 0.1180, Total Loss: 0.8787, LR: 0.000060
2025-05-17 19:08:39,303 [INFO] Epoch 7/15 - Policy Loss: 0.7585, Value Loss: 0.1170, Total Loss: 0.8755, LR: 0.001690
2025-05-17 19:09:23,461 [INFO] Epoch 8/15 - Policy Loss: 0.7574, Value Loss: 0.1167, Total Loss: 0.8740, LR: 0.003340
2025-05-17 19:10:07,479 [INFO] Epoch 9/15 - Policy Loss: 0.7558, Value Loss: 0.1160, Total Loss: 0.8718, LR: 0.004990
2025-05-17 19:10:51,626 [INFO] Epoch 10/15 - Policy Loss: 0.7551, Value Loss: 0.1157, Total Loss: 0.8708, LR: 0.003360
2025-05-17 19:11:50,337 [INFO] Epoch 11/15 - Policy Loss: 0.7547, Value Loss: 0.1154, Total Loss: 0.8701, LR: 0.001710
2025-05-17 19:13:14,361 [INFO] Epoch 12/15 - Policy Loss: 0.7536, Value Loss: 0.1150, Total Loss: 0.8686, LR: 0.000060
2025-05-17 19:14:36,782 [INFO] Epoch 13/15 - Policy Loss: 0.7525, Value Loss: 0.1145, Total Loss: 0.8670, LR: 0.001690
2025-05-17 19:15:22,955 [INFO] Epoch 14/15 - Policy Loss: 0.7520, Value Loss: 0.1141, Total Loss: 0.8661, LR: 0.003340
2025-05-17 19:16:06,693 [INFO] Epoch 15/15 - Policy Loss: 0.7517, Value Loss: 0.1141, Total Loss: 0.8658, LR: 0.004990
2025-05-17 19:16:06,714 [INFO] 训练完成，总损失: 0.8658
2025-05-17 19:16:06,714 [INFO] 保存迭代 61 的模型
2025-05-17 19:16:07,856 [INFO] Model saved to ./models/best.pt
2025-05-17 19:16:08,686 [INFO] Model saved to ./models/iteration_61.pt
2025-05-17 19:16:08,686 [INFO] 所有训练迭代完成
2025-05-17 19:16:08,686 [INFO] 开始迭代 62/300
2025-05-17 19:16:08,687 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 19:33:28,813 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 19:33:28,813 [INFO] 保存训练样本
2025-05-17 19:33:33,646 [INFO] 使用 169320 个样本训练神经网络
2025-05-17 19:33:33,647 [INFO] Training with 169320 examples
2025-05-17 19:33:33,647 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 19:33:34,078 [INFO] 循环学习率周期大小: 495 步
2025-05-17 19:34:17,453 [INFO] Epoch 1/15 - Policy Loss: 0.7860, Value Loss: 0.1375, Total Loss: 0.9235, LR: 0.001690
2025-05-17 19:35:00,753 [INFO] Epoch 2/15 - Policy Loss: 0.7791, Value Loss: 0.1341, Total Loss: 0.9133, LR: 0.003340
2025-05-17 19:35:44,172 [INFO] Epoch 3/15 - Policy Loss: 0.7754, Value Loss: 0.1315, Total Loss: 0.9068, LR: 0.004990
2025-05-17 19:36:27,642 [INFO] Epoch 4/15 - Policy Loss: 0.7744, Value Loss: 0.1303, Total Loss: 0.9047, LR: 0.003360
2025-05-17 19:37:11,298 [INFO] Epoch 5/15 - Policy Loss: 0.7701, Value Loss: 0.1276, Total Loss: 0.8977, LR: 0.001710
2025-05-17 19:37:54,792 [INFO] Epoch 6/15 - Policy Loss: 0.7673, Value Loss: 0.1259, Total Loss: 0.8932, LR: 0.000060
2025-05-17 19:38:38,599 [INFO] Epoch 7/15 - Policy Loss: 0.7642, Value Loss: 0.1243, Total Loss: 0.8885, LR: 0.001690
2025-05-17 19:39:31,079 [INFO] Epoch 8/15 - Policy Loss: 0.7620, Value Loss: 0.1227, Total Loss: 0.8847, LR: 0.003340
2025-05-17 19:40:35,542 [INFO] Epoch 9/15 - Policy Loss: 0.7606, Value Loss: 0.1218, Total Loss: 0.8824, LR: 0.004990
2025-05-17 19:41:19,238 [INFO] Epoch 10/15 - Policy Loss: 0.7601, Value Loss: 0.1211, Total Loss: 0.8812, LR: 0.003360
2025-05-17 19:42:05,880 [INFO] Epoch 11/15 - Policy Loss: 0.7594, Value Loss: 0.1202, Total Loss: 0.8795, LR: 0.001710
2025-05-17 19:43:02,412 [INFO] Epoch 12/15 - Policy Loss: 0.7580, Value Loss: 0.1192, Total Loss: 0.8772, LR: 0.000060
2025-05-17 19:43:59,247 [INFO] Epoch 13/15 - Policy Loss: 0.7568, Value Loss: 0.1183, Total Loss: 0.8751, LR: 0.001690
2025-05-17 19:44:56,088 [INFO] Epoch 14/15 - Policy Loss: 0.7557, Value Loss: 0.1175, Total Loss: 0.8732, LR: 0.003340
2025-05-17 19:45:52,693 [INFO] Epoch 15/15 - Policy Loss: 0.7551, Value Loss: 0.1169, Total Loss: 0.8719, LR: 0.004990
2025-05-17 19:45:52,715 [INFO] 训练完成，总损失: 0.8719
2025-05-17 19:45:52,715 [INFO] 保存迭代 62 的模型
2025-05-17 19:45:54,350 [INFO] Model saved to ./models/best.pt
2025-05-17 19:45:55,332 [INFO] Model saved to ./models/iteration_62.pt
2025-05-17 19:45:55,333 [INFO] 所有训练迭代完成
2025-05-17 19:45:55,333 [INFO] 开始迭代 63/300
2025-05-17 19:45:55,333 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 20:02:48,579 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 20:02:48,580 [INFO] 保存训练样本
2025-05-17 20:02:55,118 [INFO] 使用 169408 个样本训练神经网络
2025-05-17 20:02:55,118 [INFO] Training with 169408 examples
2025-05-17 20:02:55,119 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 20:02:55,794 [INFO] 循环学习率周期大小: 495 步
2025-05-17 20:03:58,021 [INFO] Epoch 1/15 - Policy Loss: 0.7675, Value Loss: 0.1234, Total Loss: 0.8909, LR: 0.001690
2025-05-17 20:05:00,279 [INFO] Epoch 2/15 - Policy Loss: 0.7642, Value Loss: 0.1221, Total Loss: 0.8863, LR: 0.003340
2025-05-17 20:06:02,310 [INFO] Epoch 3/15 - Policy Loss: 0.7628, Value Loss: 0.1212, Total Loss: 0.8839, LR: 0.004990
2025-05-17 20:07:04,711 [INFO] Epoch 4/15 - Policy Loss: 0.7621, Value Loss: 0.1219, Total Loss: 0.8840, LR: 0.003360
2025-05-17 20:08:07,046 [INFO] Epoch 5/15 - Policy Loss: 0.7590, Value Loss: 0.1208, Total Loss: 0.8798, LR: 0.001710
2025-05-17 20:09:10,101 [INFO] Epoch 6/15 - Policy Loss: 0.7562, Value Loss: 0.1196, Total Loss: 0.8759, LR: 0.000060
2025-05-17 20:10:13,079 [INFO] Epoch 7/15 - Policy Loss: 0.7549, Value Loss: 0.1191, Total Loss: 0.8740, LR: 0.001690
2025-05-17 20:11:15,805 [INFO] Epoch 8/15 - Policy Loss: 0.7536, Value Loss: 0.1187, Total Loss: 0.8722, LR: 0.003340
2025-05-17 20:12:18,212 [INFO] Epoch 9/15 - Policy Loss: 0.7530, Value Loss: 0.1183, Total Loss: 0.8712, LR: 0.004990
2025-05-17 20:13:20,259 [INFO] Epoch 10/15 - Policy Loss: 0.7524, Value Loss: 0.1180, Total Loss: 0.8703, LR: 0.003360
2025-05-17 20:14:22,503 [INFO] Epoch 11/15 - Policy Loss: 0.7516, Value Loss: 0.1176, Total Loss: 0.8692, LR: 0.001710
2025-05-17 20:15:24,182 [INFO] Epoch 12/15 - Policy Loss: 0.7509, Value Loss: 0.1171, Total Loss: 0.8680, LR: 0.000060
2025-05-17 20:16:26,837 [INFO] Epoch 13/15 - Policy Loss: 0.7500, Value Loss: 0.1166, Total Loss: 0.8665, LR: 0.001690
2025-05-17 20:17:28,509 [INFO] Epoch 14/15 - Policy Loss: 0.7490, Value Loss: 0.1163, Total Loss: 0.8654, LR: 0.003340
2025-05-17 20:18:30,087 [INFO] Epoch 15/15 - Policy Loss: 0.7483, Value Loss: 0.1161, Total Loss: 0.8644, LR: 0.004990
2025-05-17 20:18:30,112 [INFO] 训练完成，总损失: 0.8644
2025-05-17 20:18:30,113 [INFO] 保存迭代 63 的模型
2025-05-17 20:18:31,798 [INFO] Model saved to ./models/best.pt
2025-05-17 20:18:32,802 [INFO] Model saved to ./models/iteration_63.pt
2025-05-17 20:18:32,803 [INFO] 所有训练迭代完成
2025-05-17 20:18:32,803 [INFO] 开始迭代 64/300
2025-05-17 20:18:32,803 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 20:36:44,844 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 20:36:44,845 [INFO] 保存训练样本
2025-05-17 20:36:50,402 [INFO] 使用 169400 个样本训练神经网络
2025-05-17 20:36:50,403 [INFO] Training with 169400 examples
2025-05-17 20:36:50,403 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 20:36:50,882 [INFO] 循环学习率周期大小: 495 步
2025-05-17 20:37:51,441 [INFO] Epoch 1/15 - Policy Loss: 0.7678, Value Loss: 0.1278, Total Loss: 0.8955, LR: 0.001690
2025-05-17 20:38:52,066 [INFO] Epoch 2/15 - Policy Loss: 0.7658, Value Loss: 0.1255, Total Loss: 0.8913, LR: 0.003340
2025-05-17 20:39:52,890 [INFO] Epoch 3/15 - Policy Loss: 0.7638, Value Loss: 0.1244, Total Loss: 0.8882, LR: 0.004990
2025-05-17 20:40:54,504 [INFO] Epoch 4/15 - Policy Loss: 0.7624, Value Loss: 0.1234, Total Loss: 0.8859, LR: 0.003360
2025-05-17 20:41:54,965 [INFO] Epoch 5/15 - Policy Loss: 0.7601, Value Loss: 0.1217, Total Loss: 0.8818, LR: 0.001710
2025-05-17 20:42:56,756 [INFO] Epoch 6/15 - Policy Loss: 0.7574, Value Loss: 0.1198, Total Loss: 0.8771, LR: 0.000060
2025-05-17 20:43:58,262 [INFO] Epoch 7/15 - Policy Loss: 0.7556, Value Loss: 0.1183, Total Loss: 0.8738, LR: 0.001690
2025-05-17 20:45:00,097 [INFO] Epoch 8/15 - Policy Loss: 0.7540, Value Loss: 0.1171, Total Loss: 0.8711, LR: 0.003340
2025-05-17 20:46:01,959 [INFO] Epoch 9/15 - Policy Loss: 0.7530, Value Loss: 0.1163, Total Loss: 0.8693, LR: 0.004990
2025-05-17 20:47:03,890 [INFO] Epoch 10/15 - Policy Loss: 0.7521, Value Loss: 0.1158, Total Loss: 0.8679, LR: 0.003360
2025-05-17 20:48:04,993 [INFO] Epoch 11/15 - Policy Loss: 0.7509, Value Loss: 0.1149, Total Loss: 0.8658, LR: 0.001710
2025-05-17 20:49:06,634 [INFO] Epoch 12/15 - Policy Loss: 0.7500, Value Loss: 0.1141, Total Loss: 0.8641, LR: 0.000060
2025-05-17 20:50:07,526 [INFO] Epoch 13/15 - Policy Loss: 0.7486, Value Loss: 0.1134, Total Loss: 0.8620, LR: 0.001690
2025-05-17 20:51:08,784 [INFO] Epoch 14/15 - Policy Loss: 0.7475, Value Loss: 0.1129, Total Loss: 0.8604, LR: 0.003340
2025-05-17 20:52:10,229 [INFO] Epoch 15/15 - Policy Loss: 0.7471, Value Loss: 0.1124, Total Loss: 0.8595, LR: 0.004990
2025-05-17 20:52:10,253 [INFO] 训练完成，总损失: 0.8595
2025-05-17 20:52:10,253 [INFO] 保存迭代 64 的模型
2025-05-17 20:52:11,977 [INFO] Model saved to ./models/best.pt
2025-05-17 20:52:12,969 [INFO] Model saved to ./models/iteration_64.pt
2025-05-17 20:52:12,969 [INFO] 所有训练迭代完成
2025-05-17 20:52:12,969 [INFO] 开始迭代 65/300
2025-05-17 20:52:12,969 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 21:09:30,048 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 21:09:30,049 [INFO] 保存训练样本
2025-05-17 21:09:36,484 [INFO] 使用 169344 个样本训练神经网络
2025-05-17 21:09:36,485 [INFO] Training with 169344 examples
2025-05-17 21:09:36,485 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 21:09:36,559 [INFO] 循环学习率周期大小: 495 步
2025-05-17 21:10:34,907 [INFO] Epoch 1/15 - Policy Loss: 0.7618, Value Loss: 0.1175, Total Loss: 0.8793, LR: 0.001690
2025-05-17 21:11:34,904 [INFO] Epoch 2/15 - Policy Loss: 0.7593, Value Loss: 0.1156, Total Loss: 0.8749, LR: 0.003340
2025-05-17 21:12:33,859 [INFO] Epoch 3/15 - Policy Loss: 0.7584, Value Loss: 0.1152, Total Loss: 0.8736, LR: 0.004990
2025-05-17 21:13:32,511 [INFO] Epoch 4/15 - Policy Loss: 0.7569, Value Loss: 0.1157, Total Loss: 0.8726, LR: 0.003360
2025-05-17 21:14:32,578 [INFO] Epoch 5/15 - Policy Loss: 0.7557, Value Loss: 0.1149, Total Loss: 0.8706, LR: 0.001710
2025-05-17 21:15:32,152 [INFO] Epoch 6/15 - Policy Loss: 0.7529, Value Loss: 0.1139, Total Loss: 0.8667, LR: 0.000060
2025-05-17 21:16:31,940 [INFO] Epoch 7/15 - Policy Loss: 0.7510, Value Loss: 0.1128, Total Loss: 0.8638, LR: 0.001690
2025-05-17 21:17:28,347 [INFO] Epoch 8/15 - Policy Loss: 0.7490, Value Loss: 0.1121, Total Loss: 0.8611, LR: 0.003340
2025-05-17 21:18:24,257 [INFO] Epoch 9/15 - Policy Loss: 0.7480, Value Loss: 0.1113, Total Loss: 0.8593, LR: 0.004990
2025-05-17 21:19:20,127 [INFO] Epoch 10/15 - Policy Loss: 0.7472, Value Loss: 0.1111, Total Loss: 0.8584, LR: 0.003360
2025-05-17 21:20:16,373 [INFO] Epoch 11/15 - Policy Loss: 0.7465, Value Loss: 0.1106, Total Loss: 0.8571, LR: 0.001710
2025-05-17 21:21:12,597 [INFO] Epoch 12/15 - Policy Loss: 0.7453, Value Loss: 0.1100, Total Loss: 0.8553, LR: 0.000060
2025-05-17 21:22:10,144 [INFO] Epoch 13/15 - Policy Loss: 0.7443, Value Loss: 0.1095, Total Loss: 0.8538, LR: 0.001690
2025-05-17 21:23:11,273 [INFO] Epoch 14/15 - Policy Loss: 0.7441, Value Loss: 0.1092, Total Loss: 0.8533, LR: 0.003340
2025-05-17 21:24:09,775 [INFO] Epoch 15/15 - Policy Loss: 0.7435, Value Loss: 0.1089, Total Loss: 0.8524, LR: 0.004990
2025-05-17 21:24:09,797 [INFO] 训练完成，总损失: 0.8524
2025-05-17 21:24:09,797 [INFO] 保存迭代 65 的模型
2025-05-17 21:24:11,491 [INFO] Model saved to ./models/best.pt
2025-05-17 21:24:12,475 [INFO] Model saved to ./models/iteration_65.pt
2025-05-17 21:24:12,475 [INFO] 所有训练迭代完成
2025-05-17 21:24:12,475 [INFO] 开始迭代 66/300
2025-05-17 21:24:12,475 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 21:39:41,966 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 21:39:41,967 [INFO] 保存训练样本
2025-05-17 21:39:48,041 [INFO] 使用 169056 个样本训练神经网络
2025-05-17 21:39:48,041 [INFO] Training with 169056 examples
2025-05-17 21:39:48,041 [INFO] 总训练步数: 2475, 每轮次批次数: 165
2025-05-17 21:39:48,615 [INFO] 循环学习率周期大小: 495 步
2025-05-17 21:40:45,134 [INFO] Epoch 1/15 - Policy Loss: 0.7572, Value Loss: 0.1158, Total Loss: 0.8730, LR: 0.001690
2025-05-17 21:41:39,825 [INFO] Epoch 2/15 - Policy Loss: 0.7574, Value Loss: 0.1165, Total Loss: 0.8739, LR: 0.003340
2025-05-17 21:42:31,986 [INFO] Epoch 3/15 - Policy Loss: 0.7556, Value Loss: 0.1156, Total Loss: 0.8712, LR: 0.004990
2025-05-17 21:43:21,855 [INFO] Epoch 4/15 - Policy Loss: 0.7556, Value Loss: 0.1159, Total Loss: 0.8715, LR: 0.003360
2025-05-17 21:44:11,990 [INFO] Epoch 5/15 - Policy Loss: 0.7526, Value Loss: 0.1152, Total Loss: 0.8678, LR: 0.001710
2025-05-17 21:45:02,331 [INFO] Epoch 6/15 - Policy Loss: 0.7507, Value Loss: 0.1144, Total Loss: 0.8650, LR: 0.000060
2025-05-17 21:45:52,057 [INFO] Epoch 7/15 - Policy Loss: 0.7487, Value Loss: 0.1136, Total Loss: 0.8623, LR: 0.001690
2025-05-17 21:46:41,897 [INFO] Epoch 8/15 - Policy Loss: 0.7469, Value Loss: 0.1129, Total Loss: 0.8598, LR: 0.003340
2025-05-17 21:47:31,979 [INFO] Epoch 9/15 - Policy Loss: 0.7460, Value Loss: 0.1124, Total Loss: 0.8585, LR: 0.004990
2025-05-17 21:48:22,335 [INFO] Epoch 10/15 - Policy Loss: 0.7459, Value Loss: 0.1128, Total Loss: 0.8587, LR: 0.003360
2025-05-17 21:49:12,399 [INFO] Epoch 11/15 - Policy Loss: 0.7451, Value Loss: 0.1124, Total Loss: 0.8575, LR: 0.001710
2025-05-17 21:50:02,194 [INFO] Epoch 12/15 - Policy Loss: 0.7442, Value Loss: 0.1120, Total Loss: 0.8562, LR: 0.000060
2025-05-17 21:50:52,763 [INFO] Epoch 13/15 - Policy Loss: 0.7434, Value Loss: 0.1116, Total Loss: 0.8550, LR: 0.001690
2025-05-17 21:51:42,772 [INFO] Epoch 14/15 - Policy Loss: 0.7426, Value Loss: 0.1112, Total Loss: 0.8538, LR: 0.003340
2025-05-17 21:52:33,324 [INFO] Epoch 15/15 - Policy Loss: 0.7423, Value Loss: 0.1111, Total Loss: 0.8533, LR: 0.004990
2025-05-17 21:52:33,346 [INFO] 训练完成，总损失: 0.8533
2025-05-17 21:52:33,346 [INFO] 保存迭代 66 的模型
2025-05-17 21:52:34,855 [INFO] Model saved to ./models/best.pt
2025-05-17 21:52:35,739 [INFO] Model saved to ./models/iteration_66.pt
2025-05-17 21:52:35,739 [INFO] 所有训练迭代完成
2025-05-17 21:52:35,739 [INFO] 开始迭代 67/300
2025-05-17 21:52:35,740 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 22:06:30,771 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 22:06:30,772 [INFO] 保存训练样本
2025-05-17 22:06:35,523 [INFO] 使用 168040 个样本训练神经网络
2025-05-17 22:06:35,523 [INFO] Training with 168040 examples
2025-05-17 22:06:35,523 [INFO] 总训练步数: 2460, 每轮次批次数: 164
2025-05-17 22:06:35,939 [INFO] 循环学习率周期大小: 492 步
2025-05-17 22:07:25,730 [INFO] Epoch 1/15 - Policy Loss: 0.7562, Value Loss: 0.1147, Total Loss: 0.8708, LR: 0.001690
2025-05-17 22:08:15,447 [INFO] Epoch 2/15 - Policy Loss: 0.7521, Value Loss: 0.1118, Total Loss: 0.8639, LR: 0.003340
2025-05-17 22:09:04,593 [INFO] Epoch 3/15 - Policy Loss: 0.7502, Value Loss: 0.1111, Total Loss: 0.8613, LR: 0.004990
2025-05-17 22:09:54,389 [INFO] Epoch 4/15 - Policy Loss: 0.7481, Value Loss: 0.1107, Total Loss: 0.8588, LR: 0.003360
2025-05-17 22:10:43,639 [INFO] Epoch 5/15 - Policy Loss: 0.7450, Value Loss: 0.1100, Total Loss: 0.8549, LR: 0.001710
2025-05-17 22:11:33,677 [INFO] Epoch 6/15 - Policy Loss: 0.7433, Value Loss: 0.1094, Total Loss: 0.8526, LR: 0.000060
2025-05-17 22:12:23,538 [INFO] Epoch 7/15 - Policy Loss: 0.7420, Value Loss: 0.1087, Total Loss: 0.8507, LR: 0.001690
2025-05-17 22:13:13,435 [INFO] Epoch 8/15 - Policy Loss: 0.7404, Value Loss: 0.1082, Total Loss: 0.8486, LR: 0.003340
2025-05-17 22:14:03,213 [INFO] Epoch 9/15 - Policy Loss: 0.7400, Value Loss: 0.1077, Total Loss: 0.8477, LR: 0.004990
2025-05-17 22:14:53,580 [INFO] Epoch 10/15 - Policy Loss: 0.7400, Value Loss: 0.1075, Total Loss: 0.8475, LR: 0.003360
2025-05-17 22:15:43,247 [INFO] Epoch 11/15 - Policy Loss: 0.7395, Value Loss: 0.1072, Total Loss: 0.8466, LR: 0.001710
2025-05-17 22:16:32,871 [INFO] Epoch 12/15 - Policy Loss: 0.7386, Value Loss: 0.1067, Total Loss: 0.8453, LR: 0.000060
2025-05-17 22:17:22,885 [INFO] Epoch 13/15 - Policy Loss: 0.7373, Value Loss: 0.1064, Total Loss: 0.8437, LR: 0.001690
2025-05-17 22:18:12,565 [INFO] Epoch 14/15 - Policy Loss: 0.7365, Value Loss: 0.1061, Total Loss: 0.8426, LR: 0.003340
2025-05-17 22:19:02,136 [INFO] Epoch 15/15 - Policy Loss: 0.7365, Value Loss: 0.1059, Total Loss: 0.8424, LR: 0.004990
2025-05-17 22:19:02,156 [INFO] 训练完成，总损失: 0.8424
2025-05-17 22:19:02,156 [INFO] 保存迭代 67 的模型
2025-05-17 22:19:03,490 [INFO] Model saved to ./models/best.pt
2025-05-17 22:19:04,388 [INFO] Model saved to ./models/iteration_67.pt
2025-05-17 22:19:04,389 [INFO] 所有训练迭代完成
2025-05-17 22:19:04,389 [INFO] 开始迭代 68/300
2025-05-17 22:19:04,389 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 22:33:43,381 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 22:33:43,382 [INFO] 保存训练样本
2025-05-17 22:33:48,217 [INFO] 使用 167712 个样本训练神经网络
2025-05-17 22:33:48,217 [INFO] Training with 167712 examples
2025-05-17 22:33:48,217 [INFO] 总训练步数: 2445, 每轮次批次数: 163
2025-05-17 22:33:48,273 [INFO] 循环学习率周期大小: 489 步
2025-05-17 22:34:37,525 [INFO] Epoch 1/15 - Policy Loss: 0.7479, Value Loss: 0.1050, Total Loss: 0.8529, LR: 0.001690
2025-05-17 22:35:26,797 [INFO] Epoch 2/15 - Policy Loss: 0.7455, Value Loss: 0.1035, Total Loss: 0.8490, LR: 0.003340
2025-05-17 22:36:16,176 [INFO] Epoch 3/15 - Policy Loss: 0.7438, Value Loss: 0.1037, Total Loss: 0.8475, LR: 0.004990
2025-05-17 22:37:05,642 [INFO] Epoch 4/15 - Policy Loss: 0.7437, Value Loss: 0.1042, Total Loss: 0.8478, LR: 0.003360
2025-05-17 22:37:55,747 [INFO] Epoch 5/15 - Policy Loss: 0.7413, Value Loss: 0.1035, Total Loss: 0.8448, LR: 0.001710
2025-05-17 22:38:44,567 [INFO] Epoch 6/15 - Policy Loss: 0.7386, Value Loss: 0.1029, Total Loss: 0.8415, LR: 0.000060
2025-05-17 22:39:31,565 [INFO] Epoch 7/15 - Policy Loss: 0.7368, Value Loss: 0.1022, Total Loss: 0.8390, LR: 0.001690
2025-05-17 22:40:18,255 [INFO] Epoch 8/15 - Policy Loss: 0.7357, Value Loss: 0.1020, Total Loss: 0.8377, LR: 0.003340
2025-05-17 22:41:04,622 [INFO] Epoch 9/15 - Policy Loss: 0.7354, Value Loss: 0.1018, Total Loss: 0.8371, LR: 0.004990
2025-05-17 22:41:51,163 [INFO] Epoch 10/15 - Policy Loss: 0.7350, Value Loss: 0.1015, Total Loss: 0.8365, LR: 0.003360
2025-05-17 22:42:37,927 [INFO] Epoch 11/15 - Policy Loss: 0.7343, Value Loss: 0.1012, Total Loss: 0.8356, LR: 0.001710
2025-05-17 22:43:24,797 [INFO] Epoch 12/15 - Policy Loss: 0.7336, Value Loss: 0.1011, Total Loss: 0.8347, LR: 0.000060
2025-05-17 22:44:11,633 [INFO] Epoch 13/15 - Policy Loss: 0.7330, Value Loss: 0.1009, Total Loss: 0.8338, LR: 0.001690
2025-05-17 22:44:58,956 [INFO] Epoch 14/15 - Policy Loss: 0.7326, Value Loss: 0.1004, Total Loss: 0.8330, LR: 0.003340
2025-05-17 22:45:45,607 [INFO] Epoch 15/15 - Policy Loss: 0.7326, Value Loss: 0.1009, Total Loss: 0.8335, LR: 0.004990
2025-05-17 22:45:45,626 [INFO] 训练完成，总损失: 0.8335
2025-05-17 22:45:45,626 [INFO] 保存迭代 68 的模型
2025-05-17 22:45:46,877 [INFO] Model saved to ./models/best.pt
2025-05-17 22:45:47,600 [INFO] Model saved to ./models/iteration_68.pt
2025-05-17 22:45:47,600 [INFO] 所有训练迭代完成
2025-05-17 22:45:47,600 [INFO] 开始迭代 69/300
2025-05-17 22:45:47,600 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 22:57:41,791 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 22:57:41,792 [INFO] 保存训练样本
2025-05-17 22:57:46,609 [INFO] 使用 166280 个样本训练神经网络
2025-05-17 22:57:46,609 [INFO] Training with 166280 examples
2025-05-17 22:57:46,610 [INFO] 总训练步数: 2430, 每轮次批次数: 162
2025-05-17 22:57:47,030 [INFO] 循环学习率周期大小: 486 步
2025-05-17 22:58:29,461 [INFO] Epoch 1/15 - Policy Loss: 0.7539, Value Loss: 0.1123, Total Loss: 0.8661, LR: 0.001690
2025-05-17 22:59:11,946 [INFO] Epoch 2/15 - Policy Loss: 0.7502, Value Loss: 0.1070, Total Loss: 0.8572, LR: 0.003340
2025-05-17 22:59:54,449 [INFO] Epoch 3/15 - Policy Loss: 0.7458, Value Loss: 0.1049, Total Loss: 0.8507, LR: 0.004990
2025-05-17 23:00:37,194 [INFO] Epoch 4/15 - Policy Loss: 0.7444, Value Loss: 0.1034, Total Loss: 0.8478, LR: 0.003360
2025-05-17 23:01:20,188 [INFO] Epoch 5/15 - Policy Loss: 0.7422, Value Loss: 0.1021, Total Loss: 0.8443, LR: 0.001710
2025-05-17 23:02:03,248 [INFO] Epoch 6/15 - Policy Loss: 0.7410, Value Loss: 0.1008, Total Loss: 0.8418, LR: 0.000060
2025-05-17 23:02:46,193 [INFO] Epoch 7/15 - Policy Loss: 0.7393, Value Loss: 0.1000, Total Loss: 0.8394, LR: 0.001690
2025-05-17 23:03:29,006 [INFO] Epoch 8/15 - Policy Loss: 0.7378, Value Loss: 0.0994, Total Loss: 0.8372, LR: 0.003340
2025-05-17 23:04:12,140 [INFO] Epoch 9/15 - Policy Loss: 0.7370, Value Loss: 0.0989, Total Loss: 0.8360, LR: 0.004990
2025-05-17 23:04:55,218 [INFO] Epoch 10/15 - Policy Loss: 0.7368, Value Loss: 0.0988, Total Loss: 0.8356, LR: 0.003360
2025-05-17 23:05:38,333 [INFO] Epoch 11/15 - Policy Loss: 0.7365, Value Loss: 0.0983, Total Loss: 0.8348, LR: 0.001710
2025-05-17 23:06:21,535 [INFO] Epoch 12/15 - Policy Loss: 0.7357, Value Loss: 0.0977, Total Loss: 0.8334, LR: 0.000060
2025-05-17 23:07:04,817 [INFO] Epoch 13/15 - Policy Loss: 0.7345, Value Loss: 0.0972, Total Loss: 0.8317, LR: 0.001690
2025-05-17 23:07:47,987 [INFO] Epoch 14/15 - Policy Loss: 0.7339, Value Loss: 0.0969, Total Loss: 0.8308, LR: 0.003340
2025-05-17 23:08:33,383 [INFO] Epoch 15/15 - Policy Loss: 0.7336, Value Loss: 0.0967, Total Loss: 0.8303, LR: 0.004990
2025-05-17 23:08:33,403 [INFO] 训练完成，总损失: 0.8303
2025-05-17 23:08:33,403 [INFO] 保存迭代 69 的模型
2025-05-17 23:08:35,628 [INFO] Model saved to ./models/best.pt
2025-05-17 23:08:36,905 [INFO] Model saved to ./models/iteration_69.pt
2025-05-17 23:08:36,906 [INFO] 所有训练迭代完成
2025-05-17 23:08:36,906 [INFO] 开始迭代 70/300
2025-05-17 23:08:36,906 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 23:22:42,132 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 23:22:42,132 [INFO] 保存训练样本
2025-05-17 23:22:46,186 [INFO] 使用 166712 个样本训练神经网络
2025-05-17 23:22:46,186 [INFO] Training with 166712 examples
2025-05-17 23:22:46,186 [INFO] 总训练步数: 2430, 每轮次批次数: 162
2025-05-17 23:22:46,535 [INFO] 循环学习率周期大小: 486 步
2025-05-17 23:23:29,146 [INFO] Epoch 1/15 - Policy Loss: 0.7475, Value Loss: 0.0982, Total Loss: 0.8458, LR: 0.001690
2025-05-17 23:24:11,994 [INFO] Epoch 2/15 - Policy Loss: 0.7442, Value Loss: 0.0982, Total Loss: 0.8423, LR: 0.003340
2025-05-17 23:24:54,835 [INFO] Epoch 3/15 - Policy Loss: 0.7421, Value Loss: 0.0976, Total Loss: 0.8397, LR: 0.004990
2025-05-17 23:25:37,817 [INFO] Epoch 4/15 - Policy Loss: 0.7412, Value Loss: 0.0979, Total Loss: 0.8391, LR: 0.003360
2025-05-17 23:26:20,759 [INFO] Epoch 5/15 - Policy Loss: 0.7393, Value Loss: 0.0973, Total Loss: 0.8367, LR: 0.001710
2025-05-17 23:27:03,629 [INFO] Epoch 6/15 - Policy Loss: 0.7369, Value Loss: 0.0966, Total Loss: 0.8336, LR: 0.000060
2025-05-17 23:27:46,740 [INFO] Epoch 7/15 - Policy Loss: 0.7351, Value Loss: 0.0959, Total Loss: 0.8310, LR: 0.001690
2025-05-17 23:28:29,822 [INFO] Epoch 8/15 - Policy Loss: 0.7348, Value Loss: 0.0957, Total Loss: 0.8305, LR: 0.003340
2025-05-17 23:29:13,053 [INFO] Epoch 9/15 - Policy Loss: 0.7341, Value Loss: 0.0952, Total Loss: 0.8293, LR: 0.004990
2025-05-17 23:29:56,225 [INFO] Epoch 10/15 - Policy Loss: 0.7336, Value Loss: 0.0950, Total Loss: 0.8286, LR: 0.003360
2025-05-17 23:30:39,491 [INFO] Epoch 11/15 - Policy Loss: 0.7329, Value Loss: 0.0950, Total Loss: 0.8279, LR: 0.001710
2025-05-17 23:31:22,753 [INFO] Epoch 12/15 - Policy Loss: 0.7320, Value Loss: 0.0946, Total Loss: 0.8266, LR: 0.000060
2025-05-17 23:32:05,989 [INFO] Epoch 13/15 - Policy Loss: 0.7314, Value Loss: 0.0943, Total Loss: 0.8257, LR: 0.001690
2025-05-17 23:32:49,538 [INFO] Epoch 14/15 - Policy Loss: 0.7308, Value Loss: 0.0939, Total Loss: 0.8247, LR: 0.003340
2025-05-17 23:33:32,919 [INFO] Epoch 15/15 - Policy Loss: 0.7306, Value Loss: 0.0936, Total Loss: 0.8242, LR: 0.004990
2025-05-17 23:33:32,941 [INFO] 训练完成，总损失: 0.8242
2025-05-17 23:33:32,941 [INFO] 保存迭代 70 的模型
2025-05-17 23:33:34,462 [INFO] Model saved to ./models/best.pt
2025-05-17 23:33:35,315 [INFO] Model saved to ./models/iteration_70.pt
2025-05-17 23:33:35,316 [INFO] 所有训练迭代完成
2025-05-17 23:33:35,316 [INFO] 开始迭代 71/300
2025-05-17 23:33:35,316 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-17 23:48:06,101 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-17 23:48:06,101 [INFO] 保存训练样本
2025-05-17 23:48:10,515 [INFO] 使用 166168 个样本训练神经网络
2025-05-17 23:48:10,516 [INFO] Training with 166168 examples
2025-05-17 23:48:10,516 [INFO] 总训练步数: 2430, 每轮次批次数: 162
2025-05-17 23:48:10,866 [INFO] 循环学习率周期大小: 486 步
2025-05-17 23:48:53,710 [INFO] Epoch 1/15 - Policy Loss: 0.7542, Value Loss: 0.1069, Total Loss: 0.8611, LR: 0.001690
2025-05-17 23:49:36,837 [INFO] Epoch 2/15 - Policy Loss: 0.7466, Value Loss: 0.1040, Total Loss: 0.8506, LR: 0.003340
2025-05-17 23:50:19,965 [INFO] Epoch 3/15 - Policy Loss: 0.7446, Value Loss: 0.1058, Total Loss: 0.8504, LR: 0.004990
2025-05-17 23:51:02,730 [INFO] Epoch 4/15 - Policy Loss: 0.7452, Value Loss: 0.1068, Total Loss: 0.8519, LR: 0.003360
2025-05-17 23:51:45,585 [INFO] Epoch 5/15 - Policy Loss: 0.7431, Value Loss: 0.1059, Total Loss: 0.8490, LR: 0.001710
2025-05-17 23:52:28,206 [INFO] Epoch 6/15 - Policy Loss: 0.7408, Value Loss: 0.1048, Total Loss: 0.8456, LR: 0.000060
2025-05-17 23:53:11,219 [INFO] Epoch 7/15 - Policy Loss: 0.7386, Value Loss: 0.1038, Total Loss: 0.8424, LR: 0.001690
2025-05-17 23:54:01,382 [INFO] Epoch 8/15 - Policy Loss: 0.7375, Value Loss: 0.1029, Total Loss: 0.8404, LR: 0.003340
2025-05-17 23:54:44,849 [INFO] Epoch 9/15 - Policy Loss: 0.7369, Value Loss: 0.1018, Total Loss: 0.8388, LR: 0.004990
2025-05-17 23:55:28,045 [INFO] Epoch 10/15 - Policy Loss: 0.7361, Value Loss: 0.1013, Total Loss: 0.8374, LR: 0.003360
2025-05-17 23:56:11,251 [INFO] Epoch 11/15 - Policy Loss: 0.7352, Value Loss: 0.1007, Total Loss: 0.8359, LR: 0.001710
2025-05-17 23:56:54,527 [INFO] Epoch 12/15 - Policy Loss: 0.7345, Value Loss: 0.0998, Total Loss: 0.8343, LR: 0.000060
2025-05-17 23:57:37,902 [INFO] Epoch 13/15 - Policy Loss: 0.7334, Value Loss: 0.0993, Total Loss: 0.8327, LR: 0.001690
2025-05-17 23:58:21,280 [INFO] Epoch 14/15 - Policy Loss: 0.7326, Value Loss: 0.0988, Total Loss: 0.8314, LR: 0.003340
2025-05-17 23:59:04,565 [INFO] Epoch 15/15 - Policy Loss: 0.7321, Value Loss: 0.0985, Total Loss: 0.8306, LR: 0.004990
2025-05-17 23:59:04,583 [INFO] 训练完成，总损失: 0.8306
2025-05-17 23:59:04,583 [INFO] 保存迭代 71 的模型
2025-05-17 23:59:05,821 [INFO] Model saved to ./models/best.pt
2025-05-17 23:59:06,491 [INFO] Model saved to ./models/iteration_71.pt
2025-05-17 23:59:06,491 [INFO] 所有训练迭代完成
2025-05-17 23:59:06,491 [INFO] 开始迭代 72/300
2025-05-17 23:59:06,491 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 00:13:30,298 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 00:13:30,299 [INFO] 保存训练样本
2025-05-18 00:13:35,230 [INFO] 使用 165768 个样本训练神经网络
2025-05-18 00:13:35,230 [INFO] Training with 165768 examples
2025-05-18 00:13:35,231 [INFO] 总训练步数: 2415, 每轮次批次数: 161
2025-05-18 00:13:35,285 [INFO] 循环学习率周期大小: 483 步
2025-05-18 00:14:17,924 [INFO] Epoch 1/15 - Policy Loss: 0.7488, Value Loss: 0.1025, Total Loss: 0.8512, LR: 0.001690
2025-05-18 00:15:00,516 [INFO] Epoch 2/15 - Policy Loss: 0.7444, Value Loss: 0.1018, Total Loss: 0.8463, LR: 0.003340
2025-05-18 00:15:43,196 [INFO] Epoch 3/15 - Policy Loss: 0.7432, Value Loss: 0.1012, Total Loss: 0.8444, LR: 0.004990
2025-05-18 00:16:26,272 [INFO] Epoch 4/15 - Policy Loss: 0.7426, Value Loss: 0.1009, Total Loss: 0.8435, LR: 0.003360
2025-05-18 00:17:09,234 [INFO] Epoch 5/15 - Policy Loss: 0.7408, Value Loss: 0.1011, Total Loss: 0.8419, LR: 0.001710
2025-05-18 00:18:04,176 [INFO] Epoch 6/15 - Policy Loss: 0.7384, Value Loss: 0.0998, Total Loss: 0.8382, LR: 0.000060
2025-05-18 00:19:13,059 [INFO] Epoch 7/15 - Policy Loss: 0.7364, Value Loss: 0.0994, Total Loss: 0.8359, LR: 0.001690
2025-05-18 00:20:23,286 [INFO] Epoch 8/15 - Policy Loss: 0.7355, Value Loss: 0.0988, Total Loss: 0.8344, LR: 0.003340
2025-05-18 00:21:20,180 [INFO] Epoch 9/15 - Policy Loss: 0.7347, Value Loss: 0.0987, Total Loss: 0.8334, LR: 0.004990
2025-05-18 00:22:43,789 [INFO] Epoch 10/15 - Policy Loss: 0.7342, Value Loss: 0.0986, Total Loss: 0.8328, LR: 0.003360
2025-05-18 00:23:50,633 [INFO] Epoch 11/15 - Policy Loss: 0.7335, Value Loss: 0.0982, Total Loss: 0.8317, LR: 0.001710
2025-05-18 00:24:58,209 [INFO] Epoch 12/15 - Policy Loss: 0.7324, Value Loss: 0.0979, Total Loss: 0.8303, LR: 0.000060
2025-05-18 00:26:12,199 [INFO] Epoch 13/15 - Policy Loss: 0.7313, Value Loss: 0.0975, Total Loss: 0.8289, LR: 0.001690
2025-05-18 00:27:13,913 [INFO] Epoch 14/15 - Policy Loss: 0.7306, Value Loss: 0.0971, Total Loss: 0.8278, LR: 0.003340
2025-05-18 00:28:20,349 [INFO] Epoch 15/15 - Policy Loss: 0.7303, Value Loss: 0.0970, Total Loss: 0.8272, LR: 0.004990
2025-05-18 00:28:20,373 [INFO] 训练完成，总损失: 0.8272
2025-05-18 00:28:20,373 [INFO] 保存迭代 72 的模型
2025-05-18 00:28:21,472 [INFO] Model saved to ./models/best.pt
2025-05-18 00:28:22,250 [INFO] Model saved to ./models/iteration_72.pt
2025-05-18 00:28:22,251 [INFO] 所有训练迭代完成
2025-05-18 00:28:22,251 [INFO] 开始迭代 73/300
2025-05-18 00:28:22,251 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 00:47:49,047 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 00:47:49,048 [INFO] 保存训练样本
2025-05-18 00:47:53,969 [INFO] 使用 165736 个样本训练神经网络
2025-05-18 00:47:53,969 [INFO] Training with 165736 examples
2025-05-18 00:47:53,969 [INFO] 总训练步数: 2415, 每轮次批次数: 161
2025-05-18 00:47:54,364 [INFO] 循环学习率周期大小: 483 步
2025-05-18 00:49:04,640 [INFO] Epoch 1/15 - Policy Loss: 0.7503, Value Loss: 0.0976, Total Loss: 0.8479, LR: 0.001690
2025-05-18 00:50:09,715 [INFO] Epoch 2/15 - Policy Loss: 0.7456, Value Loss: 0.0962, Total Loss: 0.8417, LR: 0.003340
2025-05-18 00:51:14,052 [INFO] Epoch 3/15 - Policy Loss: 0.7430, Value Loss: 0.0950, Total Loss: 0.8380, LR: 0.004990
2025-05-18 00:52:18,739 [INFO] Epoch 4/15 - Policy Loss: 0.7421, Value Loss: 0.0946, Total Loss: 0.8367, LR: 0.003360
2025-05-18 00:53:24,388 [INFO] Epoch 5/15 - Policy Loss: 0.7401, Value Loss: 0.0940, Total Loss: 0.8341, LR: 0.001710
2025-05-18 00:54:33,777 [INFO] Epoch 6/15 - Policy Loss: 0.7379, Value Loss: 0.0934, Total Loss: 0.8313, LR: 0.000060
2025-05-18 00:55:54,219 [INFO] Epoch 7/15 - Policy Loss: 0.7359, Value Loss: 0.0927, Total Loss: 0.8286, LR: 0.001690
2025-05-18 00:56:59,075 [INFO] Epoch 8/15 - Policy Loss: 0.7345, Value Loss: 0.0921, Total Loss: 0.8266, LR: 0.003340
2025-05-18 00:58:04,895 [INFO] Epoch 9/15 - Policy Loss: 0.7335, Value Loss: 0.0916, Total Loss: 0.8251, LR: 0.004990
2025-05-18 00:59:15,233 [INFO] Epoch 10/15 - Policy Loss: 0.7331, Value Loss: 0.0914, Total Loss: 0.8245, LR: 0.003360
2025-05-18 01:00:17,197 [INFO] Epoch 11/15 - Policy Loss: 0.7327, Value Loss: 0.0913, Total Loss: 0.8241, LR: 0.001710
2025-05-18 01:01:40,102 [INFO] Epoch 12/15 - Policy Loss: 0.7316, Value Loss: 0.0911, Total Loss: 0.8227, LR: 0.000060
2025-05-18 01:02:55,554 [INFO] Epoch 13/15 - Policy Loss: 0.7306, Value Loss: 0.0908, Total Loss: 0.8214, LR: 0.001690
2025-05-18 01:04:00,000 [INFO] Epoch 14/15 - Policy Loss: 0.7296, Value Loss: 0.0906, Total Loss: 0.8203, LR: 0.003340
2025-05-18 01:05:00,836 [INFO] Epoch 15/15 - Policy Loss: 0.7291, Value Loss: 0.0903, Total Loss: 0.8194, LR: 0.004990
2025-05-18 01:05:00,861 [INFO] 训练完成，总损失: 0.8194
2025-05-18 01:05:00,861 [INFO] 保存迭代 73 的模型
2025-05-18 01:05:02,015 [INFO] Model saved to ./models/best.pt
2025-05-18 01:05:02,922 [INFO] Model saved to ./models/iteration_73.pt
2025-05-18 01:05:02,923 [INFO] 所有训练迭代完成
2025-05-18 01:05:02,923 [INFO] 开始迭代 74/300
2025-05-18 01:05:02,923 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 01:23:21,577 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 01:23:21,577 [INFO] 保存训练样本
2025-05-18 01:23:26,334 [INFO] 使用 165480 个样本训练神经网络
2025-05-18 01:23:26,334 [INFO] Training with 165480 examples
2025-05-18 01:23:26,334 [INFO] 总训练步数: 2415, 每轮次批次数: 161
2025-05-18 01:23:26,674 [INFO] 循环学习率周期大小: 483 步
2025-05-18 01:24:42,299 [INFO] Epoch 1/15 - Policy Loss: 0.7489, Value Loss: 0.0967, Total Loss: 0.8455, LR: 0.001690
2025-05-18 01:25:53,530 [INFO] Epoch 2/15 - Policy Loss: 0.7445, Value Loss: 0.0973, Total Loss: 0.8418, LR: 0.003340
2025-05-18 01:27:02,109 [INFO] Epoch 3/15 - Policy Loss: 0.7425, Value Loss: 0.0978, Total Loss: 0.8403, LR: 0.004990
2025-05-18 01:28:10,209 [INFO] Epoch 4/15 - Policy Loss: 0.7398, Value Loss: 0.0970, Total Loss: 0.8368, LR: 0.003360
2025-05-18 01:29:21,604 [INFO] Epoch 5/15 - Policy Loss: 0.7385, Value Loss: 0.0957, Total Loss: 0.8342, LR: 0.001710
2025-05-18 01:30:22,870 [INFO] Epoch 6/15 - Policy Loss: 0.7368, Value Loss: 0.0946, Total Loss: 0.8314, LR: 0.000060
2025-05-18 01:31:48,252 [INFO] Epoch 7/15 - Policy Loss: 0.7353, Value Loss: 0.0940, Total Loss: 0.8292, LR: 0.001690
2025-05-18 01:33:06,855 [INFO] Epoch 8/15 - Policy Loss: 0.7337, Value Loss: 0.0932, Total Loss: 0.8269, LR: 0.003340
2025-05-18 01:34:04,462 [INFO] Epoch 9/15 - Policy Loss: 0.7329, Value Loss: 0.0931, Total Loss: 0.8261, LR: 0.004990
2025-05-18 01:35:15,515 [INFO] Epoch 10/15 - Policy Loss: 0.7327, Value Loss: 0.0930, Total Loss: 0.8257, LR: 0.003360
2025-05-18 01:36:22,404 [INFO] Epoch 11/15 - Policy Loss: 0.7313, Value Loss: 0.0927, Total Loss: 0.8240, LR: 0.001710
2025-05-18 01:37:34,325 [INFO] Epoch 12/15 - Policy Loss: 0.7306, Value Loss: 0.0924, Total Loss: 0.8230, LR: 0.000060
2025-05-18 01:38:50,758 [INFO] Epoch 13/15 - Policy Loss: 0.7301, Value Loss: 0.0921, Total Loss: 0.8222, LR: 0.001690
2025-05-18 01:40:01,914 [INFO] Epoch 14/15 - Policy Loss: 0.7295, Value Loss: 0.0916, Total Loss: 0.8211, LR: 0.003340
2025-05-18 01:41:16,871 [INFO] Epoch 15/15 - Policy Loss: 0.7290, Value Loss: 0.0915, Total Loss: 0.8205, LR: 0.004990
2025-05-18 01:41:16,889 [INFO] 训练完成，总损失: 0.8205
2025-05-18 01:41:16,889 [INFO] 保存迭代 74 的模型
2025-05-18 01:41:17,883 [INFO] Model saved to ./models/best.pt
2025-05-18 01:41:18,535 [INFO] Model saved to ./models/iteration_74.pt
2025-05-18 01:41:18,535 [INFO] 所有训练迭代完成
2025-05-18 01:41:18,535 [INFO] 开始迭代 75/300
2025-05-18 01:41:18,535 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 01:54:54,829 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 01:54:54,830 [INFO] 保存训练样本
2025-05-18 01:54:59,177 [INFO] 使用 164968 个样本训练神经网络
2025-05-18 01:54:59,178 [INFO] Training with 164968 examples
2025-05-18 01:54:59,178 [INFO] 总训练步数: 2415, 每轮次批次数: 161
2025-05-18 01:54:59,511 [INFO] 循环学习率周期大小: 483 步
2025-05-18 01:55:41,712 [INFO] Epoch 1/15 - Policy Loss: 0.7496, Value Loss: 0.1018, Total Loss: 0.8514, LR: 0.001690
2025-05-18 01:56:24,186 [INFO] Epoch 2/15 - Policy Loss: 0.7440, Value Loss: 0.0994, Total Loss: 0.8434, LR: 0.003340
2025-05-18 01:57:06,619 [INFO] Epoch 3/15 - Policy Loss: 0.7426, Value Loss: 0.0973, Total Loss: 0.8399, LR: 0.004990
2025-05-18 01:57:49,282 [INFO] Epoch 4/15 - Policy Loss: 0.7434, Value Loss: 0.0964, Total Loss: 0.8398, LR: 0.003360
2025-05-18 01:58:31,804 [INFO] Epoch 5/15 - Policy Loss: 0.7408, Value Loss: 0.0955, Total Loss: 0.8363, LR: 0.001710
2025-05-18 01:59:14,385 [INFO] Epoch 6/15 - Policy Loss: 0.7387, Value Loss: 0.0945, Total Loss: 0.8332, LR: 0.000060
2025-05-18 01:59:57,033 [INFO] Epoch 7/15 - Policy Loss: 0.7367, Value Loss: 0.0936, Total Loss: 0.8303, LR: 0.001690
2025-05-18 02:00:39,868 [INFO] Epoch 8/15 - Policy Loss: 0.7360, Value Loss: 0.0930, Total Loss: 0.8290, LR: 0.003340
2025-05-18 02:01:22,721 [INFO] Epoch 9/15 - Policy Loss: 0.7354, Value Loss: 0.0929, Total Loss: 0.8283, LR: 0.004990
2025-05-18 02:02:05,944 [INFO] Epoch 10/15 - Policy Loss: 0.7350, Value Loss: 0.0928, Total Loss: 0.8278, LR: 0.003360
2025-05-18 02:02:48,865 [INFO] Epoch 11/15 - Policy Loss: 0.7344, Value Loss: 0.0925, Total Loss: 0.8269, LR: 0.001710
2025-05-18 02:03:31,437 [INFO] Epoch 12/15 - Policy Loss: 0.7332, Value Loss: 0.0920, Total Loss: 0.8252, LR: 0.000060
2025-05-18 02:04:14,041 [INFO] Epoch 13/15 - Policy Loss: 0.7323, Value Loss: 0.0918, Total Loss: 0.8241, LR: 0.001690
2025-05-18 02:04:56,861 [INFO] Epoch 14/15 - Policy Loss: 0.7314, Value Loss: 0.0914, Total Loss: 0.8228, LR: 0.003340
2025-05-18 02:05:39,659 [INFO] Epoch 15/15 - Policy Loss: 0.7310, Value Loss: 0.0915, Total Loss: 0.8225, LR: 0.004990
2025-05-18 02:05:39,677 [INFO] 训练完成，总损失: 0.8225
2025-05-18 02:05:39,678 [INFO] 保存迭代 75 的模型
2025-05-18 02:05:40,680 [INFO] Model saved to ./models/best.pt
2025-05-18 02:05:41,322 [INFO] Model saved to ./models/iteration_75.pt
2025-05-18 02:05:41,322 [INFO] 所有训练迭代完成
2025-05-18 02:05:41,322 [INFO] 开始迭代 76/300
2025-05-18 02:05:41,322 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 02:19:52,827 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 02:19:52,828 [INFO] 保存训练样本
2025-05-18 02:19:57,424 [INFO] 使用 164616 个样本训练神经网络
2025-05-18 02:19:57,424 [INFO] Training with 164616 examples
2025-05-18 02:19:57,425 [INFO] 总训练步数: 2400, 每轮次批次数: 160
2025-05-18 02:19:57,472 [INFO] 循环学习率周期大小: 480 步
2025-05-18 02:20:39,171 [INFO] Epoch 1/15 - Policy Loss: 0.7535, Value Loss: 0.1091, Total Loss: 0.8626, LR: 0.001690
2025-05-18 02:21:21,275 [INFO] Epoch 2/15 - Policy Loss: 0.7467, Value Loss: 0.1074, Total Loss: 0.8541, LR: 0.003340
2025-05-18 02:22:03,412 [INFO] Epoch 3/15 - Policy Loss: 0.7451, Value Loss: 0.1074, Total Loss: 0.8526, LR: 0.004990
2025-05-18 02:22:45,685 [INFO] Epoch 4/15 - Policy Loss: 0.7444, Value Loss: 0.1062, Total Loss: 0.8506, LR: 0.003360
2025-05-18 02:23:27,928 [INFO] Epoch 5/15 - Policy Loss: 0.7428, Value Loss: 0.1053, Total Loss: 0.8481, LR: 0.001710
2025-05-18 02:24:10,584 [INFO] Epoch 6/15 - Policy Loss: 0.7399, Value Loss: 0.1041, Total Loss: 0.8440, LR: 0.000060
2025-05-18 02:24:52,855 [INFO] Epoch 7/15 - Policy Loss: 0.7375, Value Loss: 0.1034, Total Loss: 0.8409, LR: 0.001690
2025-05-18 02:25:35,526 [INFO] Epoch 8/15 - Policy Loss: 0.7360, Value Loss: 0.1023, Total Loss: 0.8383, LR: 0.003340
2025-05-18 02:26:17,998 [INFO] Epoch 9/15 - Policy Loss: 0.7349, Value Loss: 0.1017, Total Loss: 0.8366, LR: 0.004990
2025-05-18 02:27:00,602 [INFO] Epoch 10/15 - Policy Loss: 0.7340, Value Loss: 0.1012, Total Loss: 0.8352, LR: 0.003360
2025-05-18 02:27:43,135 [INFO] Epoch 11/15 - Policy Loss: 0.7338, Value Loss: 0.1008, Total Loss: 0.8346, LR: 0.001710
2025-05-18 02:28:25,749 [INFO] Epoch 12/15 - Policy Loss: 0.7330, Value Loss: 0.1000, Total Loss: 0.8330, LR: 0.000060
2025-05-18 02:29:08,333 [INFO] Epoch 13/15 - Policy Loss: 0.7322, Value Loss: 0.0995, Total Loss: 0.8317, LR: 0.001690
2025-05-18 02:29:50,886 [INFO] Epoch 14/15 - Policy Loss: 0.7315, Value Loss: 0.0989, Total Loss: 0.8304, LR: 0.003340
2025-05-18 02:30:33,261 [INFO] Epoch 15/15 - Policy Loss: 0.7315, Value Loss: 0.0989, Total Loss: 0.8303, LR: 0.004990
2025-05-18 02:30:33,279 [INFO] 训练完成，总损失: 0.8303
2025-05-18 02:30:33,279 [INFO] 保存迭代 76 的模型
2025-05-18 02:30:34,245 [INFO] Model saved to ./models/best.pt
2025-05-18 02:30:34,907 [INFO] Model saved to ./models/iteration_76.pt
2025-05-18 02:30:34,907 [INFO] 所有训练迭代完成
2025-05-18 02:30:34,907 [INFO] 开始迭代 77/300
2025-05-18 02:30:34,907 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 02:45:07,101 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 02:45:07,101 [INFO] 保存训练样本
2025-05-18 02:45:12,084 [INFO] 使用 165200 个样本训练神经网络
2025-05-18 02:45:12,084 [INFO] Training with 165200 examples
2025-05-18 02:45:12,084 [INFO] 总训练步数: 2415, 每轮次批次数: 161
2025-05-18 02:45:12,502 [INFO] 循环学习率周期大小: 483 步
2025-05-18 02:45:54,655 [INFO] Epoch 1/15 - Policy Loss: 0.7580, Value Loss: 0.1224, Total Loss: 0.8804, LR: 0.001690
2025-05-18 02:46:36,975 [INFO] Epoch 2/15 - Policy Loss: 0.7508, Value Loss: 0.1168, Total Loss: 0.8676, LR: 0.003340
2025-05-18 02:47:19,394 [INFO] Epoch 3/15 - Policy Loss: 0.7492, Value Loss: 0.1163, Total Loss: 0.8655, LR: 0.004990
2025-05-18 02:48:01,880 [INFO] Epoch 4/15 - Policy Loss: 0.7459, Value Loss: 0.1140, Total Loss: 0.8599, LR: 0.003360
2025-05-18 02:48:44,575 [INFO] Epoch 5/15 - Policy Loss: 0.7432, Value Loss: 0.1126, Total Loss: 0.8558, LR: 0.001710
2025-05-18 02:49:27,254 [INFO] Epoch 6/15 - Policy Loss: 0.7414, Value Loss: 0.1109, Total Loss: 0.8523, LR: 0.000060
2025-05-18 02:50:09,932 [INFO] Epoch 7/15 - Policy Loss: 0.7390, Value Loss: 0.1099, Total Loss: 0.8489, LR: 0.001690
2025-05-18 02:50:52,679 [INFO] Epoch 8/15 - Policy Loss: 0.7375, Value Loss: 0.1092, Total Loss: 0.8466, LR: 0.003340
2025-05-18 02:51:35,385 [INFO] Epoch 9/15 - Policy Loss: 0.7365, Value Loss: 0.1084, Total Loss: 0.8449, LR: 0.004990
2025-05-18 02:52:18,144 [INFO] Epoch 10/15 - Policy Loss: 0.7362, Value Loss: 0.1079, Total Loss: 0.8441, LR: 0.003360
2025-05-18 02:53:00,784 [INFO] Epoch 11/15 - Policy Loss: 0.7352, Value Loss: 0.1073, Total Loss: 0.8425, LR: 0.001710
2025-05-18 02:53:43,515 [INFO] Epoch 12/15 - Policy Loss: 0.7342, Value Loss: 0.1066, Total Loss: 0.8408, LR: 0.000060
2025-05-18 02:54:26,358 [INFO] Epoch 13/15 - Policy Loss: 0.7332, Value Loss: 0.1060, Total Loss: 0.8392, LR: 0.001690
2025-05-18 02:55:09,175 [INFO] Epoch 14/15 - Policy Loss: 0.7322, Value Loss: 0.1054, Total Loss: 0.8377, LR: 0.003340
2025-05-18 02:55:51,996 [INFO] Epoch 15/15 - Policy Loss: 0.7316, Value Loss: 0.1053, Total Loss: 0.8369, LR: 0.004990
2025-05-18 02:55:52,016 [INFO] 训练完成，总损失: 0.8369
2025-05-18 02:55:52,017 [INFO] 保存迭代 77 的模型
2025-05-18 02:55:53,142 [INFO] Model saved to ./models/best.pt
2025-05-18 02:55:53,926 [INFO] Model saved to ./models/iteration_77.pt
2025-05-18 02:55:53,926 [INFO] 所有训练迭代完成
2025-05-18 02:55:53,926 [INFO] 开始迭代 78/300
2025-05-18 02:55:53,926 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 03:10:00,633 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 03:10:00,634 [INFO] 保存训练样本
2025-05-18 03:10:05,376 [INFO] 使用 164608 个样本训练神经网络
2025-05-18 03:10:05,376 [INFO] Training with 164608 examples
2025-05-18 03:10:05,377 [INFO] 总训练步数: 2400, 每轮次批次数: 160
2025-05-18 03:10:05,705 [INFO] 循环学习率周期大小: 480 步
2025-05-18 03:10:47,652 [INFO] Epoch 1/15 - Policy Loss: 0.7503, Value Loss: 0.1047, Total Loss: 0.8551, LR: 0.001690
2025-05-18 03:11:29,792 [INFO] Epoch 2/15 - Policy Loss: 0.7442, Value Loss: 0.1029, Total Loss: 0.8471, LR: 0.003340
2025-05-18 03:12:11,981 [INFO] Epoch 3/15 - Policy Loss: 0.7426, Value Loss: 0.1021, Total Loss: 0.8446, LR: 0.004990
2025-05-18 03:12:54,240 [INFO] Epoch 4/15 - Policy Loss: 0.7409, Value Loss: 0.1016, Total Loss: 0.8425, LR: 0.003360
2025-05-18 03:13:36,519 [INFO] Epoch 5/15 - Policy Loss: 0.7392, Value Loss: 0.1007, Total Loss: 0.8399, LR: 0.001710
2025-05-18 03:14:18,890 [INFO] Epoch 6/15 - Policy Loss: 0.7371, Value Loss: 0.0997, Total Loss: 0.8368, LR: 0.000060
2025-05-18 03:15:01,286 [INFO] Epoch 7/15 - Policy Loss: 0.7348, Value Loss: 0.0989, Total Loss: 0.8337, LR: 0.001690
2025-05-18 03:15:43,908 [INFO] Epoch 8/15 - Policy Loss: 0.7338, Value Loss: 0.0985, Total Loss: 0.8323, LR: 0.003340
2025-05-18 03:16:26,592 [INFO] Epoch 9/15 - Policy Loss: 0.7336, Value Loss: 0.0982, Total Loss: 0.8318, LR: 0.004990
2025-05-18 03:17:09,234 [INFO] Epoch 10/15 - Policy Loss: 0.7335, Value Loss: 0.0981, Total Loss: 0.8316, LR: 0.003360
2025-05-18 03:17:51,771 [INFO] Epoch 11/15 - Policy Loss: 0.7331, Value Loss: 0.0979, Total Loss: 0.8310, LR: 0.001710
2025-05-18 03:18:34,527 [INFO] Epoch 12/15 - Policy Loss: 0.7326, Value Loss: 0.0975, Total Loss: 0.8301, LR: 0.000060
2025-05-18 03:19:17,202 [INFO] Epoch 13/15 - Policy Loss: 0.7319, Value Loss: 0.0972, Total Loss: 0.8291, LR: 0.001690
2025-05-18 03:20:00,135 [INFO] Epoch 14/15 - Policy Loss: 0.7313, Value Loss: 0.0967, Total Loss: 0.8280, LR: 0.003340
2025-05-18 03:20:42,818 [INFO] Epoch 15/15 - Policy Loss: 0.7311, Value Loss: 0.0965, Total Loss: 0.8275, LR: 0.004990
2025-05-18 03:20:42,839 [INFO] 训练完成，总损失: 0.8275
2025-05-18 03:20:42,839 [INFO] 保存迭代 78 的模型
2025-05-18 03:20:44,026 [INFO] Model saved to ./models/best.pt
2025-05-18 03:20:44,839 [INFO] Model saved to ./models/iteration_78.pt
2025-05-18 03:20:44,839 [INFO] 所有训练迭代完成
2025-05-18 03:20:44,839 [INFO] 开始迭代 79/300
2025-05-18 03:20:44,839 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 03:33:40,769 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 03:33:40,769 [INFO] 保存训练样本
2025-05-18 03:33:44,915 [INFO] 使用 164232 个样本训练神经网络
2025-05-18 03:33:44,915 [INFO] Training with 164232 examples
2025-05-18 03:33:44,916 [INFO] 总训练步数: 2400, 每轮次批次数: 160
2025-05-18 03:33:45,244 [INFO] 循环学习率周期大小: 480 步
2025-05-18 03:34:27,306 [INFO] Epoch 1/15 - Policy Loss: 0.7490, Value Loss: 0.0932, Total Loss: 0.8422, LR: 0.001690
2025-05-18 03:35:09,507 [INFO] Epoch 2/15 - Policy Loss: 0.7461, Value Loss: 0.0925, Total Loss: 0.8386, LR: 0.003340
2025-05-18 03:35:51,683 [INFO] Epoch 3/15 - Policy Loss: 0.7418, Value Loss: 0.0916, Total Loss: 0.8334, LR: 0.004990
2025-05-18 03:36:33,941 [INFO] Epoch 4/15 - Policy Loss: 0.7397, Value Loss: 0.0920, Total Loss: 0.8317, LR: 0.003360
2025-05-18 03:37:16,163 [INFO] Epoch 5/15 - Policy Loss: 0.7384, Value Loss: 0.0912, Total Loss: 0.8297, LR: 0.001710
2025-05-18 03:37:58,545 [INFO] Epoch 6/15 - Policy Loss: 0.7365, Value Loss: 0.0909, Total Loss: 0.8273, LR: 0.000060
2025-05-18 03:38:41,016 [INFO] Epoch 7/15 - Policy Loss: 0.7347, Value Loss: 0.0904, Total Loss: 0.8251, LR: 0.001690
2025-05-18 03:39:23,721 [INFO] Epoch 8/15 - Policy Loss: 0.7331, Value Loss: 0.0900, Total Loss: 0.8231, LR: 0.003340
2025-05-18 03:40:06,361 [INFO] Epoch 9/15 - Policy Loss: 0.7314, Value Loss: 0.0895, Total Loss: 0.8210, LR: 0.004990
2025-05-18 03:40:49,024 [INFO] Epoch 10/15 - Policy Loss: 0.7310, Value Loss: 0.0895, Total Loss: 0.8204, LR: 0.003360
2025-05-18 03:41:31,792 [INFO] Epoch 11/15 - Policy Loss: 0.7306, Value Loss: 0.0892, Total Loss: 0.8198, LR: 0.001710
2025-05-18 03:42:14,322 [INFO] Epoch 12/15 - Policy Loss: 0.7296, Value Loss: 0.0887, Total Loss: 0.8183, LR: 0.000060
2025-05-18 03:42:56,948 [INFO] Epoch 13/15 - Policy Loss: 0.7285, Value Loss: 0.0885, Total Loss: 0.8170, LR: 0.001690
2025-05-18 03:43:39,657 [INFO] Epoch 14/15 - Policy Loss: 0.7276, Value Loss: 0.0882, Total Loss: 0.8158, LR: 0.003340
2025-05-18 03:44:22,220 [INFO] Epoch 15/15 - Policy Loss: 0.7272, Value Loss: 0.0879, Total Loss: 0.8150, LR: 0.004990
2025-05-18 03:44:22,244 [INFO] 训练完成，总损失: 0.8150
2025-05-18 03:44:22,244 [INFO] 保存迭代 79 的模型
2025-05-18 03:44:23,250 [INFO] Model saved to ./models/best.pt
2025-05-18 03:44:23,867 [INFO] Model saved to ./models/iteration_79.pt
2025-05-18 03:44:23,868 [INFO] 所有训练迭代完成
2025-05-18 03:44:23,868 [INFO] 开始迭代 80/300
2025-05-18 03:44:23,868 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 03:57:44,458 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 03:57:44,459 [INFO] 保存训练样本
2025-05-18 03:57:48,709 [INFO] 使用 163496 个样本训练神经网络
2025-05-18 03:57:48,709 [INFO] Training with 163496 examples
2025-05-18 03:57:48,710 [INFO] 总训练步数: 2385, 每轮次批次数: 159
2025-05-18 03:57:48,760 [INFO] 循环学习率周期大小: 477 步
2025-05-18 03:58:30,451 [INFO] Epoch 1/15 - Policy Loss: 0.7497, Value Loss: 0.0895, Total Loss: 0.8392, LR: 0.001690
2025-05-18 03:59:12,406 [INFO] Epoch 2/15 - Policy Loss: 0.7441, Value Loss: 0.0872, Total Loss: 0.8314, LR: 0.003340
2025-05-18 03:59:54,154 [INFO] Epoch 3/15 - Policy Loss: 0.7408, Value Loss: 0.0867, Total Loss: 0.8274, LR: 0.004990
2025-05-18 04:00:36,208 [INFO] Epoch 4/15 - Policy Loss: 0.7392, Value Loss: 0.0867, Total Loss: 0.8258, LR: 0.003360
2025-05-18 04:01:17,994 [INFO] Epoch 5/15 - Policy Loss: 0.7368, Value Loss: 0.0859, Total Loss: 0.8227, LR: 0.001710
2025-05-18 04:02:00,581 [INFO] Epoch 6/15 - Policy Loss: 0.7341, Value Loss: 0.0852, Total Loss: 0.8192, LR: 0.000060
2025-05-18 04:02:42,680 [INFO] Epoch 7/15 - Policy Loss: 0.7325, Value Loss: 0.0849, Total Loss: 0.8174, LR: 0.001690
2025-05-18 04:03:24,941 [INFO] Epoch 8/15 - Policy Loss: 0.7311, Value Loss: 0.0845, Total Loss: 0.8157, LR: 0.003340
2025-05-18 04:04:06,902 [INFO] Epoch 9/15 - Policy Loss: 0.7304, Value Loss: 0.0846, Total Loss: 0.8150, LR: 0.004990
2025-05-18 04:04:49,111 [INFO] Epoch 10/15 - Policy Loss: 0.7302, Value Loss: 0.0846, Total Loss: 0.8148, LR: 0.003360
2025-05-18 04:05:31,094 [INFO] Epoch 11/15 - Policy Loss: 0.7297, Value Loss: 0.0844, Total Loss: 0.8141, LR: 0.001710
2025-05-18 04:06:13,408 [INFO] Epoch 12/15 - Policy Loss: 0.7291, Value Loss: 0.0840, Total Loss: 0.8131, LR: 0.000060
2025-05-18 04:06:55,681 [INFO] Epoch 13/15 - Policy Loss: 0.7282, Value Loss: 0.0837, Total Loss: 0.8119, LR: 0.001690
2025-05-18 04:07:37,993 [INFO] Epoch 14/15 - Policy Loss: 0.7272, Value Loss: 0.0835, Total Loss: 0.8106, LR: 0.003340
2025-05-18 04:08:20,345 [INFO] Epoch 15/15 - Policy Loss: 0.7267, Value Loss: 0.0832, Total Loss: 0.8099, LR: 0.004990
2025-05-18 04:08:20,363 [INFO] 训练完成，总损失: 0.8099
2025-05-18 04:08:20,363 [INFO] 保存迭代 80 的模型
2025-05-18 04:08:21,339 [INFO] Model saved to ./models/best.pt
2025-05-18 04:08:21,967 [INFO] Model saved to ./models/iteration_80.pt
2025-05-18 04:08:21,967 [INFO] 所有训练迭代完成
2025-05-18 04:08:21,967 [INFO] 开始迭代 81/300
2025-05-18 04:08:21,967 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 04:21:38,508 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 04:21:38,509 [INFO] 保存训练样本
2025-05-18 04:21:42,942 [INFO] 使用 162304 个样本训练神经网络
2025-05-18 04:21:42,942 [INFO] Training with 162304 examples
2025-05-18 04:21:42,942 [INFO] 总训练步数: 2370, 每轮次批次数: 158
2025-05-18 04:21:43,281 [INFO] 循环学习率周期大小: 474 步
2025-05-18 04:22:24,873 [INFO] Epoch 1/15 - Policy Loss: 0.7469, Value Loss: 0.0982, Total Loss: 0.8452, LR: 0.001690
2025-05-18 04:23:06,512 [INFO] Epoch 2/15 - Policy Loss: 0.7420, Value Loss: 0.0957, Total Loss: 0.8377, LR: 0.003340
2025-05-18 04:23:48,263 [INFO] Epoch 3/15 - Policy Loss: 0.7396, Value Loss: 0.0949, Total Loss: 0.8345, LR: 0.004990
2025-05-18 04:24:29,780 [INFO] Epoch 4/15 - Policy Loss: 0.7387, Value Loss: 0.0936, Total Loss: 0.8323, LR: 0.003360
2025-05-18 04:25:11,444 [INFO] Epoch 5/15 - Policy Loss: 0.7367, Value Loss: 0.0923, Total Loss: 0.8290, LR: 0.001710
2025-05-18 04:25:53,246 [INFO] Epoch 6/15 - Policy Loss: 0.7345, Value Loss: 0.0909, Total Loss: 0.8254, LR: 0.000060
2025-05-18 04:26:35,229 [INFO] Epoch 7/15 - Policy Loss: 0.7327, Value Loss: 0.0904, Total Loss: 0.8231, LR: 0.001690
2025-05-18 04:27:17,193 [INFO] Epoch 8/15 - Policy Loss: 0.7313, Value Loss: 0.0897, Total Loss: 0.8210, LR: 0.003340
2025-05-18 04:27:59,148 [INFO] Epoch 9/15 - Policy Loss: 0.7306, Value Loss: 0.0892, Total Loss: 0.8197, LR: 0.004990
2025-05-18 04:28:41,159 [INFO] Epoch 10/15 - Policy Loss: 0.7298, Value Loss: 0.0889, Total Loss: 0.8186, LR: 0.003360
2025-05-18 04:29:23,260 [INFO] Epoch 11/15 - Policy Loss: 0.7293, Value Loss: 0.0886, Total Loss: 0.8178, LR: 0.001710
2025-05-18 04:30:05,051 [INFO] Epoch 12/15 - Policy Loss: 0.7283, Value Loss: 0.0881, Total Loss: 0.8164, LR: 0.000060
2025-05-18 04:30:47,028 [INFO] Epoch 13/15 - Policy Loss: 0.7276, Value Loss: 0.0877, Total Loss: 0.8153, LR: 0.001690
2025-05-18 04:31:29,040 [INFO] Epoch 14/15 - Policy Loss: 0.7272, Value Loss: 0.0873, Total Loss: 0.8145, LR: 0.003340
2025-05-18 04:32:11,228 [INFO] Epoch 15/15 - Policy Loss: 0.7272, Value Loss: 0.0872, Total Loss: 0.8144, LR: 0.004990
2025-05-18 04:32:11,248 [INFO] 训练完成，总损失: 0.8144
2025-05-18 04:32:11,248 [INFO] 保存迭代 81 的模型
2025-05-18 04:32:12,466 [INFO] Model saved to ./models/best.pt
2025-05-18 04:32:13,302 [INFO] Model saved to ./models/iteration_81.pt
2025-05-18 04:32:13,302 [INFO] 所有训练迭代完成
2025-05-18 04:32:13,302 [INFO] 开始迭代 82/300
2025-05-18 04:32:13,302 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 04:45:42,306 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 04:45:42,306 [INFO] 保存训练样本
2025-05-18 04:45:46,184 [INFO] 使用 161864 个样本训练神经网络
2025-05-18 04:45:46,184 [INFO] Training with 161864 examples
2025-05-18 04:45:46,184 [INFO] 总训练步数: 2370, 每轮次批次数: 158
2025-05-18 04:45:46,464 [INFO] 循环学习率周期大小: 474 步
2025-05-18 04:46:27,902 [INFO] Epoch 1/15 - Policy Loss: 0.7499, Value Loss: 0.0936, Total Loss: 0.8435, LR: 0.001690
2025-05-18 04:47:09,472 [INFO] Epoch 2/15 - Policy Loss: 0.7466, Value Loss: 0.0921, Total Loss: 0.8386, LR: 0.003340
2025-05-18 04:47:51,297 [INFO] Epoch 3/15 - Policy Loss: 0.7445, Value Loss: 0.0911, Total Loss: 0.8355, LR: 0.004990
2025-05-18 04:48:33,103 [INFO] Epoch 4/15 - Policy Loss: 0.7417, Value Loss: 0.0902, Total Loss: 0.8320, LR: 0.003360
2025-05-18 04:49:15,026 [INFO] Epoch 5/15 - Policy Loss: 0.7395, Value Loss: 0.0894, Total Loss: 0.8290, LR: 0.001710
2025-05-18 04:49:56,958 [INFO] Epoch 6/15 - Policy Loss: 0.7369, Value Loss: 0.0887, Total Loss: 0.8256, LR: 0.000060
2025-05-18 04:50:38,922 [INFO] Epoch 7/15 - Policy Loss: 0.7348, Value Loss: 0.0883, Total Loss: 0.8231, LR: 0.001690
2025-05-18 04:51:20,925 [INFO] Epoch 8/15 - Policy Loss: 0.7331, Value Loss: 0.0878, Total Loss: 0.8209, LR: 0.003340
2025-05-18 04:52:03,048 [INFO] Epoch 9/15 - Policy Loss: 0.7326, Value Loss: 0.0874, Total Loss: 0.8200, LR: 0.004990
2025-05-18 04:52:45,037 [INFO] Epoch 10/15 - Policy Loss: 0.7329, Value Loss: 0.0874, Total Loss: 0.8203, LR: 0.003360
2025-05-18 04:53:27,144 [INFO] Epoch 11/15 - Policy Loss: 0.7320, Value Loss: 0.0870, Total Loss: 0.8190, LR: 0.001710
2025-05-18 04:54:08,981 [INFO] Epoch 12/15 - Policy Loss: 0.7312, Value Loss: 0.0866, Total Loss: 0.8178, LR: 0.000060
2025-05-18 04:54:50,912 [INFO] Epoch 13/15 - Policy Loss: 0.7303, Value Loss: 0.0862, Total Loss: 0.8165, LR: 0.001690
2025-05-18 04:55:32,989 [INFO] Epoch 14/15 - Policy Loss: 0.7303, Value Loss: 0.0860, Total Loss: 0.8163, LR: 0.003340
2025-05-18 04:56:15,123 [INFO] Epoch 15/15 - Policy Loss: 0.7300, Value Loss: 0.0859, Total Loss: 0.8159, LR: 0.004990
2025-05-18 04:56:15,140 [INFO] 训练完成，总损失: 0.8159
2025-05-18 04:56:15,140 [INFO] 保存迭代 82 的模型
2025-05-18 04:56:16,086 [INFO] Model saved to ./models/best.pt
2025-05-18 04:56:16,734 [INFO] Model saved to ./models/iteration_82.pt
2025-05-18 04:56:16,734 [INFO] 所有训练迭代完成
2025-05-18 04:56:16,735 [INFO] 开始迭代 83/300
2025-05-18 04:56:16,735 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 05:08:25,296 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 05:08:25,297 [INFO] 保存训练样本
2025-05-18 05:08:29,996 [INFO] 使用 161320 个样本训练神经网络
2025-05-18 05:08:29,996 [INFO] Training with 161320 examples
2025-05-18 05:08:29,997 [INFO] 总训练步数: 2355, 每轮次批次数: 157
2025-05-18 05:08:30,477 [INFO] 循环学习率周期大小: 471 步
2025-05-18 05:09:11,855 [INFO] Epoch 1/15 - Policy Loss: 0.7490, Value Loss: 0.0887, Total Loss: 0.8377, LR: 0.001689
2025-05-18 05:09:53,275 [INFO] Epoch 2/15 - Policy Loss: 0.7436, Value Loss: 0.0874, Total Loss: 0.8310, LR: 0.003339
2025-05-18 05:10:34,917 [INFO] Epoch 3/15 - Policy Loss: 0.7408, Value Loss: 0.0875, Total Loss: 0.8284, LR: 0.004989
2025-05-18 05:11:16,374 [INFO] Epoch 4/15 - Policy Loss: 0.7402, Value Loss: 0.0878, Total Loss: 0.8280, LR: 0.003361
2025-05-18 05:11:57,967 [INFO] Epoch 5/15 - Policy Loss: 0.7377, Value Loss: 0.0877, Total Loss: 0.8254, LR: 0.001711
2025-05-18 05:12:39,465 [INFO] Epoch 6/15 - Policy Loss: 0.7357, Value Loss: 0.0874, Total Loss: 0.8231, LR: 0.000061
2025-05-18 05:13:21,242 [INFO] Epoch 7/15 - Policy Loss: 0.7338, Value Loss: 0.0870, Total Loss: 0.8208, LR: 0.001689
2025-05-18 05:14:02,722 [INFO] Epoch 8/15 - Policy Loss: 0.7323, Value Loss: 0.0866, Total Loss: 0.8189, LR: 0.003339
2025-05-18 05:14:44,720 [INFO] Epoch 9/15 - Policy Loss: 0.7314, Value Loss: 0.0865, Total Loss: 0.8179, LR: 0.004989
2025-05-18 05:15:26,342 [INFO] Epoch 10/15 - Policy Loss: 0.7310, Value Loss: 0.0867, Total Loss: 0.8177, LR: 0.003361
2025-05-18 05:16:08,086 [INFO] Epoch 11/15 - Policy Loss: 0.7307, Value Loss: 0.0868, Total Loss: 0.8174, LR: 0.001711
2025-05-18 05:16:49,928 [INFO] Epoch 12/15 - Policy Loss: 0.7298, Value Loss: 0.0865, Total Loss: 0.8164, LR: 0.000061
2025-05-18 05:17:31,932 [INFO] Epoch 13/15 - Policy Loss: 0.7291, Value Loss: 0.0864, Total Loss: 0.8155, LR: 0.001689
2025-05-18 05:18:13,721 [INFO] Epoch 14/15 - Policy Loss: 0.7286, Value Loss: 0.0861, Total Loss: 0.8147, LR: 0.003339
2025-05-18 05:18:55,666 [INFO] Epoch 15/15 - Policy Loss: 0.7284, Value Loss: 0.0857, Total Loss: 0.8142, LR: 0.004989
2025-05-18 05:18:55,693 [INFO] 训练完成，总损失: 0.8142
2025-05-18 05:18:55,693 [INFO] 保存迭代 83 的模型
2025-05-18 05:18:56,952 [INFO] Model saved to ./models/best.pt
2025-05-18 05:18:57,783 [INFO] Model saved to ./models/iteration_83.pt
2025-05-18 05:18:57,783 [INFO] 所有训练迭代完成
2025-05-18 05:18:57,784 [INFO] 开始迭代 84/300
2025-05-18 05:18:57,784 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 05:32:04,261 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 05:32:04,261 [INFO] 保存训练样本
2025-05-18 05:32:08,692 [INFO] 使用 160840 个样本训练神经网络
2025-05-18 05:32:08,693 [INFO] Training with 160840 examples
2025-05-18 05:32:08,693 [INFO] 总训练步数: 2355, 每轮次批次数: 157
2025-05-18 05:32:08,741 [INFO] 循环学习率周期大小: 471 步
2025-05-18 05:32:50,046 [INFO] Epoch 1/15 - Policy Loss: 0.7460, Value Loss: 0.0922, Total Loss: 0.8382, LR: 0.001689
2025-05-18 05:33:31,343 [INFO] Epoch 2/15 - Policy Loss: 0.7425, Value Loss: 0.0889, Total Loss: 0.8315, LR: 0.003339
2025-05-18 05:34:12,668 [INFO] Epoch 3/15 - Policy Loss: 0.7409, Value Loss: 0.0887, Total Loss: 0.8296, LR: 0.004989
2025-05-18 05:34:54,628 [INFO] Epoch 4/15 - Policy Loss: 0.7382, Value Loss: 0.0882, Total Loss: 0.8264, LR: 0.003361
2025-05-18 05:35:36,106 [INFO] Epoch 5/15 - Policy Loss: 0.7362, Value Loss: 0.0876, Total Loss: 0.8238, LR: 0.001711
2025-05-18 05:36:17,480 [INFO] Epoch 6/15 - Policy Loss: 0.7347, Value Loss: 0.0868, Total Loss: 0.8214, LR: 0.000061
2025-05-18 05:36:59,169 [INFO] Epoch 7/15 - Policy Loss: 0.7334, Value Loss: 0.0864, Total Loss: 0.8198, LR: 0.001689
2025-05-18 05:37:40,933 [INFO] Epoch 8/15 - Policy Loss: 0.7322, Value Loss: 0.0861, Total Loss: 0.8183, LR: 0.003339
2025-05-18 05:38:22,833 [INFO] Epoch 9/15 - Policy Loss: 0.7316, Value Loss: 0.0860, Total Loss: 0.8176, LR: 0.004989
2025-05-18 05:39:04,646 [INFO] Epoch 10/15 - Policy Loss: 0.7309, Value Loss: 0.0856, Total Loss: 0.8165, LR: 0.003361
2025-05-18 05:39:46,492 [INFO] Epoch 11/15 - Policy Loss: 0.7302, Value Loss: 0.0856, Total Loss: 0.8157, LR: 0.001711
2025-05-18 05:40:28,201 [INFO] Epoch 12/15 - Policy Loss: 0.7297, Value Loss: 0.0853, Total Loss: 0.8150, LR: 0.000061
2025-05-18 05:41:10,093 [INFO] Epoch 13/15 - Policy Loss: 0.7290, Value Loss: 0.0853, Total Loss: 0.8143, LR: 0.001689
2025-05-18 05:41:52,017 [INFO] Epoch 14/15 - Policy Loss: 0.7285, Value Loss: 0.0850, Total Loss: 0.8135, LR: 0.003339
2025-05-18 05:42:34,028 [INFO] Epoch 15/15 - Policy Loss: 0.7283, Value Loss: 0.0848, Total Loss: 0.8131, LR: 0.004989
2025-05-18 05:42:34,055 [INFO] 训练完成，总损失: 0.8131
2025-05-18 05:42:34,055 [INFO] 保存迭代 84 的模型
2025-05-18 05:42:35,082 [INFO] Model saved to ./models/best.pt
2025-05-18 05:42:35,760 [INFO] Model saved to ./models/iteration_84.pt
2025-05-18 05:42:35,761 [INFO] 所有训练迭代完成
2025-05-18 05:42:35,761 [INFO] 开始迭代 85/300
2025-05-18 05:42:35,761 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 05:54:17,164 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 05:54:17,165 [INFO] 保存训练样本
2025-05-18 05:54:22,095 [INFO] 使用 159824 个样本训练神经网络
2025-05-18 05:54:22,095 [INFO] Training with 159824 examples
2025-05-18 05:54:22,096 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-18 05:54:22,513 [INFO] 循环学习率周期大小: 468 步
2025-05-18 05:55:03,528 [INFO] Epoch 1/15 - Policy Loss: 0.7471, Value Loss: 0.0861, Total Loss: 0.8332, LR: 0.001689
2025-05-18 05:55:44,518 [INFO] Epoch 2/15 - Policy Loss: 0.7417, Value Loss: 0.0848, Total Loss: 0.8265, LR: 0.003339
2025-05-18 05:56:25,833 [INFO] Epoch 3/15 - Policy Loss: 0.7386, Value Loss: 0.0841, Total Loss: 0.8226, LR: 0.004989
2025-05-18 05:57:06,889 [INFO] Epoch 4/15 - Policy Loss: 0.7379, Value Loss: 0.0838, Total Loss: 0.8217, LR: 0.003361
2025-05-18 05:57:48,099 [INFO] Epoch 5/15 - Policy Loss: 0.7359, Value Loss: 0.0832, Total Loss: 0.8191, LR: 0.001711
2025-05-18 05:58:29,452 [INFO] Epoch 6/15 - Policy Loss: 0.7344, Value Loss: 0.0825, Total Loss: 0.8168, LR: 0.000061
2025-05-18 05:59:10,904 [INFO] Epoch 7/15 - Policy Loss: 0.7326, Value Loss: 0.0819, Total Loss: 0.8146, LR: 0.001689
2025-05-18 05:59:52,284 [INFO] Epoch 8/15 - Policy Loss: 0.7320, Value Loss: 0.0817, Total Loss: 0.8137, LR: 0.003339
2025-05-18 06:00:33,746 [INFO] Epoch 9/15 - Policy Loss: 0.7312, Value Loss: 0.0814, Total Loss: 0.8126, LR: 0.004989
2025-05-18 06:01:15,051 [INFO] Epoch 10/15 - Policy Loss: 0.7310, Value Loss: 0.0810, Total Loss: 0.8121, LR: 0.003361
2025-05-18 06:01:56,373 [INFO] Epoch 11/15 - Policy Loss: 0.7303, Value Loss: 0.0808, Total Loss: 0.8111, LR: 0.001711
2025-05-18 06:02:37,783 [INFO] Epoch 12/15 - Policy Loss: 0.7296, Value Loss: 0.0807, Total Loss: 0.8103, LR: 0.000061
2025-05-18 06:03:19,026 [INFO] Epoch 13/15 - Policy Loss: 0.7287, Value Loss: 0.0805, Total Loss: 0.8092, LR: 0.001689
2025-05-18 06:04:00,406 [INFO] Epoch 14/15 - Policy Loss: 0.7281, Value Loss: 0.0802, Total Loss: 0.8082, LR: 0.003339
2025-05-18 06:04:41,931 [INFO] Epoch 15/15 - Policy Loss: 0.7276, Value Loss: 0.0800, Total Loss: 0.8076, LR: 0.004989
2025-05-18 06:04:41,950 [INFO] 训练完成，总损失: 0.8076
2025-05-18 06:04:41,951 [INFO] 保存迭代 85 的模型
2025-05-18 06:04:43,150 [INFO] Model saved to ./models/best.pt
2025-05-18 06:04:43,935 [INFO] Model saved to ./models/iteration_85.pt
2025-05-18 06:04:43,935 [INFO] 所有训练迭代完成
2025-05-18 06:04:43,935 [INFO] 开始迭代 86/300
2025-05-18 06:04:43,935 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 06:18:47,709 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 06:18:47,709 [INFO] 保存训练样本
2025-05-18 06:18:51,777 [INFO] 使用 159896 个样本训练神经网络
2025-05-18 06:18:51,777 [INFO] Training with 159896 examples
2025-05-18 06:18:51,777 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-18 06:18:52,103 [INFO] 循环学习率周期大小: 468 步
2025-05-18 06:19:32,959 [INFO] Epoch 1/15 - Policy Loss: 0.7514, Value Loss: 0.1009, Total Loss: 0.8523, LR: 0.001689
2025-05-18 06:20:14,089 [INFO] Epoch 2/15 - Policy Loss: 0.7456, Value Loss: 0.0979, Total Loss: 0.8436, LR: 0.003339
2025-05-18 06:20:55,219 [INFO] Epoch 3/15 - Policy Loss: 0.7424, Value Loss: 0.0980, Total Loss: 0.8404, LR: 0.004989
2025-05-18 06:21:36,260 [INFO] Epoch 4/15 - Policy Loss: 0.7415, Value Loss: 0.0971, Total Loss: 0.8386, LR: 0.003361
2025-05-18 06:22:17,331 [INFO] Epoch 5/15 - Policy Loss: 0.7401, Value Loss: 0.0956, Total Loss: 0.8358, LR: 0.001711
2025-05-18 06:22:58,569 [INFO] Epoch 6/15 - Policy Loss: 0.7379, Value Loss: 0.0946, Total Loss: 0.8325, LR: 0.000061
2025-05-18 06:23:39,973 [INFO] Epoch 7/15 - Policy Loss: 0.7362, Value Loss: 0.0934, Total Loss: 0.8296, LR: 0.001689
2025-05-18 06:24:21,417 [INFO] Epoch 8/15 - Policy Loss: 0.7351, Value Loss: 0.0926, Total Loss: 0.8278, LR: 0.003339
2025-05-18 06:25:02,891 [INFO] Epoch 9/15 - Policy Loss: 0.7351, Value Loss: 0.0926, Total Loss: 0.8277, LR: 0.004989
2025-05-18 06:25:44,450 [INFO] Epoch 10/15 - Policy Loss: 0.7346, Value Loss: 0.0920, Total Loss: 0.8266, LR: 0.003361
2025-05-18 06:26:25,899 [INFO] Epoch 11/15 - Policy Loss: 0.7337, Value Loss: 0.0914, Total Loss: 0.8251, LR: 0.001711
2025-05-18 06:27:07,325 [INFO] Epoch 12/15 - Policy Loss: 0.7328, Value Loss: 0.0908, Total Loss: 0.8236, LR: 0.000061
2025-05-18 06:27:49,189 [INFO] Epoch 13/15 - Policy Loss: 0.7320, Value Loss: 0.0903, Total Loss: 0.8223, LR: 0.001689
2025-05-18 06:28:30,900 [INFO] Epoch 14/15 - Policy Loss: 0.7313, Value Loss: 0.0897, Total Loss: 0.8210, LR: 0.003339
2025-05-18 06:29:12,472 [INFO] Epoch 15/15 - Policy Loss: 0.7313, Value Loss: 0.0892, Total Loss: 0.8206, LR: 0.004989
2025-05-18 06:29:12,496 [INFO] 训练完成，总损失: 0.8206
2025-05-18 06:29:12,496 [INFO] 保存迭代 86 的模型
2025-05-18 06:29:13,513 [INFO] Model saved to ./models/best.pt
2025-05-18 06:29:14,317 [INFO] Model saved to ./models/iteration_86.pt
2025-05-18 06:29:14,317 [INFO] 所有训练迭代完成
2025-05-18 06:29:14,318 [INFO] 开始迭代 87/300
2025-05-18 06:29:14,318 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 06:43:59,823 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 06:43:59,823 [INFO] 保存训练样本
2025-05-18 06:44:04,585 [INFO] 使用 160488 个样本训练神经网络
2025-05-18 06:44:04,585 [INFO] Training with 160488 examples
2025-05-18 06:44:04,586 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-18 06:44:05,002 [INFO] 循环学习率周期大小: 468 步
2025-05-18 06:44:46,066 [INFO] Epoch 1/15 - Policy Loss: 0.7551, Value Loss: 0.0924, Total Loss: 0.8475, LR: 0.001689
2025-05-18 06:45:27,356 [INFO] Epoch 2/15 - Policy Loss: 0.7505, Value Loss: 0.0909, Total Loss: 0.8414, LR: 0.003339
2025-05-18 06:46:08,592 [INFO] Epoch 3/15 - Policy Loss: 0.7454, Value Loss: 0.0897, Total Loss: 0.8351, LR: 0.004989
2025-05-18 06:46:50,011 [INFO] Epoch 4/15 - Policy Loss: 0.7447, Value Loss: 0.0888, Total Loss: 0.8335, LR: 0.003361
2025-05-18 06:47:31,241 [INFO] Epoch 5/15 - Policy Loss: 0.7423, Value Loss: 0.0880, Total Loss: 0.8303, LR: 0.001711
2025-05-18 06:48:12,755 [INFO] Epoch 6/15 - Policy Loss: 0.7396, Value Loss: 0.0874, Total Loss: 0.8270, LR: 0.000061
2025-05-18 06:48:54,195 [INFO] Epoch 7/15 - Policy Loss: 0.7382, Value Loss: 0.0868, Total Loss: 0.8249, LR: 0.001689
2025-05-18 06:49:36,257 [INFO] Epoch 8/15 - Policy Loss: 0.7370, Value Loss: 0.0862, Total Loss: 0.8233, LR: 0.003339
2025-05-18 06:50:17,871 [INFO] Epoch 9/15 - Policy Loss: 0.7363, Value Loss: 0.0856, Total Loss: 0.8219, LR: 0.004989
2025-05-18 06:50:59,376 [INFO] Epoch 10/15 - Policy Loss: 0.7353, Value Loss: 0.0850, Total Loss: 0.8203, LR: 0.003361
2025-05-18 06:51:40,765 [INFO] Epoch 11/15 - Policy Loss: 0.7343, Value Loss: 0.0847, Total Loss: 0.8190, LR: 0.001711
2025-05-18 06:52:22,135 [INFO] Epoch 12/15 - Policy Loss: 0.7332, Value Loss: 0.0843, Total Loss: 0.8175, LR: 0.000061
2025-05-18 06:53:03,523 [INFO] Epoch 13/15 - Policy Loss: 0.7323, Value Loss: 0.0840, Total Loss: 0.8163, LR: 0.001689
2025-05-18 06:53:45,059 [INFO] Epoch 14/15 - Policy Loss: 0.7313, Value Loss: 0.0837, Total Loss: 0.8150, LR: 0.003339
2025-05-18 06:54:26,771 [INFO] Epoch 15/15 - Policy Loss: 0.7308, Value Loss: 0.0834, Total Loss: 0.8143, LR: 0.004989
2025-05-18 06:54:26,798 [INFO] 训练完成，总损失: 0.8143
2025-05-18 06:54:26,798 [INFO] 保存迭代 87 的模型
2025-05-18 06:54:27,951 [INFO] Model saved to ./models/best.pt
2025-05-18 06:54:28,566 [INFO] Model saved to ./models/iteration_87.pt
2025-05-18 06:54:28,566 [INFO] 所有训练迭代完成
2025-05-18 06:54:28,566 [INFO] 开始迭代 88/300
2025-05-18 06:54:28,566 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 07:09:03,557 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 07:09:03,557 [INFO] 保存训练样本
2025-05-18 07:09:07,935 [INFO] 使用 160376 个样本训练神经网络
2025-05-18 07:09:07,935 [INFO] Training with 160376 examples
2025-05-18 07:09:07,935 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-18 07:09:07,982 [INFO] 循环学习率周期大小: 468 步
2025-05-18 07:09:48,864 [INFO] Epoch 1/15 - Policy Loss: 0.7527, Value Loss: 0.0874, Total Loss: 0.8400, LR: 0.001689
2025-05-18 07:10:29,901 [INFO] Epoch 2/15 - Policy Loss: 0.7472, Value Loss: 0.0865, Total Loss: 0.8337, LR: 0.003339
2025-05-18 07:11:10,903 [INFO] Epoch 3/15 - Policy Loss: 0.7465, Value Loss: 0.0862, Total Loss: 0.8327, LR: 0.004989
2025-05-18 07:11:52,277 [INFO] Epoch 4/15 - Policy Loss: 0.7445, Value Loss: 0.0856, Total Loss: 0.8301, LR: 0.003361
2025-05-18 07:12:33,480 [INFO] Epoch 5/15 - Policy Loss: 0.7425, Value Loss: 0.0864, Total Loss: 0.8289, LR: 0.001711
2025-05-18 07:13:14,577 [INFO] Epoch 6/15 - Policy Loss: 0.7401, Value Loss: 0.0861, Total Loss: 0.8262, LR: 0.000061
2025-05-18 07:13:55,819 [INFO] Epoch 7/15 - Policy Loss: 0.7381, Value Loss: 0.0854, Total Loss: 0.8235, LR: 0.001689
2025-05-18 07:14:36,983 [INFO] Epoch 8/15 - Policy Loss: 0.7371, Value Loss: 0.0852, Total Loss: 0.8223, LR: 0.003339
2025-05-18 07:15:18,418 [INFO] Epoch 9/15 - Policy Loss: 0.7361, Value Loss: 0.0849, Total Loss: 0.8210, LR: 0.004989
2025-05-18 07:15:59,833 [INFO] Epoch 10/15 - Policy Loss: 0.7354, Value Loss: 0.0846, Total Loss: 0.8200, LR: 0.003361
2025-05-18 07:16:41,036 [INFO] Epoch 11/15 - Policy Loss: 0.7348, Value Loss: 0.0842, Total Loss: 0.8190, LR: 0.001711
2025-05-18 07:17:22,276 [INFO] Epoch 12/15 - Policy Loss: 0.7336, Value Loss: 0.0839, Total Loss: 0.8176, LR: 0.000061
2025-05-18 07:18:03,700 [INFO] Epoch 13/15 - Policy Loss: 0.7330, Value Loss: 0.0837, Total Loss: 0.8167, LR: 0.001689
2025-05-18 07:18:45,120 [INFO] Epoch 14/15 - Policy Loss: 0.7327, Value Loss: 0.0835, Total Loss: 0.8162, LR: 0.003339
2025-05-18 07:19:26,605 [INFO] Epoch 15/15 - Policy Loss: 0.7324, Value Loss: 0.0835, Total Loss: 0.8158, LR: 0.004989
2025-05-18 07:19:26,625 [INFO] 训练完成，总损失: 0.8158
2025-05-18 07:19:26,625 [INFO] 保存迭代 88 的模型
2025-05-18 07:19:27,789 [INFO] Model saved to ./models/best.pt
2025-05-18 07:19:28,596 [INFO] Model saved to ./models/iteration_88.pt
2025-05-18 07:19:28,596 [INFO] 所有训练迭代完成
2025-05-18 07:19:28,596 [INFO] 开始迭代 89/300
2025-05-18 07:19:28,596 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 07:33:15,871 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 07:33:15,871 [INFO] 保存训练样本
2025-05-18 07:33:20,307 [INFO] 使用 161376 个样本训练神经网络
2025-05-18 07:33:20,307 [INFO] Training with 161376 examples
2025-05-18 07:33:20,308 [INFO] 总训练步数: 2355, 每轮次批次数: 157
2025-05-18 07:33:20,701 [INFO] 循环学习率周期大小: 471 步
2025-05-18 07:34:01,988 [INFO] Epoch 1/15 - Policy Loss: 0.7558, Value Loss: 0.0834, Total Loss: 0.8393, LR: 0.001689
2025-05-18 07:34:43,380 [INFO] Epoch 2/15 - Policy Loss: 0.7475, Value Loss: 0.0834, Total Loss: 0.8309, LR: 0.003339
2025-05-18 07:35:24,726 [INFO] Epoch 3/15 - Policy Loss: 0.7458, Value Loss: 0.0832, Total Loss: 0.8291, LR: 0.004989
2025-05-18 07:36:06,106 [INFO] Epoch 4/15 - Policy Loss: 0.7446, Value Loss: 0.0826, Total Loss: 0.8272, LR: 0.003361
2025-05-18 07:36:47,437 [INFO] Epoch 5/15 - Policy Loss: 0.7420, Value Loss: 0.0823, Total Loss: 0.8243, LR: 0.001711
2025-05-18 07:37:28,754 [INFO] Epoch 6/15 - Policy Loss: 0.7386, Value Loss: 0.0818, Total Loss: 0.8204, LR: 0.000061
2025-05-18 07:38:10,465 [INFO] Epoch 7/15 - Policy Loss: 0.7370, Value Loss: 0.0813, Total Loss: 0.8183, LR: 0.001689
2025-05-18 07:38:52,306 [INFO] Epoch 8/15 - Policy Loss: 0.7350, Value Loss: 0.0811, Total Loss: 0.8161, LR: 0.003339
2025-05-18 07:39:34,093 [INFO] Epoch 9/15 - Policy Loss: 0.7339, Value Loss: 0.0810, Total Loss: 0.8149, LR: 0.004989
2025-05-18 07:40:15,826 [INFO] Epoch 10/15 - Policy Loss: 0.7334, Value Loss: 0.0809, Total Loss: 0.8143, LR: 0.003361
2025-05-18 07:40:57,503 [INFO] Epoch 11/15 - Policy Loss: 0.7322, Value Loss: 0.0807, Total Loss: 0.8129, LR: 0.001711
2025-05-18 07:41:39,197 [INFO] Epoch 12/15 - Policy Loss: 0.7312, Value Loss: 0.0803, Total Loss: 0.8115, LR: 0.000061
2025-05-18 07:42:21,002 [INFO] Epoch 13/15 - Policy Loss: 0.7309, Value Loss: 0.0802, Total Loss: 0.8111, LR: 0.001689
2025-05-18 07:43:02,777 [INFO] Epoch 14/15 - Policy Loss: 0.7301, Value Loss: 0.0801, Total Loss: 0.8102, LR: 0.003339
2025-05-18 07:43:44,358 [INFO] Epoch 15/15 - Policy Loss: 0.7296, Value Loss: 0.0799, Total Loss: 0.8095, LR: 0.004989
2025-05-18 07:43:44,376 [INFO] 训练完成，总损失: 0.8095
2025-05-18 07:43:44,376 [INFO] 保存迭代 89 的模型
2025-05-18 07:43:45,308 [INFO] Model saved to ./models/best.pt
2025-05-18 07:43:45,918 [INFO] Model saved to ./models/iteration_89.pt
2025-05-18 07:43:45,918 [INFO] 所有训练迭代完成
2025-05-18 07:43:45,918 [INFO] 开始迭代 90/300
2025-05-18 07:43:45,918 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 07:56:47,852 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 07:56:47,853 [INFO] 保存训练样本
2025-05-18 07:56:52,753 [INFO] 使用 160744 个样本训练神经网络
2025-05-18 07:56:52,753 [INFO] Training with 160744 examples
2025-05-18 07:56:52,753 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-18 07:56:53,144 [INFO] 循环学习率周期大小: 468 步
2025-05-18 07:57:34,239 [INFO] Epoch 1/15 - Policy Loss: 0.7391, Value Loss: 0.0788, Total Loss: 0.8180, LR: 0.001689
2025-05-18 07:58:15,447 [INFO] Epoch 2/15 - Policy Loss: 0.7367, Value Loss: 0.0788, Total Loss: 0.8155, LR: 0.003339
2025-05-18 07:58:56,707 [INFO] Epoch 3/15 - Policy Loss: 0.7360, Value Loss: 0.0790, Total Loss: 0.8150, LR: 0.004989
2025-05-18 07:59:37,983 [INFO] Epoch 4/15 - Policy Loss: 0.7355, Value Loss: 0.0807, Total Loss: 0.8163, LR: 0.003361
2025-05-18 08:00:19,444 [INFO] Epoch 5/15 - Policy Loss: 0.7349, Value Loss: 0.0807, Total Loss: 0.8156, LR: 0.001711
2025-05-18 08:01:00,791 [INFO] Epoch 6/15 - Policy Loss: 0.7333, Value Loss: 0.0806, Total Loss: 0.8139, LR: 0.000061
2025-05-18 08:01:42,459 [INFO] Epoch 7/15 - Policy Loss: 0.7318, Value Loss: 0.0807, Total Loss: 0.8125, LR: 0.001689
2025-05-18 08:02:23,909 [INFO] Epoch 8/15 - Policy Loss: 0.7300, Value Loss: 0.0804, Total Loss: 0.8104, LR: 0.003339
2025-05-18 08:03:05,391 [INFO] Epoch 9/15 - Policy Loss: 0.7293, Value Loss: 0.0801, Total Loss: 0.8094, LR: 0.004989
2025-05-18 08:03:46,825 [INFO] Epoch 10/15 - Policy Loss: 0.7289, Value Loss: 0.0801, Total Loss: 0.8089, LR: 0.003361
2025-05-18 08:04:28,484 [INFO] Epoch 11/15 - Policy Loss: 0.7283, Value Loss: 0.0798, Total Loss: 0.8081, LR: 0.001711
2025-05-18 08:05:10,592 [INFO] Epoch 12/15 - Policy Loss: 0.7275, Value Loss: 0.0797, Total Loss: 0.8072, LR: 0.000061
2025-05-18 08:05:52,099 [INFO] Epoch 13/15 - Policy Loss: 0.7270, Value Loss: 0.0795, Total Loss: 0.8065, LR: 0.001689
2025-05-18 08:06:33,735 [INFO] Epoch 14/15 - Policy Loss: 0.7265, Value Loss: 0.0793, Total Loss: 0.8058, LR: 0.003339
2025-05-18 08:07:15,512 [INFO] Epoch 15/15 - Policy Loss: 0.7260, Value Loss: 0.0791, Total Loss: 0.8051, LR: 0.004989
2025-05-18 08:07:15,539 [INFO] 训练完成，总损失: 0.8051
2025-05-18 08:07:15,539 [INFO] 保存迭代 90 的模型
2025-05-18 08:07:16,769 [INFO] Model saved to ./models/best.pt
2025-05-18 08:07:17,578 [INFO] Model saved to ./models/iteration_90.pt
2025-05-18 08:07:17,578 [INFO] 所有训练迭代完成
2025-05-18 08:07:17,578 [INFO] 开始迭代 91/300
2025-05-18 08:07:17,578 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 08:20:28,525 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 08:20:28,526 [INFO] 保存训练样本
2025-05-18 08:20:33,449 [INFO] 使用 160704 个样本训练神经网络
2025-05-18 08:20:33,450 [INFO] Training with 160704 examples
2025-05-18 08:20:33,450 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-18 08:20:33,507 [INFO] 循环学习率周期大小: 468 步
2025-05-18 08:21:14,611 [INFO] Epoch 1/15 - Policy Loss: 0.7434, Value Loss: 0.0729, Total Loss: 0.8163, LR: 0.001689
2025-05-18 08:21:55,785 [INFO] Epoch 2/15 - Policy Loss: 0.7391, Value Loss: 0.0730, Total Loss: 0.8121, LR: 0.003339
2025-05-18 08:22:37,137 [INFO] Epoch 3/15 - Policy Loss: 0.7390, Value Loss: 0.0744, Total Loss: 0.8133, LR: 0.004989
2025-05-18 08:23:18,391 [INFO] Epoch 4/15 - Policy Loss: 0.7422, Value Loss: 0.0797, Total Loss: 0.8219, LR: 0.003361
2025-05-18 08:23:59,809 [INFO] Epoch 5/15 - Policy Loss: 0.7420, Value Loss: 0.0787, Total Loss: 0.8207, LR: 0.001711
2025-05-18 08:24:41,269 [INFO] Epoch 6/15 - Policy Loss: 0.7401, Value Loss: 0.0780, Total Loss: 0.8182, LR: 0.000061
2025-05-18 08:25:23,239 [INFO] Epoch 7/15 - Policy Loss: 0.7377, Value Loss: 0.0771, Total Loss: 0.8147, LR: 0.001689
2025-05-18 08:26:04,866 [INFO] Epoch 8/15 - Policy Loss: 0.7368, Value Loss: 0.0765, Total Loss: 0.8133, LR: 0.003339
2025-05-18 08:26:46,498 [INFO] Epoch 9/15 - Policy Loss: 0.7359, Value Loss: 0.0764, Total Loss: 0.8123, LR: 0.004989
2025-05-18 08:27:27,916 [INFO] Epoch 10/15 - Policy Loss: 0.7345, Value Loss: 0.0761, Total Loss: 0.8106, LR: 0.003361
2025-05-18 08:28:09,260 [INFO] Epoch 11/15 - Policy Loss: 0.7335, Value Loss: 0.0758, Total Loss: 0.8093, LR: 0.001711
2025-05-18 08:28:50,584 [INFO] Epoch 12/15 - Policy Loss: 0.7322, Value Loss: 0.0755, Total Loss: 0.8077, LR: 0.000061
2025-05-18 08:29:31,858 [INFO] Epoch 13/15 - Policy Loss: 0.7310, Value Loss: 0.0751, Total Loss: 0.8062, LR: 0.001689
2025-05-18 08:30:13,072 [INFO] Epoch 14/15 - Policy Loss: 0.7302, Value Loss: 0.0749, Total Loss: 0.8052, LR: 0.003339
2025-05-18 08:30:54,422 [INFO] Epoch 15/15 - Policy Loss: 0.7297, Value Loss: 0.0748, Total Loss: 0.8045, LR: 0.004989
2025-05-18 08:30:54,439 [INFO] 训练完成，总损失: 0.8045
2025-05-18 08:30:54,439 [INFO] 保存迭代 91 的模型
2025-05-18 08:30:55,711 [INFO] Model saved to ./models/best.pt
2025-05-18 08:30:56,617 [INFO] Model saved to ./models/iteration_91.pt
2025-05-18 08:30:56,617 [INFO] 所有训练迭代完成
2025-05-18 08:30:56,618 [INFO] 开始迭代 92/300
2025-05-18 08:30:56,618 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 08:43:32,266 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 08:43:32,267 [INFO] 保存训练样本
2025-05-18 08:43:37,282 [INFO] 使用 160440 个样本训练神经网络
2025-05-18 08:43:37,282 [INFO] Training with 160440 examples
2025-05-18 08:43:37,282 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-18 08:43:37,338 [INFO] 循环学习率周期大小: 468 步
2025-05-18 08:44:18,802 [INFO] Epoch 1/15 - Policy Loss: 0.7440, Value Loss: 0.0813, Total Loss: 0.8252, LR: 0.001689
2025-05-18 08:44:59,971 [INFO] Epoch 2/15 - Policy Loss: 0.7410, Value Loss: 0.0803, Total Loss: 0.8213, LR: 0.003339
2025-05-18 08:45:40,986 [INFO] Epoch 3/15 - Policy Loss: 0.7387, Value Loss: 0.0794, Total Loss: 0.8181, LR: 0.004989
2025-05-18 08:46:22,042 [INFO] Epoch 4/15 - Policy Loss: 0.7369, Value Loss: 0.0779, Total Loss: 0.8147, LR: 0.003361
2025-05-18 08:47:03,111 [INFO] Epoch 5/15 - Policy Loss: 0.7353, Value Loss: 0.0770, Total Loss: 0.8123, LR: 0.001711
2025-05-18 08:47:44,208 [INFO] Epoch 6/15 - Policy Loss: 0.7330, Value Loss: 0.0759, Total Loss: 0.8089, LR: 0.000061
2025-05-18 08:48:25,430 [INFO] Epoch 7/15 - Policy Loss: 0.7315, Value Loss: 0.0752, Total Loss: 0.8067, LR: 0.001689
2025-05-18 08:49:06,589 [INFO] Epoch 8/15 - Policy Loss: 0.7295, Value Loss: 0.0748, Total Loss: 0.8043, LR: 0.003339
2025-05-18 08:49:47,863 [INFO] Epoch 9/15 - Policy Loss: 0.7288, Value Loss: 0.0747, Total Loss: 0.8035, LR: 0.004989
2025-05-18 08:50:29,161 [INFO] Epoch 10/15 - Policy Loss: 0.7286, Value Loss: 0.0744, Total Loss: 0.8030, LR: 0.003361
2025-05-18 08:51:10,441 [INFO] Epoch 11/15 - Policy Loss: 0.7277, Value Loss: 0.0743, Total Loss: 0.8019, LR: 0.001711
2025-05-18 08:51:51,773 [INFO] Epoch 12/15 - Policy Loss: 0.7265, Value Loss: 0.0740, Total Loss: 0.8005, LR: 0.000061
2025-05-18 08:52:33,133 [INFO] Epoch 13/15 - Policy Loss: 0.7254, Value Loss: 0.0736, Total Loss: 0.7990, LR: 0.001689
2025-05-18 08:53:14,491 [INFO] Epoch 14/15 - Policy Loss: 0.7250, Value Loss: 0.0734, Total Loss: 0.7984, LR: 0.003339
2025-05-18 08:53:55,865 [INFO] Epoch 15/15 - Policy Loss: 0.7245, Value Loss: 0.0732, Total Loss: 0.7978, LR: 0.004989
2025-05-18 08:53:55,889 [INFO] 训练完成，总损失: 0.7978
2025-05-18 08:53:55,889 [INFO] 保存迭代 92 的模型
2025-05-18 08:53:57,194 [INFO] Model saved to ./models/best.pt
2025-05-18 08:53:57,985 [INFO] Model saved to ./models/iteration_92.pt
2025-05-18 08:53:57,986 [INFO] 所有训练迭代完成
2025-05-18 08:53:57,986 [INFO] 开始迭代 93/300
2025-05-18 08:53:57,986 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 09:07:04,185 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 09:07:04,185 [INFO] 保存训练样本
2025-05-18 09:07:09,238 [INFO] 使用 160000 个样本训练神经网络
2025-05-18 09:07:09,238 [INFO] Training with 160000 examples
2025-05-18 09:07:09,239 [INFO] 总训练步数: 2340, 每轮次批次数: 156
2025-05-18 09:07:09,642 [INFO] 循环学习率周期大小: 468 步
2025-05-18 09:07:50,682 [INFO] Epoch 1/15 - Policy Loss: 0.7386, Value Loss: 0.0803, Total Loss: 0.8190, LR: 0.001689
2025-05-18 09:08:31,804 [INFO] Epoch 2/15 - Policy Loss: 0.7359, Value Loss: 0.0816, Total Loss: 0.8175, LR: 0.003339
2025-05-18 09:09:12,978 [INFO] Epoch 3/15 - Policy Loss: 0.7338, Value Loss: 0.0811, Total Loss: 0.8149, LR: 0.004989
2025-05-18 09:09:54,027 [INFO] Epoch 4/15 - Policy Loss: 0.7322, Value Loss: 0.0804, Total Loss: 0.8126, LR: 0.003361
2025-05-18 09:10:35,029 [INFO] Epoch 5/15 - Policy Loss: 0.7300, Value Loss: 0.0797, Total Loss: 0.8097, LR: 0.001711
2025-05-18 09:11:16,050 [INFO] Epoch 6/15 - Policy Loss: 0.7288, Value Loss: 0.0795, Total Loss: 0.8083, LR: 0.000061
2025-05-18 09:11:57,271 [INFO] Epoch 7/15 - Policy Loss: 0.7274, Value Loss: 0.0794, Total Loss: 0.8068, LR: 0.001689
2025-05-18 09:12:38,406 [INFO] Epoch 8/15 - Policy Loss: 0.7261, Value Loss: 0.0791, Total Loss: 0.8051, LR: 0.003339
2025-05-18 09:13:19,747 [INFO] Epoch 9/15 - Policy Loss: 0.7261, Value Loss: 0.0787, Total Loss: 0.8048, LR: 0.004989
2025-05-18 09:14:01,175 [INFO] Epoch 10/15 - Policy Loss: 0.7263, Value Loss: 0.0787, Total Loss: 0.8050, LR: 0.003361
2025-05-18 09:14:42,445 [INFO] Epoch 11/15 - Policy Loss: 0.7255, Value Loss: 0.0784, Total Loss: 0.8039, LR: 0.001711
2025-05-18 09:15:23,902 [INFO] Epoch 12/15 - Policy Loss: 0.7253, Value Loss: 0.0781, Total Loss: 0.8033, LR: 0.000061
2025-05-18 09:16:14,624 [INFO] Epoch 13/15 - Policy Loss: 0.7247, Value Loss: 0.0776, Total Loss: 0.8023, LR: 0.001689
2025-05-18 09:17:28,523 [INFO] Epoch 14/15 - Policy Loss: 0.7243, Value Loss: 0.0773, Total Loss: 0.8016, LR: 0.003339
2025-05-18 09:18:36,837 [INFO] Epoch 15/15 - Policy Loss: 0.7239, Value Loss: 0.0771, Total Loss: 0.8010, LR: 0.004989
2025-05-18 09:18:36,857 [INFO] 训练完成，总损失: 0.8010
2025-05-18 09:18:36,857 [INFO] 保存迭代 93 的模型
2025-05-18 09:18:38,315 [INFO] Model saved to ./models/best.pt
2025-05-18 09:18:39,198 [INFO] Model saved to ./models/iteration_93.pt
2025-05-18 09:18:39,198 [INFO] 所有训练迭代完成
2025-05-18 09:18:39,198 [INFO] 开始迭代 94/300
2025-05-18 09:18:39,198 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 09:35:37,553 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 09:35:37,554 [INFO] 保存训练样本
2025-05-18 09:35:42,305 [INFO] 使用 159664 个样本训练神经网络
2025-05-18 09:35:42,305 [INFO] Training with 159664 examples
2025-05-18 09:35:42,306 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-18 09:35:42,721 [INFO] 循环学习率周期大小: 465 步
2025-05-18 09:36:53,741 [INFO] Epoch 1/15 - Policy Loss: 0.7411, Value Loss: 0.0894, Total Loss: 0.8305, LR: 0.001689
2025-05-18 09:37:53,109 [INFO] Epoch 2/15 - Policy Loss: 0.7363, Value Loss: 0.0891, Total Loss: 0.8255, LR: 0.003339
2025-05-18 09:38:58,567 [INFO] Epoch 3/15 - Policy Loss: 0.7345, Value Loss: 0.0883, Total Loss: 0.8227, LR: 0.004989
2025-05-18 09:40:08,562 [INFO] Epoch 4/15 - Policy Loss: 0.7339, Value Loss: 0.0877, Total Loss: 0.8216, LR: 0.003361
2025-05-18 09:41:29,374 [INFO] Epoch 5/15 - Policy Loss: 0.7327, Value Loss: 0.0865, Total Loss: 0.8192, LR: 0.001711
2025-05-18 09:42:40,440 [INFO] Epoch 6/15 - Policy Loss: 0.7314, Value Loss: 0.0856, Total Loss: 0.8170, LR: 0.000061
2025-05-18 09:43:48,237 [INFO] Epoch 7/15 - Policy Loss: 0.7301, Value Loss: 0.0848, Total Loss: 0.8149, LR: 0.001689
2025-05-18 09:44:55,266 [INFO] Epoch 8/15 - Policy Loss: 0.7286, Value Loss: 0.0841, Total Loss: 0.8127, LR: 0.003339
2025-05-18 09:46:03,837 [INFO] Epoch 9/15 - Policy Loss: 0.7280, Value Loss: 0.0838, Total Loss: 0.8118, LR: 0.004989
2025-05-18 09:47:07,656 [INFO] Epoch 10/15 - Policy Loss: 0.7281, Value Loss: 0.0835, Total Loss: 0.8115, LR: 0.003361
2025-05-18 09:48:09,248 [INFO] Epoch 11/15 - Policy Loss: 0.7275, Value Loss: 0.0831, Total Loss: 0.8106, LR: 0.001711
2025-05-18 09:49:16,660 [INFO] Epoch 12/15 - Policy Loss: 0.7268, Value Loss: 0.0826, Total Loss: 0.8093, LR: 0.000061
2025-05-18 09:50:30,521 [INFO] Epoch 13/15 - Policy Loss: 0.7263, Value Loss: 0.0824, Total Loss: 0.8086, LR: 0.001689
2025-05-18 09:51:40,394 [INFO] Epoch 14/15 - Policy Loss: 0.7256, Value Loss: 0.0821, Total Loss: 0.8077, LR: 0.003339
2025-05-18 09:52:47,699 [INFO] Epoch 15/15 - Policy Loss: 0.7255, Value Loss: 0.0819, Total Loss: 0.8075, LR: 0.004989
2025-05-18 09:52:47,722 [INFO] 训练完成，总损失: 0.8075
2025-05-18 09:52:47,722 [INFO] 保存迭代 94 的模型
2025-05-18 09:52:48,995 [INFO] Model saved to ./models/best.pt
2025-05-18 09:52:49,687 [INFO] Model saved to ./models/iteration_94.pt
2025-05-18 09:52:49,688 [INFO] 所有训练迭代完成
2025-05-18 09:52:49,688 [INFO] 开始迭代 95/300
2025-05-18 09:52:49,688 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 10:09:51,139 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 10:09:51,139 [INFO] 保存训练样本
2025-05-18 10:09:55,605 [INFO] 使用 159576 个样本训练神经网络
2025-05-18 10:09:55,605 [INFO] Training with 159576 examples
2025-05-18 10:09:55,606 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-18 10:09:55,653 [INFO] 循环学习率周期大小: 465 步
2025-05-18 10:11:18,785 [INFO] Epoch 1/15 - Policy Loss: 0.7453, Value Loss: 0.0893, Total Loss: 0.8346, LR: 0.001689
2025-05-18 10:12:28,371 [INFO] Epoch 2/15 - Policy Loss: 0.7417, Value Loss: 0.0867, Total Loss: 0.8284, LR: 0.003339
2025-05-18 10:13:29,964 [INFO] Epoch 3/15 - Policy Loss: 0.7391, Value Loss: 0.0858, Total Loss: 0.8249, LR: 0.004989
2025-05-18 10:14:32,464 [INFO] Epoch 4/15 - Policy Loss: 0.7364, Value Loss: 0.0861, Total Loss: 0.8224, LR: 0.003361
2025-05-18 10:15:37,784 [INFO] Epoch 5/15 - Policy Loss: 0.7329, Value Loss: 0.0856, Total Loss: 0.8184, LR: 0.001711
2025-05-18 10:16:52,918 [INFO] Epoch 6/15 - Policy Loss: 0.7305, Value Loss: 0.0845, Total Loss: 0.8150, LR: 0.000061
2025-05-18 10:18:04,358 [INFO] Epoch 7/15 - Policy Loss: 0.7287, Value Loss: 0.0839, Total Loss: 0.8126, LR: 0.001689
2025-05-18 10:19:26,851 [INFO] Epoch 8/15 - Policy Loss: 0.7271, Value Loss: 0.0835, Total Loss: 0.8106, LR: 0.003339
2025-05-18 10:20:34,162 [INFO] Epoch 9/15 - Policy Loss: 0.7266, Value Loss: 0.0832, Total Loss: 0.8098, LR: 0.004989
2025-05-18 10:21:43,532 [INFO] Epoch 10/15 - Policy Loss: 0.7262, Value Loss: 0.0829, Total Loss: 0.8091, LR: 0.003361
2025-05-18 10:22:45,770 [INFO] Epoch 11/15 - Policy Loss: 0.7254, Value Loss: 0.0826, Total Loss: 0.8080, LR: 0.001711
2025-05-18 10:23:48,909 [INFO] Epoch 12/15 - Policy Loss: 0.7247, Value Loss: 0.0822, Total Loss: 0.8069, LR: 0.000061
2025-05-18 10:25:12,321 [INFO] Epoch 13/15 - Policy Loss: 0.7236, Value Loss: 0.0817, Total Loss: 0.8053, LR: 0.001689
2025-05-18 10:26:19,483 [INFO] Epoch 14/15 - Policy Loss: 0.7230, Value Loss: 0.0812, Total Loss: 0.8043, LR: 0.003339
2025-05-18 10:27:29,480 [INFO] Epoch 15/15 - Policy Loss: 0.7228, Value Loss: 0.0811, Total Loss: 0.8038, LR: 0.004989
2025-05-18 10:27:29,502 [INFO] 训练完成，总损失: 0.8038
2025-05-18 10:27:29,502 [INFO] 保存迭代 95 的模型
2025-05-18 10:27:30,889 [INFO] Model saved to ./models/best.pt
2025-05-18 10:27:31,730 [INFO] Model saved to ./models/iteration_95.pt
2025-05-18 10:27:31,731 [INFO] 所有训练迭代完成
2025-05-18 10:27:31,731 [INFO] 开始迭代 96/300
2025-05-18 10:27:31,731 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 10:44:44,832 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 10:44:44,833 [INFO] 保存训练样本
2025-05-18 10:44:49,615 [INFO] 使用 159456 个样本训练神经网络
2025-05-18 10:44:49,616 [INFO] Training with 159456 examples
2025-05-18 10:44:49,616 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-18 10:44:49,940 [INFO] 循环学习率周期大小: 465 步
2025-05-18 10:46:08,381 [INFO] Epoch 1/15 - Policy Loss: 0.7444, Value Loss: 0.0840, Total Loss: 0.8284, LR: 0.001689
2025-05-18 10:47:10,582 [INFO] Epoch 2/15 - Policy Loss: 0.7413, Value Loss: 0.0815, Total Loss: 0.8229, LR: 0.003339
2025-05-18 10:48:14,735 [INFO] Epoch 3/15 - Policy Loss: 0.7390, Value Loss: 0.0804, Total Loss: 0.8194, LR: 0.004989
2025-05-18 10:49:25,945 [INFO] Epoch 4/15 - Policy Loss: 0.7360, Value Loss: 0.0796, Total Loss: 0.8156, LR: 0.003361
2025-05-18 10:50:35,374 [INFO] Epoch 5/15 - Policy Loss: 0.7341, Value Loss: 0.0788, Total Loss: 0.8130, LR: 0.001711
2025-05-18 10:51:40,871 [INFO] Epoch 6/15 - Policy Loss: 0.7310, Value Loss: 0.0781, Total Loss: 0.8090, LR: 0.000061
2025-05-18 10:53:06,073 [INFO] Epoch 7/15 - Policy Loss: 0.7291, Value Loss: 0.0775, Total Loss: 0.8065, LR: 0.001689
2025-05-18 10:54:13,034 [INFO] Epoch 8/15 - Policy Loss: 0.7277, Value Loss: 0.0769, Total Loss: 0.8046, LR: 0.003339
2025-05-18 10:55:32,508 [INFO] Epoch 9/15 - Policy Loss: 0.7271, Value Loss: 0.0763, Total Loss: 0.8035, LR: 0.004989
2025-05-18 10:56:24,642 [INFO] Epoch 10/15 - Policy Loss: 0.7268, Value Loss: 0.0761, Total Loss: 0.8029, LR: 0.003361
2025-05-18 10:57:05,752 [INFO] Epoch 11/15 - Policy Loss: 0.7262, Value Loss: 0.0759, Total Loss: 0.8020, LR: 0.001711
2025-05-18 10:57:46,769 [INFO] Epoch 12/15 - Policy Loss: 0.7253, Value Loss: 0.0756, Total Loss: 0.8009, LR: 0.000061
2025-05-18 10:58:27,839 [INFO] Epoch 13/15 - Policy Loss: 0.7245, Value Loss: 0.0755, Total Loss: 0.8000, LR: 0.001689
2025-05-18 10:59:08,961 [INFO] Epoch 14/15 - Policy Loss: 0.7237, Value Loss: 0.0752, Total Loss: 0.7989, LR: 0.003339
2025-05-18 10:59:50,130 [INFO] Epoch 15/15 - Policy Loss: 0.7234, Value Loss: 0.0749, Total Loss: 0.7983, LR: 0.004989
2025-05-18 10:59:50,148 [INFO] 训练完成，总损失: 0.7983
2025-05-18 10:59:50,148 [INFO] 保存迭代 96 的模型
2025-05-18 10:59:51,350 [INFO] Model saved to ./models/best.pt
2025-05-18 10:59:52,032 [INFO] Model saved to ./models/iteration_96.pt
2025-05-18 10:59:52,032 [INFO] 所有训练迭代完成
2025-05-18 10:59:52,032 [INFO] 开始迭代 97/300
2025-05-18 10:59:52,032 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 11:14:41,958 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 11:14:41,958 [INFO] 保存训练样本
2025-05-18 11:14:46,334 [INFO] 使用 159376 个样本训练神经网络
2025-05-18 11:14:46,334 [INFO] Training with 159376 examples
2025-05-18 11:14:46,334 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-18 11:14:46,650 [INFO] 循环学习率周期大小: 465 步
2025-05-18 11:15:27,079 [INFO] Epoch 1/15 - Policy Loss: 0.7436, Value Loss: 0.0872, Total Loss: 0.8308, LR: 0.001689
2025-05-18 11:16:07,615 [INFO] Epoch 2/15 - Policy Loss: 0.7390, Value Loss: 0.0824, Total Loss: 0.8214, LR: 0.003339
2025-05-18 11:16:48,266 [INFO] Epoch 3/15 - Policy Loss: 0.7371, Value Loss: 0.0806, Total Loss: 0.8177, LR: 0.004989
2025-05-18 11:17:28,838 [INFO] Epoch 4/15 - Policy Loss: 0.7353, Value Loss: 0.0788, Total Loss: 0.8141, LR: 0.003361
2025-05-18 11:18:09,493 [INFO] Epoch 5/15 - Policy Loss: 0.7334, Value Loss: 0.0780, Total Loss: 0.8115, LR: 0.001711
2025-05-18 11:18:50,236 [INFO] Epoch 6/15 - Policy Loss: 0.7315, Value Loss: 0.0771, Total Loss: 0.8086, LR: 0.000061
2025-05-18 11:19:30,949 [INFO] Epoch 7/15 - Policy Loss: 0.7288, Value Loss: 0.0765, Total Loss: 0.8053, LR: 0.001689
2025-05-18 11:20:11,705 [INFO] Epoch 8/15 - Policy Loss: 0.7276, Value Loss: 0.0760, Total Loss: 0.8037, LR: 0.003339
2025-05-18 11:20:52,503 [INFO] Epoch 9/15 - Policy Loss: 0.7273, Value Loss: 0.0756, Total Loss: 0.8029, LR: 0.004989
2025-05-18 11:21:33,379 [INFO] Epoch 10/15 - Policy Loss: 0.7268, Value Loss: 0.0753, Total Loss: 0.8021, LR: 0.003361
2025-05-18 11:22:14,245 [INFO] Epoch 11/15 - Policy Loss: 0.7261, Value Loss: 0.0749, Total Loss: 0.8009, LR: 0.001711
2025-05-18 11:22:55,199 [INFO] Epoch 12/15 - Policy Loss: 0.7254, Value Loss: 0.0746, Total Loss: 0.8000, LR: 0.000061
2025-05-18 11:23:36,134 [INFO] Epoch 13/15 - Policy Loss: 0.7243, Value Loss: 0.0743, Total Loss: 0.7987, LR: 0.001689
2025-05-18 11:24:17,483 [INFO] Epoch 14/15 - Policy Loss: 0.7237, Value Loss: 0.0741, Total Loss: 0.7978, LR: 0.003339
2025-05-18 11:24:58,512 [INFO] Epoch 15/15 - Policy Loss: 0.7229, Value Loss: 0.0738, Total Loss: 0.7966, LR: 0.004989
2025-05-18 11:24:58,532 [INFO] 训练完成，总损失: 0.7966
2025-05-18 11:24:58,532 [INFO] 保存迭代 97 的模型
2025-05-18 11:24:59,902 [INFO] Model saved to ./models/best.pt
2025-05-18 11:25:00,722 [INFO] Model saved to ./models/iteration_97.pt
2025-05-18 11:25:00,722 [INFO] 所有训练迭代完成
2025-05-18 11:25:00,723 [INFO] 开始迭代 98/300
2025-05-18 11:25:00,723 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 11:37:28,668 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 11:37:28,669 [INFO] 保存训练样本
2025-05-18 11:37:32,675 [INFO] 使用 158728 个样本训练神经网络
2025-05-18 11:37:32,676 [INFO] Training with 158728 examples
2025-05-18 11:37:32,676 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-18 11:37:33,004 [INFO] 循环学习率周期大小: 465 步
2025-05-18 11:38:13,517 [INFO] Epoch 1/15 - Policy Loss: 0.7383, Value Loss: 0.0702, Total Loss: 0.8086, LR: 0.001689
2025-05-18 11:38:54,138 [INFO] Epoch 2/15 - Policy Loss: 0.7354, Value Loss: 0.0689, Total Loss: 0.8043, LR: 0.003339
2025-05-18 11:39:34,732 [INFO] Epoch 3/15 - Policy Loss: 0.7325, Value Loss: 0.0685, Total Loss: 0.8010, LR: 0.004989
2025-05-18 11:40:15,491 [INFO] Epoch 4/15 - Policy Loss: 0.7321, Value Loss: 0.0685, Total Loss: 0.8005, LR: 0.003361
2025-05-18 11:40:56,135 [INFO] Epoch 5/15 - Policy Loss: 0.7301, Value Loss: 0.0682, Total Loss: 0.7983, LR: 0.001711
2025-05-18 11:41:36,828 [INFO] Epoch 6/15 - Policy Loss: 0.7283, Value Loss: 0.0678, Total Loss: 0.7961, LR: 0.000061
2025-05-18 11:42:17,590 [INFO] Epoch 7/15 - Policy Loss: 0.7269, Value Loss: 0.0677, Total Loss: 0.7945, LR: 0.001689
2025-05-18 11:42:58,293 [INFO] Epoch 8/15 - Policy Loss: 0.7258, Value Loss: 0.0676, Total Loss: 0.7933, LR: 0.003339
2025-05-18 11:43:39,072 [INFO] Epoch 9/15 - Policy Loss: 0.7248, Value Loss: 0.0673, Total Loss: 0.7921, LR: 0.004989
2025-05-18 11:44:20,362 [INFO] Epoch 10/15 - Policy Loss: 0.7250, Value Loss: 0.0673, Total Loss: 0.7922, LR: 0.003361
2025-05-18 11:45:01,283 [INFO] Epoch 11/15 - Policy Loss: 0.7246, Value Loss: 0.0672, Total Loss: 0.7918, LR: 0.001711
2025-05-18 11:45:42,190 [INFO] Epoch 12/15 - Policy Loss: 0.7237, Value Loss: 0.0671, Total Loss: 0.7907, LR: 0.000061
2025-05-18 11:46:23,090 [INFO] Epoch 13/15 - Policy Loss: 0.7224, Value Loss: 0.0669, Total Loss: 0.7892, LR: 0.001689
2025-05-18 11:47:04,049 [INFO] Epoch 14/15 - Policy Loss: 0.7216, Value Loss: 0.0668, Total Loss: 0.7884, LR: 0.003339
2025-05-18 11:47:45,055 [INFO] Epoch 15/15 - Policy Loss: 0.7216, Value Loss: 0.0667, Total Loss: 0.7883, LR: 0.004989
2025-05-18 11:47:45,072 [INFO] 训练完成，总损失: 0.7883
2025-05-18 11:47:45,073 [INFO] 保存迭代 98 的模型
2025-05-18 11:47:46,292 [INFO] Model saved to ./models/best.pt
2025-05-18 11:47:46,976 [INFO] Model saved to ./models/iteration_98.pt
2025-05-18 11:47:46,977 [INFO] 所有训练迭代完成
2025-05-18 11:47:46,977 [INFO] 开始迭代 99/300
2025-05-18 11:47:46,977 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 11:59:16,381 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 11:59:16,382 [INFO] 保存训练样本
2025-05-18 11:59:20,689 [INFO] 使用 158040 个样本训练神经网络
2025-05-18 11:59:20,689 [INFO] Training with 158040 examples
2025-05-18 11:59:20,689 [INFO] 总训练步数: 2310, 每轮次批次数: 154
2025-05-18 11:59:20,737 [INFO] 循环学习率周期大小: 462 步
2025-05-18 12:00:01,007 [INFO] Epoch 1/15 - Policy Loss: 0.7407, Value Loss: 0.0746, Total Loss: 0.8153, LR: 0.001689
2025-05-18 12:00:41,395 [INFO] Epoch 2/15 - Policy Loss: 0.7353, Value Loss: 0.0736, Total Loss: 0.8088, LR: 0.003339
2025-05-18 12:01:21,675 [INFO] Epoch 3/15 - Policy Loss: 0.7331, Value Loss: 0.0730, Total Loss: 0.8060, LR: 0.004989
2025-05-18 12:02:02,015 [INFO] Epoch 4/15 - Policy Loss: 0.7314, Value Loss: 0.0725, Total Loss: 0.8039, LR: 0.003361
2025-05-18 12:02:42,419 [INFO] Epoch 5/15 - Policy Loss: 0.7306, Value Loss: 0.0726, Total Loss: 0.8031, LR: 0.001711
2025-05-18 12:03:22,781 [INFO] Epoch 6/15 - Policy Loss: 0.7285, Value Loss: 0.0723, Total Loss: 0.8008, LR: 0.000061
2025-05-18 12:04:03,453 [INFO] Epoch 7/15 - Policy Loss: 0.7276, Value Loss: 0.0722, Total Loss: 0.7998, LR: 0.001689
2025-05-18 12:04:43,898 [INFO] Epoch 8/15 - Policy Loss: 0.7263, Value Loss: 0.0716, Total Loss: 0.7980, LR: 0.003339
2025-05-18 12:05:24,342 [INFO] Epoch 9/15 - Policy Loss: 0.7257, Value Loss: 0.0714, Total Loss: 0.7971, LR: 0.004989
2025-05-18 12:06:04,892 [INFO] Epoch 10/15 - Policy Loss: 0.7250, Value Loss: 0.0712, Total Loss: 0.7962, LR: 0.003361
2025-05-18 12:06:45,501 [INFO] Epoch 11/15 - Policy Loss: 0.7245, Value Loss: 0.0712, Total Loss: 0.7957, LR: 0.001711
2025-05-18 12:07:26,123 [INFO] Epoch 12/15 - Policy Loss: 0.7241, Value Loss: 0.0712, Total Loss: 0.7953, LR: 0.000061
2025-05-18 12:08:06,779 [INFO] Epoch 13/15 - Policy Loss: 0.7237, Value Loss: 0.0711, Total Loss: 0.7948, LR: 0.001689
2025-05-18 12:08:47,552 [INFO] Epoch 14/15 - Policy Loss: 0.7232, Value Loss: 0.0710, Total Loss: 0.7942, LR: 0.003339
2025-05-18 12:09:28,312 [INFO] Epoch 15/15 - Policy Loss: 0.7230, Value Loss: 0.0709, Total Loss: 0.7939, LR: 0.004989
2025-05-18 12:09:28,329 [INFO] 训练完成，总损失: 0.7939
2025-05-18 12:09:28,329 [INFO] 保存迭代 99 的模型
2025-05-18 12:09:29,719 [INFO] Model saved to ./models/best.pt
2025-05-18 12:09:30,597 [INFO] Model saved to ./models/iteration_99.pt
2025-05-18 12:09:30,597 [INFO] 所有训练迭代完成
2025-05-18 12:09:30,597 [INFO] 开始迭代 100/300
2025-05-18 12:09:30,597 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 12:21:32,513 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 12:21:32,513 [INFO] 保存训练样本
2025-05-18 12:21:37,424 [INFO] 使用 157504 个样本训练神经网络
2025-05-18 12:21:37,425 [INFO] Training with 157504 examples
2025-05-18 12:21:37,425 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-18 12:21:37,481 [INFO] 循环学习率周期大小: 459 步
2025-05-18 12:22:18,287 [INFO] Epoch 1/15 - Policy Loss: 0.7387, Value Loss: 0.0793, Total Loss: 0.8179, LR: 0.001689
2025-05-18 12:22:58,622 [INFO] Epoch 2/15 - Policy Loss: 0.7352, Value Loss: 0.0787, Total Loss: 0.8139, LR: 0.003339
2025-05-18 12:23:38,984 [INFO] Epoch 3/15 - Policy Loss: 0.7336, Value Loss: 0.0780, Total Loss: 0.8116, LR: 0.004989
2025-05-18 12:24:19,495 [INFO] Epoch 4/15 - Policy Loss: 0.7319, Value Loss: 0.0780, Total Loss: 0.8099, LR: 0.003361
2025-05-18 12:24:59,953 [INFO] Epoch 5/15 - Policy Loss: 0.7309, Value Loss: 0.0776, Total Loss: 0.8085, LR: 0.001711
2025-05-18 12:25:40,256 [INFO] Epoch 6/15 - Policy Loss: 0.7291, Value Loss: 0.0771, Total Loss: 0.8063, LR: 0.000061
2025-05-18 12:26:20,701 [INFO] Epoch 7/15 - Policy Loss: 0.7277, Value Loss: 0.0769, Total Loss: 0.8047, LR: 0.001689
2025-05-18 12:27:01,122 [INFO] Epoch 8/15 - Policy Loss: 0.7271, Value Loss: 0.0766, Total Loss: 0.8037, LR: 0.003339
2025-05-18 12:27:41,566 [INFO] Epoch 9/15 - Policy Loss: 0.7266, Value Loss: 0.0766, Total Loss: 0.8032, LR: 0.004989
2025-05-18 12:28:22,068 [INFO] Epoch 10/15 - Policy Loss: 0.7263, Value Loss: 0.0764, Total Loss: 0.8027, LR: 0.003361
2025-05-18 12:29:02,647 [INFO] Epoch 11/15 - Policy Loss: 0.7258, Value Loss: 0.0763, Total Loss: 0.8021, LR: 0.001711
2025-05-18 12:29:43,063 [INFO] Epoch 12/15 - Policy Loss: 0.7253, Value Loss: 0.0763, Total Loss: 0.8015, LR: 0.000061
2025-05-18 12:30:23,514 [INFO] Epoch 13/15 - Policy Loss: 0.7248, Value Loss: 0.0761, Total Loss: 0.8009, LR: 0.001689
2025-05-18 12:31:04,105 [INFO] Epoch 14/15 - Policy Loss: 0.7242, Value Loss: 0.0760, Total Loss: 0.8002, LR: 0.003339
2025-05-18 12:31:44,700 [INFO] Epoch 15/15 - Policy Loss: 0.7243, Value Loss: 0.0759, Total Loss: 0.8002, LR: 0.004989
2025-05-18 12:31:44,720 [INFO] 训练完成，总损失: 0.8002
2025-05-18 12:31:44,720 [INFO] 保存迭代 100 的模型
2025-05-18 12:31:46,010 [INFO] Model saved to ./models/best.pt
2025-05-18 12:31:47,014 [INFO] Model saved to ./models/iteration_100.pt
2025-05-18 12:31:47,015 [INFO] 所有训练迭代完成
2025-05-18 12:31:47,015 [INFO] 开始迭代 101/300
2025-05-18 12:31:47,015 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 12:43:28,122 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 12:43:28,123 [INFO] 保存训练样本
2025-05-18 12:43:32,496 [INFO] 使用 156936 个样本训练神经网络
2025-05-18 12:43:32,496 [INFO] Training with 156936 examples
2025-05-18 12:43:32,496 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-18 12:43:32,795 [INFO] 循环学习率周期大小: 459 步
2025-05-18 12:44:12,833 [INFO] Epoch 1/15 - Policy Loss: 0.7414, Value Loss: 0.0718, Total Loss: 0.8132, LR: 0.001689
2025-05-18 12:44:53,072 [INFO] Epoch 2/15 - Policy Loss: 0.7374, Value Loss: 0.0711, Total Loss: 0.8086, LR: 0.003339
2025-05-18 12:45:33,225 [INFO] Epoch 3/15 - Policy Loss: 0.7336, Value Loss: 0.0713, Total Loss: 0.8049, LR: 0.004989
2025-05-18 12:46:13,465 [INFO] Epoch 4/15 - Policy Loss: 0.7328, Value Loss: 0.0718, Total Loss: 0.8046, LR: 0.003361
2025-05-18 12:46:53,778 [INFO] Epoch 5/15 - Policy Loss: 0.7296, Value Loss: 0.0712, Total Loss: 0.8008, LR: 0.001711
2025-05-18 12:47:34,231 [INFO] Epoch 6/15 - Policy Loss: 0.7282, Value Loss: 0.0706, Total Loss: 0.7987, LR: 0.000061
2025-05-18 12:48:14,893 [INFO] Epoch 7/15 - Policy Loss: 0.7266, Value Loss: 0.0703, Total Loss: 0.7969, LR: 0.001689
2025-05-18 12:48:55,520 [INFO] Epoch 8/15 - Policy Loss: 0.7253, Value Loss: 0.0704, Total Loss: 0.7958, LR: 0.003339
2025-05-18 12:49:36,094 [INFO] Epoch 9/15 - Policy Loss: 0.7245, Value Loss: 0.0703, Total Loss: 0.7948, LR: 0.004989
2025-05-18 12:50:16,758 [INFO] Epoch 10/15 - Policy Loss: 0.7244, Value Loss: 0.0702, Total Loss: 0.7946, LR: 0.003361
2025-05-18 12:50:57,464 [INFO] Epoch 11/15 - Policy Loss: 0.7240, Value Loss: 0.0700, Total Loss: 0.7940, LR: 0.001711
2025-05-18 12:51:38,253 [INFO] Epoch 12/15 - Policy Loss: 0.7235, Value Loss: 0.0699, Total Loss: 0.7933, LR: 0.000061
2025-05-18 12:52:19,377 [INFO] Epoch 13/15 - Policy Loss: 0.7227, Value Loss: 0.0697, Total Loss: 0.7924, LR: 0.001689
2025-05-18 12:53:00,098 [INFO] Epoch 14/15 - Policy Loss: 0.7223, Value Loss: 0.0697, Total Loss: 0.7920, LR: 0.003339
2025-05-18 12:53:40,873 [INFO] Epoch 15/15 - Policy Loss: 0.7223, Value Loss: 0.0696, Total Loss: 0.7919, LR: 0.004989
2025-05-18 12:53:40,890 [INFO] 训练完成，总损失: 0.7919
2025-05-18 12:53:40,890 [INFO] 保存迭代 101 的模型
2025-05-18 12:53:42,147 [INFO] Model saved to ./models/best.pt
2025-05-18 12:53:43,184 [INFO] Model saved to ./models/iteration_101.pt
2025-05-18 12:53:43,184 [INFO] 所有训练迭代完成
2025-05-18 12:53:43,184 [INFO] 开始迭代 102/300
2025-05-18 12:53:43,184 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 13:05:23,990 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 13:05:23,990 [INFO] 保存训练样本
2025-05-18 13:05:28,440 [INFO] 使用 156072 个样本训练神经网络
2025-05-18 13:05:28,440 [INFO] Training with 156072 examples
2025-05-18 13:05:28,441 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-18 13:05:28,754 [INFO] 循环学习率周期大小: 456 步
2025-05-18 13:06:08,534 [INFO] Epoch 1/15 - Policy Loss: 0.7361, Value Loss: 0.0711, Total Loss: 0.8072, LR: 0.001689
2025-05-18 13:06:48,243 [INFO] Epoch 2/15 - Policy Loss: 0.7329, Value Loss: 0.0709, Total Loss: 0.8038, LR: 0.003339
2025-05-18 13:07:28,028 [INFO] Epoch 3/15 - Policy Loss: 0.7315, Value Loss: 0.0715, Total Loss: 0.8029, LR: 0.004989
2025-05-18 13:08:07,944 [INFO] Epoch 4/15 - Policy Loss: 0.7328, Value Loss: 0.0712, Total Loss: 0.8041, LR: 0.003361
2025-05-18 13:08:48,021 [INFO] Epoch 5/15 - Policy Loss: 0.7299, Value Loss: 0.0708, Total Loss: 0.8007, LR: 0.001711
2025-05-18 13:09:27,938 [INFO] Epoch 6/15 - Policy Loss: 0.7281, Value Loss: 0.0703, Total Loss: 0.7983, LR: 0.000061
2025-05-18 13:10:08,061 [INFO] Epoch 7/15 - Policy Loss: 0.7268, Value Loss: 0.0700, Total Loss: 0.7968, LR: 0.001689
2025-05-18 13:10:48,326 [INFO] Epoch 8/15 - Policy Loss: 0.7258, Value Loss: 0.0696, Total Loss: 0.7954, LR: 0.003339
2025-05-18 13:11:29,069 [INFO] Epoch 9/15 - Policy Loss: 0.7251, Value Loss: 0.0695, Total Loss: 0.7947, LR: 0.004989
2025-05-18 13:12:09,356 [INFO] Epoch 10/15 - Policy Loss: 0.7250, Value Loss: 0.0693, Total Loss: 0.7943, LR: 0.003361
2025-05-18 13:12:49,590 [INFO] Epoch 11/15 - Policy Loss: 0.7244, Value Loss: 0.0693, Total Loss: 0.7936, LR: 0.001711
2025-05-18 13:13:29,911 [INFO] Epoch 12/15 - Policy Loss: 0.7236, Value Loss: 0.0690, Total Loss: 0.7926, LR: 0.000061
2025-05-18 13:14:10,296 [INFO] Epoch 13/15 - Policy Loss: 0.7229, Value Loss: 0.0690, Total Loss: 0.7919, LR: 0.001689
2025-05-18 13:14:50,555 [INFO] Epoch 14/15 - Policy Loss: 0.7226, Value Loss: 0.0687, Total Loss: 0.7913, LR: 0.003339
2025-05-18 13:15:30,829 [INFO] Epoch 15/15 - Policy Loss: 0.7224, Value Loss: 0.0685, Total Loss: 0.7909, LR: 0.004989
2025-05-18 13:15:30,845 [INFO] 训练完成，总损失: 0.7909
2025-05-18 13:15:30,845 [INFO] 保存迭代 102 的模型
2025-05-18 13:15:32,387 [INFO] Model saved to ./models/best.pt
2025-05-18 13:15:33,426 [INFO] Model saved to ./models/iteration_102.pt
2025-05-18 13:15:33,427 [INFO] 所有训练迭代完成
2025-05-18 13:15:33,427 [INFO] 开始迭代 103/300
2025-05-18 13:15:33,427 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 13:34:03,057 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 13:34:03,057 [INFO] 保存训练样本
2025-05-18 13:34:07,633 [INFO] 使用 156560 个样本训练神经网络
2025-05-18 13:34:07,634 [INFO] Training with 156560 examples
2025-05-18 13:34:07,634 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-18 13:34:07,678 [INFO] 循环学习率周期大小: 456 步
2025-05-18 13:35:30,827 [INFO] Epoch 1/15 - Policy Loss: 0.7378, Value Loss: 0.0919, Total Loss: 0.8296, LR: 0.001689
2025-05-18 13:36:46,216 [INFO] Epoch 2/15 - Policy Loss: 0.7339, Value Loss: 0.0895, Total Loss: 0.8234, LR: 0.003339
2025-05-18 13:38:05,980 [INFO] Epoch 3/15 - Policy Loss: 0.7323, Value Loss: 0.0884, Total Loss: 0.8208, LR: 0.004989
2025-05-18 13:39:29,547 [INFO] Epoch 4/15 - Policy Loss: 0.7305, Value Loss: 0.0870, Total Loss: 0.8175, LR: 0.003361
2025-05-18 13:40:41,725 [INFO] Epoch 5/15 - Policy Loss: 0.7289, Value Loss: 0.0860, Total Loss: 0.8148, LR: 0.001711
2025-05-18 13:42:00,222 [INFO] Epoch 6/15 - Policy Loss: 0.7271, Value Loss: 0.0851, Total Loss: 0.8121, LR: 0.000061
2025-05-18 13:43:21,291 [INFO] Epoch 7/15 - Policy Loss: 0.7256, Value Loss: 0.0845, Total Loss: 0.8100, LR: 0.001689
2025-05-18 13:44:36,878 [INFO] Epoch 8/15 - Policy Loss: 0.7245, Value Loss: 0.0837, Total Loss: 0.8082, LR: 0.003339
2025-05-18 13:45:56,999 [INFO] Epoch 9/15 - Policy Loss: 0.7237, Value Loss: 0.0831, Total Loss: 0.8068, LR: 0.004989
2025-05-18 13:47:20,601 [INFO] Epoch 10/15 - Policy Loss: 0.7234, Value Loss: 0.0829, Total Loss: 0.8063, LR: 0.003361
2025-05-18 13:48:35,593 [INFO] Epoch 11/15 - Policy Loss: 0.7228, Value Loss: 0.0826, Total Loss: 0.8054, LR: 0.001711
2025-05-18 13:49:53,331 [INFO] Epoch 12/15 - Policy Loss: 0.7224, Value Loss: 0.0823, Total Loss: 0.8047, LR: 0.000061
2025-05-18 13:51:19,547 [INFO] Epoch 13/15 - Policy Loss: 0.7215, Value Loss: 0.0819, Total Loss: 0.8035, LR: 0.001689
2025-05-18 13:52:46,752 [INFO] Epoch 14/15 - Policy Loss: 0.7210, Value Loss: 0.0816, Total Loss: 0.8026, LR: 0.003339
2025-05-18 13:54:11,050 [INFO] Epoch 15/15 - Policy Loss: 0.7207, Value Loss: 0.0814, Total Loss: 0.8021, LR: 0.004989
2025-05-18 13:54:11,067 [INFO] 训练完成，总损失: 0.8021
2025-05-18 13:54:11,067 [INFO] 保存迭代 103 的模型
2025-05-18 13:54:12,325 [INFO] Model saved to ./models/best.pt
2025-05-18 13:54:13,049 [INFO] Model saved to ./models/iteration_103.pt
2025-05-18 13:54:13,049 [INFO] 所有训练迭代完成
2025-05-18 13:54:13,049 [INFO] 开始迭代 104/300
2025-05-18 13:54:13,049 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 14:14:06,428 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 14:14:06,429 [INFO] 保存训练样本
2025-05-18 14:14:10,861 [INFO] 使用 156928 个样本训练神经网络
2025-05-18 14:14:10,861 [INFO] Training with 156928 examples
2025-05-18 14:14:10,861 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-18 14:14:11,183 [INFO] 循环学习率周期大小: 459 步
2025-05-18 14:15:25,079 [INFO] Epoch 1/15 - Policy Loss: 0.7518, Value Loss: 0.0817, Total Loss: 0.8335, LR: 0.001689
2025-05-18 14:16:44,197 [INFO] Epoch 2/15 - Policy Loss: 0.7437, Value Loss: 0.0808, Total Loss: 0.8245, LR: 0.003339
2025-05-18 14:18:07,521 [INFO] Epoch 3/15 - Policy Loss: 0.7385, Value Loss: 0.0800, Total Loss: 0.8185, LR: 0.004989
2025-05-18 14:19:24,657 [INFO] Epoch 4/15 - Policy Loss: 0.7357, Value Loss: 0.0795, Total Loss: 0.8152, LR: 0.003361
2025-05-18 14:20:43,906 [INFO] Epoch 5/15 - Policy Loss: 0.7341, Value Loss: 0.0785, Total Loss: 0.8125, LR: 0.001711
2025-05-18 14:21:59,682 [INFO] Epoch 6/15 - Policy Loss: 0.7313, Value Loss: 0.0780, Total Loss: 0.8093, LR: 0.000061
2025-05-18 14:23:21,841 [INFO] Epoch 7/15 - Policy Loss: 0.7301, Value Loss: 0.0774, Total Loss: 0.8075, LR: 0.001689
2025-05-18 14:24:46,950 [INFO] Epoch 8/15 - Policy Loss: 0.7282, Value Loss: 0.0770, Total Loss: 0.8052, LR: 0.003339
2025-05-18 14:26:08,527 [INFO] Epoch 9/15 - Policy Loss: 0.7272, Value Loss: 0.0767, Total Loss: 0.8040, LR: 0.004989
2025-05-18 14:27:32,678 [INFO] Epoch 10/15 - Policy Loss: 0.7266, Value Loss: 0.0764, Total Loss: 0.8030, LR: 0.003361
2025-05-18 14:28:47,367 [INFO] Epoch 11/15 - Policy Loss: 0.7257, Value Loss: 0.0761, Total Loss: 0.8017, LR: 0.001711
2025-05-18 14:30:10,365 [INFO] Epoch 12/15 - Policy Loss: 0.7250, Value Loss: 0.0760, Total Loss: 0.8010, LR: 0.000061
2025-05-18 14:31:30,401 [INFO] Epoch 13/15 - Policy Loss: 0.7240, Value Loss: 0.0759, Total Loss: 0.7999, LR: 0.001689
2025-05-18 14:32:47,899 [INFO] Epoch 14/15 - Policy Loss: 0.7236, Value Loss: 0.0756, Total Loss: 0.7992, LR: 0.003339
2025-05-18 14:34:02,159 [INFO] Epoch 15/15 - Policy Loss: 0.7228, Value Loss: 0.0754, Total Loss: 0.7982, LR: 0.004989
2025-05-18 14:34:02,176 [INFO] 训练完成，总损失: 0.7982
2025-05-18 14:34:02,176 [INFO] 保存迭代 104 的模型
2025-05-18 14:34:03,397 [INFO] Model saved to ./models/best.pt
2025-05-18 14:34:04,093 [INFO] Model saved to ./models/iteration_104.pt
2025-05-18 14:34:04,093 [INFO] 所有训练迭代完成
2025-05-18 14:34:04,093 [INFO] 开始迭代 105/300
2025-05-18 14:34:04,093 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 14:51:09,320 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 14:51:09,321 [INFO] 保存训练样本
2025-05-18 14:51:13,502 [INFO] 使用 157192 个样本训练神经网络
2025-05-18 14:51:13,502 [INFO] Training with 157192 examples
2025-05-18 14:51:13,503 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-18 14:51:13,821 [INFO] 循环学习率周期大小: 459 步
2025-05-18 14:52:38,540 [INFO] Epoch 1/15 - Policy Loss: 0.7430, Value Loss: 0.0714, Total Loss: 0.8144, LR: 0.001689
2025-05-18 14:53:58,712 [INFO] Epoch 2/15 - Policy Loss: 0.7358, Value Loss: 0.0721, Total Loss: 0.8079, LR: 0.003339
2025-05-18 14:55:20,476 [INFO] Epoch 3/15 - Policy Loss: 0.7351, Value Loss: 0.0717, Total Loss: 0.8068, LR: 0.004989
2025-05-18 14:56:38,668 [INFO] Epoch 4/15 - Policy Loss: 0.7330, Value Loss: 0.0721, Total Loss: 0.8050, LR: 0.003361
2025-05-18 14:57:53,013 [INFO] Epoch 5/15 - Policy Loss: 0.7292, Value Loss: 0.0719, Total Loss: 0.8011, LR: 0.001711
2025-05-18 14:59:16,765 [INFO] Epoch 6/15 - Policy Loss: 0.7269, Value Loss: 0.0719, Total Loss: 0.7988, LR: 0.000061
2025-05-18 15:00:32,162 [INFO] Epoch 7/15 - Policy Loss: 0.7251, Value Loss: 0.0717, Total Loss: 0.7968, LR: 0.001689
2025-05-18 15:01:55,671 [INFO] Epoch 8/15 - Policy Loss: 0.7239, Value Loss: 0.0716, Total Loss: 0.7955, LR: 0.003339
2025-05-18 15:03:17,146 [INFO] Epoch 9/15 - Policy Loss: 0.7234, Value Loss: 0.0717, Total Loss: 0.7951, LR: 0.004989
2025-05-18 15:04:42,502 [INFO] Epoch 10/15 - Policy Loss: 0.7232, Value Loss: 0.0716, Total Loss: 0.7949, LR: 0.003361
2025-05-18 15:06:02,651 [INFO] Epoch 11/15 - Policy Loss: 0.7229, Value Loss: 0.0716, Total Loss: 0.7945, LR: 0.001711
2025-05-18 15:07:19,319 [INFO] Epoch 12/15 - Policy Loss: 0.7219, Value Loss: 0.0714, Total Loss: 0.7934, LR: 0.000061
2025-05-18 15:08:45,325 [INFO] Epoch 13/15 - Policy Loss: 0.7208, Value Loss: 0.0713, Total Loss: 0.7921, LR: 0.001689
2025-05-18 15:10:06,671 [INFO] Epoch 14/15 - Policy Loss: 0.7200, Value Loss: 0.0711, Total Loss: 0.7911, LR: 0.003339
2025-05-18 15:11:37,143 [INFO] Epoch 15/15 - Policy Loss: 0.7197, Value Loss: 0.0711, Total Loss: 0.7909, LR: 0.004989
2025-05-18 15:11:37,160 [INFO] 训练完成，总损失: 0.7909
2025-05-18 15:11:37,160 [INFO] 保存迭代 105 的模型
2025-05-18 15:11:38,399 [INFO] Model saved to ./models/best.pt
2025-05-18 15:11:39,093 [INFO] Model saved to ./models/iteration_105.pt
2025-05-18 15:11:39,093 [INFO] 所有训练迭代完成
2025-05-18 15:11:39,093 [INFO] 开始迭代 106/300
2025-05-18 15:11:39,093 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 15:27:31,257 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 15:27:31,257 [INFO] 保存训练样本
2025-05-18 15:27:36,269 [INFO] 使用 157072 个样本训练神经网络
2025-05-18 15:27:36,270 [INFO] Training with 157072 examples
2025-05-18 15:27:36,270 [INFO] 总训练步数: 2295, 每轮次批次数: 153
2025-05-18 15:27:36,331 [INFO] 循环学习率周期大小: 459 步
2025-05-18 15:28:56,242 [INFO] Epoch 1/15 - Policy Loss: 0.7305, Value Loss: 0.0766, Total Loss: 0.8071, LR: 0.001689
2025-05-18 15:30:06,889 [INFO] Epoch 2/15 - Policy Loss: 0.7292, Value Loss: 0.0763, Total Loss: 0.8055, LR: 0.003339
2025-05-18 15:31:34,540 [INFO] Epoch 3/15 - Policy Loss: 0.7282, Value Loss: 0.0760, Total Loss: 0.8043, LR: 0.004989
2025-05-18 15:32:49,443 [INFO] Epoch 4/15 - Policy Loss: 0.7271, Value Loss: 0.0751, Total Loss: 0.8022, LR: 0.003361
2025-05-18 15:34:08,813 [INFO] Epoch 5/15 - Policy Loss: 0.7243, Value Loss: 0.0747, Total Loss: 0.7990, LR: 0.001711
2025-05-18 15:35:25,914 [INFO] Epoch 6/15 - Policy Loss: 0.7220, Value Loss: 0.0738, Total Loss: 0.7957, LR: 0.000061
2025-05-18 15:36:39,911 [INFO] Epoch 7/15 - Policy Loss: 0.7209, Value Loss: 0.0735, Total Loss: 0.7944, LR: 0.001689
2025-05-18 15:37:55,829 [INFO] Epoch 8/15 - Policy Loss: 0.7207, Value Loss: 0.0730, Total Loss: 0.7937, LR: 0.003339
2025-05-18 15:39:16,505 [INFO] Epoch 9/15 - Policy Loss: 0.7211, Value Loss: 0.0732, Total Loss: 0.7942, LR: 0.004989
2025-05-18 15:40:33,316 [INFO] Epoch 10/15 - Policy Loss: 0.7211, Value Loss: 0.0730, Total Loss: 0.7941, LR: 0.003361
2025-05-18 15:41:52,110 [INFO] Epoch 11/15 - Policy Loss: 0.7209, Value Loss: 0.0730, Total Loss: 0.7939, LR: 0.001711
2025-05-18 15:43:04,714 [INFO] Epoch 12/15 - Policy Loss: 0.7199, Value Loss: 0.0727, Total Loss: 0.7927, LR: 0.000061
2025-05-18 15:44:17,755 [INFO] Epoch 13/15 - Policy Loss: 0.7193, Value Loss: 0.0725, Total Loss: 0.7918, LR: 0.001689
2025-05-18 15:45:43,857 [INFO] Epoch 14/15 - Policy Loss: 0.7190, Value Loss: 0.0724, Total Loss: 0.7914, LR: 0.003339
2025-05-18 15:47:11,195 [INFO] Epoch 15/15 - Policy Loss: 0.7188, Value Loss: 0.0724, Total Loss: 0.7912, LR: 0.004989
2025-05-18 15:47:11,218 [INFO] 训练完成，总损失: 0.7912
2025-05-18 15:47:11,218 [INFO] 保存迭代 106 的模型
2025-05-18 15:47:12,493 [INFO] Model saved to ./models/best.pt
2025-05-18 15:47:13,388 [INFO] Model saved to ./models/iteration_106.pt
2025-05-18 15:47:13,388 [INFO] 所有训练迭代完成
2025-05-18 15:47:13,388 [INFO] 开始迭代 107/300
2025-05-18 15:47:13,388 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 16:02:57,775 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 16:02:57,776 [INFO] 保存训练样本
2025-05-18 16:03:02,270 [INFO] 使用 156008 个样本训练神经网络
2025-05-18 16:03:02,270 [INFO] Training with 156008 examples
2025-05-18 16:03:02,271 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-18 16:03:02,622 [INFO] 循环学习率周期大小: 456 步
2025-05-18 16:04:28,168 [INFO] Epoch 1/15 - Policy Loss: 0.7330, Value Loss: 0.0715, Total Loss: 0.8045, LR: 0.001689
2025-05-18 16:05:39,527 [INFO] Epoch 2/15 - Policy Loss: 0.7268, Value Loss: 0.0712, Total Loss: 0.7981, LR: 0.003339
2025-05-18 16:06:55,934 [INFO] Epoch 3/15 - Policy Loss: 0.7258, Value Loss: 0.0712, Total Loss: 0.7971, LR: 0.004989
2025-05-18 16:08:17,786 [INFO] Epoch 4/15 - Policy Loss: 0.7266, Value Loss: 0.0719, Total Loss: 0.7985, LR: 0.003361
2025-05-18 16:09:30,044 [INFO] Epoch 5/15 - Policy Loss: 0.7252, Value Loss: 0.0714, Total Loss: 0.7966, LR: 0.001711
2025-05-18 16:10:50,551 [INFO] Epoch 6/15 - Policy Loss: 0.7233, Value Loss: 0.0709, Total Loss: 0.7942, LR: 0.000061
2025-05-18 16:12:03,886 [INFO] Epoch 7/15 - Policy Loss: 0.7221, Value Loss: 0.0708, Total Loss: 0.7928, LR: 0.001689
2025-05-18 16:13:16,349 [INFO] Epoch 8/15 - Policy Loss: 0.7210, Value Loss: 0.0705, Total Loss: 0.7915, LR: 0.003339
2025-05-18 16:14:41,380 [INFO] Epoch 9/15 - Policy Loss: 0.7206, Value Loss: 0.0703, Total Loss: 0.7909, LR: 0.004989
2025-05-18 16:16:03,932 [INFO] Epoch 10/15 - Policy Loss: 0.7205, Value Loss: 0.0701, Total Loss: 0.7906, LR: 0.003361
2025-05-18 16:17:22,016 [INFO] Epoch 11/15 - Policy Loss: 0.7198, Value Loss: 0.0701, Total Loss: 0.7898, LR: 0.001711
2025-05-18 16:18:43,771 [INFO] Epoch 12/15 - Policy Loss: 0.7186, Value Loss: 0.0699, Total Loss: 0.7884, LR: 0.000061
2025-05-18 16:20:03,611 [INFO] Epoch 13/15 - Policy Loss: 0.7181, Value Loss: 0.0696, Total Loss: 0.7877, LR: 0.001689
2025-05-18 16:21:13,987 [INFO] Epoch 14/15 - Policy Loss: 0.7175, Value Loss: 0.0696, Total Loss: 0.7871, LR: 0.003339
2025-05-18 16:22:23,253 [INFO] Epoch 15/15 - Policy Loss: 0.7175, Value Loss: 0.0696, Total Loss: 0.7871, LR: 0.004989
2025-05-18 16:22:23,278 [INFO] 训练完成，总损失: 0.7871
2025-05-18 16:22:23,279 [INFO] 保存迭代 107 的模型
2025-05-18 16:22:24,742 [INFO] Model saved to ./models/best.pt
2025-05-18 16:22:25,655 [INFO] Model saved to ./models/iteration_107.pt
2025-05-18 16:22:25,655 [INFO] 所有训练迭代完成
2025-05-18 16:22:25,656 [INFO] 开始迭代 108/300
2025-05-18 16:22:25,656 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 16:39:02,525 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 16:39:02,526 [INFO] 保存训练样本
2025-05-18 16:39:07,693 [INFO] 使用 155528 个样本训练神经网络
2025-05-18 16:39:07,693 [INFO] Training with 155528 examples
2025-05-18 16:39:07,694 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-18 16:39:08,120 [INFO] 循环学习率周期大小: 453 步
2025-05-18 16:40:25,211 [INFO] Epoch 1/15 - Policy Loss: 0.7390, Value Loss: 0.0743, Total Loss: 0.8133, LR: 0.001689
2025-05-18 16:41:40,315 [INFO] Epoch 2/15 - Policy Loss: 0.7343, Value Loss: 0.0728, Total Loss: 0.8070, LR: 0.003339
2025-05-18 16:42:53,291 [INFO] Epoch 3/15 - Policy Loss: 0.7309, Value Loss: 0.0721, Total Loss: 0.8030, LR: 0.004989
2025-05-18 16:44:13,342 [INFO] Epoch 4/15 - Policy Loss: 0.7292, Value Loss: 0.0718, Total Loss: 0.8010, LR: 0.003361
2025-05-18 16:45:27,634 [INFO] Epoch 5/15 - Policy Loss: 0.7270, Value Loss: 0.0716, Total Loss: 0.7986, LR: 0.001711
2025-05-18 16:46:45,745 [INFO] Epoch 6/15 - Policy Loss: 0.7239, Value Loss: 0.0712, Total Loss: 0.7951, LR: 0.000061
2025-05-18 16:48:04,749 [INFO] Epoch 7/15 - Policy Loss: 0.7226, Value Loss: 0.0710, Total Loss: 0.7936, LR: 0.001689
2025-05-18 16:49:24,392 [INFO] Epoch 8/15 - Policy Loss: 0.7217, Value Loss: 0.0705, Total Loss: 0.7921, LR: 0.003339
2025-05-18 16:50:41,945 [INFO] Epoch 9/15 - Policy Loss: 0.7209, Value Loss: 0.0701, Total Loss: 0.7910, LR: 0.004989
2025-05-18 16:52:05,682 [INFO] Epoch 10/15 - Policy Loss: 0.7205, Value Loss: 0.0700, Total Loss: 0.7905, LR: 0.003361
2025-05-18 16:53:22,605 [INFO] Epoch 11/15 - Policy Loss: 0.7194, Value Loss: 0.0699, Total Loss: 0.7893, LR: 0.001711
2025-05-18 16:54:50,884 [INFO] Epoch 12/15 - Policy Loss: 0.7185, Value Loss: 0.0698, Total Loss: 0.7883, LR: 0.000061
2025-05-18 16:55:46,505 [INFO] Epoch 13/15 - Policy Loss: 0.7179, Value Loss: 0.0697, Total Loss: 0.7876, LR: 0.001689
2025-05-18 16:56:26,474 [INFO] Epoch 14/15 - Policy Loss: 0.7173, Value Loss: 0.0697, Total Loss: 0.7869, LR: 0.003339
2025-05-18 16:57:06,740 [INFO] Epoch 15/15 - Policy Loss: 0.7170, Value Loss: 0.0696, Total Loss: 0.7865, LR: 0.004989
2025-05-18 16:57:06,757 [INFO] 训练完成，总损失: 0.7865
2025-05-18 16:57:06,757 [INFO] 保存迭代 108 的模型
2025-05-18 16:57:07,971 [INFO] Model saved to ./models/best.pt
2025-05-18 16:57:08,660 [INFO] Model saved to ./models/iteration_108.pt
2025-05-18 16:57:08,661 [INFO] 所有训练迭代完成
2025-05-18 16:57:08,661 [INFO] 开始迭代 109/300
2025-05-18 16:57:08,661 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 17:08:48,371 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 17:08:48,372 [INFO] 保存训练样本
2025-05-18 17:08:52,691 [INFO] 使用 154688 个样本训练神经网络
2025-05-18 17:08:52,691 [INFO] Training with 154688 examples
2025-05-18 17:08:52,691 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-18 17:08:53,049 [INFO] 循环学习率周期大小: 453 步
2025-05-18 17:09:32,608 [INFO] Epoch 1/15 - Policy Loss: 0.7289, Value Loss: 0.0717, Total Loss: 0.8007, LR: 0.001689
2025-05-18 17:10:12,401 [INFO] Epoch 2/15 - Policy Loss: 0.7259, Value Loss: 0.0714, Total Loss: 0.7974, LR: 0.003339
2025-05-18 17:10:52,008 [INFO] Epoch 3/15 - Policy Loss: 0.7250, Value Loss: 0.0714, Total Loss: 0.7963, LR: 0.004989
2025-05-18 17:11:31,732 [INFO] Epoch 4/15 - Policy Loss: 0.7237, Value Loss: 0.0712, Total Loss: 0.7949, LR: 0.003361
2025-05-18 17:12:11,435 [INFO] Epoch 5/15 - Policy Loss: 0.7219, Value Loss: 0.0712, Total Loss: 0.7931, LR: 0.001711
2025-05-18 17:12:51,324 [INFO] Epoch 6/15 - Policy Loss: 0.7204, Value Loss: 0.0710, Total Loss: 0.7913, LR: 0.000061
2025-05-18 17:13:31,281 [INFO] Epoch 7/15 - Policy Loss: 0.7198, Value Loss: 0.0708, Total Loss: 0.7906, LR: 0.001689
2025-05-18 17:14:11,100 [INFO] Epoch 8/15 - Policy Loss: 0.7186, Value Loss: 0.0708, Total Loss: 0.7895, LR: 0.003339
2025-05-18 17:14:51,101 [INFO] Epoch 9/15 - Policy Loss: 0.7181, Value Loss: 0.0706, Total Loss: 0.7887, LR: 0.004989
2025-05-18 17:15:31,221 [INFO] Epoch 10/15 - Policy Loss: 0.7183, Value Loss: 0.0706, Total Loss: 0.7889, LR: 0.003361
2025-05-18 17:16:11,415 [INFO] Epoch 11/15 - Policy Loss: 0.7173, Value Loss: 0.0705, Total Loss: 0.7878, LR: 0.001711
2025-05-18 17:16:51,861 [INFO] Epoch 12/15 - Policy Loss: 0.7166, Value Loss: 0.0704, Total Loss: 0.7870, LR: 0.000061
2025-05-18 17:17:32,011 [INFO] Epoch 13/15 - Policy Loss: 0.7156, Value Loss: 0.0702, Total Loss: 0.7858, LR: 0.001689
2025-05-18 17:18:12,020 [INFO] Epoch 14/15 - Policy Loss: 0.7152, Value Loss: 0.0701, Total Loss: 0.7853, LR: 0.003339
2025-05-18 17:18:52,063 [INFO] Epoch 15/15 - Policy Loss: 0.7148, Value Loss: 0.0701, Total Loss: 0.7850, LR: 0.004989
2025-05-18 17:18:52,088 [INFO] 训练完成，总损失: 0.7850
2025-05-18 17:18:52,088 [INFO] 保存迭代 109 的模型
2025-05-18 17:18:53,546 [INFO] Model saved to ./models/best.pt
2025-05-18 17:18:54,441 [INFO] Model saved to ./models/iteration_109.pt
2025-05-18 17:18:54,441 [INFO] 所有训练迭代完成
2025-05-18 17:18:54,441 [INFO] 开始迭代 110/300
2025-05-18 17:18:54,441 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 17:31:36,775 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 17:31:36,776 [INFO] 保存训练样本
2025-05-18 17:31:41,633 [INFO] 使用 154952 个样本训练神经网络
2025-05-18 17:31:41,633 [INFO] Training with 154952 examples
2025-05-18 17:31:41,634 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-18 17:31:41,690 [INFO] 循环学习率周期大小: 453 步
2025-05-18 17:32:21,467 [INFO] Epoch 1/15 - Policy Loss: 0.7322, Value Loss: 0.0700, Total Loss: 0.8022, LR: 0.001689
2025-05-18 17:33:01,331 [INFO] Epoch 2/15 - Policy Loss: 0.7296, Value Loss: 0.0691, Total Loss: 0.7987, LR: 0.003339
2025-05-18 17:33:41,179 [INFO] Epoch 3/15 - Policy Loss: 0.7285, Value Loss: 0.0691, Total Loss: 0.7975, LR: 0.004989
2025-05-18 17:34:21,108 [INFO] Epoch 4/15 - Policy Loss: 0.7267, Value Loss: 0.0696, Total Loss: 0.7963, LR: 0.003361
2025-05-18 17:35:01,027 [INFO] Epoch 5/15 - Policy Loss: 0.7235, Value Loss: 0.0695, Total Loss: 0.7930, LR: 0.001711
2025-05-18 17:35:41,433 [INFO] Epoch 6/15 - Policy Loss: 0.7218, Value Loss: 0.0691, Total Loss: 0.7909, LR: 0.000061
2025-05-18 17:36:21,419 [INFO] Epoch 7/15 - Policy Loss: 0.7200, Value Loss: 0.0691, Total Loss: 0.7891, LR: 0.001689
2025-05-18 17:37:15,020 [INFO] Epoch 8/15 - Policy Loss: 0.7188, Value Loss: 0.0690, Total Loss: 0.7879, LR: 0.003339
2025-05-18 17:38:03,792 [INFO] Epoch 9/15 - Policy Loss: 0.7185, Value Loss: 0.0689, Total Loss: 0.7874, LR: 0.004989
2025-05-18 17:38:44,016 [INFO] Epoch 10/15 - Policy Loss: 0.7177, Value Loss: 0.0689, Total Loss: 0.7866, LR: 0.003361
2025-05-18 17:39:24,754 [INFO] Epoch 11/15 - Policy Loss: 0.7172, Value Loss: 0.0688, Total Loss: 0.7860, LR: 0.001711
2025-05-18 17:40:05,552 [INFO] Epoch 12/15 - Policy Loss: 0.7163, Value Loss: 0.0685, Total Loss: 0.7848, LR: 0.000061
2025-05-18 17:40:46,316 [INFO] Epoch 13/15 - Policy Loss: 0.7155, Value Loss: 0.0685, Total Loss: 0.7840, LR: 0.001689
2025-05-18 17:41:27,039 [INFO] Epoch 14/15 - Policy Loss: 0.7150, Value Loss: 0.0683, Total Loss: 0.7833, LR: 0.003339
2025-05-18 17:42:07,857 [INFO] Epoch 15/15 - Policy Loss: 0.7145, Value Loss: 0.0684, Total Loss: 0.7829, LR: 0.004989
2025-05-18 17:42:07,877 [INFO] 训练完成，总损失: 0.7829
2025-05-18 17:42:07,877 [INFO] 保存迭代 110 的模型
2025-05-18 17:42:09,407 [INFO] Model saved to ./models/best.pt
2025-05-18 17:42:10,290 [INFO] Model saved to ./models/iteration_110.pt
2025-05-18 17:42:10,290 [INFO] 所有训练迭代完成
2025-05-18 17:42:10,290 [INFO] 开始迭代 111/300
2025-05-18 17:42:10,290 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 17:54:32,326 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 17:54:32,327 [INFO] 保存训练样本
2025-05-18 17:54:36,804 [INFO] 使用 154512 个样本训练神经网络
2025-05-18 17:54:36,804 [INFO] Training with 154512 examples
2025-05-18 17:54:36,805 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-18 17:54:36,851 [INFO] 循环学习率周期大小: 450 步
2025-05-18 17:55:17,257 [INFO] Epoch 1/15 - Policy Loss: 0.7362, Value Loss: 0.0766, Total Loss: 0.8128, LR: 0.001689
2025-05-18 17:55:57,445 [INFO] Epoch 2/15 - Policy Loss: 0.7316, Value Loss: 0.0757, Total Loss: 0.8073, LR: 0.003339
2025-05-18 17:56:37,579 [INFO] Epoch 3/15 - Policy Loss: 0.7284, Value Loss: 0.0745, Total Loss: 0.8029, LR: 0.004989
2025-05-18 17:57:17,815 [INFO] Epoch 4/15 - Policy Loss: 0.7268, Value Loss: 0.0737, Total Loss: 0.8006, LR: 0.003361
2025-05-18 17:57:58,047 [INFO] Epoch 5/15 - Policy Loss: 0.7247, Value Loss: 0.0732, Total Loss: 0.7979, LR: 0.001711
2025-05-18 17:58:38,291 [INFO] Epoch 6/15 - Policy Loss: 0.7235, Value Loss: 0.0728, Total Loss: 0.7963, LR: 0.000061
2025-05-18 17:59:18,582 [INFO] Epoch 7/15 - Policy Loss: 0.7225, Value Loss: 0.0725, Total Loss: 0.7950, LR: 0.001689
2025-05-18 17:59:58,924 [INFO] Epoch 8/15 - Policy Loss: 0.7212, Value Loss: 0.0722, Total Loss: 0.7934, LR: 0.003339
2025-05-18 18:00:39,254 [INFO] Epoch 9/15 - Policy Loss: 0.7203, Value Loss: 0.0720, Total Loss: 0.7924, LR: 0.004989
2025-05-18 18:01:19,742 [INFO] Epoch 10/15 - Policy Loss: 0.7202, Value Loss: 0.0718, Total Loss: 0.7920, LR: 0.003361
2025-05-18 18:02:01,967 [INFO] Epoch 11/15 - Policy Loss: 0.7192, Value Loss: 0.0714, Total Loss: 0.7906, LR: 0.001711
2025-05-18 18:02:42,703 [INFO] Epoch 12/15 - Policy Loss: 0.7186, Value Loss: 0.0713, Total Loss: 0.7899, LR: 0.000061
2025-05-18 18:03:23,443 [INFO] Epoch 13/15 - Policy Loss: 0.7174, Value Loss: 0.0712, Total Loss: 0.7886, LR: 0.001689
2025-05-18 18:04:04,241 [INFO] Epoch 14/15 - Policy Loss: 0.7170, Value Loss: 0.0710, Total Loss: 0.7880, LR: 0.003339
2025-05-18 18:04:44,899 [INFO] Epoch 15/15 - Policy Loss: 0.7165, Value Loss: 0.0709, Total Loss: 0.7874, LR: 0.004989
2025-05-18 18:04:44,922 [INFO] 训练完成，总损失: 0.7874
2025-05-18 18:04:44,923 [INFO] 保存迭代 111 的模型
2025-05-18 18:04:46,315 [INFO] Model saved to ./models/best.pt
2025-05-18 18:04:47,268 [INFO] Model saved to ./models/iteration_111.pt
2025-05-18 18:04:47,269 [INFO] 所有训练迭代完成
2025-05-18 18:04:47,269 [INFO] 开始迭代 112/300
2025-05-18 18:04:47,269 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 18:17:43,510 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 18:17:43,510 [INFO] 保存训练样本
2025-05-18 18:17:48,485 [INFO] 使用 154232 个样本训练神经网络
2025-05-18 18:17:48,485 [INFO] Training with 154232 examples
2025-05-18 18:17:48,486 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-18 18:17:48,886 [INFO] 循环学习率周期大小: 450 步
2025-05-18 18:18:29,094 [INFO] Epoch 1/15 - Policy Loss: 0.7428, Value Loss: 0.0810, Total Loss: 0.8238, LR: 0.001689
2025-05-18 18:19:10,605 [INFO] Epoch 2/15 - Policy Loss: 0.7355, Value Loss: 0.0801, Total Loss: 0.8156, LR: 0.003339
2025-05-18 18:19:51,870 [INFO] Epoch 3/15 - Policy Loss: 0.7321, Value Loss: 0.0803, Total Loss: 0.8124, LR: 0.004989
2025-05-18 18:20:32,350 [INFO] Epoch 4/15 - Policy Loss: 0.7293, Value Loss: 0.0797, Total Loss: 0.8090, LR: 0.003361
2025-05-18 18:21:13,086 [INFO] Epoch 5/15 - Policy Loss: 0.7276, Value Loss: 0.0795, Total Loss: 0.8071, LR: 0.001711
2025-05-18 18:21:53,652 [INFO] Epoch 6/15 - Policy Loss: 0.7255, Value Loss: 0.0791, Total Loss: 0.8046, LR: 0.000061
2025-05-18 18:22:34,280 [INFO] Epoch 7/15 - Policy Loss: 0.7243, Value Loss: 0.0785, Total Loss: 0.8028, LR: 0.001689
2025-05-18 18:23:15,005 [INFO] Epoch 8/15 - Policy Loss: 0.7234, Value Loss: 0.0786, Total Loss: 0.8020, LR: 0.003339
2025-05-18 18:23:56,501 [INFO] Epoch 9/15 - Policy Loss: 0.7220, Value Loss: 0.0785, Total Loss: 0.8005, LR: 0.004989
2025-05-18 18:24:40,908 [INFO] Epoch 10/15 - Policy Loss: 0.7214, Value Loss: 0.0783, Total Loss: 0.7998, LR: 0.003361
2025-05-18 18:25:27,240 [INFO] Epoch 11/15 - Policy Loss: 0.7209, Value Loss: 0.0779, Total Loss: 0.7988, LR: 0.001711
2025-05-18 18:26:16,438 [INFO] Epoch 12/15 - Policy Loss: 0.7200, Value Loss: 0.0775, Total Loss: 0.7974, LR: 0.000061
2025-05-18 18:27:05,881 [INFO] Epoch 13/15 - Policy Loss: 0.7194, Value Loss: 0.0772, Total Loss: 0.7966, LR: 0.001689
2025-05-18 18:27:54,777 [INFO] Epoch 14/15 - Policy Loss: 0.7190, Value Loss: 0.0770, Total Loss: 0.7959, LR: 0.003339
2025-05-18 18:28:44,149 [INFO] Epoch 15/15 - Policy Loss: 0.7190, Value Loss: 0.0767, Total Loss: 0.7957, LR: 0.004989
2025-05-18 18:28:44,166 [INFO] 训练完成，总损失: 0.7957
2025-05-18 18:28:44,166 [INFO] 保存迭代 112 的模型
2025-05-18 18:28:45,753 [INFO] Model saved to ./models/best.pt
2025-05-18 18:28:46,732 [INFO] Model saved to ./models/iteration_112.pt
2025-05-18 18:28:46,732 [INFO] 所有训练迭代完成
2025-05-18 18:28:46,733 [INFO] 开始迭代 113/300
2025-05-18 18:28:46,733 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 18:41:14,434 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 18:41:14,434 [INFO] 保存训练样本
2025-05-18 18:41:18,835 [INFO] 使用 153456 个样本训练神经网络
2025-05-18 18:41:18,836 [INFO] Training with 153456 examples
2025-05-18 18:41:18,837 [INFO] 总训练步数: 2235, 每轮次批次数: 149
2025-05-18 18:41:19,332 [INFO] 循环学习率周期大小: 447 步
2025-05-18 18:42:07,622 [INFO] Epoch 1/15 - Policy Loss: 0.7331, Value Loss: 0.0767, Total Loss: 0.8098, LR: 0.001689
2025-05-18 18:42:56,429 [INFO] Epoch 2/15 - Policy Loss: 0.7299, Value Loss: 0.0752, Total Loss: 0.8052, LR: 0.003339
2025-05-18 18:43:44,862 [INFO] Epoch 3/15 - Policy Loss: 0.7291, Value Loss: 0.0755, Total Loss: 0.8046, LR: 0.004989
2025-05-18 18:44:33,333 [INFO] Epoch 4/15 - Policy Loss: 0.7285, Value Loss: 0.0755, Total Loss: 0.8040, LR: 0.003361
2025-05-18 18:45:22,169 [INFO] Epoch 5/15 - Policy Loss: 0.7274, Value Loss: 0.0757, Total Loss: 0.8031, LR: 0.001711
2025-05-18 18:46:10,319 [INFO] Epoch 6/15 - Policy Loss: 0.7253, Value Loss: 0.0754, Total Loss: 0.8008, LR: 0.000061
2025-05-18 18:46:59,066 [INFO] Epoch 7/15 - Policy Loss: 0.7225, Value Loss: 0.0754, Total Loss: 0.7979, LR: 0.001689
2025-05-18 18:47:48,111 [INFO] Epoch 8/15 - Policy Loss: 0.7217, Value Loss: 0.0755, Total Loss: 0.7971, LR: 0.003339
2025-05-18 18:48:36,701 [INFO] Epoch 9/15 - Policy Loss: 0.7207, Value Loss: 0.0752, Total Loss: 0.7960, LR: 0.004989
2025-05-18 18:49:25,667 [INFO] Epoch 10/15 - Policy Loss: 0.7200, Value Loss: 0.0750, Total Loss: 0.7951, LR: 0.003361
2025-05-18 18:50:14,761 [INFO] Epoch 11/15 - Policy Loss: 0.7194, Value Loss: 0.0751, Total Loss: 0.7944, LR: 0.001711
2025-05-18 18:51:03,689 [INFO] Epoch 12/15 - Policy Loss: 0.7185, Value Loss: 0.0748, Total Loss: 0.7933, LR: 0.000061
2025-05-18 18:51:52,418 [INFO] Epoch 13/15 - Policy Loss: 0.7181, Value Loss: 0.0748, Total Loss: 0.7929, LR: 0.001689
2025-05-18 18:52:41,470 [INFO] Epoch 14/15 - Policy Loss: 0.7180, Value Loss: 0.0748, Total Loss: 0.7927, LR: 0.003339
2025-05-18 18:53:29,676 [INFO] Epoch 15/15 - Policy Loss: 0.7176, Value Loss: 0.0747, Total Loss: 0.7922, LR: 0.004989
2025-05-18 18:53:29,701 [INFO] 训练完成，总损失: 0.7922
2025-05-18 18:53:29,701 [INFO] 保存迭代 113 的模型
2025-05-18 18:53:31,044 [INFO] Model saved to ./models/best.pt
2025-05-18 18:53:31,811 [INFO] Model saved to ./models/iteration_113.pt
2025-05-18 18:53:31,811 [INFO] 所有训练迭代完成
2025-05-18 18:53:31,811 [INFO] 开始迭代 114/300
2025-05-18 18:53:31,811 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 19:07:52,301 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 19:07:52,301 [INFO] 保存训练样本
2025-05-18 19:07:57,679 [INFO] 使用 153160 个样本训练神经网络
2025-05-18 19:07:57,680 [INFO] Training with 153160 examples
2025-05-18 19:07:57,681 [INFO] 总训练步数: 2235, 每轮次批次数: 149
2025-05-18 19:07:57,743 [INFO] 循环学习率周期大小: 447 步
2025-05-18 19:08:45,942 [INFO] Epoch 1/15 - Policy Loss: 0.7465, Value Loss: 0.0859, Total Loss: 0.8324, LR: 0.001689
2025-05-18 19:09:34,099 [INFO] Epoch 2/15 - Policy Loss: 0.7381, Value Loss: 0.0839, Total Loss: 0.8220, LR: 0.003339
2025-05-18 19:10:22,279 [INFO] Epoch 3/15 - Policy Loss: 0.7371, Value Loss: 0.0832, Total Loss: 0.8204, LR: 0.004989
2025-05-18 19:11:10,093 [INFO] Epoch 4/15 - Policy Loss: 0.7343, Value Loss: 0.0819, Total Loss: 0.8162, LR: 0.003361
2025-05-18 19:11:58,410 [INFO] Epoch 5/15 - Policy Loss: 0.7314, Value Loss: 0.0808, Total Loss: 0.8122, LR: 0.001711
2025-05-18 19:12:46,900 [INFO] Epoch 6/15 - Policy Loss: 0.7302, Value Loss: 0.0801, Total Loss: 0.8103, LR: 0.000061
2025-05-18 19:13:35,367 [INFO] Epoch 7/15 - Policy Loss: 0.7274, Value Loss: 0.0792, Total Loss: 0.8066, LR: 0.001689
2025-05-18 19:14:23,928 [INFO] Epoch 8/15 - Policy Loss: 0.7263, Value Loss: 0.0786, Total Loss: 0.8049, LR: 0.003339
2025-05-18 19:15:12,457 [INFO] Epoch 9/15 - Policy Loss: 0.7254, Value Loss: 0.0783, Total Loss: 0.8038, LR: 0.004989
2025-05-18 19:16:01,618 [INFO] Epoch 10/15 - Policy Loss: 0.7254, Value Loss: 0.0782, Total Loss: 0.8036, LR: 0.003361
2025-05-18 19:16:49,482 [INFO] Epoch 11/15 - Policy Loss: 0.7243, Value Loss: 0.0778, Total Loss: 0.8021, LR: 0.001711
2025-05-18 19:17:38,165 [INFO] Epoch 12/15 - Policy Loss: 0.7235, Value Loss: 0.0775, Total Loss: 0.8011, LR: 0.000061
2025-05-18 19:18:27,040 [INFO] Epoch 13/15 - Policy Loss: 0.7232, Value Loss: 0.0770, Total Loss: 0.8002, LR: 0.001689
2025-05-18 19:19:16,230 [INFO] Epoch 14/15 - Policy Loss: 0.7226, Value Loss: 0.0767, Total Loss: 0.7993, LR: 0.003339
2025-05-18 19:20:04,710 [INFO] Epoch 15/15 - Policy Loss: 0.7222, Value Loss: 0.0765, Total Loss: 0.7987, LR: 0.004989
2025-05-18 19:20:04,734 [INFO] 训练完成，总损失: 0.7987
2025-05-18 19:20:04,734 [INFO] 保存迭代 114 的模型
2025-05-18 19:20:05,903 [INFO] Model saved to ./models/best.pt
2025-05-18 19:20:06,645 [INFO] Model saved to ./models/iteration_114.pt
2025-05-18 19:20:06,645 [INFO] 所有训练迭代完成
2025-05-18 19:20:06,646 [INFO] 开始迭代 115/300
2025-05-18 19:20:06,646 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 19:34:21,547 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 19:34:21,547 [INFO] 保存训练样本
2025-05-18 19:34:26,320 [INFO] 使用 153280 个样本训练神经网络
2025-05-18 19:34:26,321 [INFO] Training with 153280 examples
2025-05-18 19:34:26,321 [INFO] 总训练步数: 2235, 每轮次批次数: 149
2025-05-18 19:34:26,366 [INFO] 循环学习率周期大小: 447 步
2025-05-18 19:35:13,964 [INFO] Epoch 1/15 - Policy Loss: 0.7434, Value Loss: 0.0916, Total Loss: 0.8350, LR: 0.001689
2025-05-18 19:36:02,221 [INFO] Epoch 2/15 - Policy Loss: 0.7375, Value Loss: 0.0896, Total Loss: 0.8271, LR: 0.003339
2025-05-18 19:36:50,060 [INFO] Epoch 3/15 - Policy Loss: 0.7337, Value Loss: 0.0877, Total Loss: 0.8214, LR: 0.004989
2025-05-18 19:37:38,284 [INFO] Epoch 4/15 - Policy Loss: 0.7323, Value Loss: 0.0855, Total Loss: 0.8178, LR: 0.003361
2025-05-18 19:38:26,320 [INFO] Epoch 5/15 - Policy Loss: 0.7305, Value Loss: 0.0840, Total Loss: 0.8145, LR: 0.001711
2025-05-18 19:39:14,529 [INFO] Epoch 6/15 - Policy Loss: 0.7285, Value Loss: 0.0830, Total Loss: 0.8115, LR: 0.000061
2025-05-18 19:40:02,695 [INFO] Epoch 7/15 - Policy Loss: 0.7267, Value Loss: 0.0824, Total Loss: 0.8091, LR: 0.001689
2025-05-18 19:40:49,967 [INFO] Epoch 8/15 - Policy Loss: 0.7253, Value Loss: 0.0819, Total Loss: 0.8072, LR: 0.003339
2025-05-18 19:41:37,614 [INFO] Epoch 9/15 - Policy Loss: 0.7252, Value Loss: 0.0817, Total Loss: 0.8068, LR: 0.004989
2025-05-18 19:42:25,345 [INFO] Epoch 10/15 - Policy Loss: 0.7246, Value Loss: 0.0813, Total Loss: 0.8059, LR: 0.003361
2025-05-18 19:43:13,364 [INFO] Epoch 11/15 - Policy Loss: 0.7240, Value Loss: 0.0809, Total Loss: 0.8049, LR: 0.001711
2025-05-18 19:44:01,380 [INFO] Epoch 12/15 - Policy Loss: 0.7231, Value Loss: 0.0804, Total Loss: 0.8036, LR: 0.000061
2025-05-18 19:44:49,414 [INFO] Epoch 13/15 - Policy Loss: 0.7220, Value Loss: 0.0800, Total Loss: 0.8020, LR: 0.001689
2025-05-18 19:45:37,477 [INFO] Epoch 14/15 - Policy Loss: 0.7212, Value Loss: 0.0797, Total Loss: 0.8009, LR: 0.003339
2025-05-18 19:46:25,422 [INFO] Epoch 15/15 - Policy Loss: 0.7210, Value Loss: 0.0796, Total Loss: 0.8006, LR: 0.004989
2025-05-18 19:46:25,442 [INFO] 训练完成，总损失: 0.8006
2025-05-18 19:46:25,442 [INFO] 保存迭代 115 的模型
2025-05-18 19:46:26,891 [INFO] Model saved to ./models/best.pt
2025-05-18 19:46:27,785 [INFO] Model saved to ./models/iteration_115.pt
2025-05-18 19:46:27,785 [INFO] 所有训练迭代完成
2025-05-18 19:46:27,785 [INFO] 开始迭代 116/300
2025-05-18 19:46:27,785 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 19:58:43,683 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 19:58:43,684 [INFO] 保存训练样本
2025-05-18 19:58:48,115 [INFO] 使用 152336 个样本训练神经网络
2025-05-18 19:58:48,115 [INFO] Training with 152336 examples
2025-05-18 19:58:48,115 [INFO] 总训练步数: 2220, 每轮次批次数: 148
2025-05-18 19:58:48,454 [INFO] 循环学习率周期大小: 444 步
2025-05-18 19:59:31,647 [INFO] Epoch 1/15 - Policy Loss: 0.7338, Value Loss: 0.0829, Total Loss: 0.8166, LR: 0.001689
2025-05-18 20:00:14,119 [INFO] Epoch 2/15 - Policy Loss: 0.7296, Value Loss: 0.0827, Total Loss: 0.8123, LR: 0.003339
2025-05-18 20:00:56,580 [INFO] Epoch 3/15 - Policy Loss: 0.7292, Value Loss: 0.0819, Total Loss: 0.8112, LR: 0.004989
2025-05-18 20:01:39,136 [INFO] Epoch 4/15 - Policy Loss: 0.7272, Value Loss: 0.0811, Total Loss: 0.8083, LR: 0.003361
2025-05-18 20:02:21,588 [INFO] Epoch 5/15 - Policy Loss: 0.7258, Value Loss: 0.0803, Total Loss: 0.8062, LR: 0.001711
2025-05-18 20:03:01,925 [INFO] Epoch 6/15 - Policy Loss: 0.7252, Value Loss: 0.0794, Total Loss: 0.8045, LR: 0.000061
2025-05-18 20:03:41,211 [INFO] Epoch 7/15 - Policy Loss: 0.7234, Value Loss: 0.0786, Total Loss: 0.8020, LR: 0.001689
2025-05-18 20:04:20,417 [INFO] Epoch 8/15 - Policy Loss: 0.7225, Value Loss: 0.0783, Total Loss: 0.8008, LR: 0.003339
2025-05-18 20:04:59,666 [INFO] Epoch 9/15 - Policy Loss: 0.7221, Value Loss: 0.0781, Total Loss: 0.8003, LR: 0.004989
2025-05-18 20:05:38,932 [INFO] Epoch 10/15 - Policy Loss: 0.7217, Value Loss: 0.0778, Total Loss: 0.7995, LR: 0.003361
2025-05-18 20:06:18,218 [INFO] Epoch 11/15 - Policy Loss: 0.7208, Value Loss: 0.0775, Total Loss: 0.7983, LR: 0.001711
2025-05-18 20:06:57,445 [INFO] Epoch 12/15 - Policy Loss: 0.7201, Value Loss: 0.0772, Total Loss: 0.7973, LR: 0.000061
2025-05-18 20:07:36,776 [INFO] Epoch 13/15 - Policy Loss: 0.7191, Value Loss: 0.0770, Total Loss: 0.7961, LR: 0.001689
2025-05-18 20:08:15,932 [INFO] Epoch 14/15 - Policy Loss: 0.7188, Value Loss: 0.0769, Total Loss: 0.7957, LR: 0.003339
2025-05-18 20:08:55,575 [INFO] Epoch 15/15 - Policy Loss: 0.7186, Value Loss: 0.0767, Total Loss: 0.7953, LR: 0.004989
2025-05-18 20:08:55,594 [INFO] 训练完成，总损失: 0.7953
2025-05-18 20:08:55,594 [INFO] 保存迭代 116 的模型
2025-05-18 20:08:57,252 [INFO] Model saved to ./models/best.pt
2025-05-18 20:08:57,966 [INFO] Model saved to ./models/iteration_116.pt
2025-05-18 20:08:57,966 [INFO] 所有训练迭代完成
2025-05-18 20:08:57,966 [INFO] 开始迭代 117/300
2025-05-18 20:08:57,966 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 20:22:17,942 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 20:22:17,943 [INFO] 保存训练样本
2025-05-18 20:22:21,111 [INFO] 使用 152040 个样本训练神经网络
2025-05-18 20:22:21,111 [INFO] Training with 152040 examples
2025-05-18 20:22:21,111 [INFO] 总训练步数: 2220, 每轮次批次数: 148
2025-05-18 20:22:21,377 [INFO] 循环学习率周期大小: 444 步
2025-05-18 20:23:00,284 [INFO] Epoch 1/15 - Policy Loss: 0.7419, Value Loss: 0.0764, Total Loss: 0.8184, LR: 0.001689
2025-05-18 20:23:39,138 [INFO] Epoch 2/15 - Policy Loss: 0.7340, Value Loss: 0.0752, Total Loss: 0.8092, LR: 0.003339
2025-05-18 20:24:18,109 [INFO] Epoch 3/15 - Policy Loss: 0.7334, Value Loss: 0.0751, Total Loss: 0.8085, LR: 0.004989
2025-05-18 20:24:57,009 [INFO] Epoch 4/15 - Policy Loss: 0.7322, Value Loss: 0.0744, Total Loss: 0.8066, LR: 0.003361
2025-05-18 20:25:35,935 [INFO] Epoch 5/15 - Policy Loss: 0.7306, Value Loss: 0.0741, Total Loss: 0.8046, LR: 0.001711
2025-05-18 20:26:16,113 [INFO] Epoch 6/15 - Policy Loss: 0.7281, Value Loss: 0.0734, Total Loss: 0.8015, LR: 0.000061
2025-05-18 20:26:58,581 [INFO] Epoch 7/15 - Policy Loss: 0.7260, Value Loss: 0.0733, Total Loss: 0.7993, LR: 0.001689
2025-05-18 20:27:41,038 [INFO] Epoch 8/15 - Policy Loss: 0.7247, Value Loss: 0.0733, Total Loss: 0.7980, LR: 0.003339
2025-05-18 20:28:23,703 [INFO] Epoch 9/15 - Policy Loss: 0.7243, Value Loss: 0.0732, Total Loss: 0.7975, LR: 0.004989
2025-05-18 20:29:06,371 [INFO] Epoch 10/15 - Policy Loss: 0.7243, Value Loss: 0.0729, Total Loss: 0.7972, LR: 0.003361
2025-05-18 20:29:49,561 [INFO] Epoch 11/15 - Policy Loss: 0.7242, Value Loss: 0.0730, Total Loss: 0.7972, LR: 0.001711
2025-05-18 20:30:32,090 [INFO] Epoch 12/15 - Policy Loss: 0.7231, Value Loss: 0.0729, Total Loss: 0.7960, LR: 0.000061
2025-05-18 20:31:14,884 [INFO] Epoch 13/15 - Policy Loss: 0.7226, Value Loss: 0.0726, Total Loss: 0.7951, LR: 0.001689
2025-05-18 20:31:57,612 [INFO] Epoch 14/15 - Policy Loss: 0.7217, Value Loss: 0.0723, Total Loss: 0.7939, LR: 0.003339
2025-05-18 20:32:40,361 [INFO] Epoch 15/15 - Policy Loss: 0.7213, Value Loss: 0.0722, Total Loss: 0.7935, LR: 0.004989
2025-05-18 20:32:40,387 [INFO] 训练完成，总损失: 0.7935
2025-05-18 20:32:40,387 [INFO] 保存迭代 117 的模型
2025-05-18 20:32:41,925 [INFO] Model saved to ./models/best.pt
2025-05-18 20:32:42,698 [INFO] Model saved to ./models/iteration_117.pt
2025-05-18 20:32:42,699 [INFO] 所有训练迭代完成
2025-05-18 20:32:42,699 [INFO] 开始迭代 118/300
2025-05-18 20:32:42,699 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 20:45:51,074 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 20:45:51,075 [INFO] 保存训练样本
2025-05-18 20:45:55,689 [INFO] 使用 151904 个样本训练神经网络
2025-05-18 20:45:55,689 [INFO] Training with 151904 examples
2025-05-18 20:45:55,689 [INFO] 总训练步数: 2220, 每轮次批次数: 148
2025-05-18 20:45:55,740 [INFO] 循环学习率周期大小: 444 步
2025-05-18 20:46:47,497 [INFO] Epoch 1/15 - Policy Loss: 0.7325, Value Loss: 0.0853, Total Loss: 0.8179, LR: 0.001689
2025-05-18 20:47:38,589 [INFO] Epoch 2/15 - Policy Loss: 0.7313, Value Loss: 0.0819, Total Loss: 0.8132, LR: 0.003339
2025-05-18 20:48:30,069 [INFO] Epoch 3/15 - Policy Loss: 0.7305, Value Loss: 0.0818, Total Loss: 0.8123, LR: 0.004989
2025-05-18 20:49:20,733 [INFO] Epoch 4/15 - Policy Loss: 0.7306, Value Loss: 0.0810, Total Loss: 0.8116, LR: 0.003361
2025-05-18 20:50:12,480 [INFO] Epoch 5/15 - Policy Loss: 0.7289, Value Loss: 0.0800, Total Loss: 0.8090, LR: 0.001711
2025-05-18 20:51:04,078 [INFO] Epoch 6/15 - Policy Loss: 0.7266, Value Loss: 0.0792, Total Loss: 0.8058, LR: 0.000061
2025-05-18 20:51:55,422 [INFO] Epoch 7/15 - Policy Loss: 0.7253, Value Loss: 0.0789, Total Loss: 0.8042, LR: 0.001689
2025-05-18 20:52:45,834 [INFO] Epoch 8/15 - Policy Loss: 0.7238, Value Loss: 0.0784, Total Loss: 0.8022, LR: 0.003339
2025-05-18 20:53:36,547 [INFO] Epoch 9/15 - Policy Loss: 0.7235, Value Loss: 0.0781, Total Loss: 0.8015, LR: 0.004989
2025-05-18 20:54:27,776 [INFO] Epoch 10/15 - Policy Loss: 0.7235, Value Loss: 0.0778, Total Loss: 0.8013, LR: 0.003361
2025-05-18 20:55:18,370 [INFO] Epoch 11/15 - Policy Loss: 0.7227, Value Loss: 0.0775, Total Loss: 0.8003, LR: 0.001711
2025-05-18 20:56:09,331 [INFO] Epoch 12/15 - Policy Loss: 0.7214, Value Loss: 0.0773, Total Loss: 0.7987, LR: 0.000061
2025-05-18 20:56:59,095 [INFO] Epoch 13/15 - Policy Loss: 0.7207, Value Loss: 0.0771, Total Loss: 0.7979, LR: 0.001689
2025-05-18 20:57:50,358 [INFO] Epoch 14/15 - Policy Loss: 0.7201, Value Loss: 0.0769, Total Loss: 0.7970, LR: 0.003339
2025-05-18 20:58:41,249 [INFO] Epoch 15/15 - Policy Loss: 0.7197, Value Loss: 0.0768, Total Loss: 0.7965, LR: 0.004989
2025-05-18 20:58:41,268 [INFO] 训练完成，总损失: 0.7965
2025-05-18 20:58:41,268 [INFO] 保存迭代 118 的模型
2025-05-18 20:58:42,900 [INFO] Model saved to ./models/best.pt
2025-05-18 20:58:43,798 [INFO] Model saved to ./models/iteration_118.pt
2025-05-18 20:58:43,798 [INFO] 所有训练迭代完成
2025-05-18 20:58:43,798 [INFO] 开始迭代 119/300
2025-05-18 20:58:43,798 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 21:13:41,676 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 21:13:41,677 [INFO] 保存训练样本
2025-05-18 21:13:46,285 [INFO] 使用 152624 个样本训练神经网络
2025-05-18 21:13:46,285 [INFO] Training with 152624 examples
2025-05-18 21:13:46,285 [INFO] 总训练步数: 2235, 每轮次批次数: 149
2025-05-18 21:13:46,333 [INFO] 循环学习率周期大小: 447 步
2025-05-18 21:14:38,134 [INFO] Epoch 1/15 - Policy Loss: 0.7338, Value Loss: 0.0871, Total Loss: 0.8209, LR: 0.001689
2025-05-18 21:15:28,791 [INFO] Epoch 2/15 - Policy Loss: 0.7323, Value Loss: 0.0869, Total Loss: 0.8191, LR: 0.003339
2025-05-18 21:16:19,745 [INFO] Epoch 3/15 - Policy Loss: 0.7301, Value Loss: 0.0856, Total Loss: 0.8157, LR: 0.004989
2025-05-18 21:17:10,230 [INFO] Epoch 4/15 - Policy Loss: 0.7292, Value Loss: 0.0846, Total Loss: 0.8137, LR: 0.003361
2025-05-18 21:18:01,402 [INFO] Epoch 5/15 - Policy Loss: 0.7276, Value Loss: 0.0842, Total Loss: 0.8118, LR: 0.001711
2025-05-18 21:18:51,709 [INFO] Epoch 6/15 - Policy Loss: 0.7253, Value Loss: 0.0837, Total Loss: 0.8091, LR: 0.000061
2025-05-18 21:19:42,417 [INFO] Epoch 7/15 - Policy Loss: 0.7245, Value Loss: 0.0834, Total Loss: 0.8079, LR: 0.001689
2025-05-18 21:20:33,163 [INFO] Epoch 8/15 - Policy Loss: 0.7232, Value Loss: 0.0829, Total Loss: 0.8061, LR: 0.003339
2025-05-18 21:21:23,268 [INFO] Epoch 9/15 - Policy Loss: 0.7224, Value Loss: 0.0825, Total Loss: 0.8050, LR: 0.004989
2025-05-18 21:22:13,922 [INFO] Epoch 10/15 - Policy Loss: 0.7221, Value Loss: 0.0824, Total Loss: 0.8045, LR: 0.003361
2025-05-18 21:23:04,274 [INFO] Epoch 11/15 - Policy Loss: 0.7217, Value Loss: 0.0824, Total Loss: 0.8041, LR: 0.001711
2025-05-18 21:23:54,958 [INFO] Epoch 12/15 - Policy Loss: 0.7212, Value Loss: 0.0824, Total Loss: 0.8036, LR: 0.000061
2025-05-18 21:24:45,736 [INFO] Epoch 13/15 - Policy Loss: 0.7206, Value Loss: 0.0821, Total Loss: 0.8027, LR: 0.001689
2025-05-18 21:25:36,391 [INFO] Epoch 14/15 - Policy Loss: 0.7201, Value Loss: 0.0818, Total Loss: 0.8019, LR: 0.003339
2025-05-18 21:26:27,193 [INFO] Epoch 15/15 - Policy Loss: 0.7197, Value Loss: 0.0817, Total Loss: 0.8014, LR: 0.004989
2025-05-18 21:26:27,213 [INFO] 训练完成，总损失: 0.8014
2025-05-18 21:26:27,213 [INFO] 保存迭代 119 的模型
2025-05-18 21:26:28,623 [INFO] Model saved to ./models/best.pt
2025-05-18 21:26:29,585 [INFO] Model saved to ./models/iteration_119.pt
2025-05-18 21:26:29,586 [INFO] 所有训练迭代完成
2025-05-18 21:26:29,586 [INFO] 开始迭代 120/300
2025-05-18 21:26:29,586 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 21:42:10,582 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 21:42:10,582 [INFO] 保存训练样本
2025-05-18 21:42:15,658 [INFO] 使用 153160 个样本训练神经网络
2025-05-18 21:42:15,658 [INFO] Training with 153160 examples
2025-05-18 21:42:15,658 [INFO] 总训练步数: 2235, 每轮次批次数: 149
2025-05-18 21:42:16,062 [INFO] 循环学习率周期大小: 447 步
2025-05-18 21:43:06,893 [INFO] Epoch 1/15 - Policy Loss: 0.7459, Value Loss: 0.1001, Total Loss: 0.8460, LR: 0.001689
2025-05-18 21:43:57,260 [INFO] Epoch 2/15 - Policy Loss: 0.7404, Value Loss: 0.0970, Total Loss: 0.8374, LR: 0.003339
2025-05-18 21:44:47,673 [INFO] Epoch 3/15 - Policy Loss: 0.7387, Value Loss: 0.0959, Total Loss: 0.8346, LR: 0.004989
2025-05-18 21:45:37,869 [INFO] Epoch 4/15 - Policy Loss: 0.7366, Value Loss: 0.0952, Total Loss: 0.8318, LR: 0.003361
2025-05-18 21:46:28,391 [INFO] Epoch 5/15 - Policy Loss: 0.7330, Value Loss: 0.0940, Total Loss: 0.8270, LR: 0.001711
2025-05-18 21:47:18,933 [INFO] Epoch 6/15 - Policy Loss: 0.7300, Value Loss: 0.0932, Total Loss: 0.8232, LR: 0.000061
2025-05-18 21:48:09,697 [INFO] Epoch 7/15 - Policy Loss: 0.7277, Value Loss: 0.0925, Total Loss: 0.8202, LR: 0.001689
2025-05-18 21:49:00,074 [INFO] Epoch 8/15 - Policy Loss: 0.7263, Value Loss: 0.0918, Total Loss: 0.8181, LR: 0.003339
2025-05-18 21:49:51,096 [INFO] Epoch 9/15 - Policy Loss: 0.7256, Value Loss: 0.0912, Total Loss: 0.8168, LR: 0.004989
2025-05-18 21:50:41,825 [INFO] Epoch 10/15 - Policy Loss: 0.7251, Value Loss: 0.0907, Total Loss: 0.8158, LR: 0.003361
2025-05-18 21:51:31,684 [INFO] Epoch 11/15 - Policy Loss: 0.7246, Value Loss: 0.0902, Total Loss: 0.8148, LR: 0.001711
2025-05-18 21:52:21,934 [INFO] Epoch 12/15 - Policy Loss: 0.7235, Value Loss: 0.0896, Total Loss: 0.8131, LR: 0.000061
2025-05-18 21:53:12,404 [INFO] Epoch 13/15 - Policy Loss: 0.7222, Value Loss: 0.0894, Total Loss: 0.8116, LR: 0.001689
2025-05-18 21:54:02,338 [INFO] Epoch 14/15 - Policy Loss: 0.7216, Value Loss: 0.0890, Total Loss: 0.8106, LR: 0.003339
2025-05-18 21:54:52,759 [INFO] Epoch 15/15 - Policy Loss: 0.7213, Value Loss: 0.0887, Total Loss: 0.8100, LR: 0.004989
2025-05-18 21:54:52,780 [INFO] 训练完成，总损失: 0.8100
2025-05-18 21:54:52,780 [INFO] 保存迭代 120 的模型
2025-05-18 21:54:54,361 [INFO] Model saved to ./models/best.pt
2025-05-18 21:54:55,318 [INFO] Model saved to ./models/iteration_120.pt
2025-05-18 21:54:55,318 [INFO] 所有训练迭代完成
2025-05-18 21:54:55,318 [INFO] 开始迭代 121/300
2025-05-18 21:54:55,318 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 22:09:06,974 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 22:09:06,974 [INFO] 保存训练样本
2025-05-18 22:09:12,073 [INFO] 使用 153664 个样本训练神经网络
2025-05-18 22:09:12,074 [INFO] Training with 153664 examples
2025-05-18 22:09:12,074 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-18 22:09:12,670 [INFO] 循环学习率周期大小: 450 步
2025-05-18 22:10:01,416 [INFO] Epoch 1/15 - Policy Loss: 0.7417, Value Loss: 0.0940, Total Loss: 0.8357, LR: 0.001689
2025-05-18 22:10:50,854 [INFO] Epoch 2/15 - Policy Loss: 0.7385, Value Loss: 0.0926, Total Loss: 0.8311, LR: 0.003339
2025-05-18 22:11:39,846 [INFO] Epoch 3/15 - Policy Loss: 0.7356, Value Loss: 0.0922, Total Loss: 0.8278, LR: 0.004989
2025-05-18 22:12:28,469 [INFO] Epoch 4/15 - Policy Loss: 0.7331, Value Loss: 0.0915, Total Loss: 0.8247, LR: 0.003361
2025-05-18 22:13:17,022 [INFO] Epoch 5/15 - Policy Loss: 0.7310, Value Loss: 0.0904, Total Loss: 0.8214, LR: 0.001711
2025-05-18 22:14:05,721 [INFO] Epoch 6/15 - Policy Loss: 0.7281, Value Loss: 0.0899, Total Loss: 0.8180, LR: 0.000061
2025-05-18 22:14:51,786 [INFO] Epoch 7/15 - Policy Loss: 0.7264, Value Loss: 0.0895, Total Loss: 0.8159, LR: 0.001689
2025-05-18 22:15:35,996 [INFO] Epoch 8/15 - Policy Loss: 0.7249, Value Loss: 0.0894, Total Loss: 0.8142, LR: 0.003339
2025-05-18 22:16:19,079 [INFO] Epoch 9/15 - Policy Loss: 0.7237, Value Loss: 0.0888, Total Loss: 0.8126, LR: 0.004989
2025-05-18 22:17:01,517 [INFO] Epoch 10/15 - Policy Loss: 0.7233, Value Loss: 0.0888, Total Loss: 0.8120, LR: 0.003361
2025-05-18 22:17:44,519 [INFO] Epoch 11/15 - Policy Loss: 0.7227, Value Loss: 0.0886, Total Loss: 0.8113, LR: 0.001711
2025-05-18 22:18:27,194 [INFO] Epoch 12/15 - Policy Loss: 0.7220, Value Loss: 0.0882, Total Loss: 0.8102, LR: 0.000061
2025-05-18 22:19:09,769 [INFO] Epoch 13/15 - Policy Loss: 0.7215, Value Loss: 0.0879, Total Loss: 0.8095, LR: 0.001689
2025-05-18 22:19:52,457 [INFO] Epoch 14/15 - Policy Loss: 0.7212, Value Loss: 0.0878, Total Loss: 0.8089, LR: 0.003339
2025-05-18 22:20:35,065 [INFO] Epoch 15/15 - Policy Loss: 0.7210, Value Loss: 0.0876, Total Loss: 0.8086, LR: 0.004989
2025-05-18 22:20:35,084 [INFO] 训练完成，总损失: 0.8086
2025-05-18 22:20:35,084 [INFO] 保存迭代 121 的模型
2025-05-18 22:20:36,465 [INFO] Model saved to ./models/best.pt
2025-05-18 22:20:37,299 [INFO] Model saved to ./models/iteration_121.pt
2025-05-18 22:20:37,300 [INFO] 所有训练迭代完成
2025-05-18 22:20:37,300 [INFO] 开始迭代 122/300
2025-05-18 22:20:37,300 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 22:33:54,490 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 22:33:54,490 [INFO] 保存训练样本
2025-05-18 22:33:58,875 [INFO] 使用 154208 个样本训练神经网络
2025-05-18 22:33:58,875 [INFO] Training with 154208 examples
2025-05-18 22:33:58,876 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-18 22:33:58,923 [INFO] 循环学习率周期大小: 450 步
2025-05-18 22:34:41,314 [INFO] Epoch 1/15 - Policy Loss: 0.7366, Value Loss: 0.0915, Total Loss: 0.8281, LR: 0.001689
2025-05-18 22:35:23,397 [INFO] Epoch 2/15 - Policy Loss: 0.7327, Value Loss: 0.0916, Total Loss: 0.8242, LR: 0.003339
2025-05-18 22:36:06,069 [INFO] Epoch 3/15 - Policy Loss: 0.7320, Value Loss: 0.0909, Total Loss: 0.8228, LR: 0.004989
2025-05-18 22:36:48,604 [INFO] Epoch 4/15 - Policy Loss: 0.7291, Value Loss: 0.0900, Total Loss: 0.8191, LR: 0.003361
2025-05-18 22:37:30,931 [INFO] Epoch 5/15 - Policy Loss: 0.7269, Value Loss: 0.0897, Total Loss: 0.8167, LR: 0.001711
2025-05-18 22:38:13,766 [INFO] Epoch 6/15 - Policy Loss: 0.7257, Value Loss: 0.0892, Total Loss: 0.8149, LR: 0.000061
2025-05-18 22:38:56,379 [INFO] Epoch 7/15 - Policy Loss: 0.7240, Value Loss: 0.0890, Total Loss: 0.8129, LR: 0.001689
2025-05-18 22:39:38,982 [INFO] Epoch 8/15 - Policy Loss: 0.7231, Value Loss: 0.0889, Total Loss: 0.8120, LR: 0.003339
2025-05-18 22:40:21,873 [INFO] Epoch 9/15 - Policy Loss: 0.7226, Value Loss: 0.0886, Total Loss: 0.8112, LR: 0.004989
2025-05-18 22:41:04,767 [INFO] Epoch 10/15 - Policy Loss: 0.7223, Value Loss: 0.0882, Total Loss: 0.8105, LR: 0.003361
2025-05-18 22:41:47,778 [INFO] Epoch 11/15 - Policy Loss: 0.7214, Value Loss: 0.0881, Total Loss: 0.8095, LR: 0.001711
2025-05-18 22:42:30,808 [INFO] Epoch 12/15 - Policy Loss: 0.7209, Value Loss: 0.0878, Total Loss: 0.8087, LR: 0.000061
2025-05-18 22:43:13,776 [INFO] Epoch 13/15 - Policy Loss: 0.7198, Value Loss: 0.0876, Total Loss: 0.8074, LR: 0.001689
2025-05-18 22:43:56,898 [INFO] Epoch 14/15 - Policy Loss: 0.7192, Value Loss: 0.0874, Total Loss: 0.8066, LR: 0.003339
2025-05-18 22:44:39,949 [INFO] Epoch 15/15 - Policy Loss: 0.7188, Value Loss: 0.0873, Total Loss: 0.8061, LR: 0.004989
2025-05-18 22:44:39,969 [INFO] 训练完成，总损失: 0.8061
2025-05-18 22:44:39,969 [INFO] 保存迭代 122 的模型
2025-05-18 22:44:41,507 [INFO] Model saved to ./models/best.pt
2025-05-18 22:44:42,428 [INFO] Model saved to ./models/iteration_122.pt
2025-05-18 22:44:42,429 [INFO] 所有训练迭代完成
2025-05-18 22:44:42,429 [INFO] 开始迭代 123/300
2025-05-18 22:44:42,429 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 22:58:20,725 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 22:58:20,726 [INFO] 保存训练样本
2025-05-18 22:58:25,866 [INFO] 使用 153856 个样本训练神经网络
2025-05-18 22:58:25,866 [INFO] Training with 153856 examples
2025-05-18 22:58:25,867 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-18 22:58:26,214 [INFO] 循环学习率周期大小: 450 步
2025-05-18 22:59:06,086 [INFO] Epoch 1/15 - Policy Loss: 0.7420, Value Loss: 0.0872, Total Loss: 0.8291, LR: 0.001689
2025-05-18 22:59:46,314 [INFO] Epoch 2/15 - Policy Loss: 0.7383, Value Loss: 0.0845, Total Loss: 0.8229, LR: 0.003339
2025-05-18 23:00:26,573 [INFO] Epoch 3/15 - Policy Loss: 0.7338, Value Loss: 0.0826, Total Loss: 0.8164, LR: 0.004989
2025-05-18 23:01:06,857 [INFO] Epoch 4/15 - Policy Loss: 0.7310, Value Loss: 0.0812, Total Loss: 0.8123, LR: 0.003361
2025-05-18 23:01:47,141 [INFO] Epoch 5/15 - Policy Loss: 0.7282, Value Loss: 0.0805, Total Loss: 0.8087, LR: 0.001711
2025-05-18 23:02:27,391 [INFO] Epoch 6/15 - Policy Loss: 0.7271, Value Loss: 0.0800, Total Loss: 0.8071, LR: 0.000061
2025-05-18 23:03:07,744 [INFO] Epoch 7/15 - Policy Loss: 0.7256, Value Loss: 0.0797, Total Loss: 0.8053, LR: 0.001689
2025-05-18 23:03:48,052 [INFO] Epoch 8/15 - Policy Loss: 0.7240, Value Loss: 0.0794, Total Loss: 0.8034, LR: 0.003339
2025-05-18 23:04:28,444 [INFO] Epoch 9/15 - Policy Loss: 0.7229, Value Loss: 0.0791, Total Loss: 0.8020, LR: 0.004989
2025-05-18 23:05:08,700 [INFO] Epoch 10/15 - Policy Loss: 0.7226, Value Loss: 0.0789, Total Loss: 0.8014, LR: 0.003361
2025-05-18 23:05:48,919 [INFO] Epoch 11/15 - Policy Loss: 0.7218, Value Loss: 0.0787, Total Loss: 0.8005, LR: 0.001711
2025-05-18 23:06:29,454 [INFO] Epoch 12/15 - Policy Loss: 0.7207, Value Loss: 0.0784, Total Loss: 0.7991, LR: 0.000061
2025-05-18 23:07:09,939 [INFO] Epoch 13/15 - Policy Loss: 0.7198, Value Loss: 0.0781, Total Loss: 0.7979, LR: 0.001689
2025-05-18 23:07:50,452 [INFO] Epoch 14/15 - Policy Loss: 0.7195, Value Loss: 0.0779, Total Loss: 0.7974, LR: 0.003339
2025-05-18 23:08:31,025 [INFO] Epoch 15/15 - Policy Loss: 0.7190, Value Loss: 0.0778, Total Loss: 0.7968, LR: 0.004989
2025-05-18 23:08:31,054 [INFO] 训练完成，总损失: 0.7968
2025-05-18 23:08:31,054 [INFO] 保存迭代 123 的模型
2025-05-18 23:08:32,782 [INFO] Model saved to ./models/best.pt
2025-05-18 23:08:33,864 [INFO] Model saved to ./models/iteration_123.pt
2025-05-18 23:08:33,864 [INFO] 所有训练迭代完成
2025-05-18 23:08:33,865 [INFO] 开始迭代 124/300
2025-05-18 23:08:33,865 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 23:21:24,232 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 23:21:24,232 [INFO] 保存训练样本
2025-05-18 23:21:29,391 [INFO] 使用 153368 个样本训练神经网络
2025-05-18 23:21:29,391 [INFO] Training with 153368 examples
2025-05-18 23:21:29,392 [INFO] 总训练步数: 2235, 每轮次批次数: 149
2025-05-18 23:21:29,745 [INFO] 循环学习率周期大小: 447 步
2025-05-18 23:22:09,313 [INFO] Epoch 1/15 - Policy Loss: 0.7361, Value Loss: 0.0901, Total Loss: 0.8261, LR: 0.001689
2025-05-18 23:22:49,061 [INFO] Epoch 2/15 - Policy Loss: 0.7315, Value Loss: 0.0906, Total Loss: 0.8220, LR: 0.003339
2025-05-18 23:23:28,570 [INFO] Epoch 3/15 - Policy Loss: 0.7300, Value Loss: 0.0899, Total Loss: 0.8199, LR: 0.004989
2025-05-18 23:24:08,350 [INFO] Epoch 4/15 - Policy Loss: 0.7275, Value Loss: 0.0885, Total Loss: 0.8160, LR: 0.003361
2025-05-18 23:24:48,011 [INFO] Epoch 5/15 - Policy Loss: 0.7261, Value Loss: 0.0875, Total Loss: 0.8136, LR: 0.001711
2025-05-18 23:25:27,972 [INFO] Epoch 6/15 - Policy Loss: 0.7246, Value Loss: 0.0866, Total Loss: 0.8112, LR: 0.000061
2025-05-18 23:26:07,860 [INFO] Epoch 7/15 - Policy Loss: 0.7226, Value Loss: 0.0860, Total Loss: 0.8086, LR: 0.001689
2025-05-18 23:26:47,640 [INFO] Epoch 8/15 - Policy Loss: 0.7221, Value Loss: 0.0855, Total Loss: 0.8075, LR: 0.003339
2025-05-18 23:27:27,473 [INFO] Epoch 9/15 - Policy Loss: 0.7216, Value Loss: 0.0850, Total Loss: 0.8066, LR: 0.004989
2025-05-18 23:28:07,220 [INFO] Epoch 10/15 - Policy Loss: 0.7219, Value Loss: 0.0848, Total Loss: 0.8067, LR: 0.003361
2025-05-18 23:28:47,095 [INFO] Epoch 11/15 - Policy Loss: 0.7214, Value Loss: 0.0844, Total Loss: 0.8058, LR: 0.001711
2025-05-18 23:29:26,971 [INFO] Epoch 12/15 - Policy Loss: 0.7209, Value Loss: 0.0840, Total Loss: 0.8049, LR: 0.000061
2025-05-18 23:30:07,024 [INFO] Epoch 13/15 - Policy Loss: 0.7202, Value Loss: 0.0837, Total Loss: 0.8038, LR: 0.001689
2025-05-18 23:30:47,048 [INFO] Epoch 14/15 - Policy Loss: 0.7195, Value Loss: 0.0835, Total Loss: 0.8030, LR: 0.003339
2025-05-18 23:31:27,025 [INFO] Epoch 15/15 - Policy Loss: 0.7193, Value Loss: 0.0832, Total Loss: 0.8024, LR: 0.004989
2025-05-18 23:31:27,044 [INFO] 训练完成，总损失: 0.8024
2025-05-18 23:31:27,044 [INFO] 保存迭代 124 的模型
2025-05-18 23:31:28,645 [INFO] Model saved to ./models/best.pt
2025-05-18 23:31:29,581 [INFO] Model saved to ./models/iteration_124.pt
2025-05-18 23:31:29,582 [INFO] 所有训练迭代完成
2025-05-18 23:31:29,582 [INFO] 开始迭代 125/300
2025-05-18 23:31:29,582 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-18 23:44:23,433 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-18 23:44:23,434 [INFO] 保存训练样本
2025-05-18 23:44:27,605 [INFO] 使用 153288 个样本训练神经网络
2025-05-18 23:44:27,605 [INFO] Training with 153288 examples
2025-05-18 23:44:27,605 [INFO] 总训练步数: 2235, 每轮次批次数: 149
2025-05-18 23:44:27,946 [INFO] 循环学习率周期大小: 447 步
2025-05-18 23:45:07,411 [INFO] Epoch 1/15 - Policy Loss: 0.7376, Value Loss: 0.0911, Total Loss: 0.8287, LR: 0.001689
2025-05-18 23:45:46,859 [INFO] Epoch 2/15 - Policy Loss: 0.7356, Value Loss: 0.0905, Total Loss: 0.8262, LR: 0.003339
2025-05-18 23:46:26,444 [INFO] Epoch 3/15 - Policy Loss: 0.7329, Value Loss: 0.0889, Total Loss: 0.8217, LR: 0.004989
2025-05-18 23:47:06,171 [INFO] Epoch 4/15 - Policy Loss: 0.7294, Value Loss: 0.0885, Total Loss: 0.8179, LR: 0.003361
2025-05-18 23:47:45,704 [INFO] Epoch 5/15 - Policy Loss: 0.7281, Value Loss: 0.0878, Total Loss: 0.8159, LR: 0.001711
2025-05-18 23:48:25,410 [INFO] Epoch 6/15 - Policy Loss: 0.7260, Value Loss: 0.0870, Total Loss: 0.8130, LR: 0.000061
2025-05-18 23:49:05,127 [INFO] Epoch 7/15 - Policy Loss: 0.7241, Value Loss: 0.0863, Total Loss: 0.8105, LR: 0.001689
2025-05-18 23:49:44,874 [INFO] Epoch 8/15 - Policy Loss: 0.7238, Value Loss: 0.0861, Total Loss: 0.8100, LR: 0.003339
2025-05-18 23:50:24,639 [INFO] Epoch 9/15 - Policy Loss: 0.7234, Value Loss: 0.0860, Total Loss: 0.8094, LR: 0.004989
2025-05-18 23:51:04,759 [INFO] Epoch 10/15 - Policy Loss: 0.7232, Value Loss: 0.0857, Total Loss: 0.8089, LR: 0.003361
2025-05-18 23:51:44,587 [INFO] Epoch 11/15 - Policy Loss: 0.7228, Value Loss: 0.0857, Total Loss: 0.8085, LR: 0.001711
2025-05-18 23:52:24,378 [INFO] Epoch 12/15 - Policy Loss: 0.7220, Value Loss: 0.0853, Total Loss: 0.8073, LR: 0.000061
2025-05-18 23:53:04,217 [INFO] Epoch 13/15 - Policy Loss: 0.7212, Value Loss: 0.0850, Total Loss: 0.8062, LR: 0.001689
2025-05-18 23:53:44,162 [INFO] Epoch 14/15 - Policy Loss: 0.7210, Value Loss: 0.0849, Total Loss: 0.8059, LR: 0.003339
2025-05-18 23:54:24,225 [INFO] Epoch 15/15 - Policy Loss: 0.7205, Value Loss: 0.0848, Total Loss: 0.8054, LR: 0.004989
2025-05-18 23:54:24,249 [INFO] 训练完成，总损失: 0.8054
2025-05-18 23:54:24,249 [INFO] 保存迭代 125 的模型
2025-05-18 23:54:25,684 [INFO] Model saved to ./models/best.pt
2025-05-18 23:54:26,467 [INFO] Model saved to ./models/iteration_125.pt
2025-05-18 23:54:26,468 [INFO] 所有训练迭代完成
2025-05-18 23:54:26,468 [INFO] 开始迭代 126/300
2025-05-18 23:54:26,468 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 00:07:37,587 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 00:07:37,588 [INFO] 保存训练样本
2025-05-19 00:07:43,276 [INFO] 使用 152728 个样本训练神经网络
2025-05-19 00:07:43,276 [INFO] Training with 152728 examples
2025-05-19 00:07:43,277 [INFO] 总训练步数: 2235, 每轮次批次数: 149
2025-05-19 00:07:43,341 [INFO] 循环学习率周期大小: 447 步
2025-05-19 00:08:23,158 [INFO] Epoch 1/15 - Policy Loss: 0.7388, Value Loss: 0.0812, Total Loss: 0.8200, LR: 0.001689
2025-05-19 00:09:02,942 [INFO] Epoch 2/15 - Policy Loss: 0.7388, Value Loss: 0.0820, Total Loss: 0.8208, LR: 0.003339
2025-05-19 00:09:42,553 [INFO] Epoch 3/15 - Policy Loss: 0.7353, Value Loss: 0.0821, Total Loss: 0.8174, LR: 0.004989
2025-05-19 00:10:22,244 [INFO] Epoch 4/15 - Policy Loss: 0.7335, Value Loss: 0.0820, Total Loss: 0.8154, LR: 0.003361
2025-05-19 00:11:02,243 [INFO] Epoch 5/15 - Policy Loss: 0.7312, Value Loss: 0.0814, Total Loss: 0.8126, LR: 0.001711
2025-05-19 00:11:41,925 [INFO] Epoch 6/15 - Policy Loss: 0.7291, Value Loss: 0.0811, Total Loss: 0.8102, LR: 0.000061
2025-05-19 00:12:21,743 [INFO] Epoch 7/15 - Policy Loss: 0.7273, Value Loss: 0.0806, Total Loss: 0.8079, LR: 0.001689
2025-05-19 00:13:01,252 [INFO] Epoch 8/15 - Policy Loss: 0.7260, Value Loss: 0.0805, Total Loss: 0.8064, LR: 0.003339
2025-05-19 00:13:40,577 [INFO] Epoch 9/15 - Policy Loss: 0.7256, Value Loss: 0.0803, Total Loss: 0.8059, LR: 0.004989
2025-05-19 00:14:19,993 [INFO] Epoch 10/15 - Policy Loss: 0.7248, Value Loss: 0.0802, Total Loss: 0.8050, LR: 0.003361
2025-05-19 00:14:59,564 [INFO] Epoch 11/15 - Policy Loss: 0.7244, Value Loss: 0.0799, Total Loss: 0.8043, LR: 0.001711
2025-05-19 00:15:39,021 [INFO] Epoch 12/15 - Policy Loss: 0.7239, Value Loss: 0.0796, Total Loss: 0.8035, LR: 0.000061
2025-05-19 00:16:18,475 [INFO] Epoch 13/15 - Policy Loss: 0.7233, Value Loss: 0.0794, Total Loss: 0.8028, LR: 0.001689
2025-05-19 00:16:58,113 [INFO] Epoch 14/15 - Policy Loss: 0.7229, Value Loss: 0.0793, Total Loss: 0.8021, LR: 0.003339
2025-05-19 00:17:37,764 [INFO] Epoch 15/15 - Policy Loss: 0.7227, Value Loss: 0.0792, Total Loss: 0.8019, LR: 0.004989
2025-05-19 00:17:37,786 [INFO] 训练完成，总损失: 0.8019
2025-05-19 00:17:37,786 [INFO] 保存迭代 126 的模型
2025-05-19 00:17:39,145 [INFO] Model saved to ./models/best.pt
2025-05-19 00:17:39,877 [INFO] Model saved to ./models/iteration_126.pt
2025-05-19 00:17:39,877 [INFO] 所有训练迭代完成
2025-05-19 00:17:39,877 [INFO] 开始迭代 127/300
2025-05-19 00:17:39,877 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 00:30:44,806 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 00:30:44,806 [INFO] 保存训练样本
2025-05-19 00:30:49,121 [INFO] 使用 153280 个样本训练神经网络
2025-05-19 00:30:49,121 [INFO] Training with 153280 examples
2025-05-19 00:30:49,121 [INFO] 总训练步数: 2235, 每轮次批次数: 149
2025-05-19 00:30:49,452 [INFO] 循环学习率周期大小: 447 步
2025-05-19 00:31:28,850 [INFO] Epoch 1/15 - Policy Loss: 0.7391, Value Loss: 0.0849, Total Loss: 0.8241, LR: 0.001689
2025-05-19 00:32:08,296 [INFO] Epoch 2/15 - Policy Loss: 0.7345, Value Loss: 0.0833, Total Loss: 0.8178, LR: 0.003339
2025-05-19 00:32:47,708 [INFO] Epoch 3/15 - Policy Loss: 0.7319, Value Loss: 0.0824, Total Loss: 0.8143, LR: 0.004989
2025-05-19 00:33:27,132 [INFO] Epoch 4/15 - Policy Loss: 0.7296, Value Loss: 0.0821, Total Loss: 0.8117, LR: 0.003361
2025-05-19 00:34:06,622 [INFO] Epoch 5/15 - Policy Loss: 0.7277, Value Loss: 0.0815, Total Loss: 0.8093, LR: 0.001711
2025-05-19 00:34:46,125 [INFO] Epoch 6/15 - Policy Loss: 0.7261, Value Loss: 0.0812, Total Loss: 0.8073, LR: 0.000061
2025-05-19 00:35:25,668 [INFO] Epoch 7/15 - Policy Loss: 0.7250, Value Loss: 0.0807, Total Loss: 0.8057, LR: 0.001689
2025-05-19 00:36:05,128 [INFO] Epoch 8/15 - Policy Loss: 0.7239, Value Loss: 0.0803, Total Loss: 0.8041, LR: 0.003339
2025-05-19 00:36:44,816 [INFO] Epoch 9/15 - Policy Loss: 0.7231, Value Loss: 0.0799, Total Loss: 0.8030, LR: 0.004989
2025-05-19 00:37:24,482 [INFO] Epoch 10/15 - Policy Loss: 0.7223, Value Loss: 0.0796, Total Loss: 0.8020, LR: 0.003361
2025-05-19 00:38:04,182 [INFO] Epoch 11/15 - Policy Loss: 0.7218, Value Loss: 0.0793, Total Loss: 0.8012, LR: 0.001711
2025-05-19 00:38:43,836 [INFO] Epoch 12/15 - Policy Loss: 0.7211, Value Loss: 0.0790, Total Loss: 0.8001, LR: 0.000061
2025-05-19 00:39:23,825 [INFO] Epoch 13/15 - Policy Loss: 0.7204, Value Loss: 0.0787, Total Loss: 0.7991, LR: 0.001689
2025-05-19 00:40:03,871 [INFO] Epoch 14/15 - Policy Loss: 0.7197, Value Loss: 0.0784, Total Loss: 0.7981, LR: 0.003339
2025-05-19 00:40:43,889 [INFO] Epoch 15/15 - Policy Loss: 0.7193, Value Loss: 0.0783, Total Loss: 0.7975, LR: 0.004989
2025-05-19 00:40:43,915 [INFO] 训练完成，总损失: 0.7975
2025-05-19 00:40:43,915 [INFO] 保存迭代 127 的模型
2025-05-19 00:40:45,467 [INFO] Model saved to ./models/best.pt
2025-05-19 00:40:46,374 [INFO] Model saved to ./models/iteration_127.pt
2025-05-19 00:40:46,375 [INFO] 所有训练迭代完成
2025-05-19 00:40:46,375 [INFO] 开始迭代 128/300
2025-05-19 00:40:46,375 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 00:55:03,419 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 00:55:03,419 [INFO] 保存训练样本
2025-05-19 00:55:07,600 [INFO] 使用 153888 个样本训练神经网络
2025-05-19 00:55:07,600 [INFO] Training with 153888 examples
2025-05-19 00:55:07,600 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-19 00:55:07,950 [INFO] 循环学习率周期大小: 450 步
2025-05-19 00:55:47,537 [INFO] Epoch 1/15 - Policy Loss: 0.7471, Value Loss: 0.0867, Total Loss: 0.8338, LR: 0.001689
2025-05-19 00:56:27,348 [INFO] Epoch 2/15 - Policy Loss: 0.7429, Value Loss: 0.0845, Total Loss: 0.8274, LR: 0.003339
2025-05-19 00:57:07,044 [INFO] Epoch 3/15 - Policy Loss: 0.7409, Value Loss: 0.0834, Total Loss: 0.8243, LR: 0.004989
2025-05-19 00:57:46,770 [INFO] Epoch 4/15 - Policy Loss: 0.7380, Value Loss: 0.0825, Total Loss: 0.8206, LR: 0.003361
2025-05-19 00:58:26,519 [INFO] Epoch 5/15 - Policy Loss: 0.7350, Value Loss: 0.0819, Total Loss: 0.8169, LR: 0.001711
2025-05-19 00:59:06,375 [INFO] Epoch 6/15 - Policy Loss: 0.7329, Value Loss: 0.0813, Total Loss: 0.8142, LR: 0.000061
2025-05-19 00:59:46,223 [INFO] Epoch 7/15 - Policy Loss: 0.7308, Value Loss: 0.0809, Total Loss: 0.8117, LR: 0.001689
2025-05-19 01:00:26,105 [INFO] Epoch 8/15 - Policy Loss: 0.7292, Value Loss: 0.0804, Total Loss: 0.8096, LR: 0.003339
2025-05-19 01:01:06,019 [INFO] Epoch 9/15 - Policy Loss: 0.7282, Value Loss: 0.0800, Total Loss: 0.8083, LR: 0.004989
2025-05-19 01:01:45,992 [INFO] Epoch 10/15 - Policy Loss: 0.7276, Value Loss: 0.0801, Total Loss: 0.8077, LR: 0.003361
2025-05-19 01:02:26,035 [INFO] Epoch 11/15 - Policy Loss: 0.7268, Value Loss: 0.0799, Total Loss: 0.8067, LR: 0.001711
2025-05-19 01:03:06,032 [INFO] Epoch 12/15 - Policy Loss: 0.7257, Value Loss: 0.0797, Total Loss: 0.8053, LR: 0.000061
2025-05-19 01:03:46,044 [INFO] Epoch 13/15 - Policy Loss: 0.7250, Value Loss: 0.0797, Total Loss: 0.8047, LR: 0.001689
2025-05-19 01:04:26,470 [INFO] Epoch 14/15 - Policy Loss: 0.7243, Value Loss: 0.0795, Total Loss: 0.8037, LR: 0.003339
2025-05-19 01:05:06,599 [INFO] Epoch 15/15 - Policy Loss: 0.7234, Value Loss: 0.0794, Total Loss: 0.8029, LR: 0.004989
2025-05-19 01:05:06,618 [INFO] 训练完成，总损失: 0.8029
2025-05-19 01:05:06,619 [INFO] 保存迭代 128 的模型
2025-05-19 01:05:08,222 [INFO] Model saved to ./models/best.pt
2025-05-19 01:05:09,152 [INFO] Model saved to ./models/iteration_128.pt
2025-05-19 01:05:09,152 [INFO] 所有训练迭代完成
2025-05-19 01:05:09,152 [INFO] 开始迭代 129/300
2025-05-19 01:05:09,152 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 01:18:25,848 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 01:18:25,849 [INFO] 保存训练样本
2025-05-19 01:18:30,166 [INFO] 使用 154280 个样本训练神经网络
2025-05-19 01:18:30,166 [INFO] Training with 154280 examples
2025-05-19 01:18:30,166 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-19 01:18:30,506 [INFO] 循环学习率周期大小: 450 步
2025-05-19 01:19:10,135 [INFO] Epoch 1/15 - Policy Loss: 0.7433, Value Loss: 0.0946, Total Loss: 0.8379, LR: 0.001689
2025-05-19 01:19:49,847 [INFO] Epoch 2/15 - Policy Loss: 0.7371, Value Loss: 0.0939, Total Loss: 0.8310, LR: 0.003339
2025-05-19 01:20:29,595 [INFO] Epoch 3/15 - Policy Loss: 0.7335, Value Loss: 0.0931, Total Loss: 0.8266, LR: 0.004989
2025-05-19 01:21:09,400 [INFO] Epoch 4/15 - Policy Loss: 0.7328, Value Loss: 0.0930, Total Loss: 0.8258, LR: 0.003361
2025-05-19 01:21:49,200 [INFO] Epoch 5/15 - Policy Loss: 0.7311, Value Loss: 0.0922, Total Loss: 0.8233, LR: 0.001711
2025-05-19 01:22:29,068 [INFO] Epoch 6/15 - Policy Loss: 0.7297, Value Loss: 0.0923, Total Loss: 0.8219, LR: 0.000061
2025-05-19 01:23:08,996 [INFO] Epoch 7/15 - Policy Loss: 0.7285, Value Loss: 0.0921, Total Loss: 0.8206, LR: 0.001689
2025-05-19 01:23:48,884 [INFO] Epoch 8/15 - Policy Loss: 0.7274, Value Loss: 0.0917, Total Loss: 0.8191, LR: 0.003339
2025-05-19 01:24:28,791 [INFO] Epoch 9/15 - Policy Loss: 0.7262, Value Loss: 0.0913, Total Loss: 0.8175, LR: 0.004989
2025-05-19 01:25:09,025 [INFO] Epoch 10/15 - Policy Loss: 0.7257, Value Loss: 0.0914, Total Loss: 0.8171, LR: 0.003361
2025-05-19 01:25:49,008 [INFO] Epoch 11/15 - Policy Loss: 0.7250, Value Loss: 0.0910, Total Loss: 0.8159, LR: 0.001711
2025-05-19 01:26:29,028 [INFO] Epoch 12/15 - Policy Loss: 0.7238, Value Loss: 0.0907, Total Loss: 0.8146, LR: 0.000061
2025-05-19 01:27:09,143 [INFO] Epoch 13/15 - Policy Loss: 0.7228, Value Loss: 0.0906, Total Loss: 0.8134, LR: 0.001689
2025-05-19 01:27:49,151 [INFO] Epoch 14/15 - Policy Loss: 0.7226, Value Loss: 0.0905, Total Loss: 0.8130, LR: 0.003339
2025-05-19 01:28:29,092 [INFO] Epoch 15/15 - Policy Loss: 0.7226, Value Loss: 0.0903, Total Loss: 0.8129, LR: 0.004989
2025-05-19 01:28:29,111 [INFO] 训练完成，总损失: 0.8129
2025-05-19 01:28:29,111 [INFO] 保存迭代 129 的模型
2025-05-19 01:28:30,613 [INFO] Model saved to ./models/best.pt
2025-05-19 01:28:31,519 [INFO] Model saved to ./models/iteration_129.pt
2025-05-19 01:28:31,519 [INFO] 所有训练迭代完成
2025-05-19 01:28:31,519 [INFO] 开始迭代 130/300
2025-05-19 01:28:31,519 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 01:41:41,245 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 01:41:41,245 [INFO] 保存训练样本
2025-05-19 01:41:45,561 [INFO] 使用 154104 个样本训练神经网络
2025-05-19 01:41:45,562 [INFO] Training with 154104 examples
2025-05-19 01:41:45,562 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-19 01:41:45,609 [INFO] 循环学习率周期大小: 450 步
2025-05-19 01:42:24,879 [INFO] Epoch 1/15 - Policy Loss: 0.7423, Value Loss: 0.0950, Total Loss: 0.8374, LR: 0.001689
2025-05-19 01:43:04,395 [INFO] Epoch 2/15 - Policy Loss: 0.7404, Value Loss: 0.0957, Total Loss: 0.8361, LR: 0.003339
2025-05-19 01:43:43,868 [INFO] Epoch 3/15 - Policy Loss: 0.7366, Value Loss: 0.0960, Total Loss: 0.8325, LR: 0.004989
2025-05-19 01:44:23,368 [INFO] Epoch 4/15 - Policy Loss: 0.7362, Value Loss: 0.0962, Total Loss: 0.8324, LR: 0.003361
2025-05-19 01:45:03,314 [INFO] Epoch 5/15 - Policy Loss: 0.7327, Value Loss: 0.0953, Total Loss: 0.8280, LR: 0.001711
2025-05-19 01:45:42,721 [INFO] Epoch 6/15 - Policy Loss: 0.7309, Value Loss: 0.0953, Total Loss: 0.8261, LR: 0.000061
2025-05-19 01:46:22,257 [INFO] Epoch 7/15 - Policy Loss: 0.7297, Value Loss: 0.0947, Total Loss: 0.8244, LR: 0.001689
2025-05-19 01:47:01,831 [INFO] Epoch 8/15 - Policy Loss: 0.7282, Value Loss: 0.0944, Total Loss: 0.8226, LR: 0.003339
2025-05-19 01:47:41,395 [INFO] Epoch 9/15 - Policy Loss: 0.7271, Value Loss: 0.0940, Total Loss: 0.8211, LR: 0.004989
2025-05-19 01:48:21,046 [INFO] Epoch 10/15 - Policy Loss: 0.7263, Value Loss: 0.0938, Total Loss: 0.8201, LR: 0.003361
2025-05-19 01:49:00,655 [INFO] Epoch 11/15 - Policy Loss: 0.7257, Value Loss: 0.0936, Total Loss: 0.8194, LR: 0.001711
2025-05-19 01:49:40,296 [INFO] Epoch 12/15 - Policy Loss: 0.7250, Value Loss: 0.0936, Total Loss: 0.8186, LR: 0.000061
2025-05-19 01:50:20,028 [INFO] Epoch 13/15 - Policy Loss: 0.7244, Value Loss: 0.0935, Total Loss: 0.8179, LR: 0.001689
2025-05-19 01:50:59,722 [INFO] Epoch 14/15 - Policy Loss: 0.7239, Value Loss: 0.0933, Total Loss: 0.8172, LR: 0.003339
2025-05-19 01:51:39,453 [INFO] Epoch 15/15 - Policy Loss: 0.7236, Value Loss: 0.0933, Total Loss: 0.8169, LR: 0.004989
2025-05-19 01:51:39,469 [INFO] 训练完成，总损失: 0.8169
2025-05-19 01:51:39,469 [INFO] 保存迭代 130 的模型
2025-05-19 01:51:40,689 [INFO] Model saved to ./models/best.pt
2025-05-19 01:51:41,391 [INFO] Model saved to ./models/iteration_130.pt
2025-05-19 01:51:41,391 [INFO] 所有训练迭代完成
2025-05-19 01:51:41,391 [INFO] 开始迭代 131/300
2025-05-19 01:51:41,391 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 02:04:21,155 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 02:04:21,156 [INFO] 保存训练样本
2025-05-19 02:04:25,356 [INFO] 使用 154104 个样本训练神经网络
2025-05-19 02:04:25,356 [INFO] Training with 154104 examples
2025-05-19 02:04:25,357 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-19 02:04:25,664 [INFO] 循环学习率周期大小: 450 步
2025-05-19 02:05:05,028 [INFO] Epoch 1/15 - Policy Loss: 0.7451, Value Loss: 0.0982, Total Loss: 0.8433, LR: 0.001689
2025-05-19 02:05:44,453 [INFO] Epoch 2/15 - Policy Loss: 0.7393, Value Loss: 0.0967, Total Loss: 0.8360, LR: 0.003339
2025-05-19 02:06:23,781 [INFO] Epoch 3/15 - Policy Loss: 0.7361, Value Loss: 0.0965, Total Loss: 0.8325, LR: 0.004989
2025-05-19 02:07:03,251 [INFO] Epoch 4/15 - Policy Loss: 0.7333, Value Loss: 0.0961, Total Loss: 0.8293, LR: 0.003361
2025-05-19 02:07:42,674 [INFO] Epoch 5/15 - Policy Loss: 0.7314, Value Loss: 0.0952, Total Loss: 0.8265, LR: 0.001711
2025-05-19 02:08:22,138 [INFO] Epoch 6/15 - Policy Loss: 0.7297, Value Loss: 0.0948, Total Loss: 0.8245, LR: 0.000061
2025-05-19 02:09:01,737 [INFO] Epoch 7/15 - Policy Loss: 0.7287, Value Loss: 0.0943, Total Loss: 0.8230, LR: 0.001689
2025-05-19 02:09:41,320 [INFO] Epoch 8/15 - Policy Loss: 0.7279, Value Loss: 0.0942, Total Loss: 0.8221, LR: 0.003339
2025-05-19 02:10:20,792 [INFO] Epoch 9/15 - Policy Loss: 0.7271, Value Loss: 0.0941, Total Loss: 0.8212, LR: 0.004989
2025-05-19 02:11:00,489 [INFO] Epoch 10/15 - Policy Loss: 0.7267, Value Loss: 0.0939, Total Loss: 0.8206, LR: 0.003361
2025-05-19 02:11:40,213 [INFO] Epoch 11/15 - Policy Loss: 0.7264, Value Loss: 0.0936, Total Loss: 0.8200, LR: 0.001711
2025-05-19 02:12:19,841 [INFO] Epoch 12/15 - Policy Loss: 0.7258, Value Loss: 0.0934, Total Loss: 0.8193, LR: 0.000061
2025-05-19 02:12:59,548 [INFO] Epoch 13/15 - Policy Loss: 0.7249, Value Loss: 0.0933, Total Loss: 0.8183, LR: 0.001689
2025-05-19 02:13:39,283 [INFO] Epoch 14/15 - Policy Loss: 0.7244, Value Loss: 0.0931, Total Loss: 0.8175, LR: 0.003339
2025-05-19 02:14:19,059 [INFO] Epoch 15/15 - Policy Loss: 0.7241, Value Loss: 0.0930, Total Loss: 0.8172, LR: 0.004989
2025-05-19 02:14:19,081 [INFO] 训练完成，总损失: 0.8172
2025-05-19 02:14:19,082 [INFO] 保存迭代 131 的模型
2025-05-19 02:14:20,397 [INFO] Model saved to ./models/best.pt
2025-05-19 02:14:21,285 [INFO] Model saved to ./models/iteration_131.pt
2025-05-19 02:14:21,285 [INFO] 所有训练迭代完成
2025-05-19 02:14:21,285 [INFO] 开始迭代 132/300
2025-05-19 02:14:21,285 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 02:28:11,398 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 02:28:11,398 [INFO] 保存训练样本
2025-05-19 02:28:15,853 [INFO] 使用 154504 个样本训练神经网络
2025-05-19 02:28:15,853 [INFO] Training with 154504 examples
2025-05-19 02:28:15,854 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-19 02:28:16,177 [INFO] 循环学习率周期大小: 450 步
2025-05-19 02:28:55,439 [INFO] Epoch 1/15 - Policy Loss: 0.7416, Value Loss: 0.0996, Total Loss: 0.8413, LR: 0.001689
2025-05-19 02:29:34,703 [INFO] Epoch 2/15 - Policy Loss: 0.7405, Value Loss: 0.0973, Total Loss: 0.8377, LR: 0.003339
2025-05-19 02:30:13,967 [INFO] Epoch 3/15 - Policy Loss: 0.7362, Value Loss: 0.0970, Total Loss: 0.8332, LR: 0.004989
2025-05-19 02:30:53,421 [INFO] Epoch 4/15 - Policy Loss: 0.7347, Value Loss: 0.0960, Total Loss: 0.8307, LR: 0.003361
2025-05-19 02:31:32,856 [INFO] Epoch 5/15 - Policy Loss: 0.7328, Value Loss: 0.0949, Total Loss: 0.8277, LR: 0.001711
2025-05-19 02:32:12,248 [INFO] Epoch 6/15 - Policy Loss: 0.7312, Value Loss: 0.0943, Total Loss: 0.8255, LR: 0.000061
2025-05-19 02:32:51,648 [INFO] Epoch 7/15 - Policy Loss: 0.7293, Value Loss: 0.0938, Total Loss: 0.8230, LR: 0.001689
2025-05-19 02:33:31,105 [INFO] Epoch 8/15 - Policy Loss: 0.7276, Value Loss: 0.0937, Total Loss: 0.8213, LR: 0.003339
2025-05-19 02:34:10,725 [INFO] Epoch 9/15 - Policy Loss: 0.7266, Value Loss: 0.0937, Total Loss: 0.8203, LR: 0.004989
2025-05-19 02:34:50,328 [INFO] Epoch 10/15 - Policy Loss: 0.7260, Value Loss: 0.0935, Total Loss: 0.8194, LR: 0.003361
2025-05-19 02:35:29,958 [INFO] Epoch 11/15 - Policy Loss: 0.7248, Value Loss: 0.0932, Total Loss: 0.8179, LR: 0.001711
2025-05-19 02:36:09,671 [INFO] Epoch 12/15 - Policy Loss: 0.7240, Value Loss: 0.0927, Total Loss: 0.8167, LR: 0.000061
2025-05-19 02:36:49,472 [INFO] Epoch 13/15 - Policy Loss: 0.7234, Value Loss: 0.0923, Total Loss: 0.8157, LR: 0.001689
2025-05-19 02:37:29,281 [INFO] Epoch 14/15 - Policy Loss: 0.7228, Value Loss: 0.0921, Total Loss: 0.8149, LR: 0.003339
2025-05-19 02:38:09,191 [INFO] Epoch 15/15 - Policy Loss: 0.7228, Value Loss: 0.0919, Total Loss: 0.8146, LR: 0.004989
2025-05-19 02:38:09,208 [INFO] 训练完成，总损失: 0.8146
2025-05-19 02:38:09,208 [INFO] 保存迭代 132 的模型
2025-05-19 02:38:10,426 [INFO] Model saved to ./models/best.pt
2025-05-19 02:38:11,119 [INFO] Model saved to ./models/iteration_132.pt
2025-05-19 02:38:11,119 [INFO] 所有训练迭代完成
2025-05-19 02:38:11,119 [INFO] 开始迭代 133/300
2025-05-19 02:38:11,119 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 02:50:56,952 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 02:50:56,953 [INFO] 保存训练样本
2025-05-19 02:51:00,328 [INFO] 使用 155024 个样本训练神经网络
2025-05-19 02:51:00,328 [INFO] Training with 155024 examples
2025-05-19 02:51:00,328 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 02:51:00,622 [INFO] 循环学习率周期大小: 453 步
2025-05-19 02:51:40,365 [INFO] Epoch 1/15 - Policy Loss: 0.7437, Value Loss: 0.0906, Total Loss: 0.8343, LR: 0.001689
2025-05-19 02:52:20,017 [INFO] Epoch 2/15 - Policy Loss: 0.7367, Value Loss: 0.0893, Total Loss: 0.8260, LR: 0.003339
2025-05-19 02:52:59,620 [INFO] Epoch 3/15 - Policy Loss: 0.7334, Value Loss: 0.0896, Total Loss: 0.8230, LR: 0.004989
2025-05-19 02:53:39,344 [INFO] Epoch 4/15 - Policy Loss: 0.7323, Value Loss: 0.0897, Total Loss: 0.8220, LR: 0.003361
2025-05-19 02:54:19,149 [INFO] Epoch 5/15 - Policy Loss: 0.7301, Value Loss: 0.0897, Total Loss: 0.8198, LR: 0.001711
2025-05-19 02:54:59,014 [INFO] Epoch 6/15 - Policy Loss: 0.7288, Value Loss: 0.0894, Total Loss: 0.8181, LR: 0.000061
2025-05-19 02:55:38,742 [INFO] Epoch 7/15 - Policy Loss: 0.7277, Value Loss: 0.0890, Total Loss: 0.8167, LR: 0.001689
2025-05-19 02:56:18,644 [INFO] Epoch 8/15 - Policy Loss: 0.7264, Value Loss: 0.0887, Total Loss: 0.8151, LR: 0.003339
2025-05-19 02:56:58,560 [INFO] Epoch 9/15 - Policy Loss: 0.7256, Value Loss: 0.0888, Total Loss: 0.8145, LR: 0.004989
2025-05-19 02:57:38,605 [INFO] Epoch 10/15 - Policy Loss: 0.7250, Value Loss: 0.0887, Total Loss: 0.8137, LR: 0.003361
2025-05-19 02:58:18,947 [INFO] Epoch 11/15 - Policy Loss: 0.7247, Value Loss: 0.0886, Total Loss: 0.8133, LR: 0.001711
2025-05-19 02:58:58,958 [INFO] Epoch 12/15 - Policy Loss: 0.7241, Value Loss: 0.0885, Total Loss: 0.8125, LR: 0.000061
2025-05-19 02:59:38,982 [INFO] Epoch 13/15 - Policy Loss: 0.7236, Value Loss: 0.0883, Total Loss: 0.8119, LR: 0.001689
2025-05-19 03:00:19,068 [INFO] Epoch 14/15 - Policy Loss: 0.7232, Value Loss: 0.0881, Total Loss: 0.8113, LR: 0.003339
2025-05-19 03:00:59,237 [INFO] Epoch 15/15 - Policy Loss: 0.7225, Value Loss: 0.0879, Total Loss: 0.8104, LR: 0.004989
2025-05-19 03:00:59,256 [INFO] 训练完成，总损失: 0.8104
2025-05-19 03:00:59,256 [INFO] 保存迭代 133 的模型
2025-05-19 03:01:00,819 [INFO] Model saved to ./models/best.pt
2025-05-19 03:01:01,739 [INFO] Model saved to ./models/iteration_133.pt
2025-05-19 03:01:01,739 [INFO] 所有训练迭代完成
2025-05-19 03:01:01,739 [INFO] 开始迭代 134/300
2025-05-19 03:01:01,739 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 03:13:24,729 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 03:13:24,729 [INFO] 保存训练样本
2025-05-19 03:13:28,532 [INFO] 使用 154960 个样本训练神经网络
2025-05-19 03:13:28,532 [INFO] Training with 154960 examples
2025-05-19 03:13:28,533 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 03:13:28,845 [INFO] 循环学习率周期大小: 453 步
2025-05-19 03:14:08,509 [INFO] Epoch 1/15 - Policy Loss: 0.7365, Value Loss: 0.0866, Total Loss: 0.8231, LR: 0.001689
2025-05-19 03:14:48,301 [INFO] Epoch 2/15 - Policy Loss: 0.7323, Value Loss: 0.0859, Total Loss: 0.8182, LR: 0.003339
2025-05-19 03:15:28,077 [INFO] Epoch 3/15 - Policy Loss: 0.7302, Value Loss: 0.0856, Total Loss: 0.8158, LR: 0.004989
2025-05-19 03:16:07,851 [INFO] Epoch 4/15 - Policy Loss: 0.7305, Value Loss: 0.0851, Total Loss: 0.8157, LR: 0.003361
2025-05-19 03:16:47,646 [INFO] Epoch 5/15 - Policy Loss: 0.7286, Value Loss: 0.0847, Total Loss: 0.8133, LR: 0.001711
2025-05-19 03:17:27,331 [INFO] Epoch 6/15 - Policy Loss: 0.7258, Value Loss: 0.0844, Total Loss: 0.8101, LR: 0.000061
2025-05-19 03:18:07,195 [INFO] Epoch 7/15 - Policy Loss: 0.7244, Value Loss: 0.0840, Total Loss: 0.8084, LR: 0.001689
2025-05-19 03:18:47,545 [INFO] Epoch 8/15 - Policy Loss: 0.7232, Value Loss: 0.0837, Total Loss: 0.8070, LR: 0.003339
2025-05-19 03:19:27,439 [INFO] Epoch 9/15 - Policy Loss: 0.7226, Value Loss: 0.0835, Total Loss: 0.8061, LR: 0.004989
2025-05-19 03:20:07,477 [INFO] Epoch 10/15 - Policy Loss: 0.7224, Value Loss: 0.0834, Total Loss: 0.8058, LR: 0.003361
2025-05-19 03:20:47,662 [INFO] Epoch 11/15 - Policy Loss: 0.7219, Value Loss: 0.0835, Total Loss: 0.8053, LR: 0.001711
2025-05-19 03:21:27,770 [INFO] Epoch 12/15 - Policy Loss: 0.7213, Value Loss: 0.0833, Total Loss: 0.8045, LR: 0.000061
2025-05-19 03:22:07,815 [INFO] Epoch 13/15 - Policy Loss: 0.7205, Value Loss: 0.0832, Total Loss: 0.8037, LR: 0.001689
2025-05-19 03:22:48,055 [INFO] Epoch 14/15 - Policy Loss: 0.7199, Value Loss: 0.0829, Total Loss: 0.8029, LR: 0.003339
2025-05-19 03:23:28,303 [INFO] Epoch 15/15 - Policy Loss: 0.7198, Value Loss: 0.0829, Total Loss: 0.8027, LR: 0.004989
2025-05-19 03:23:28,326 [INFO] 训练完成，总损失: 0.8027
2025-05-19 03:23:28,326 [INFO] 保存迭代 134 的模型
2025-05-19 03:23:29,679 [INFO] Model saved to ./models/best.pt
2025-05-19 03:23:30,448 [INFO] Model saved to ./models/iteration_134.pt
2025-05-19 03:23:30,448 [INFO] 所有训练迭代完成
2025-05-19 03:23:30,448 [INFO] 开始迭代 135/300
2025-05-19 03:23:30,448 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 03:35:50,689 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 03:35:50,690 [INFO] 保存训练样本
2025-05-19 03:35:55,411 [INFO] 使用 154784 个样本训练神经网络
2025-05-19 03:35:55,412 [INFO] Training with 154784 examples
2025-05-19 03:35:55,412 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 03:35:55,464 [INFO] 循环学习率周期大小: 453 步
2025-05-19 03:36:35,183 [INFO] Epoch 1/15 - Policy Loss: 0.7416, Value Loss: 0.0763, Total Loss: 0.8179, LR: 0.001689
2025-05-19 03:37:15,248 [INFO] Epoch 2/15 - Policy Loss: 0.7368, Value Loss: 0.0758, Total Loss: 0.8126, LR: 0.003339
2025-05-19 03:37:55,057 [INFO] Epoch 3/15 - Policy Loss: 0.7337, Value Loss: 0.0762, Total Loss: 0.8100, LR: 0.004989
2025-05-19 03:38:34,931 [INFO] Epoch 4/15 - Policy Loss: 0.7309, Value Loss: 0.0760, Total Loss: 0.8070, LR: 0.003361
2025-05-19 03:39:14,763 [INFO] Epoch 5/15 - Policy Loss: 0.7289, Value Loss: 0.0752, Total Loss: 0.8041, LR: 0.001711
2025-05-19 03:39:54,538 [INFO] Epoch 6/15 - Policy Loss: 0.7276, Value Loss: 0.0751, Total Loss: 0.8027, LR: 0.000061
2025-05-19 03:40:34,508 [INFO] Epoch 7/15 - Policy Loss: 0.7260, Value Loss: 0.0747, Total Loss: 0.8007, LR: 0.001689
2025-05-19 03:41:14,372 [INFO] Epoch 8/15 - Policy Loss: 0.7254, Value Loss: 0.0748, Total Loss: 0.8002, LR: 0.003339
2025-05-19 03:41:54,458 [INFO] Epoch 9/15 - Policy Loss: 0.7241, Value Loss: 0.0747, Total Loss: 0.7988, LR: 0.004989
2025-05-19 03:42:34,396 [INFO] Epoch 10/15 - Policy Loss: 0.7238, Value Loss: 0.0745, Total Loss: 0.7984, LR: 0.003361
2025-05-19 03:43:14,373 [INFO] Epoch 11/15 - Policy Loss: 0.7235, Value Loss: 0.0745, Total Loss: 0.7980, LR: 0.001711
2025-05-19 03:43:54,420 [INFO] Epoch 12/15 - Policy Loss: 0.7227, Value Loss: 0.0745, Total Loss: 0.7972, LR: 0.000061
2025-05-19 03:44:34,461 [INFO] Epoch 13/15 - Policy Loss: 0.7215, Value Loss: 0.0743, Total Loss: 0.7958, LR: 0.001689
2025-05-19 03:45:14,594 [INFO] Epoch 14/15 - Policy Loss: 0.7210, Value Loss: 0.0744, Total Loss: 0.7954, LR: 0.003339
2025-05-19 03:45:54,642 [INFO] Epoch 15/15 - Policy Loss: 0.7207, Value Loss: 0.0745, Total Loss: 0.7951, LR: 0.004989
2025-05-19 03:45:54,665 [INFO] 训练完成，总损失: 0.7951
2025-05-19 03:45:54,665 [INFO] 保存迭代 135 的模型
2025-05-19 03:45:56,033 [INFO] Model saved to ./models/best.pt
2025-05-19 03:45:56,915 [INFO] Model saved to ./models/iteration_135.pt
2025-05-19 03:45:56,916 [INFO] 所有训练迭代完成
2025-05-19 03:45:56,916 [INFO] 开始迭代 136/300
2025-05-19 03:45:56,916 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 03:58:06,273 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 03:58:06,274 [INFO] 保存训练样本
2025-05-19 03:58:11,094 [INFO] 使用 155416 个样本训练神经网络
2025-05-19 03:58:11,094 [INFO] Training with 155416 examples
2025-05-19 03:58:11,095 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 03:58:11,485 [INFO] 循环学习率周期大小: 453 步
2025-05-19 03:58:51,229 [INFO] Epoch 1/15 - Policy Loss: 0.7336, Value Loss: 0.0829, Total Loss: 0.8165, LR: 0.001689
2025-05-19 03:59:31,074 [INFO] Epoch 2/15 - Policy Loss: 0.7307, Value Loss: 0.0820, Total Loss: 0.8128, LR: 0.003339
2025-05-19 04:00:10,841 [INFO] Epoch 3/15 - Policy Loss: 0.7277, Value Loss: 0.0804, Total Loss: 0.8081, LR: 0.004989
2025-05-19 04:00:50,483 [INFO] Epoch 4/15 - Policy Loss: 0.7262, Value Loss: 0.0802, Total Loss: 0.8063, LR: 0.003361
2025-05-19 04:01:30,422 [INFO] Epoch 5/15 - Policy Loss: 0.7253, Value Loss: 0.0800, Total Loss: 0.8052, LR: 0.001711
2025-05-19 04:02:10,197 [INFO] Epoch 6/15 - Policy Loss: 0.7232, Value Loss: 0.0795, Total Loss: 0.8027, LR: 0.000061
2025-05-19 04:02:50,106 [INFO] Epoch 7/15 - Policy Loss: 0.7221, Value Loss: 0.0787, Total Loss: 0.8008, LR: 0.001689
2025-05-19 04:03:30,118 [INFO] Epoch 8/15 - Policy Loss: 0.7208, Value Loss: 0.0782, Total Loss: 0.7989, LR: 0.003339
2025-05-19 04:04:10,186 [INFO] Epoch 9/15 - Policy Loss: 0.7201, Value Loss: 0.0777, Total Loss: 0.7978, LR: 0.004989
2025-05-19 04:04:50,189 [INFO] Epoch 10/15 - Policy Loss: 0.7195, Value Loss: 0.0774, Total Loss: 0.7969, LR: 0.003361
2025-05-19 04:05:30,195 [INFO] Epoch 11/15 - Policy Loss: 0.7186, Value Loss: 0.0772, Total Loss: 0.7959, LR: 0.001711
2025-05-19 04:06:10,189 [INFO] Epoch 12/15 - Policy Loss: 0.7180, Value Loss: 0.0770, Total Loss: 0.7950, LR: 0.000061
2025-05-19 04:06:50,413 [INFO] Epoch 13/15 - Policy Loss: 0.7177, Value Loss: 0.0768, Total Loss: 0.7945, LR: 0.001689
2025-05-19 04:07:30,527 [INFO] Epoch 14/15 - Policy Loss: 0.7174, Value Loss: 0.0765, Total Loss: 0.7939, LR: 0.003339
2025-05-19 04:08:10,667 [INFO] Epoch 15/15 - Policy Loss: 0.7170, Value Loss: 0.0764, Total Loss: 0.7934, LR: 0.004989
2025-05-19 04:08:10,691 [INFO] 训练完成，总损失: 0.7934
2025-05-19 04:08:10,691 [INFO] 保存迭代 136 的模型
2025-05-19 04:08:12,671 [INFO] Model saved to ./models/best.pt
2025-05-19 04:08:13,399 [INFO] Model saved to ./models/iteration_136.pt
2025-05-19 04:08:13,400 [INFO] 所有训练迭代完成
2025-05-19 04:08:13,400 [INFO] 开始迭代 137/300
2025-05-19 04:08:13,400 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 04:22:08,896 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 04:22:08,896 [INFO] 保存训练样本
2025-05-19 04:22:12,050 [INFO] 使用 155496 个样本训练神经网络
2025-05-19 04:22:12,050 [INFO] Training with 155496 examples
2025-05-19 04:22:12,050 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 04:22:12,317 [INFO] 循环学习率周期大小: 453 步
2025-05-19 04:22:51,745 [INFO] Epoch 1/15 - Policy Loss: 0.7402, Value Loss: 0.0895, Total Loss: 0.8297, LR: 0.001689
2025-05-19 04:23:31,467 [INFO] Epoch 2/15 - Policy Loss: 0.7364, Value Loss: 0.0866, Total Loss: 0.8230, LR: 0.003339
2025-05-19 04:24:11,210 [INFO] Epoch 3/15 - Policy Loss: 0.7330, Value Loss: 0.0854, Total Loss: 0.8184, LR: 0.004989
2025-05-19 04:24:50,948 [INFO] Epoch 4/15 - Policy Loss: 0.7306, Value Loss: 0.0842, Total Loss: 0.8148, LR: 0.003361
2025-05-19 04:25:30,647 [INFO] Epoch 5/15 - Policy Loss: 0.7285, Value Loss: 0.0838, Total Loss: 0.8123, LR: 0.001711
2025-05-19 04:26:10,511 [INFO] Epoch 6/15 - Policy Loss: 0.7262, Value Loss: 0.0833, Total Loss: 0.8095, LR: 0.000061
2025-05-19 04:26:50,309 [INFO] Epoch 7/15 - Policy Loss: 0.7241, Value Loss: 0.0828, Total Loss: 0.8069, LR: 0.001689
2025-05-19 04:27:30,478 [INFO] Epoch 8/15 - Policy Loss: 0.7231, Value Loss: 0.0826, Total Loss: 0.8057, LR: 0.003339
2025-05-19 04:28:10,461 [INFO] Epoch 9/15 - Policy Loss: 0.7225, Value Loss: 0.0820, Total Loss: 0.8046, LR: 0.004989
2025-05-19 04:28:50,284 [INFO] Epoch 10/15 - Policy Loss: 0.7219, Value Loss: 0.0818, Total Loss: 0.8036, LR: 0.003361
2025-05-19 04:29:30,116 [INFO] Epoch 11/15 - Policy Loss: 0.7213, Value Loss: 0.0816, Total Loss: 0.8029, LR: 0.001711
2025-05-19 04:30:09,983 [INFO] Epoch 12/15 - Policy Loss: 0.7203, Value Loss: 0.0811, Total Loss: 0.8015, LR: 0.000061
2025-05-19 04:30:50,095 [INFO] Epoch 13/15 - Policy Loss: 0.7199, Value Loss: 0.0809, Total Loss: 0.8008, LR: 0.001689
2025-05-19 04:31:30,278 [INFO] Epoch 14/15 - Policy Loss: 0.7195, Value Loss: 0.0808, Total Loss: 0.8002, LR: 0.003339
2025-05-19 04:32:10,514 [INFO] Epoch 15/15 - Policy Loss: 0.7190, Value Loss: 0.0806, Total Loss: 0.7996, LR: 0.004989
2025-05-19 04:32:10,534 [INFO] 训练完成，总损失: 0.7996
2025-05-19 04:32:10,534 [INFO] 保存迭代 137 的模型
2025-05-19 04:32:12,007 [INFO] Model saved to ./models/best.pt
2025-05-19 04:32:12,907 [INFO] Model saved to ./models/iteration_137.pt
2025-05-19 04:32:12,907 [INFO] 所有训练迭代完成
2025-05-19 04:32:12,907 [INFO] 开始迭代 138/300
2025-05-19 04:32:12,907 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 04:45:37,595 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 04:45:37,596 [INFO] 保存训练样本
2025-05-19 04:45:41,093 [INFO] 使用 156120 个样本训练神经网络
2025-05-19 04:45:41,093 [INFO] Training with 156120 examples
2025-05-19 04:45:41,094 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-19 04:45:41,131 [INFO] 循环学习率周期大小: 456 步
2025-05-19 04:46:20,966 [INFO] Epoch 1/15 - Policy Loss: 0.7381, Value Loss: 0.0890, Total Loss: 0.8271, LR: 0.001689
2025-05-19 04:47:01,017 [INFO] Epoch 2/15 - Policy Loss: 0.7335, Value Loss: 0.0881, Total Loss: 0.8216, LR: 0.003339
2025-05-19 04:47:40,957 [INFO] Epoch 3/15 - Policy Loss: 0.7300, Value Loss: 0.0876, Total Loss: 0.8175, LR: 0.004989
2025-05-19 04:48:21,279 [INFO] Epoch 4/15 - Policy Loss: 0.7283, Value Loss: 0.0870, Total Loss: 0.8153, LR: 0.003361
2025-05-19 04:49:01,376 [INFO] Epoch 5/15 - Policy Loss: 0.7265, Value Loss: 0.0864, Total Loss: 0.8128, LR: 0.001711
2025-05-19 04:49:41,453 [INFO] Epoch 6/15 - Policy Loss: 0.7246, Value Loss: 0.0854, Total Loss: 0.8100, LR: 0.000061
2025-05-19 04:50:21,352 [INFO] Epoch 7/15 - Policy Loss: 0.7233, Value Loss: 0.0848, Total Loss: 0.8081, LR: 0.001689
2025-05-19 04:51:01,318 [INFO] Epoch 8/15 - Policy Loss: 0.7215, Value Loss: 0.0842, Total Loss: 0.8058, LR: 0.003339
2025-05-19 04:51:41,407 [INFO] Epoch 9/15 - Policy Loss: 0.7206, Value Loss: 0.0840, Total Loss: 0.8047, LR: 0.004989
2025-05-19 04:52:21,503 [INFO] Epoch 10/15 - Policy Loss: 0.7198, Value Loss: 0.0837, Total Loss: 0.8035, LR: 0.003361
2025-05-19 04:53:01,672 [INFO] Epoch 11/15 - Policy Loss: 0.7189, Value Loss: 0.0835, Total Loss: 0.8024, LR: 0.001711
2025-05-19 04:53:41,866 [INFO] Epoch 12/15 - Policy Loss: 0.7180, Value Loss: 0.0833, Total Loss: 0.8013, LR: 0.000061
2025-05-19 04:54:22,064 [INFO] Epoch 13/15 - Policy Loss: 0.7174, Value Loss: 0.0830, Total Loss: 0.8005, LR: 0.001689
2025-05-19 04:55:02,254 [INFO] Epoch 14/15 - Policy Loss: 0.7168, Value Loss: 0.0827, Total Loss: 0.7995, LR: 0.003339
2025-05-19 04:55:42,516 [INFO] Epoch 15/15 - Policy Loss: 0.7164, Value Loss: 0.0826, Total Loss: 0.7989, LR: 0.004989
2025-05-19 04:55:42,534 [INFO] 训练完成，总损失: 0.7989
2025-05-19 04:55:42,535 [INFO] 保存迭代 138 的模型
2025-05-19 04:55:43,999 [INFO] Model saved to ./models/best.pt
2025-05-19 04:55:44,900 [INFO] Model saved to ./models/iteration_138.pt
2025-05-19 04:55:44,900 [INFO] 所有训练迭代完成
2025-05-19 04:55:44,900 [INFO] 开始迭代 139/300
2025-05-19 04:55:44,900 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 05:08:09,821 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 05:08:09,822 [INFO] 保存训练样本
2025-05-19 05:08:13,978 [INFO] 使用 155736 个样本训练神经网络
2025-05-19 05:08:13,978 [INFO] Training with 155736 examples
2025-05-19 05:08:13,979 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-19 05:08:14,285 [INFO] 循环学习率周期大小: 456 步
2025-05-19 05:08:54,066 [INFO] Epoch 1/15 - Policy Loss: 0.7381, Value Loss: 0.0897, Total Loss: 0.8278, LR: 0.001689
2025-05-19 05:09:33,844 [INFO] Epoch 2/15 - Policy Loss: 0.7331, Value Loss: 0.0884, Total Loss: 0.8215, LR: 0.003339
2025-05-19 05:10:13,826 [INFO] Epoch 3/15 - Policy Loss: 0.7323, Value Loss: 0.0870, Total Loss: 0.8193, LR: 0.004989
2025-05-19 05:10:53,629 [INFO] Epoch 4/15 - Policy Loss: 0.7312, Value Loss: 0.0859, Total Loss: 0.8172, LR: 0.003361
2025-05-19 05:11:33,474 [INFO] Epoch 5/15 - Policy Loss: 0.7280, Value Loss: 0.0850, Total Loss: 0.8130, LR: 0.001711
2025-05-19 05:12:13,427 [INFO] Epoch 6/15 - Policy Loss: 0.7261, Value Loss: 0.0839, Total Loss: 0.8100, LR: 0.000061
2025-05-19 05:12:53,348 [INFO] Epoch 7/15 - Policy Loss: 0.7249, Value Loss: 0.0831, Total Loss: 0.8079, LR: 0.001689
2025-05-19 05:13:33,491 [INFO] Epoch 8/15 - Policy Loss: 0.7225, Value Loss: 0.0825, Total Loss: 0.8050, LR: 0.003339
2025-05-19 05:14:13,610 [INFO] Epoch 9/15 - Policy Loss: 0.7210, Value Loss: 0.0819, Total Loss: 0.8029, LR: 0.004989
2025-05-19 05:14:53,799 [INFO] Epoch 10/15 - Policy Loss: 0.7203, Value Loss: 0.0818, Total Loss: 0.8021, LR: 0.003361
2025-05-19 05:15:33,926 [INFO] Epoch 11/15 - Policy Loss: 0.7193, Value Loss: 0.0814, Total Loss: 0.8008, LR: 0.001711
2025-05-19 05:16:14,095 [INFO] Epoch 12/15 - Policy Loss: 0.7187, Value Loss: 0.0810, Total Loss: 0.7997, LR: 0.000061
2025-05-19 05:16:54,276 [INFO] Epoch 13/15 - Policy Loss: 0.7178, Value Loss: 0.0808, Total Loss: 0.7986, LR: 0.001689
2025-05-19 05:17:34,497 [INFO] Epoch 14/15 - Policy Loss: 0.7174, Value Loss: 0.0806, Total Loss: 0.7981, LR: 0.003339
2025-05-19 05:18:14,830 [INFO] Epoch 15/15 - Policy Loss: 0.7170, Value Loss: 0.0804, Total Loss: 0.7974, LR: 0.004989
2025-05-19 05:18:14,849 [INFO] 训练完成，总损失: 0.7974
2025-05-19 05:18:14,849 [INFO] 保存迭代 139 的模型
2025-05-19 05:18:16,301 [INFO] Model saved to ./models/best.pt
2025-05-19 05:18:17,027 [INFO] Model saved to ./models/iteration_139.pt
2025-05-19 05:18:17,028 [INFO] 所有训练迭代完成
2025-05-19 05:18:17,028 [INFO] 开始迭代 140/300
2025-05-19 05:18:17,028 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 05:30:43,883 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 05:30:43,884 [INFO] 保存训练样本
2025-05-19 05:30:47,865 [INFO] 使用 155656 个样本训练神经网络
2025-05-19 05:30:47,865 [INFO] Training with 155656 examples
2025-05-19 05:30:47,866 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-19 05:30:48,175 [INFO] 循环学习率周期大小: 456 步
2025-05-19 05:31:28,044 [INFO] Epoch 1/15 - Policy Loss: 0.7360, Value Loss: 0.0890, Total Loss: 0.8250, LR: 0.001689
2025-05-19 05:32:07,992 [INFO] Epoch 2/15 - Policy Loss: 0.7310, Value Loss: 0.0857, Total Loss: 0.8168, LR: 0.003339
2025-05-19 05:32:47,837 [INFO] Epoch 3/15 - Policy Loss: 0.7270, Value Loss: 0.0828, Total Loss: 0.8098, LR: 0.004989
2025-05-19 05:33:27,737 [INFO] Epoch 4/15 - Policy Loss: 0.7249, Value Loss: 0.0814, Total Loss: 0.8063, LR: 0.003361
2025-05-19 05:34:07,673 [INFO] Epoch 5/15 - Policy Loss: 0.7229, Value Loss: 0.0804, Total Loss: 0.8033, LR: 0.001711
2025-05-19 05:34:47,673 [INFO] Epoch 6/15 - Policy Loss: 0.7210, Value Loss: 0.0794, Total Loss: 0.8003, LR: 0.000061
2025-05-19 05:35:27,655 [INFO] Epoch 7/15 - Policy Loss: 0.7192, Value Loss: 0.0785, Total Loss: 0.7977, LR: 0.001689
2025-05-19 05:36:07,609 [INFO] Epoch 8/15 - Policy Loss: 0.7175, Value Loss: 0.0779, Total Loss: 0.7953, LR: 0.003339
2025-05-19 05:36:47,750 [INFO] Epoch 9/15 - Policy Loss: 0.7167, Value Loss: 0.0773, Total Loss: 0.7940, LR: 0.004989
2025-05-19 05:37:27,868 [INFO] Epoch 10/15 - Policy Loss: 0.7166, Value Loss: 0.0772, Total Loss: 0.7938, LR: 0.003361
2025-05-19 05:38:08,288 [INFO] Epoch 11/15 - Policy Loss: 0.7156, Value Loss: 0.0767, Total Loss: 0.7923, LR: 0.001711
2025-05-19 05:38:48,603 [INFO] Epoch 12/15 - Policy Loss: 0.7147, Value Loss: 0.0762, Total Loss: 0.7909, LR: 0.000061
2025-05-19 05:39:28,951 [INFO] Epoch 13/15 - Policy Loss: 0.7141, Value Loss: 0.0759, Total Loss: 0.7900, LR: 0.001689
2025-05-19 05:40:09,325 [INFO] Epoch 14/15 - Policy Loss: 0.7135, Value Loss: 0.0755, Total Loss: 0.7890, LR: 0.003339
2025-05-19 05:40:49,626 [INFO] Epoch 15/15 - Policy Loss: 0.7129, Value Loss: 0.0753, Total Loss: 0.7882, LR: 0.004989
2025-05-19 05:40:49,646 [INFO] 训练完成，总损失: 0.7882
2025-05-19 05:40:49,646 [INFO] 保存迭代 140 的模型
2025-05-19 05:40:51,173 [INFO] Model saved to ./models/best.pt
2025-05-19 05:40:52,065 [INFO] Model saved to ./models/iteration_140.pt
2025-05-19 05:40:52,066 [INFO] 所有训练迭代完成
2025-05-19 05:40:52,066 [INFO] 开始迭代 141/300
2025-05-19 05:40:52,066 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 05:52:31,227 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 05:52:31,227 [INFO] 保存训练样本
2025-05-19 05:52:35,409 [INFO] 使用 155040 个样本训练神经网络
2025-05-19 05:52:35,409 [INFO] Training with 155040 examples
2025-05-19 05:52:35,409 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 05:52:35,454 [INFO] 循环学习率周期大小: 453 步
2025-05-19 05:53:14,828 [INFO] Epoch 1/15 - Policy Loss: 0.7324, Value Loss: 0.0791, Total Loss: 0.8115, LR: 0.001689
2025-05-19 05:53:54,468 [INFO] Epoch 2/15 - Policy Loss: 0.7290, Value Loss: 0.0781, Total Loss: 0.8070, LR: 0.003339
2025-05-19 05:54:34,109 [INFO] Epoch 3/15 - Policy Loss: 0.7270, Value Loss: 0.0771, Total Loss: 0.8040, LR: 0.004989
2025-05-19 05:55:13,771 [INFO] Epoch 4/15 - Policy Loss: 0.7239, Value Loss: 0.0762, Total Loss: 0.8002, LR: 0.003361
2025-05-19 05:55:53,441 [INFO] Epoch 5/15 - Policy Loss: 0.7220, Value Loss: 0.0754, Total Loss: 0.7974, LR: 0.001711
2025-05-19 05:56:33,446 [INFO] Epoch 6/15 - Policy Loss: 0.7195, Value Loss: 0.0756, Total Loss: 0.7952, LR: 0.000061
2025-05-19 05:57:13,215 [INFO] Epoch 7/15 - Policy Loss: 0.7176, Value Loss: 0.0750, Total Loss: 0.7926, LR: 0.001689
2025-05-19 05:57:52,985 [INFO] Epoch 8/15 - Policy Loss: 0.7176, Value Loss: 0.0746, Total Loss: 0.7921, LR: 0.003339
2025-05-19 05:58:32,810 [INFO] Epoch 9/15 - Policy Loss: 0.7168, Value Loss: 0.0746, Total Loss: 0.7914, LR: 0.004989
2025-05-19 05:59:12,710 [INFO] Epoch 10/15 - Policy Loss: 0.7162, Value Loss: 0.0746, Total Loss: 0.7908, LR: 0.003361
2025-05-19 05:59:52,559 [INFO] Epoch 11/15 - Policy Loss: 0.7155, Value Loss: 0.0743, Total Loss: 0.7898, LR: 0.001711
2025-05-19 06:00:32,384 [INFO] Epoch 12/15 - Policy Loss: 0.7148, Value Loss: 0.0739, Total Loss: 0.7887, LR: 0.000061
2025-05-19 06:01:12,229 [INFO] Epoch 13/15 - Policy Loss: 0.7145, Value Loss: 0.0737, Total Loss: 0.7882, LR: 0.001689
2025-05-19 06:01:52,203 [INFO] Epoch 14/15 - Policy Loss: 0.7143, Value Loss: 0.0736, Total Loss: 0.7879, LR: 0.003339
2025-05-19 06:02:32,149 [INFO] Epoch 15/15 - Policy Loss: 0.7139, Value Loss: 0.0733, Total Loss: 0.7873, LR: 0.004989
2025-05-19 06:02:32,165 [INFO] 训练完成，总损失: 0.7873
2025-05-19 06:02:32,165 [INFO] 保存迭代 141 的模型
2025-05-19 06:02:33,305 [INFO] Model saved to ./models/best.pt
2025-05-19 06:02:33,961 [INFO] Model saved to ./models/iteration_141.pt
2025-05-19 06:02:33,962 [INFO] 所有训练迭代完成
2025-05-19 06:02:33,962 [INFO] 开始迭代 142/300
2025-05-19 06:02:33,962 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 06:15:02,387 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 06:15:02,388 [INFO] 保存训练样本
2025-05-19 06:15:05,914 [INFO] 使用 155040 个样本训练神经网络
2025-05-19 06:15:05,914 [INFO] Training with 155040 examples
2025-05-19 06:15:05,915 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 06:15:05,953 [INFO] 循环学习率周期大小: 453 步
2025-05-19 06:15:45,642 [INFO] Epoch 1/15 - Policy Loss: 0.7340, Value Loss: 0.0862, Total Loss: 0.8202, LR: 0.001689
2025-05-19 06:16:25,172 [INFO] Epoch 2/15 - Policy Loss: 0.7295, Value Loss: 0.0835, Total Loss: 0.8130, LR: 0.003339
2025-05-19 06:17:04,698 [INFO] Epoch 3/15 - Policy Loss: 0.7268, Value Loss: 0.0820, Total Loss: 0.8087, LR: 0.004989
2025-05-19 06:17:44,323 [INFO] Epoch 4/15 - Policy Loss: 0.7249, Value Loss: 0.0808, Total Loss: 0.8057, LR: 0.003361
2025-05-19 06:18:23,996 [INFO] Epoch 5/15 - Policy Loss: 0.7236, Value Loss: 0.0799, Total Loss: 0.8035, LR: 0.001711
2025-05-19 06:19:03,669 [INFO] Epoch 6/15 - Policy Loss: 0.7219, Value Loss: 0.0788, Total Loss: 0.8007, LR: 0.000061
2025-05-19 06:19:43,368 [INFO] Epoch 7/15 - Policy Loss: 0.7203, Value Loss: 0.0779, Total Loss: 0.7982, LR: 0.001689
2025-05-19 06:20:23,274 [INFO] Epoch 8/15 - Policy Loss: 0.7189, Value Loss: 0.0774, Total Loss: 0.7963, LR: 0.003339
2025-05-19 06:21:03,125 [INFO] Epoch 9/15 - Policy Loss: 0.7180, Value Loss: 0.0770, Total Loss: 0.7950, LR: 0.004989
2025-05-19 06:21:43,083 [INFO] Epoch 10/15 - Policy Loss: 0.7178, Value Loss: 0.0772, Total Loss: 0.7950, LR: 0.003361
2025-05-19 06:22:22,960 [INFO] Epoch 11/15 - Policy Loss: 0.7170, Value Loss: 0.0769, Total Loss: 0.7938, LR: 0.001711
2025-05-19 06:23:02,847 [INFO] Epoch 12/15 - Policy Loss: 0.7162, Value Loss: 0.0765, Total Loss: 0.7928, LR: 0.000061
2025-05-19 06:23:42,975 [INFO] Epoch 13/15 - Policy Loss: 0.7155, Value Loss: 0.0762, Total Loss: 0.7916, LR: 0.001689
2025-05-19 06:24:22,915 [INFO] Epoch 14/15 - Policy Loss: 0.7150, Value Loss: 0.0761, Total Loss: 0.7911, LR: 0.003339
2025-05-19 06:25:02,918 [INFO] Epoch 15/15 - Policy Loss: 0.7147, Value Loss: 0.0757, Total Loss: 0.7904, LR: 0.004989
2025-05-19 06:25:02,935 [INFO] 训练完成，总损失: 0.7904
2025-05-19 06:25:02,935 [INFO] 保存迭代 142 的模型
2025-05-19 06:25:04,232 [INFO] Model saved to ./models/best.pt
2025-05-19 06:25:04,948 [INFO] Model saved to ./models/iteration_142.pt
2025-05-19 06:25:04,948 [INFO] 所有训练迭代完成
2025-05-19 06:25:04,948 [INFO] 开始迭代 143/300
2025-05-19 06:25:04,948 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 06:35:57,638 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 06:35:57,638 [INFO] 保存训练样本
2025-05-19 06:36:01,895 [INFO] 使用 154128 个样本训练神经网络
2025-05-19 06:36:01,895 [INFO] Training with 154128 examples
2025-05-19 06:36:01,896 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-19 06:36:02,219 [INFO] 循环学习率周期大小: 450 步
2025-05-19 06:36:41,364 [INFO] Epoch 1/15 - Policy Loss: 0.7361, Value Loss: 0.0807, Total Loss: 0.8168, LR: 0.001689
2025-05-19 06:37:20,602 [INFO] Epoch 2/15 - Policy Loss: 0.7289, Value Loss: 0.0784, Total Loss: 0.8073, LR: 0.003339
2025-05-19 06:37:59,815 [INFO] Epoch 3/15 - Policy Loss: 0.7275, Value Loss: 0.0775, Total Loss: 0.8050, LR: 0.004989
2025-05-19 06:38:39,078 [INFO] Epoch 4/15 - Policy Loss: 0.7564, Value Loss: 0.0773, Total Loss: 0.8337, LR: 0.003361
2025-05-19 06:39:18,613 [INFO] Epoch 5/15 - Policy Loss: 0.7493, Value Loss: 0.0768, Total Loss: 0.8261, LR: 0.001711
2025-05-19 06:39:58,162 [INFO] Epoch 6/15 - Policy Loss: 0.7429, Value Loss: 0.0764, Total Loss: 0.8193, LR: 0.000061
2025-05-19 06:40:37,725 [INFO] Epoch 7/15 - Policy Loss: 0.7380, Value Loss: 0.0761, Total Loss: 0.8141, LR: 0.001689
2025-05-19 06:41:17,369 [INFO] Epoch 8/15 - Policy Loss: 0.7352, Value Loss: 0.0759, Total Loss: 0.8112, LR: 0.003339
2025-05-19 06:41:57,053 [INFO] Epoch 9/15 - Policy Loss: 0.7333, Value Loss: 0.0758, Total Loss: 0.8090, LR: 0.004989
2025-05-19 06:42:36,604 [INFO] Epoch 10/15 - Policy Loss: 0.7313, Value Loss: 0.0755, Total Loss: 0.8068, LR: 0.003361
2025-05-19 06:43:16,130 [INFO] Epoch 11/15 - Policy Loss: 0.7296, Value Loss: 0.0752, Total Loss: 0.8048, LR: 0.001711
2025-05-19 06:43:55,705 [INFO] Epoch 12/15 - Policy Loss: 0.7278, Value Loss: 0.0750, Total Loss: 0.8028, LR: 0.000061
2025-05-19 06:44:35,324 [INFO] Epoch 13/15 - Policy Loss: 0.7261, Value Loss: 0.0747, Total Loss: 0.8008, LR: 0.001689
2025-05-19 06:45:15,426 [INFO] Epoch 14/15 - Policy Loss: 0.7249, Value Loss: 0.0746, Total Loss: 0.7995, LR: 0.003339
2025-05-19 06:45:55,175 [INFO] Epoch 15/15 - Policy Loss: 0.7241, Value Loss: 0.0743, Total Loss: 0.7985, LR: 0.004989
2025-05-19 06:45:55,194 [INFO] 训练完成，总损失: 0.7985
2025-05-19 06:45:55,194 [INFO] 保存迭代 143 的模型
2025-05-19 06:45:56,406 [INFO] Model saved to ./models/best.pt
2025-05-19 06:45:57,101 [INFO] Model saved to ./models/iteration_143.pt
2025-05-19 06:45:57,102 [INFO] 所有训练迭代完成
2025-05-19 06:45:57,102 [INFO] 开始迭代 144/300
2025-05-19 06:45:57,102 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 06:57:35,946 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 06:57:35,947 [INFO] 保存训练样本
2025-05-19 06:57:39,831 [INFO] 使用 153704 个样本训练神经网络
2025-05-19 06:57:39,831 [INFO] Training with 153704 examples
2025-05-19 06:57:39,832 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-19 06:57:40,254 [INFO] 循环学习率周期大小: 450 步
2025-05-19 06:58:19,563 [INFO] Epoch 1/15 - Policy Loss: 0.7398, Value Loss: 0.0706, Total Loss: 0.8104, LR: 0.001689
2025-05-19 06:58:58,841 [INFO] Epoch 2/15 - Policy Loss: 0.7341, Value Loss: 0.0700, Total Loss: 0.8042, LR: 0.003339
2025-05-19 06:59:38,282 [INFO] Epoch 3/15 - Policy Loss: 0.7308, Value Loss: 0.0699, Total Loss: 0.8007, LR: 0.004989
2025-05-19 07:00:17,762 [INFO] Epoch 4/15 - Policy Loss: 0.7287, Value Loss: 0.0696, Total Loss: 0.7983, LR: 0.003361
2025-05-19 07:00:57,215 [INFO] Epoch 5/15 - Policy Loss: 0.7272, Value Loss: 0.0692, Total Loss: 0.7964, LR: 0.001711
2025-05-19 07:01:36,693 [INFO] Epoch 6/15 - Policy Loss: 0.7245, Value Loss: 0.0690, Total Loss: 0.7935, LR: 0.000061
2025-05-19 07:02:16,339 [INFO] Epoch 7/15 - Policy Loss: 0.7231, Value Loss: 0.0687, Total Loss: 0.7918, LR: 0.001689
2025-05-19 07:02:55,925 [INFO] Epoch 8/15 - Policy Loss: 0.7217, Value Loss: 0.0685, Total Loss: 0.7902, LR: 0.003339
2025-05-19 07:03:35,580 [INFO] Epoch 9/15 - Policy Loss: 0.7214, Value Loss: 0.0686, Total Loss: 0.7900, LR: 0.004989
2025-05-19 07:04:15,397 [INFO] Epoch 10/15 - Policy Loss: 0.7212, Value Loss: 0.0686, Total Loss: 0.7898, LR: 0.003361
2025-05-19 07:04:54,924 [INFO] Epoch 11/15 - Policy Loss: 0.7204, Value Loss: 0.0685, Total Loss: 0.7890, LR: 0.001711
2025-05-19 07:05:34,563 [INFO] Epoch 12/15 - Policy Loss: 0.7200, Value Loss: 0.0686, Total Loss: 0.7886, LR: 0.000061
2025-05-19 07:06:14,172 [INFO] Epoch 13/15 - Policy Loss: 0.7194, Value Loss: 0.0685, Total Loss: 0.7879, LR: 0.001689
2025-05-19 07:06:53,882 [INFO] Epoch 14/15 - Policy Loss: 0.7187, Value Loss: 0.0685, Total Loss: 0.7872, LR: 0.003339
2025-05-19 07:07:33,563 [INFO] Epoch 15/15 - Policy Loss: 0.7183, Value Loss: 0.0684, Total Loss: 0.7867, LR: 0.004989
2025-05-19 07:07:33,579 [INFO] 训练完成，总损失: 0.7867
2025-05-19 07:07:33,580 [INFO] 保存迭代 144 的模型
2025-05-19 07:07:34,672 [INFO] Model saved to ./models/best.pt
2025-05-19 07:07:35,269 [INFO] Model saved to ./models/iteration_144.pt
2025-05-19 07:07:35,269 [INFO] 所有训练迭代完成
2025-05-19 07:07:35,269 [INFO] 开始迭代 145/300
2025-05-19 07:07:35,269 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 07:20:58,134 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 07:20:58,134 [INFO] 保存训练样本
2025-05-19 07:21:02,236 [INFO] 使用 154304 个样本训练神经网络
2025-05-19 07:21:02,236 [INFO] Training with 154304 examples
2025-05-19 07:21:02,236 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-19 07:21:02,280 [INFO] 循环学习率周期大小: 450 步
2025-05-19 07:21:41,604 [INFO] Epoch 1/15 - Policy Loss: 0.7424, Value Loss: 0.0814, Total Loss: 0.8238, LR: 0.001689
2025-05-19 07:22:20,861 [INFO] Epoch 2/15 - Policy Loss: 0.7366, Value Loss: 0.0813, Total Loss: 0.8179, LR: 0.003339
2025-05-19 07:23:00,214 [INFO] Epoch 3/15 - Policy Loss: 0.7316, Value Loss: 0.0811, Total Loss: 0.8126, LR: 0.004989
2025-05-19 07:23:39,639 [INFO] Epoch 4/15 - Policy Loss: 0.7298, Value Loss: 0.0808, Total Loss: 0.8106, LR: 0.003361
2025-05-19 07:24:19,083 [INFO] Epoch 5/15 - Policy Loss: 0.7278, Value Loss: 0.0806, Total Loss: 0.8083, LR: 0.001711
2025-05-19 07:24:58,732 [INFO] Epoch 6/15 - Policy Loss: 0.7257, Value Loss: 0.0800, Total Loss: 0.8057, LR: 0.000061
2025-05-19 07:25:38,224 [INFO] Epoch 7/15 - Policy Loss: 0.7239, Value Loss: 0.0797, Total Loss: 0.8036, LR: 0.001689
2025-05-19 07:26:17,642 [INFO] Epoch 8/15 - Policy Loss: 0.7231, Value Loss: 0.0795, Total Loss: 0.8026, LR: 0.003339
2025-05-19 07:26:57,180 [INFO] Epoch 9/15 - Policy Loss: 0.7222, Value Loss: 0.0793, Total Loss: 0.8015, LR: 0.004989
2025-05-19 07:27:36,741 [INFO] Epoch 10/15 - Policy Loss: 0.7219, Value Loss: 0.0791, Total Loss: 0.8010, LR: 0.003361
2025-05-19 07:28:16,368 [INFO] Epoch 11/15 - Policy Loss: 0.7212, Value Loss: 0.0789, Total Loss: 0.8001, LR: 0.001711
2025-05-19 07:28:56,048 [INFO] Epoch 12/15 - Policy Loss: 0.7201, Value Loss: 0.0787, Total Loss: 0.7989, LR: 0.000061
2025-05-19 07:29:35,765 [INFO] Epoch 13/15 - Policy Loss: 0.7195, Value Loss: 0.0787, Total Loss: 0.7982, LR: 0.001689
2025-05-19 07:30:15,514 [INFO] Epoch 14/15 - Policy Loss: 0.7190, Value Loss: 0.0785, Total Loss: 0.7975, LR: 0.003339
2025-05-19 07:30:55,210 [INFO] Epoch 15/15 - Policy Loss: 0.7184, Value Loss: 0.0782, Total Loss: 0.7966, LR: 0.004989
2025-05-19 07:30:55,227 [INFO] 训练完成，总损失: 0.7966
2025-05-19 07:30:55,227 [INFO] 保存迭代 145 的模型
2025-05-19 07:30:56,385 [INFO] Model saved to ./models/best.pt
2025-05-19 07:30:57,063 [INFO] Model saved to ./models/iteration_145.pt
2025-05-19 07:30:57,063 [INFO] 所有训练迭代完成
2025-05-19 07:30:57,063 [INFO] 开始迭代 146/300
2025-05-19 07:30:57,063 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 07:43:38,662 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 07:43:38,663 [INFO] 保存训练样本
2025-05-19 07:43:42,562 [INFO] 使用 154664 个样本训练神经网络
2025-05-19 07:43:42,562 [INFO] Training with 154664 examples
2025-05-19 07:43:42,562 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 07:43:42,606 [INFO] 循环学习率周期大小: 453 步
2025-05-19 07:44:22,494 [INFO] Epoch 1/15 - Policy Loss: 0.7364, Value Loss: 0.0918, Total Loss: 0.8282, LR: 0.001689
2025-05-19 07:45:01,952 [INFO] Epoch 2/15 - Policy Loss: 0.7334, Value Loss: 0.0894, Total Loss: 0.8228, LR: 0.003339
2025-05-19 07:45:41,484 [INFO] Epoch 3/15 - Policy Loss: 0.7295, Value Loss: 0.0874, Total Loss: 0.8170, LR: 0.004989
2025-05-19 07:46:21,211 [INFO] Epoch 4/15 - Policy Loss: 0.7264, Value Loss: 0.0862, Total Loss: 0.8125, LR: 0.003361
2025-05-19 07:47:00,854 [INFO] Epoch 5/15 - Policy Loss: 0.7245, Value Loss: 0.0849, Total Loss: 0.8094, LR: 0.001711
2025-05-19 07:47:40,593 [INFO] Epoch 6/15 - Policy Loss: 0.7226, Value Loss: 0.0844, Total Loss: 0.8070, LR: 0.000061
2025-05-19 07:48:20,359 [INFO] Epoch 7/15 - Policy Loss: 0.7213, Value Loss: 0.0834, Total Loss: 0.8047, LR: 0.001689
2025-05-19 07:49:00,181 [INFO] Epoch 8/15 - Policy Loss: 0.7198, Value Loss: 0.0832, Total Loss: 0.8031, LR: 0.003339
2025-05-19 07:49:39,985 [INFO] Epoch 9/15 - Policy Loss: 0.7189, Value Loss: 0.0830, Total Loss: 0.8019, LR: 0.004989
2025-05-19 07:50:19,777 [INFO] Epoch 10/15 - Policy Loss: 0.7181, Value Loss: 0.0824, Total Loss: 0.8005, LR: 0.003361
2025-05-19 07:50:59,617 [INFO] Epoch 11/15 - Policy Loss: 0.7177, Value Loss: 0.0820, Total Loss: 0.7997, LR: 0.001711
2025-05-19 07:51:39,513 [INFO] Epoch 12/15 - Policy Loss: 0.7166, Value Loss: 0.0818, Total Loss: 0.7985, LR: 0.000061
2025-05-19 07:52:19,398 [INFO] Epoch 13/15 - Policy Loss: 0.7161, Value Loss: 0.0816, Total Loss: 0.7977, LR: 0.001689
2025-05-19 07:52:59,375 [INFO] Epoch 14/15 - Policy Loss: 0.7156, Value Loss: 0.0814, Total Loss: 0.7970, LR: 0.003339
2025-05-19 07:53:39,268 [INFO] Epoch 15/15 - Policy Loss: 0.7155, Value Loss: 0.0811, Total Loss: 0.7966, LR: 0.004989
2025-05-19 07:53:39,287 [INFO] 训练完成，总损失: 0.7966
2025-05-19 07:53:39,287 [INFO] 保存迭代 146 的模型
2025-05-19 07:53:40,862 [INFO] Model saved to ./models/best.pt
2025-05-19 07:53:41,715 [INFO] Model saved to ./models/iteration_146.pt
2025-05-19 07:53:41,716 [INFO] 所有训练迭代完成
2025-05-19 07:53:41,716 [INFO] 开始迭代 147/300
2025-05-19 07:53:41,716 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 08:05:35,284 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 08:05:35,284 [INFO] 保存训练样本
2025-05-19 08:05:39,495 [INFO] 使用 154440 个样本训练神经网络
2025-05-19 08:05:39,496 [INFO] Training with 154440 examples
2025-05-19 08:05:39,496 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-19 08:05:39,810 [INFO] 循环学习率周期大小: 450 步
2025-05-19 08:06:19,169 [INFO] Epoch 1/15 - Policy Loss: 0.7298, Value Loss: 0.0851, Total Loss: 0.8149, LR: 0.001689
2025-05-19 08:06:58,589 [INFO] Epoch 2/15 - Policy Loss: 0.7294, Value Loss: 0.0844, Total Loss: 0.8139, LR: 0.003339
2025-05-19 08:07:38,049 [INFO] Epoch 3/15 - Policy Loss: 0.7261, Value Loss: 0.0845, Total Loss: 0.8106, LR: 0.004989
2025-05-19 08:08:17,574 [INFO] Epoch 4/15 - Policy Loss: 0.7256, Value Loss: 0.0850, Total Loss: 0.8105, LR: 0.003361
2025-05-19 08:08:56,956 [INFO] Epoch 5/15 - Policy Loss: 0.7236, Value Loss: 0.0845, Total Loss: 0.8081, LR: 0.001711
2025-05-19 08:09:36,441 [INFO] Epoch 6/15 - Policy Loss: 0.7215, Value Loss: 0.0836, Total Loss: 0.8051, LR: 0.000061
2025-05-19 08:10:16,092 [INFO] Epoch 7/15 - Policy Loss: 0.7201, Value Loss: 0.0830, Total Loss: 0.8031, LR: 0.001689
2025-05-19 08:10:55,701 [INFO] Epoch 8/15 - Policy Loss: 0.7188, Value Loss: 0.0826, Total Loss: 0.8014, LR: 0.003339
2025-05-19 08:11:35,271 [INFO] Epoch 9/15 - Policy Loss: 0.7180, Value Loss: 0.0824, Total Loss: 0.8004, LR: 0.004989
2025-05-19 08:12:14,932 [INFO] Epoch 10/15 - Policy Loss: 0.7172, Value Loss: 0.0820, Total Loss: 0.7993, LR: 0.003361
2025-05-19 08:12:54,653 [INFO] Epoch 11/15 - Policy Loss: 0.7170, Value Loss: 0.0819, Total Loss: 0.7989, LR: 0.001711
2025-05-19 08:13:34,443 [INFO] Epoch 12/15 - Policy Loss: 0.7165, Value Loss: 0.0817, Total Loss: 0.7983, LR: 0.000061
2025-05-19 08:14:14,235 [INFO] Epoch 13/15 - Policy Loss: 0.7158, Value Loss: 0.0816, Total Loss: 0.7974, LR: 0.001689
2025-05-19 08:14:54,246 [INFO] Epoch 14/15 - Policy Loss: 0.7153, Value Loss: 0.0815, Total Loss: 0.7968, LR: 0.003339
2025-05-19 08:15:33,970 [INFO] Epoch 15/15 - Policy Loss: 0.7148, Value Loss: 0.0813, Total Loss: 0.7961, LR: 0.004989
2025-05-19 08:15:33,986 [INFO] 训练完成，总损失: 0.7961
2025-05-19 08:15:33,987 [INFO] 保存迭代 147 的模型
2025-05-19 08:15:35,205 [INFO] Model saved to ./models/best.pt
2025-05-19 08:15:35,909 [INFO] Model saved to ./models/iteration_147.pt
2025-05-19 08:15:35,910 [INFO] 所有训练迭代完成
2025-05-19 08:15:35,910 [INFO] 开始迭代 148/300
2025-05-19 08:15:35,910 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 08:28:17,837 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 08:28:17,838 [INFO] 保存训练样本
2025-05-19 08:28:22,100 [INFO] 使用 154216 个样本训练神经网络
2025-05-19 08:28:22,101 [INFO] Training with 154216 examples
2025-05-19 08:28:22,101 [INFO] 总训练步数: 2250, 每轮次批次数: 150
2025-05-19 08:28:22,410 [INFO] 循环学习率周期大小: 450 步
2025-05-19 08:29:01,715 [INFO] Epoch 1/15 - Policy Loss: 0.7329, Value Loss: 0.0914, Total Loss: 0.8243, LR: 0.001689
2025-05-19 08:29:41,209 [INFO] Epoch 2/15 - Policy Loss: 0.7309, Value Loss: 0.0909, Total Loss: 0.8218, LR: 0.003339
2025-05-19 08:30:20,744 [INFO] Epoch 3/15 - Policy Loss: 0.7277, Value Loss: 0.0894, Total Loss: 0.8171, LR: 0.004989
2025-05-19 08:31:00,267 [INFO] Epoch 4/15 - Policy Loss: 0.7255, Value Loss: 0.0890, Total Loss: 0.8146, LR: 0.003361
2025-05-19 08:31:39,756 [INFO] Epoch 5/15 - Policy Loss: 0.7230, Value Loss: 0.0880, Total Loss: 0.8110, LR: 0.001711
2025-05-19 08:32:19,274 [INFO] Epoch 6/15 - Policy Loss: 0.7211, Value Loss: 0.0874, Total Loss: 0.8085, LR: 0.000061
2025-05-19 08:32:58,831 [INFO] Epoch 7/15 - Policy Loss: 0.7192, Value Loss: 0.0870, Total Loss: 0.8063, LR: 0.001689
2025-05-19 08:33:38,497 [INFO] Epoch 8/15 - Policy Loss: 0.7183, Value Loss: 0.0868, Total Loss: 0.8051, LR: 0.003339
2025-05-19 08:34:18,215 [INFO] Epoch 9/15 - Policy Loss: 0.7175, Value Loss: 0.0865, Total Loss: 0.8040, LR: 0.004989
2025-05-19 08:34:57,812 [INFO] Epoch 10/15 - Policy Loss: 0.7166, Value Loss: 0.0862, Total Loss: 0.8027, LR: 0.003361
2025-05-19 08:35:37,875 [INFO] Epoch 11/15 - Policy Loss: 0.7157, Value Loss: 0.0861, Total Loss: 0.8018, LR: 0.001711
2025-05-19 08:36:17,649 [INFO] Epoch 12/15 - Policy Loss: 0.7152, Value Loss: 0.0859, Total Loss: 0.8011, LR: 0.000061
2025-05-19 08:36:57,363 [INFO] Epoch 13/15 - Policy Loss: 0.7144, Value Loss: 0.0858, Total Loss: 0.8001, LR: 0.001689
2025-05-19 08:37:37,175 [INFO] Epoch 14/15 - Policy Loss: 0.7142, Value Loss: 0.0855, Total Loss: 0.7997, LR: 0.003339
2025-05-19 08:38:17,037 [INFO] Epoch 15/15 - Policy Loss: 0.7140, Value Loss: 0.0853, Total Loss: 0.7994, LR: 0.004989
2025-05-19 08:38:17,056 [INFO] 训练完成，总损失: 0.7994
2025-05-19 08:38:17,056 [INFO] 保存迭代 148 的模型
2025-05-19 08:38:18,482 [INFO] Model saved to ./models/best.pt
2025-05-19 08:38:19,314 [INFO] Model saved to ./models/iteration_148.pt
2025-05-19 08:38:19,314 [INFO] 所有训练迭代完成
2025-05-19 08:38:19,314 [INFO] 开始迭代 149/300
2025-05-19 08:38:19,314 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 08:51:21,714 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 08:51:21,715 [INFO] 保存训练样本
2025-05-19 08:51:25,278 [INFO] 使用 154744 个样本训练神经网络
2025-05-19 08:51:25,278 [INFO] Training with 154744 examples
2025-05-19 08:51:25,279 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 08:51:25,323 [INFO] 循环学习率周期大小: 453 步
2025-05-19 08:52:04,947 [INFO] Epoch 1/15 - Policy Loss: 0.7372, Value Loss: 0.0979, Total Loss: 0.8351, LR: 0.001689
2025-05-19 08:52:44,644 [INFO] Epoch 2/15 - Policy Loss: 0.7334, Value Loss: 0.0974, Total Loss: 0.8308, LR: 0.003339
2025-05-19 08:53:24,341 [INFO] Epoch 3/15 - Policy Loss: 0.7295, Value Loss: 0.0950, Total Loss: 0.8245, LR: 0.004989
2025-05-19 08:54:03,866 [INFO] Epoch 4/15 - Policy Loss: 0.7281, Value Loss: 0.0946, Total Loss: 0.8227, LR: 0.003361
2025-05-19 08:54:43,633 [INFO] Epoch 5/15 - Policy Loss: 0.7246, Value Loss: 0.0935, Total Loss: 0.8181, LR: 0.001711
2025-05-19 08:55:23,639 [INFO] Epoch 6/15 - Policy Loss: 0.7213, Value Loss: 0.0926, Total Loss: 0.8139, LR: 0.000061
2025-05-19 08:56:03,399 [INFO] Epoch 7/15 - Policy Loss: 0.7197, Value Loss: 0.0921, Total Loss: 0.8119, LR: 0.001689
2025-05-19 08:56:43,255 [INFO] Epoch 8/15 - Policy Loss: 0.7181, Value Loss: 0.0916, Total Loss: 0.8097, LR: 0.003339
2025-05-19 08:57:23,139 [INFO] Epoch 9/15 - Policy Loss: 0.7169, Value Loss: 0.0914, Total Loss: 0.8082, LR: 0.004989
2025-05-19 08:58:02,861 [INFO] Epoch 10/15 - Policy Loss: 0.7166, Value Loss: 0.0909, Total Loss: 0.8076, LR: 0.003361
2025-05-19 08:58:42,801 [INFO] Epoch 11/15 - Policy Loss: 0.7159, Value Loss: 0.0906, Total Loss: 0.8065, LR: 0.001711
2025-05-19 08:59:22,885 [INFO] Epoch 12/15 - Policy Loss: 0.7150, Value Loss: 0.0902, Total Loss: 0.8052, LR: 0.000061
2025-05-19 09:00:02,968 [INFO] Epoch 13/15 - Policy Loss: 0.7141, Value Loss: 0.0900, Total Loss: 0.8041, LR: 0.001689
2025-05-19 09:00:43,054 [INFO] Epoch 14/15 - Policy Loss: 0.7133, Value Loss: 0.0894, Total Loss: 0.8028, LR: 0.003339
2025-05-19 09:01:23,225 [INFO] Epoch 15/15 - Policy Loss: 0.7128, Value Loss: 0.0890, Total Loss: 0.8018, LR: 0.004989
2025-05-19 09:01:23,244 [INFO] 训练完成，总损失: 0.8018
2025-05-19 09:01:23,244 [INFO] 保存迭代 149 的模型
2025-05-19 09:01:24,677 [INFO] Model saved to ./models/best.pt
2025-05-19 09:01:25,543 [INFO] Model saved to ./models/iteration_149.pt
2025-05-19 09:01:25,543 [INFO] 所有训练迭代完成
2025-05-19 09:01:25,543 [INFO] 开始迭代 150/300
2025-05-19 09:01:25,543 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 09:14:25,572 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 09:14:25,573 [INFO] 保存训练样本
2025-05-19 09:14:29,752 [INFO] 使用 155048 个样本训练神经网络
2025-05-19 09:14:29,752 [INFO] Training with 155048 examples
2025-05-19 09:14:29,752 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 09:14:29,796 [INFO] 循环学习率周期大小: 453 步
2025-05-19 09:15:09,741 [INFO] Epoch 1/15 - Policy Loss: 0.7248, Value Loss: 0.0888, Total Loss: 0.8136, LR: 0.001689
2025-05-19 09:15:49,313 [INFO] Epoch 2/15 - Policy Loss: 0.7205, Value Loss: 0.0877, Total Loss: 0.8082, LR: 0.003339
2025-05-19 09:16:28,774 [INFO] Epoch 3/15 - Policy Loss: 0.7185, Value Loss: 0.0871, Total Loss: 0.8057, LR: 0.004989
2025-05-19 09:17:08,379 [INFO] Epoch 4/15 - Policy Loss: 0.7178, Value Loss: 0.0869, Total Loss: 0.8047, LR: 0.003361
2025-05-19 09:17:48,157 [INFO] Epoch 5/15 - Policy Loss: 0.7155, Value Loss: 0.0865, Total Loss: 0.8020, LR: 0.001711
2025-05-19 09:18:27,971 [INFO] Epoch 6/15 - Policy Loss: 0.7144, Value Loss: 0.0858, Total Loss: 0.8002, LR: 0.000061
2025-05-19 09:19:07,808 [INFO] Epoch 7/15 - Policy Loss: 0.7130, Value Loss: 0.0855, Total Loss: 0.7985, LR: 0.001689
2025-05-19 09:19:47,475 [INFO] Epoch 8/15 - Policy Loss: 0.7116, Value Loss: 0.0852, Total Loss: 0.7968, LR: 0.003339
2025-05-19 09:20:27,090 [INFO] Epoch 9/15 - Policy Loss: 0.7113, Value Loss: 0.0851, Total Loss: 0.7963, LR: 0.004989
2025-05-19 09:21:06,827 [INFO] Epoch 10/15 - Policy Loss: 0.7112, Value Loss: 0.0849, Total Loss: 0.7961, LR: 0.003361
2025-05-19 09:21:46,606 [INFO] Epoch 11/15 - Policy Loss: 0.7104, Value Loss: 0.0850, Total Loss: 0.7953, LR: 0.001711
2025-05-19 09:22:26,397 [INFO] Epoch 12/15 - Policy Loss: 0.7096, Value Loss: 0.0849, Total Loss: 0.7945, LR: 0.000061
2025-05-19 09:23:06,197 [INFO] Epoch 13/15 - Policy Loss: 0.7089, Value Loss: 0.0846, Total Loss: 0.7935, LR: 0.001689
2025-05-19 09:23:46,232 [INFO] Epoch 14/15 - Policy Loss: 0.7083, Value Loss: 0.0844, Total Loss: 0.7927, LR: 0.003339
2025-05-19 09:24:26,373 [INFO] Epoch 15/15 - Policy Loss: 0.7081, Value Loss: 0.0843, Total Loss: 0.7924, LR: 0.004989
2025-05-19 09:24:26,391 [INFO] 训练完成，总损失: 0.7924
2025-05-19 09:24:26,391 [INFO] 保存迭代 150 的模型
2025-05-19 09:24:27,849 [INFO] Model saved to ./models/best.pt
2025-05-19 09:24:28,686 [INFO] Model saved to ./models/iteration_150.pt
2025-05-19 09:24:28,687 [INFO] 所有训练迭代完成
2025-05-19 09:24:28,687 [INFO] 开始迭代 151/300
2025-05-19 09:24:28,687 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 09:36:37,067 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 09:36:37,068 [INFO] 保存训练样本
2025-05-19 09:36:41,618 [INFO] 使用 155024 个样本训练神经网络
2025-05-19 09:36:41,618 [INFO] Training with 155024 examples
2025-05-19 09:36:41,618 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 09:36:41,937 [INFO] 循环学习率周期大小: 453 步
2025-05-19 09:37:21,481 [INFO] Epoch 1/15 - Policy Loss: 0.7227, Value Loss: 0.0981, Total Loss: 0.8207, LR: 0.001689
2025-05-19 09:38:01,018 [INFO] Epoch 2/15 - Policy Loss: 0.7213, Value Loss: 0.0961, Total Loss: 0.8174, LR: 0.003339
2025-05-19 09:38:40,569 [INFO] Epoch 3/15 - Policy Loss: 0.7189, Value Loss: 0.0948, Total Loss: 0.8137, LR: 0.004989
2025-05-19 09:39:20,355 [INFO] Epoch 4/15 - Policy Loss: 0.7161, Value Loss: 0.0937, Total Loss: 0.8098, LR: 0.003361
2025-05-19 09:40:00,156 [INFO] Epoch 5/15 - Policy Loss: 0.7148, Value Loss: 0.0925, Total Loss: 0.8073, LR: 0.001711
2025-05-19 09:40:39,984 [INFO] Epoch 6/15 - Policy Loss: 0.7132, Value Loss: 0.0918, Total Loss: 0.8050, LR: 0.000061
2025-05-19 09:41:19,865 [INFO] Epoch 7/15 - Policy Loss: 0.7118, Value Loss: 0.0914, Total Loss: 0.8032, LR: 0.001689
2025-05-19 09:41:59,688 [INFO] Epoch 8/15 - Policy Loss: 0.7105, Value Loss: 0.0913, Total Loss: 0.8018, LR: 0.003339
2025-05-19 09:42:39,605 [INFO] Epoch 9/15 - Policy Loss: 0.7096, Value Loss: 0.0910, Total Loss: 0.8006, LR: 0.004989
2025-05-19 09:43:19,653 [INFO] Epoch 10/15 - Policy Loss: 0.7093, Value Loss: 0.0905, Total Loss: 0.7998, LR: 0.003361
2025-05-19 09:43:59,624 [INFO] Epoch 11/15 - Policy Loss: 0.7085, Value Loss: 0.0901, Total Loss: 0.7986, LR: 0.001711
2025-05-19 09:44:39,501 [INFO] Epoch 12/15 - Policy Loss: 0.7077, Value Loss: 0.0897, Total Loss: 0.7975, LR: 0.000061
2025-05-19 09:45:19,586 [INFO] Epoch 13/15 - Policy Loss: 0.7072, Value Loss: 0.0896, Total Loss: 0.7968, LR: 0.001689
2025-05-19 09:45:59,734 [INFO] Epoch 14/15 - Policy Loss: 0.7070, Value Loss: 0.0893, Total Loss: 0.7962, LR: 0.003339
2025-05-19 09:46:39,836 [INFO] Epoch 15/15 - Policy Loss: 0.7067, Value Loss: 0.0892, Total Loss: 0.7959, LR: 0.004989
2025-05-19 09:46:39,853 [INFO] 训练完成，总损失: 0.7959
2025-05-19 09:46:39,853 [INFO] 保存迭代 151 的模型
2025-05-19 09:46:41,145 [INFO] Model saved to ./models/best.pt
2025-05-19 09:46:41,820 [INFO] Model saved to ./models/iteration_151.pt
2025-05-19 09:46:41,820 [INFO] 所有训练迭代完成
2025-05-19 09:46:41,820 [INFO] 开始迭代 152/300
2025-05-19 09:46:41,820 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 09:59:20,883 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 09:59:20,883 [INFO] 保存训练样本
2025-05-19 09:59:24,232 [INFO] 使用 154816 个样本训练神经网络
2025-05-19 09:59:24,232 [INFO] Training with 154816 examples
2025-05-19 09:59:24,232 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 09:59:24,545 [INFO] 循环学习率周期大小: 453 步
2025-05-19 10:00:04,174 [INFO] Epoch 1/15 - Policy Loss: 0.7202, Value Loss: 0.0938, Total Loss: 0.8140, LR: 0.001689
2025-05-19 10:00:43,906 [INFO] Epoch 2/15 - Policy Loss: 0.7174, Value Loss: 0.0938, Total Loss: 0.8112, LR: 0.003339
2025-05-19 10:01:23,552 [INFO] Epoch 3/15 - Policy Loss: 0.7164, Value Loss: 0.0930, Total Loss: 0.8094, LR: 0.004989
2025-05-19 10:02:03,116 [INFO] Epoch 4/15 - Policy Loss: 0.7149, Value Loss: 0.0934, Total Loss: 0.8083, LR: 0.003361
2025-05-19 10:02:42,942 [INFO] Epoch 5/15 - Policy Loss: 0.7126, Value Loss: 0.0929, Total Loss: 0.8056, LR: 0.001711
2025-05-19 10:03:22,750 [INFO] Epoch 6/15 - Policy Loss: 0.7112, Value Loss: 0.0927, Total Loss: 0.8039, LR: 0.000061
2025-05-19 10:04:02,438 [INFO] Epoch 7/15 - Policy Loss: 0.7091, Value Loss: 0.0923, Total Loss: 0.8014, LR: 0.001689
2025-05-19 10:04:42,205 [INFO] Epoch 8/15 - Policy Loss: 0.7081, Value Loss: 0.0922, Total Loss: 0.8003, LR: 0.003339
2025-05-19 10:05:21,906 [INFO] Epoch 9/15 - Policy Loss: 0.7076, Value Loss: 0.0919, Total Loss: 0.7995, LR: 0.004989
2025-05-19 10:06:01,946 [INFO] Epoch 10/15 - Policy Loss: 0.7073, Value Loss: 0.0919, Total Loss: 0.7992, LR: 0.003361
2025-05-19 10:06:41,789 [INFO] Epoch 11/15 - Policy Loss: 0.7066, Value Loss: 0.0918, Total Loss: 0.7984, LR: 0.001711
2025-05-19 10:07:21,602 [INFO] Epoch 12/15 - Policy Loss: 0.7062, Value Loss: 0.0917, Total Loss: 0.7978, LR: 0.000061
2025-05-19 10:08:01,465 [INFO] Epoch 13/15 - Policy Loss: 0.7056, Value Loss: 0.0915, Total Loss: 0.7971, LR: 0.001689
2025-05-19 10:08:41,488 [INFO] Epoch 14/15 - Policy Loss: 0.7051, Value Loss: 0.0913, Total Loss: 0.7964, LR: 0.003339
2025-05-19 10:09:21,616 [INFO] Epoch 15/15 - Policy Loss: 0.7049, Value Loss: 0.0912, Total Loss: 0.7961, LR: 0.004989
2025-05-19 10:09:21,636 [INFO] 训练完成，总损失: 0.7961
2025-05-19 10:09:21,636 [INFO] 保存迭代 152 的模型
2025-05-19 10:09:23,104 [INFO] Model saved to ./models/best.pt
2025-05-19 10:09:23,959 [INFO] Model saved to ./models/iteration_152.pt
2025-05-19 10:09:23,960 [INFO] 所有训练迭代完成
2025-05-19 10:09:23,960 [INFO] 开始迭代 153/300
2025-05-19 10:09:23,960 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 10:21:43,385 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 10:21:43,385 [INFO] 保存训练样本
2025-05-19 10:21:47,766 [INFO] 使用 154992 个样本训练神经网络
2025-05-19 10:21:47,766 [INFO] Training with 154992 examples
2025-05-19 10:21:47,766 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 10:21:47,829 [INFO] 循环学习率周期大小: 453 步
2025-05-19 10:22:27,445 [INFO] Epoch 1/15 - Policy Loss: 0.7230, Value Loss: 0.0962, Total Loss: 0.8192, LR: 0.001689
2025-05-19 10:23:07,016 [INFO] Epoch 2/15 - Policy Loss: 0.7187, Value Loss: 0.0962, Total Loss: 0.8149, LR: 0.003339
2025-05-19 10:23:46,544 [INFO] Epoch 3/15 - Policy Loss: 0.7163, Value Loss: 0.0954, Total Loss: 0.8117, LR: 0.004989
2025-05-19 10:24:26,121 [INFO] Epoch 4/15 - Policy Loss: 0.7152, Value Loss: 0.0956, Total Loss: 0.8108, LR: 0.003361
2025-05-19 10:25:06,128 [INFO] Epoch 5/15 - Policy Loss: 0.7131, Value Loss: 0.0954, Total Loss: 0.8084, LR: 0.001711
2025-05-19 10:25:45,782 [INFO] Epoch 6/15 - Policy Loss: 0.7106, Value Loss: 0.0952, Total Loss: 0.8058, LR: 0.000061
2025-05-19 10:26:25,465 [INFO] Epoch 7/15 - Policy Loss: 0.7090, Value Loss: 0.0950, Total Loss: 0.8041, LR: 0.001689
2025-05-19 10:27:05,175 [INFO] Epoch 8/15 - Policy Loss: 0.7077, Value Loss: 0.0949, Total Loss: 0.8027, LR: 0.003339
2025-05-19 10:27:44,924 [INFO] Epoch 9/15 - Policy Loss: 0.7070, Value Loss: 0.0947, Total Loss: 0.8017, LR: 0.004989
2025-05-19 10:28:24,723 [INFO] Epoch 10/15 - Policy Loss: 0.7063, Value Loss: 0.0948, Total Loss: 0.8011, LR: 0.003361
2025-05-19 10:29:04,559 [INFO] Epoch 11/15 - Policy Loss: 0.7056, Value Loss: 0.0946, Total Loss: 0.8002, LR: 0.001711
2025-05-19 10:29:44,636 [INFO] Epoch 12/15 - Policy Loss: 0.7049, Value Loss: 0.0944, Total Loss: 0.7994, LR: 0.000061
2025-05-19 10:30:24,701 [INFO] Epoch 13/15 - Policy Loss: 0.7044, Value Loss: 0.0941, Total Loss: 0.7985, LR: 0.001689
2025-05-19 10:31:04,715 [INFO] Epoch 14/15 - Policy Loss: 0.7039, Value Loss: 0.0940, Total Loss: 0.7979, LR: 0.003339
2025-05-19 10:31:44,802 [INFO] Epoch 15/15 - Policy Loss: 0.7037, Value Loss: 0.0938, Total Loss: 0.7975, LR: 0.004989
2025-05-19 10:31:44,821 [INFO] 训练完成，总损失: 0.7975
2025-05-19 10:31:44,822 [INFO] 保存迭代 153 的模型
2025-05-19 10:31:46,267 [INFO] Model saved to ./models/best.pt
2025-05-19 10:31:46,949 [INFO] Model saved to ./models/iteration_153.pt
2025-05-19 10:31:46,950 [INFO] 所有训练迭代完成
2025-05-19 10:31:46,950 [INFO] 开始迭代 154/300
2025-05-19 10:31:46,950 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 10:43:49,953 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 10:43:49,953 [INFO] 保存训练样本
2025-05-19 10:43:54,279 [INFO] 使用 155192 个样本训练神经网络
2025-05-19 10:43:54,280 [INFO] Training with 155192 examples
2025-05-19 10:43:54,280 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 10:43:54,598 [INFO] 循环学习率周期大小: 453 步
2025-05-19 10:44:33,974 [INFO] Epoch 1/15 - Policy Loss: 0.7171, Value Loss: 0.1043, Total Loss: 0.8214, LR: 0.001689
2025-05-19 10:45:13,516 [INFO] Epoch 2/15 - Policy Loss: 0.7134, Value Loss: 0.1039, Total Loss: 0.8173, LR: 0.003339
2025-05-19 10:45:53,110 [INFO] Epoch 3/15 - Policy Loss: 0.7117, Value Loss: 0.1030, Total Loss: 0.8146, LR: 0.004989
2025-05-19 10:46:32,894 [INFO] Epoch 4/15 - Policy Loss: 0.7095, Value Loss: 0.1023, Total Loss: 0.8117, LR: 0.003361
2025-05-19 10:47:12,681 [INFO] Epoch 5/15 - Policy Loss: 0.7086, Value Loss: 0.1014, Total Loss: 0.8100, LR: 0.001711
2025-05-19 10:47:52,343 [INFO] Epoch 6/15 - Policy Loss: 0.7079, Value Loss: 0.1008, Total Loss: 0.8086, LR: 0.000061
2025-05-19 10:48:31,983 [INFO] Epoch 7/15 - Policy Loss: 0.7069, Value Loss: 0.1003, Total Loss: 0.8072, LR: 0.001689
2025-05-19 10:49:11,646 [INFO] Epoch 8/15 - Policy Loss: 0.7054, Value Loss: 0.1000, Total Loss: 0.8054, LR: 0.003339
2025-05-19 10:49:51,465 [INFO] Epoch 9/15 - Policy Loss: 0.7050, Value Loss: 0.0998, Total Loss: 0.8048, LR: 0.004989
2025-05-19 10:50:31,249 [INFO] Epoch 10/15 - Policy Loss: 0.7051, Value Loss: 0.0998, Total Loss: 0.8049, LR: 0.003361
2025-05-19 10:51:11,085 [INFO] Epoch 11/15 - Policy Loss: 0.7040, Value Loss: 0.0994, Total Loss: 0.8034, LR: 0.001711
2025-05-19 10:51:50,984 [INFO] Epoch 12/15 - Policy Loss: 0.7033, Value Loss: 0.0990, Total Loss: 0.8023, LR: 0.000061
2025-05-19 10:52:30,838 [INFO] Epoch 13/15 - Policy Loss: 0.7023, Value Loss: 0.0988, Total Loss: 0.8010, LR: 0.001689
2025-05-19 10:53:10,797 [INFO] Epoch 14/15 - Policy Loss: 0.7020, Value Loss: 0.0987, Total Loss: 0.8007, LR: 0.003339
2025-05-19 10:53:50,740 [INFO] Epoch 15/15 - Policy Loss: 0.7017, Value Loss: 0.0985, Total Loss: 0.8002, LR: 0.004989
2025-05-19 10:53:50,757 [INFO] 训练完成，总损失: 0.8002
2025-05-19 10:53:50,757 [INFO] 保存迭代 154 的模型
2025-05-19 10:53:51,893 [INFO] Model saved to ./models/best.pt
2025-05-19 10:53:52,590 [INFO] Model saved to ./models/iteration_154.pt
2025-05-19 10:53:52,590 [INFO] 所有训练迭代完成
2025-05-19 10:53:52,590 [INFO] 开始迭代 155/300
2025-05-19 10:53:52,591 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 11:06:28,003 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 11:06:28,004 [INFO] 保存训练样本
2025-05-19 11:06:32,319 [INFO] 使用 155384 个样本训练神经网络
2025-05-19 11:06:32,319 [INFO] Training with 155384 examples
2025-05-19 11:06:32,319 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 11:06:32,633 [INFO] 循环学习率周期大小: 453 步
2025-05-19 11:07:12,266 [INFO] Epoch 1/15 - Policy Loss: 0.7154, Value Loss: 0.1039, Total Loss: 0.8192, LR: 0.001689
2025-05-19 11:07:52,032 [INFO] Epoch 2/15 - Policy Loss: 0.7123, Value Loss: 0.1043, Total Loss: 0.8166, LR: 0.003339
2025-05-19 11:08:31,695 [INFO] Epoch 3/15 - Policy Loss: 0.7087, Value Loss: 0.1029, Total Loss: 0.8116, LR: 0.004989
2025-05-19 11:09:11,230 [INFO] Epoch 4/15 - Policy Loss: 0.7074, Value Loss: 0.1027, Total Loss: 0.8101, LR: 0.003361
2025-05-19 11:09:50,834 [INFO] Epoch 5/15 - Policy Loss: 0.7059, Value Loss: 0.1022, Total Loss: 0.8081, LR: 0.001711
2025-05-19 11:10:30,468 [INFO] Epoch 6/15 - Policy Loss: 0.7041, Value Loss: 0.1014, Total Loss: 0.8055, LR: 0.000061
2025-05-19 11:11:10,133 [INFO] Epoch 7/15 - Policy Loss: 0.7026, Value Loss: 0.1013, Total Loss: 0.8039, LR: 0.001689
2025-05-19 11:11:49,948 [INFO] Epoch 8/15 - Policy Loss: 0.7011, Value Loss: 0.1010, Total Loss: 0.8021, LR: 0.003339
2025-05-19 11:12:29,761 [INFO] Epoch 9/15 - Policy Loss: 0.7009, Value Loss: 0.1007, Total Loss: 0.8016, LR: 0.004989
2025-05-19 11:13:09,730 [INFO] Epoch 10/15 - Policy Loss: 0.7004, Value Loss: 0.1006, Total Loss: 0.8010, LR: 0.003361
2025-05-19 11:13:49,752 [INFO] Epoch 11/15 - Policy Loss: 0.7002, Value Loss: 0.1007, Total Loss: 0.8009, LR: 0.001711
2025-05-19 11:14:29,773 [INFO] Epoch 12/15 - Policy Loss: 0.6998, Value Loss: 0.1006, Total Loss: 0.8003, LR: 0.000061
2025-05-19 11:15:09,900 [INFO] Epoch 13/15 - Policy Loss: 0.6997, Value Loss: 0.1002, Total Loss: 0.7999, LR: 0.001689
2025-05-19 11:15:50,402 [INFO] Epoch 14/15 - Policy Loss: 0.6989, Value Loss: 0.1000, Total Loss: 0.7989, LR: 0.003339
2025-05-19 11:16:30,398 [INFO] Epoch 15/15 - Policy Loss: 0.6985, Value Loss: 0.1000, Total Loss: 0.7985, LR: 0.004989
2025-05-19 11:16:30,421 [INFO] 训练完成，总损失: 0.7985
2025-05-19 11:16:30,421 [INFO] 保存迭代 155 的模型
2025-05-19 11:16:31,677 [INFO] Model saved to ./models/best.pt
2025-05-19 11:16:32,394 [INFO] Model saved to ./models/iteration_155.pt
2025-05-19 11:16:32,394 [INFO] 所有训练迭代完成
2025-05-19 11:16:32,394 [INFO] 开始迭代 156/300
2025-05-19 11:16:32,394 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 11:29:11,154 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 11:29:11,154 [INFO] 保存训练样本
2025-05-19 11:29:15,192 [INFO] 使用 155888 个样本训练神经网络
2025-05-19 11:29:15,192 [INFO] Training with 155888 examples
2025-05-19 11:29:15,193 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-19 11:29:15,506 [INFO] 循环学习率周期大小: 456 步
2025-05-19 11:29:55,299 [INFO] Epoch 1/15 - Policy Loss: 0.7178, Value Loss: 0.1004, Total Loss: 0.8182, LR: 0.001689
2025-05-19 11:30:35,260 [INFO] Epoch 2/15 - Policy Loss: 0.7116, Value Loss: 0.0993, Total Loss: 0.8108, LR: 0.003339
2025-05-19 11:31:15,166 [INFO] Epoch 3/15 - Policy Loss: 0.7103, Value Loss: 0.0989, Total Loss: 0.8092, LR: 0.004989
2025-05-19 11:31:55,047 [INFO] Epoch 4/15 - Policy Loss: 0.7082, Value Loss: 0.0990, Total Loss: 0.8072, LR: 0.003361
2025-05-19 11:32:34,928 [INFO] Epoch 5/15 - Policy Loss: 0.7060, Value Loss: 0.0986, Total Loss: 0.8046, LR: 0.001711
2025-05-19 11:33:14,797 [INFO] Epoch 6/15 - Policy Loss: 0.7033, Value Loss: 0.0983, Total Loss: 0.8017, LR: 0.000061
2025-05-19 11:33:54,650 [INFO] Epoch 7/15 - Policy Loss: 0.7017, Value Loss: 0.0980, Total Loss: 0.7997, LR: 0.001689
2025-05-19 11:34:34,526 [INFO] Epoch 8/15 - Policy Loss: 0.7004, Value Loss: 0.0976, Total Loss: 0.7980, LR: 0.003339
2025-05-19 11:35:14,642 [INFO] Epoch 9/15 - Policy Loss: 0.6999, Value Loss: 0.0974, Total Loss: 0.7973, LR: 0.004989
2025-05-19 11:35:54,980 [INFO] Epoch 10/15 - Policy Loss: 0.6996, Value Loss: 0.0972, Total Loss: 0.7968, LR: 0.003361
2025-05-19 11:36:35,720 [INFO] Epoch 11/15 - Policy Loss: 0.6990, Value Loss: 0.0970, Total Loss: 0.7960, LR: 0.001711
2025-05-19 11:37:16,066 [INFO] Epoch 12/15 - Policy Loss: 0.6979, Value Loss: 0.0968, Total Loss: 0.7947, LR: 0.000061
2025-05-19 11:37:56,480 [INFO] Epoch 13/15 - Policy Loss: 0.6975, Value Loss: 0.0967, Total Loss: 0.7942, LR: 0.001689
2025-05-19 11:38:37,133 [INFO] Epoch 14/15 - Policy Loss: 0.6965, Value Loss: 0.0965, Total Loss: 0.7931, LR: 0.003339
2025-05-19 11:39:18,027 [INFO] Epoch 15/15 - Policy Loss: 0.6963, Value Loss: 0.0964, Total Loss: 0.7927, LR: 0.004989
2025-05-19 11:39:18,063 [INFO] 训练完成，总损失: 0.7927
2025-05-19 11:39:18,063 [INFO] 保存迭代 156 的模型
2025-05-19 11:39:19,621 [INFO] Model saved to ./models/best.pt
2025-05-19 11:39:20,505 [INFO] Model saved to ./models/iteration_156.pt
2025-05-19 11:39:20,506 [INFO] 所有训练迭代完成
2025-05-19 11:39:20,506 [INFO] 开始迭代 157/300
2025-05-19 11:39:20,506 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 11:53:02,371 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 11:53:02,371 [INFO] 保存训练样本
2025-05-19 11:53:06,774 [INFO] 使用 155600 个样本训练神经网络
2025-05-19 11:53:06,775 [INFO] Training with 155600 examples
2025-05-19 11:53:06,775 [INFO] 总训练步数: 2265, 每轮次批次数: 151
2025-05-19 11:53:06,822 [INFO] 循环学习率周期大小: 453 步
2025-05-19 11:53:46,722 [INFO] Epoch 1/15 - Policy Loss: 0.7233, Value Loss: 0.1103, Total Loss: 0.8336, LR: 0.001689
2025-05-19 11:54:26,681 [INFO] Epoch 2/15 - Policy Loss: 0.7169, Value Loss: 0.1068, Total Loss: 0.8237, LR: 0.003339
2025-05-19 11:55:06,894 [INFO] Epoch 3/15 - Policy Loss: 0.7122, Value Loss: 0.1045, Total Loss: 0.8167, LR: 0.004989
2025-05-19 11:55:47,162 [INFO] Epoch 4/15 - Policy Loss: 0.7110, Value Loss: 0.1027, Total Loss: 0.8137, LR: 0.003361
2025-05-19 11:56:27,239 [INFO] Epoch 5/15 - Policy Loss: 0.7087, Value Loss: 0.1008, Total Loss: 0.8095, LR: 0.001711
2025-05-19 11:57:07,270 [INFO] Epoch 6/15 - Policy Loss: 0.7061, Value Loss: 0.1001, Total Loss: 0.8062, LR: 0.000061
2025-05-19 11:57:48,109 [INFO] Epoch 7/15 - Policy Loss: 0.7039, Value Loss: 0.0997, Total Loss: 0.8036, LR: 0.001689
2025-05-19 11:58:28,497 [INFO] Epoch 8/15 - Policy Loss: 0.7022, Value Loss: 0.0989, Total Loss: 0.8010, LR: 0.003339
2025-05-19 11:59:08,790 [INFO] Epoch 9/15 - Policy Loss: 0.7015, Value Loss: 0.0989, Total Loss: 0.8003, LR: 0.004989
2025-05-19 11:59:48,989 [INFO] Epoch 10/15 - Policy Loss: 0.7009, Value Loss: 0.0986, Total Loss: 0.7995, LR: 0.003361
2025-05-19 12:00:29,122 [INFO] Epoch 11/15 - Policy Loss: 0.7000, Value Loss: 0.0981, Total Loss: 0.7981, LR: 0.001711
2025-05-19 12:01:09,399 [INFO] Epoch 12/15 - Policy Loss: 0.6994, Value Loss: 0.0979, Total Loss: 0.7973, LR: 0.000061
2025-05-19 12:01:49,639 [INFO] Epoch 13/15 - Policy Loss: 0.6989, Value Loss: 0.0978, Total Loss: 0.7966, LR: 0.001689
2025-05-19 12:02:29,798 [INFO] Epoch 14/15 - Policy Loss: 0.6982, Value Loss: 0.0974, Total Loss: 0.7956, LR: 0.003339
2025-05-19 12:03:10,314 [INFO] Epoch 15/15 - Policy Loss: 0.6979, Value Loss: 0.0972, Total Loss: 0.7951, LR: 0.004989
2025-05-19 12:03:10,337 [INFO] 训练完成，总损失: 0.7951
2025-05-19 12:03:10,338 [INFO] 保存迭代 157 的模型
2025-05-19 12:03:11,652 [INFO] Model saved to ./models/best.pt
2025-05-19 12:03:12,565 [INFO] Model saved to ./models/iteration_157.pt
2025-05-19 12:03:12,565 [INFO] 所有训练迭代完成
2025-05-19 12:03:12,565 [INFO] 开始迭代 158/300
2025-05-19 12:03:12,565 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 12:16:26,270 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 12:16:26,271 [INFO] 保存训练样本
2025-05-19 12:16:30,957 [INFO] 使用 155648 个样本训练神经网络
2025-05-19 12:16:30,957 [INFO] Training with 155648 examples
2025-05-19 12:16:30,958 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-19 12:16:31,011 [INFO] 循环学习率周期大小: 456 步
2025-05-19 12:17:11,264 [INFO] Epoch 1/15 - Policy Loss: 0.7151, Value Loss: 0.1065, Total Loss: 0.8216, LR: 0.001689
2025-05-19 12:17:51,141 [INFO] Epoch 2/15 - Policy Loss: 0.7112, Value Loss: 0.1060, Total Loss: 0.8172, LR: 0.003339
2025-05-19 12:18:31,202 [INFO] Epoch 3/15 - Policy Loss: 0.7100, Value Loss: 0.1047, Total Loss: 0.8147, LR: 0.004989
2025-05-19 12:19:11,235 [INFO] Epoch 4/15 - Policy Loss: 0.7080, Value Loss: 0.1041, Total Loss: 0.8120, LR: 0.003361
2025-05-19 12:19:51,274 [INFO] Epoch 5/15 - Policy Loss: 0.7061, Value Loss: 0.1032, Total Loss: 0.8093, LR: 0.001711
2025-05-19 12:20:31,271 [INFO] Epoch 6/15 - Policy Loss: 0.7043, Value Loss: 0.1027, Total Loss: 0.8070, LR: 0.000061
2025-05-19 12:21:11,309 [INFO] Epoch 7/15 - Policy Loss: 0.7030, Value Loss: 0.1023, Total Loss: 0.8052, LR: 0.001689
2025-05-19 12:21:51,397 [INFO] Epoch 8/15 - Policy Loss: 0.7021, Value Loss: 0.1019, Total Loss: 0.8040, LR: 0.003339
2025-05-19 12:22:31,548 [INFO] Epoch 9/15 - Policy Loss: 0.7014, Value Loss: 0.1014, Total Loss: 0.8028, LR: 0.004989
2025-05-19 12:23:11,754 [INFO] Epoch 10/15 - Policy Loss: 0.7009, Value Loss: 0.1011, Total Loss: 0.8020, LR: 0.003361
2025-05-19 12:23:51,881 [INFO] Epoch 11/15 - Policy Loss: 0.7002, Value Loss: 0.1007, Total Loss: 0.8009, LR: 0.001711
2025-05-19 12:24:32,105 [INFO] Epoch 12/15 - Policy Loss: 0.6989, Value Loss: 0.1004, Total Loss: 0.7993, LR: 0.000061
2025-05-19 12:25:12,399 [INFO] Epoch 13/15 - Policy Loss: 0.6980, Value Loss: 0.1001, Total Loss: 0.7981, LR: 0.001689
2025-05-19 12:25:52,712 [INFO] Epoch 14/15 - Policy Loss: 0.6973, Value Loss: 0.0999, Total Loss: 0.7972, LR: 0.003339
2025-05-19 12:26:33,132 [INFO] Epoch 15/15 - Policy Loss: 0.6967, Value Loss: 0.0996, Total Loss: 0.7963, LR: 0.004989
2025-05-19 12:26:33,155 [INFO] 训练完成，总损失: 0.7963
2025-05-19 12:26:33,155 [INFO] 保存迭代 158 的模型
2025-05-19 12:26:34,510 [INFO] Model saved to ./models/best.pt
2025-05-19 12:26:35,249 [INFO] Model saved to ./models/iteration_158.pt
2025-05-19 12:26:35,249 [INFO] 所有训练迭代完成
2025-05-19 12:26:35,250 [INFO] 开始迭代 159/300
2025-05-19 12:26:35,250 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 12:39:11,796 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 12:39:11,797 [INFO] 保存训练样本
2025-05-19 12:39:15,851 [INFO] 使用 155904 个样本训练神经网络
2025-05-19 12:39:15,853 [INFO] Training with 155904 examples
2025-05-19 12:39:15,857 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-19 12:39:16,183 [INFO] 循环学习率周期大小: 456 步
2025-05-19 12:39:55,969 [INFO] Epoch 1/15 - Policy Loss: 0.7120, Value Loss: 0.0952, Total Loss: 0.8073, LR: 0.001689
2025-05-19 12:40:35,851 [INFO] Epoch 2/15 - Policy Loss: 0.7075, Value Loss: 0.0940, Total Loss: 0.8015, LR: 0.003339
2025-05-19 12:41:15,677 [INFO] Epoch 3/15 - Policy Loss: 0.7064, Value Loss: 0.0934, Total Loss: 0.7998, LR: 0.004989
2025-05-19 12:41:55,788 [INFO] Epoch 4/15 - Policy Loss: 0.7035, Value Loss: 0.0932, Total Loss: 0.7967, LR: 0.003361
2025-05-19 12:42:35,782 [INFO] Epoch 5/15 - Policy Loss: 0.7022, Value Loss: 0.0928, Total Loss: 0.7949, LR: 0.001711
2025-05-19 12:43:15,681 [INFO] Epoch 6/15 - Policy Loss: 0.7004, Value Loss: 0.0924, Total Loss: 0.7928, LR: 0.000061
2025-05-19 12:43:55,701 [INFO] Epoch 7/15 - Policy Loss: 0.6987, Value Loss: 0.0923, Total Loss: 0.7910, LR: 0.001689
2025-05-19 12:44:35,701 [INFO] Epoch 8/15 - Policy Loss: 0.6976, Value Loss: 0.0921, Total Loss: 0.7897, LR: 0.003339
2025-05-19 12:45:15,662 [INFO] Epoch 9/15 - Policy Loss: 0.6969, Value Loss: 0.0918, Total Loss: 0.7887, LR: 0.004989
2025-05-19 12:45:55,837 [INFO] Epoch 10/15 - Policy Loss: 0.6965, Value Loss: 0.0916, Total Loss: 0.7882, LR: 0.003361
2025-05-19 12:46:35,978 [INFO] Epoch 11/15 - Policy Loss: 0.6960, Value Loss: 0.0914, Total Loss: 0.7874, LR: 0.001711
2025-05-19 12:47:16,132 [INFO] Epoch 12/15 - Policy Loss: 0.6954, Value Loss: 0.0914, Total Loss: 0.7868, LR: 0.000061
2025-05-19 12:47:56,357 [INFO] Epoch 13/15 - Policy Loss: 0.6949, Value Loss: 0.0913, Total Loss: 0.7862, LR: 0.001689
2025-05-19 12:48:36,596 [INFO] Epoch 14/15 - Policy Loss: 0.6942, Value Loss: 0.0913, Total Loss: 0.7855, LR: 0.003339
2025-05-19 12:49:16,853 [INFO] Epoch 15/15 - Policy Loss: 0.6940, Value Loss: 0.0912, Total Loss: 0.7852, LR: 0.004989
2025-05-19 12:49:16,876 [INFO] 训练完成，总损失: 0.7852
2025-05-19 12:49:16,876 [INFO] 保存迭代 159 的模型
2025-05-19 12:49:18,205 [INFO] Model saved to ./models/best.pt
2025-05-19 12:49:19,141 [INFO] Model saved to ./models/iteration_159.pt
2025-05-19 12:49:19,142 [INFO] 所有训练迭代完成
2025-05-19 12:49:19,142 [INFO] 开始迭代 160/300
2025-05-19 12:49:19,142 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 13:02:09,689 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 13:02:09,690 [INFO] 保存训练样本
2025-05-19 13:02:13,739 [INFO] 使用 156096 个样本训练神经网络
2025-05-19 13:02:13,739 [INFO] Training with 156096 examples
2025-05-19 13:02:13,739 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-19 13:02:14,056 [INFO] 循环学习率周期大小: 456 步
2025-05-19 13:02:53,753 [INFO] Epoch 1/15 - Policy Loss: 0.7093, Value Loss: 0.1038, Total Loss: 0.8131, LR: 0.001689
2025-05-19 13:03:33,570 [INFO] Epoch 2/15 - Policy Loss: 0.7060, Value Loss: 0.1015, Total Loss: 0.8075, LR: 0.003339
2025-05-19 13:04:13,293 [INFO] Epoch 3/15 - Policy Loss: 0.7029, Value Loss: 0.1003, Total Loss: 0.8031, LR: 0.004989
2025-05-19 13:04:53,028 [INFO] Epoch 4/15 - Policy Loss: 0.7017, Value Loss: 0.0997, Total Loss: 0.8014, LR: 0.003361
2025-05-19 13:05:32,969 [INFO] Epoch 5/15 - Policy Loss: 0.6996, Value Loss: 0.0986, Total Loss: 0.7983, LR: 0.001711
2025-05-19 13:06:13,033 [INFO] Epoch 6/15 - Policy Loss: 0.6982, Value Loss: 0.0979, Total Loss: 0.7961, LR: 0.000061
2025-05-19 13:06:53,072 [INFO] Epoch 7/15 - Policy Loss: 0.6975, Value Loss: 0.0971, Total Loss: 0.7946, LR: 0.001689
2025-05-19 13:07:33,714 [INFO] Epoch 8/15 - Policy Loss: 0.6965, Value Loss: 0.0963, Total Loss: 0.7929, LR: 0.003339
2025-05-19 13:08:13,965 [INFO] Epoch 9/15 - Policy Loss: 0.6957, Value Loss: 0.0958, Total Loss: 0.7915, LR: 0.004989
2025-05-19 13:08:54,380 [INFO] Epoch 10/15 - Policy Loss: 0.6949, Value Loss: 0.0953, Total Loss: 0.7902, LR: 0.003361
2025-05-19 13:09:35,058 [INFO] Epoch 11/15 - Policy Loss: 0.6941, Value Loss: 0.0949, Total Loss: 0.7890, LR: 0.001711
2025-05-19 13:10:15,312 [INFO] Epoch 12/15 - Policy Loss: 0.6930, Value Loss: 0.0945, Total Loss: 0.7875, LR: 0.000061
2025-05-19 13:10:55,593 [INFO] Epoch 13/15 - Policy Loss: 0.6924, Value Loss: 0.0942, Total Loss: 0.7866, LR: 0.001689
2025-05-19 13:11:35,938 [INFO] Epoch 14/15 - Policy Loss: 0.6918, Value Loss: 0.0940, Total Loss: 0.7858, LR: 0.003339
2025-05-19 13:12:16,206 [INFO] Epoch 15/15 - Policy Loss: 0.6916, Value Loss: 0.0937, Total Loss: 0.7853, LR: 0.004989
2025-05-19 13:12:16,223 [INFO] 训练完成，总损失: 0.7853
2025-05-19 13:12:16,223 [INFO] 保存迭代 160 的模型
2025-05-19 13:12:17,482 [INFO] Model saved to ./models/best.pt
2025-05-19 13:12:18,149 [INFO] Model saved to ./models/iteration_160.pt
2025-05-19 13:12:18,149 [INFO] 所有训练迭代完成
2025-05-19 13:12:18,150 [INFO] 开始迭代 161/300
2025-05-19 13:12:18,150 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 13:24:14,405 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 13:24:14,405 [INFO] 保存训练样本
2025-05-19 13:24:19,683 [INFO] 使用 156352 个样本训练神经网络
2025-05-19 13:24:19,683 [INFO] Training with 156352 examples
2025-05-19 13:24:19,684 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-19 13:24:19,741 [INFO] 循环学习率周期大小: 456 步
2025-05-19 13:25:00,004 [INFO] Epoch 1/15 - Policy Loss: 0.7036, Value Loss: 0.0906, Total Loss: 0.7942, LR: 0.001689
2025-05-19 13:25:40,328 [INFO] Epoch 2/15 - Policy Loss: 0.7011, Value Loss: 0.0894, Total Loss: 0.7906, LR: 0.003339
2025-05-19 13:26:21,029 [INFO] Epoch 3/15 - Policy Loss: 0.6993, Value Loss: 0.0894, Total Loss: 0.7887, LR: 0.004989
2025-05-19 13:27:01,585 [INFO] Epoch 4/15 - Policy Loss: 0.6988, Value Loss: 0.0890, Total Loss: 0.7879, LR: 0.003361
2025-05-19 13:27:42,299 [INFO] Epoch 5/15 - Policy Loss: 0.6976, Value Loss: 0.0887, Total Loss: 0.7864, LR: 0.001711
2025-05-19 13:28:22,792 [INFO] Epoch 6/15 - Policy Loss: 0.6957, Value Loss: 0.0885, Total Loss: 0.7842, LR: 0.000061
2025-05-19 13:29:03,609 [INFO] Epoch 7/15 - Policy Loss: 0.6939, Value Loss: 0.0882, Total Loss: 0.7821, LR: 0.001689
2025-05-19 13:29:44,199 [INFO] Epoch 8/15 - Policy Loss: 0.6935, Value Loss: 0.0882, Total Loss: 0.7817, LR: 0.003339
2025-05-19 13:30:24,850 [INFO] Epoch 9/15 - Policy Loss: 0.6935, Value Loss: 0.0886, Total Loss: 0.7821, LR: 0.004989
2025-05-19 13:31:05,540 [INFO] Epoch 10/15 - Policy Loss: 0.6940, Value Loss: 0.0890, Total Loss: 0.7830, LR: 0.003361
2025-05-19 13:31:46,285 [INFO] Epoch 11/15 - Policy Loss: 0.6939, Value Loss: 0.0890, Total Loss: 0.7829, LR: 0.001711
2025-05-19 13:32:26,991 [INFO] Epoch 12/15 - Policy Loss: 0.6930, Value Loss: 0.0890, Total Loss: 0.7819, LR: 0.000061
2025-05-19 13:33:07,913 [INFO] Epoch 13/15 - Policy Loss: 0.6923, Value Loss: 0.0887, Total Loss: 0.7811, LR: 0.001689
2025-05-19 13:33:48,790 [INFO] Epoch 14/15 - Policy Loss: 0.6919, Value Loss: 0.0885, Total Loss: 0.7804, LR: 0.003339
2025-05-19 13:34:29,530 [INFO] Epoch 15/15 - Policy Loss: 0.6918, Value Loss: 0.0883, Total Loss: 0.7802, LR: 0.004989
2025-05-19 13:34:29,547 [INFO] 训练完成，总损失: 0.7802
2025-05-19 13:34:29,548 [INFO] 保存迭代 161 的模型
2025-05-19 13:34:30,814 [INFO] Model saved to ./models/best.pt
2025-05-19 13:34:31,515 [INFO] Model saved to ./models/iteration_161.pt
2025-05-19 13:34:31,515 [INFO] 所有训练迭代完成
2025-05-19 13:34:31,515 [INFO] 开始迭代 162/300
2025-05-19 13:34:31,515 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 13:48:23,416 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 13:48:23,417 [INFO] 保存训练样本
2025-05-19 13:48:27,916 [INFO] 使用 156560 个样本训练神经网络
2025-05-19 13:48:27,916 [INFO] Training with 156560 examples
2025-05-19 13:48:27,917 [INFO] 总训练步数: 2280, 每轮次批次数: 152
2025-05-19 13:48:27,963 [INFO] 循环学习率周期大小: 456 步
2025-05-19 13:49:08,300 [INFO] Epoch 1/15 - Policy Loss: 0.7102, Value Loss: 0.0914, Total Loss: 0.8016, LR: 0.001689
2025-05-19 13:49:48,775 [INFO] Epoch 2/15 - Policy Loss: 0.7073, Value Loss: 0.0898, Total Loss: 0.7971, LR: 0.003339
2025-05-19 13:50:29,208 [INFO] Epoch 3/15 - Policy Loss: 0.7047, Value Loss: 0.0912, Total Loss: 0.7959, LR: 0.004989
2025-05-19 13:51:09,886 [INFO] Epoch 4/15 - Policy Loss: 0.7029, Value Loss: 0.0915, Total Loss: 0.7944, LR: 0.003361
2025-05-19 13:51:50,605 [INFO] Epoch 5/15 - Policy Loss: 0.7017, Value Loss: 0.0913, Total Loss: 0.7929, LR: 0.001711
2025-05-19 13:52:31,195 [INFO] Epoch 6/15 - Policy Loss: 0.6998, Value Loss: 0.0912, Total Loss: 0.7910, LR: 0.000061
2025-05-19 13:53:11,939 [INFO] Epoch 7/15 - Policy Loss: 0.6975, Value Loss: 0.0906, Total Loss: 0.7881, LR: 0.001689
2025-05-19 13:53:52,738 [INFO] Epoch 8/15 - Policy Loss: 0.6962, Value Loss: 0.0903, Total Loss: 0.7864, LR: 0.003339
2025-05-19 13:54:33,477 [INFO] Epoch 9/15 - Policy Loss: 0.6957, Value Loss: 0.0900, Total Loss: 0.7857, LR: 0.004989
2025-05-19 13:55:14,340 [INFO] Epoch 10/15 - Policy Loss: 0.6949, Value Loss: 0.0899, Total Loss: 0.7849, LR: 0.003361
2025-05-19 13:55:55,105 [INFO] Epoch 11/15 - Policy Loss: 0.6941, Value Loss: 0.0894, Total Loss: 0.7835, LR: 0.001711
2025-05-19 13:56:35,965 [INFO] Epoch 12/15 - Policy Loss: 0.6933, Value Loss: 0.0892, Total Loss: 0.7825, LR: 0.000061
2025-05-19 13:57:16,852 [INFO] Epoch 13/15 - Policy Loss: 0.6925, Value Loss: 0.0887, Total Loss: 0.7812, LR: 0.001689
2025-05-19 13:57:57,761 [INFO] Epoch 14/15 - Policy Loss: 0.6914, Value Loss: 0.0886, Total Loss: 0.7801, LR: 0.003339
2025-05-19 13:58:38,722 [INFO] Epoch 15/15 - Policy Loss: 0.6911, Value Loss: 0.0886, Total Loss: 0.7797, LR: 0.004989
2025-05-19 13:58:38,748 [INFO] 训练完成，总损失: 0.7797
2025-05-19 13:58:38,749 [INFO] 保存迭代 162 的模型
2025-05-19 13:58:40,281 [INFO] Model saved to ./models/best.pt
2025-05-19 13:58:41,157 [INFO] Model saved to ./models/iteration_162.pt
2025-05-19 13:58:41,158 [INFO] 所有训练迭代完成
2025-05-19 13:58:41,158 [INFO] 开始迭代 163/300
2025-05-19 13:58:41,158 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 14:12:27,698 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 14:12:27,699 [INFO] 保存训练样本
2025-05-19 14:12:32,143 [INFO] 使用 157960 个样本训练神经网络
2025-05-19 14:12:32,143 [INFO] Training with 157960 examples
2025-05-19 14:12:32,144 [INFO] 总训练步数: 2310, 每轮次批次数: 154
2025-05-19 14:12:32,485 [INFO] 循环学习率周期大小: 462 步
2025-05-19 14:13:13,365 [INFO] Epoch 1/15 - Policy Loss: 0.7040, Value Loss: 0.0975, Total Loss: 0.8014, LR: 0.001689
2025-05-19 14:13:54,574 [INFO] Epoch 2/15 - Policy Loss: 0.7023, Value Loss: 0.0963, Total Loss: 0.7985, LR: 0.003339
2025-05-19 14:14:35,659 [INFO] Epoch 3/15 - Policy Loss: 0.7008, Value Loss: 0.0961, Total Loss: 0.7970, LR: 0.004989
2025-05-19 14:15:16,580 [INFO] Epoch 4/15 - Policy Loss: 0.6984, Value Loss: 0.0958, Total Loss: 0.7942, LR: 0.003361
2025-05-19 14:15:57,502 [INFO] Epoch 5/15 - Policy Loss: 0.6963, Value Loss: 0.0946, Total Loss: 0.7910, LR: 0.001711
2025-05-19 14:16:38,369 [INFO] Epoch 6/15 - Policy Loss: 0.6944, Value Loss: 0.0938, Total Loss: 0.7881, LR: 0.000061
2025-05-19 14:17:19,574 [INFO] Epoch 7/15 - Policy Loss: 0.6932, Value Loss: 0.0933, Total Loss: 0.7865, LR: 0.001689
2025-05-19 14:18:00,835 [INFO] Epoch 8/15 - Policy Loss: 0.6922, Value Loss: 0.0928, Total Loss: 0.7850, LR: 0.003339
2025-05-19 14:18:42,133 [INFO] Epoch 9/15 - Policy Loss: 0.6909, Value Loss: 0.0923, Total Loss: 0.7832, LR: 0.004989
2025-05-19 14:19:23,261 [INFO] Epoch 10/15 - Policy Loss: 0.6907, Value Loss: 0.0921, Total Loss: 0.7829, LR: 0.003361
2025-05-19 14:20:04,425 [INFO] Epoch 11/15 - Policy Loss: 0.6907, Value Loss: 0.0920, Total Loss: 0.7827, LR: 0.001711
2025-05-19 14:20:45,392 [INFO] Epoch 12/15 - Policy Loss: 0.6899, Value Loss: 0.0917, Total Loss: 0.7816, LR: 0.000061
2025-05-19 14:21:26,970 [INFO] Epoch 13/15 - Policy Loss: 0.6892, Value Loss: 0.0915, Total Loss: 0.7807, LR: 0.001689
2025-05-19 14:22:09,141 [INFO] Epoch 14/15 - Policy Loss: 0.6887, Value Loss: 0.0914, Total Loss: 0.7800, LR: 0.003339
2025-05-19 14:22:50,708 [INFO] Epoch 15/15 - Policy Loss: 0.6885, Value Loss: 0.0913, Total Loss: 0.7798, LR: 0.004989
2025-05-19 14:22:50,734 [INFO] 训练完成，总损失: 0.7798
2025-05-19 14:22:50,734 [INFO] 保存迭代 163 的模型
2025-05-19 14:22:52,198 [INFO] Model saved to ./models/best.pt
2025-05-19 14:22:53,405 [INFO] Model saved to ./models/iteration_163.pt
2025-05-19 14:22:53,405 [INFO] 所有训练迭代完成
2025-05-19 14:22:53,405 [INFO] 开始迭代 164/300
2025-05-19 14:22:53,405 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 14:37:30,506 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 14:37:30,506 [INFO] 保存训练样本
2025-05-19 14:37:36,136 [INFO] 使用 159264 个样本训练神经网络
2025-05-19 14:37:36,136 [INFO] Training with 159264 examples
2025-05-19 14:37:36,137 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-19 14:37:36,791 [INFO] 循环学习率周期大小: 465 步
2025-05-19 14:38:18,369 [INFO] Epoch 1/15 - Policy Loss: 0.7126, Value Loss: 0.1034, Total Loss: 0.8161, LR: 0.001689
2025-05-19 14:38:59,909 [INFO] Epoch 2/15 - Policy Loss: 0.7067, Value Loss: 0.1019, Total Loss: 0.8086, LR: 0.003339
2025-05-19 14:39:41,367 [INFO] Epoch 3/15 - Policy Loss: 0.7028, Value Loss: 0.1013, Total Loss: 0.8042, LR: 0.004989
2025-05-19 14:40:22,814 [INFO] Epoch 4/15 - Policy Loss: 0.6995, Value Loss: 0.1009, Total Loss: 0.8005, LR: 0.003361
2025-05-19 14:41:04,122 [INFO] Epoch 5/15 - Policy Loss: 0.6966, Value Loss: 0.0998, Total Loss: 0.7964, LR: 0.001711
2025-05-19 14:41:45,536 [INFO] Epoch 6/15 - Policy Loss: 0.6948, Value Loss: 0.0992, Total Loss: 0.7940, LR: 0.000061
2025-05-19 14:42:26,975 [INFO] Epoch 7/15 - Policy Loss: 0.6929, Value Loss: 0.0984, Total Loss: 0.7913, LR: 0.001689
2025-05-19 14:43:08,702 [INFO] Epoch 8/15 - Policy Loss: 0.6915, Value Loss: 0.0979, Total Loss: 0.7894, LR: 0.003339
2025-05-19 14:43:50,380 [INFO] Epoch 9/15 - Policy Loss: 0.6908, Value Loss: 0.0973, Total Loss: 0.7880, LR: 0.004989
2025-05-19 14:44:32,084 [INFO] Epoch 10/15 - Policy Loss: 0.6900, Value Loss: 0.0969, Total Loss: 0.7869, LR: 0.003361
2025-05-19 14:45:14,394 [INFO] Epoch 11/15 - Policy Loss: 0.6894, Value Loss: 0.0966, Total Loss: 0.7860, LR: 0.001711
2025-05-19 14:45:56,337 [INFO] Epoch 12/15 - Policy Loss: 0.6884, Value Loss: 0.0961, Total Loss: 0.7845, LR: 0.000061
2025-05-19 14:46:38,271 [INFO] Epoch 13/15 - Policy Loss: 0.6874, Value Loss: 0.0958, Total Loss: 0.7832, LR: 0.001689
2025-05-19 14:47:20,255 [INFO] Epoch 14/15 - Policy Loss: 0.6866, Value Loss: 0.0955, Total Loss: 0.7821, LR: 0.003339
2025-05-19 14:48:02,260 [INFO] Epoch 15/15 - Policy Loss: 0.6861, Value Loss: 0.0952, Total Loss: 0.7813, LR: 0.004989
2025-05-19 14:48:02,288 [INFO] 训练完成，总损失: 0.7813
2025-05-19 14:48:02,288 [INFO] 保存迭代 164 的模型
2025-05-19 14:48:04,233 [INFO] Model saved to ./models/best.pt
2025-05-19 14:48:05,661 [INFO] Model saved to ./models/iteration_164.pt
2025-05-19 14:48:05,662 [INFO] 所有训练迭代完成
2025-05-19 14:48:05,662 [INFO] 开始迭代 165/300
2025-05-19 14:48:05,662 [INFO] 使用 8 个进程进行并行自我对弈
2025-05-19 15:00:22,332 [INFO] 移除最早的训练样本，保持历史长度为 20
2025-05-19 15:00:22,332 [INFO] 保存训练样本
2025-05-19 15:00:27,033 [INFO] 使用 158792 个样本训练神经网络
2025-05-19 15:00:27,033 [INFO] Training with 158792 examples
2025-05-19 15:00:27,033 [INFO] 总训练步数: 2325, 每轮次批次数: 155
2025-05-19 15:00:27,087 [INFO] 循环学习率周期大小: 465 步
2025-05-19 15:01:08,526 [INFO] Epoch 1/15 - Policy Loss: 0.7037, Value Loss: 0.0947, Total Loss: 0.7984, LR: 0.001689
2025-05-19 15:01:50,033 [INFO] Epoch 2/15 - Policy Loss: 0.6981, Value Loss: 0.0932, Total Loss: 0.7914, LR: 0.003339
2025-05-19 15:02:31,763 [INFO] Epoch 3/15 - Policy Loss: 0.6960, Value Loss: 0.0912, Total Loss: 0.7872, LR: 0.004989
2025-05-19 15:03:13,199 [INFO] Epoch 4/15 - Policy Loss: 0.6946, Value Loss: 0.0903, Total Loss: 0.7849, LR: 0.003361
2025-05-19 15:03:54,483 [INFO] Epoch 5/15 - Policy Loss: 0.6926, Value Loss: 0.0890, Total Loss: 0.7817, LR: 0.001711
2025-05-19 15:04:36,195 [INFO] Epoch 6/15 - Policy Loss: 0.6907, Value Loss: 0.0886, Total Loss: 0.7794, LR: 0.000061
2025-05-19 15:05:17,611 [INFO] Epoch 7/15 - Policy Loss: 0.6892, Value Loss: 0.0881, Total Loss: 0.7772, LR: 0.001689
2025-05-19 15:05:59,043 [INFO] Epoch 8/15 - Policy Loss: 0.6882, Value Loss: 0.0878, Total Loss: 0.7761, LR: 0.003339
2025-05-19 15:06:40,519 [INFO] Epoch 9/15 - Policy Loss: 0.6877, Value Loss: 0.0875, Total Loss: 0.7753, LR: 0.004989
2025-05-19 15:07:22,209 [INFO] Epoch 10/15 - Policy Loss: 0.6873, Value Loss: 0.0872, Total Loss: 0.7745, LR: 0.003361
2025-05-19 15:08:04,014 [INFO] Epoch 11/15 - Policy Loss: 0.6870, Value Loss: 0.0868, Total Loss: 0.7737, LR: 0.001711
2025-05-19 15:08:45,783 [INFO] Epoch 12/15 - Policy Loss: 0.6864, Value Loss: 0.0866, Total Loss: 0.7730, LR: 0.000061
2025-05-19 15:09:27,604 [INFO] Epoch 13/15 - Policy Loss: 0.6858, Value Loss: 0.0865, Total Loss: 0.7722, LR: 0.001689
2025-05-19 15:10:09,381 [INFO] Epoch 14/15 - Policy Loss: 0.6855, Value Loss: 0.0863, Total Loss: 0.7719, LR: 0.003339
2025-05-19 15:10:51,231 [INFO] Epoch 15/15 - Policy Loss: 0.6850, Value Loss: 0.0862, Total Loss: 0.7711, LR: 0.004989
2025-05-19 15:10:51,252 [INFO] 训练完成，总损失: 0.7711
2025-05-19 15:10:51,252 [INFO] 保存迭代 165 的模型
2025-05-19 15:10:53,202 [INFO] Model saved to ./models/best.pt
